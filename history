 3/1:
cool_number = 56
print(int(cool_number += 67))
 4/1:
s = "Learning Python is so much fun!"

s.split()
# Sample output: ['Learning', 'Python', 'is', 'so', 'much', 'fun!']
 4/2:
s = "Learning Python is so much fun!"

s.split()
# Sample output: ['Learning', 'Python', 'is', 'so', 'much', 'fun!']
 4/3:
s = "Learning Python is so much fun!"

s.split()
# Sample output: ['Learning', 'Python', 'is', 'so', 'much', 'fun!']
 4/4:
thing = "light"
speed = 299792458  # m/s

print(f"The speed of {thing} is {speed:2e} m/s.")
 4/5:
l = [10, [3, 4], [5, [100, 200], [23, ["DATA301"], 27], 11], 1, 7]

l[2][1][2]
# Sample output: 'DATA301'
 4/6:
l = [10, [3, 4], [5, [100, 200], [23, ["DATA301"], 27], 11], 1, 7]

l[2][2][2]
# Sample output: 'DATA301'
 4/7:
l = [10, [3, 4], [5, [100, 200], [23, ["DATA301"], 27], 11], 1, 7]

l[2][2][2]
# Sample output: 'DATA301'
 4/8:
l = [10, [3, 4], [5, [100, 200], [23, ["DATA301"], 27], 11], 1, 7]

l[2][2][1]
# Sample output: 'DATA301'
 4/9:
d['outer'][3]['inner'][3]['inner_inner'][3]
# Sample output: 'DATA301'
4/10:
d['outer'][3]['inner'][3]['inner_inner'][3]
# Sample output: 'DATA301'
4/11:
d = {
    "outer": [
        1,
        2,
        3,
        {
            "inner": [
                "this",
                "is",
                "inception",
                {"inner_inner": ["a", "b", "c", "DATA301", 1, 2, 3]},
            ]
        },
    ]
}
4/12:
d['outer'][3]['inner'][3]['inner_inner'][3]
# Sample output: 'DATA301'
4/13:
d['outer'][3]['inner'][3]['inner_inner'][2]
# Sample output: 'DATA301'
4/14:
d['outer'][3]['inner'][3]['inner_inner'][1]
# Sample output: 'DATA301'
4/15:
d['outer'][3]['inner'][3]['inner_inner'][3]
# Sample output: 'DATA301'
4/16:
d['outer'][2]['inner'][3]['inner_inner'][3]
# Sample output: 'DATA301'
4/17:
d['outer'][3]['inner'][3]['inner_inner'][3]
# Sample output: 'DATA301'
4/18:
language = "java"

if language == "java:
print("I love coffee!")
elif language == "python"
print("Are you a snake?")
else:
    print(f"What is {language}?")
# If language is "Java", the output would be "I love coffee!"
# If language is "PYTHON", the output would be "Are you a snake?"
# If language is anything else, the output would be anything this language is, for example, if language is "R", output is "R".
# You don't need to display the results of your test for EACH condition, just make sure your code works like this.
4/19:
language = "java"

if language == "java":
print("I love coffee!")
elif language == "python"
print("Are you a snake?")
else:
    print(f"What is {language}?")
# If language is "Java", the output would be "I love coffee!"
# If language is "PYTHON", the output would be "Are you a snake?"
# If language is anything else, the output would be anything this language is, for example, if language is "R", output is "R".
# You don't need to display the results of your test for EACH condition, just make sure your code works like this.
4/20:
language = "java"

if language == "java":
   print("I love coffee!")
elif language == "python"
print("Are you a snake?")
else:
    print(f"What is {language}?")
# If language is "Java", the output would be "I love coffee!"
# If language is "PYTHON", the output would be "Are you a snake?"
# If language is anything else, the output would be anything this language is, for example, if language is "R", output is "R".
# You don't need to display the results of your test for EACH condition, just make sure your code works like this.
4/21:
language = "java"

if language == "java":
   print("I love coffee!")
elif language == "python":
   print("Are you a snake?")
else:
   print(f"What is {language}?")
# If language is "Java", the output would be "I love coffee!"
# If language is "PYTHON", the output would be "Are you a snake?"
# If language is anything else, the output would be anything this language is, for example, if language is "R", output is "R".
# You don't need to display the results of your test for EACH condition, just make sure your code works like this.
4/22:
language = "java"

if language == "java":
   print("I love coffee!")
elif language == "python":
   print("Are you a snake?")
else:
   print(f"What is {language}?")
# If language is "Java", the output would be "I love coffee!"
# If language is "PYTHON", the output would be "Are you a snake?"
# If language is anything else, the output would be anything this language is, for example, if language is "R", output is "R".
# You don't need to display the results of your test for EACH condition, just make sure your code works like this.
4/23:
language = "python"

if language == "java":
   print("I love coffee!")
elif language == "python":
   print("Are you a snake?")
else:
   print(f"What is {language}?")
# If language is "Java", the output would be "I love coffee!"
# If language is "PYTHON", the output would be "Are you a snake?"
# If language is anything else, the output would be anything this language is, for example, if language is "R", output is "R".
# You don't need to display the results of your test for EACH condition, just make sure your code works like this.
4/24:
language = "games"

if language == "java":
   print("I love coffee!")
elif language == "python":
   print("Are you a snake?")
else:
   print(f"What is {language}?")
# If language is "Java", the output would be "I love coffee!"
# If language is "PYTHON", the output would be "Are you a snake?"
# If language is anything else, the output would be anything this language is, for example, if language is "R", output is "R".
# You don't need to display the results of your test for EACH condition, just make sure your code works like this.
4/25:
language = "java"

if language == "java":
   print("I love coffee!")
elif language == "python":
   print("Are you a snake?")
else:
   print(f"What is {language}?")
# If language is "Java", the output would be "I love coffee!"
# If language is "PYTHON", the output would be "Are you a snake?"
# If language is anything else, the output would be anything this language is, for example, if language is "R", output is "R".
# You don't need to display the results of your test for EACH condition, just make sure your code works like this.
4/26: import numpy as np
4/27:
print(np.full(10 ,"NaN")
# Sample output: array([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan])
4/28:
print(np.full(10 ,"NaN"))
# Sample output: array([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan])
4/29:
 array == print(np.full(10 ,"NaN"))
# Sample output: array([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan])
4/30:
print(np.full(10 ,"NaN"))
# Sample output: array([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan])
4/31:
array(np.full(10 ,"NaN"))
# Sample output: array([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan])
4/32:
 array = array((10 ,"NaN"))
    print array
# Sample output: array([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan])
4/33:
 array = array((10 ,"NaN"))
    print(array)
# Sample output: array([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan])
4/34:
 array = array((10 ,"NaN"))
 print(array)
# Sample output: array([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan])
4/35:
 import array
array = array((10 ,"NaN"))
 print(array)
# Sample output: array([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan])
4/36:
import array
array = Array((10 ,"NaN"))
 print(array)
# Sample output: array([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan])
4/37:
import array
array = array((10 ,"NaN"))
 print(array)
# Sample output: array([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan])
 7/1:
info = {'name' : Jeff Bezoos',
        'age' : 57,
        'salary' : 6746563247}
 7/2:
info = {'name' : 'Jeff Bezoos',
        'age' : 57,
        'salary' : 6746563247}
 7/3:
info = {'name' : 'Jeff Bezoos',
        'age' : 57,
        'salary' : 6746563247}
print(info)
 7/4:
info = {'name' : ['Jeff Bezoos' , 'Elon musk']
        'age' : 57,
        'salary' : 6746563247}
 7/5:
info = {'name' : ,['Jeff Bezoos' , 'Elon musk']
        'age' : 57,
        'salary' : 6746563247}
 7/6:
info = {'name' : ['Jeff Bezoos' , 'Elon musk']
        'age' : 57,
        'salary' : 6746563247}
 7/7:
info = {'name' : 'Jeff Bezoos' , 'Elon musk'
        'age' : 57,
        'salary' : 6746563247}
 7/8:
info = {'name' : 'Jeff Bezoos' , 'Elon musk'
        'age' : 57,
        'salary' : 6746563247}
 7/9:
info = {'name' : 'Jeff Bezoos' , 'Elon musk'
        'age' : 57,
        'salary' : 6746563247}
print(info)
7/10:
info = {'name' : ['Jeff Bezoos' , 'Elon musk']
        'age' : 57,
        'salary' : 6746563247}
print(info)
7/11:
info = {'name' : 'Jeff Bezoos , Elon musk'
        'age' : 57,
        'salary' : 6746563247}
print(info)
7/12:
info = {'name' : 'Jeff Bezoos , Elon musk' ,
        'age' : 57,
        'salary' : 6746563247}
print(info)
7/13:
info = {'name' : '['Jeff Bezos' , Elon musk ,' ,
        'age' : 57,
        'salary' : 6746563247}
print(info)
7/14:
info = {'name' : '[Jeff Bezos, Elon musk ,' ,
        'age' : 57,
        'salary' : 6746563247}
print(info)
12/1:
info = {'name' : ('Jeff Bezos', 'Elon musk ') ,
        'age' : 57,
        'salary' : 6746563247}
print(info)
12/2:
info = {'name' : ['Jeff Bezos', 'Elon musk '] ,
        'age' : 57,
        'salary' : 6746563247}
print(info)
12/3:
info = {'name' : ['Jeff Bezos', 'Elon musk ' , 'Mukesh Ambani'] ,
        'age' : 57,
        'salary' : 6746563247}
print(info)
12/4:
info = {'name' : ['Jeff Bezos', 'Elon musk ' , 'Mukesh Ambani'] ,
        'age' : [57,24,40]
        'salary' : [30000000.0, 200000.0, 900000.0]
print(info)
12/5:
info = {'name' : ['Jeff Bezos', 'Elon musk ' , 'Mukesh Ambani'] ,
        'age' : [57,24,40]
        'salary' : [30000000.0, 200000.0, 900000.0]}
print(info)
12/6:
info = {'name' : ['Jeff Bezos', 'Elon musk ' , 'Mukesh Ambani'] ,
        'age' : [57,24,40]
        'salary' : [30000000.0, 200000.0, 900000.0]}
print(info)
12/7:
info = {'name' : ['Jeff Bezos', 'Elon musk ' , 'Mukesh Ambani'] ,
        'age' : [57,24,40],
        'salary' : [30000000.0, 200000.0, 900000.0]}
print(info)
13/1:
# Usually all the import statements are at the top of the file

import pandas as pd
import seaborn as sns
import numpy as np
import os
import matplotlib.pyplot as plt
13/2:
import panadas as pd
pd.read.csv('/Users/poojalal/Desktop/DATA301/lab04-DARTH-LAL/data/pokemon.csv')
13/3:
import pandas as pd
pd.read.csv('/Users/poojalal/Desktop/DATA301/lab04-DARTH-LAL/data/pokemon.csv')
13/4:
import pandas as pd
df = pd.read.csv('/Users/poojalal/Desktop/DATA301/lab04-DARTH-LAL/data/pokemon.csv')
df
13/5:
# Usually all the import statements are at the top of the file

import pandas as pd
import seaborn as sns
import numpy as np
import os
import matplotlib.pyplot as plt
13/6:
import pandas as pd
df = pd.read.csv('/Users/poojalal/Desktop/DATA301/lab04-DARTH-LAL/data/pokemon.csv')
df
13/7:
import pandas as pd
df = pd.read_csv('/Users/poojalal/Desktop/DATA301/lab04-DARTH-LAL/data/pokemon.csv')
df
13/8: df.count()
13/9:
df2 = df['Generation']
df2
13/10:
df2 = df['Generation']
df2.head()
13/11:
df2 = df['Generation']
df2
13/12:
df.count()
df.head()
13/13: df.count()
13/14:
df2 = df["Generation"]
df2
13/15:
df2 = df["Generation"]
df2.head()
13/16:
df2 = df[["Generation"]]
df2.head()
13/17:
df2 = df[["Generation"]]
df2.
13/18:
df2 = df[["Generation"]]
df2
13/19:
df2 = df[["Generation" == 1]]
df2
13/20:
df2 = df[["Generation"]== 1]
df2
13/21:
df2 = df[["Generation"] == 1]
df2
13/22:
df2 = df[df["Generation"] == 1]
df2
13/23: df[['HP ' , 'Attack' , 'Defense' , 'Speed']]
13/24: df[['HP' , 'Attack' , 'Defense' , 'Speed']]
13/25: df2[['HP' , 'Attack' , 'Defense' , 'Speed']]
14/1:
info = {'name' : 'Tim Cook' ,
        'age' : [59],
        'salary' :[3000000.0]}
14/2:
info = {'name' : 'Tim Cook' ,
        'age' : [59],
        'salary' :[3000000.0]}
14/3:
info = {'name' : 'Tim Cook' ,
        'age' : [59],
        'salary' :[3000000.0]}
14/4:
info = {'name' : 'Tim Cook' ,
        'age' : [59],
        'salary' :[3000000.0]}
info
14/5:
info = {'name' : 'Tim Cook' ,
        'age' : 59,
        'salary' :3000000.0}
info
14/6:
info = {'name' : ['Tim Cook', 'Elon musk ' , 'Mukesh Ambani' , 'Donald Trump' , 'Jay-Z'] ,
        'age' : [59, 24, 40, 20, 54],
        'salary' : [30000000.0, 200000.0, 900000.0, 450000.0, 20000.0]]}
14/7:
info = {'name' : ['Tim Cook', 'Elon musk ' , 'Mukesh Ambani' , 'Donald Trump' , 'Jay-Z'] ,
        'age' : [59, 24, 40, 20, 54],
        'salary' : [30000000.0, 200000.0, 900000.0, 450000.0, 20000.0]}
14/8:
info = {'name' : ['Tim Cook', 'Elon musk ' , 'Mukesh Ambani' , 'Donald Trump' , 'Jay-Z'] ,
        'age' : [59, 24, 40, 20, 54],
        'salary' : [30000000.0, 200000.0, 900000.0, 450000.0, 20000.0]}
14/9:
info2 = {'name' : ['Tim Cook', 'Elon musk ' , 'Mukesh Ambani' , 'Donald Trump' , 'Jay-Z'] ,
        'age' : [59, 24, 40, 20, 54],
        'salary' : [30000000.0, 200000.0, 900000.0, 450000.0, 20000.0]}
info2
14/10:
info2 = {'name' : ['Tim Cook', 'Elon musk ' , 'Mukesh Ambani' , 'Donald Trump' , 'Jay-Z'] ,'age' : [59, 24, 40, 20, 54],
         'salary' : [30000000.0, 200000.0, 900000.0, 450000.0, 20000.0]}
info2
14/11:
info2 = {'name' : ['Tim Cook', 'Elon musk ' , 'Jayz' , 'Donald Trump' , 'Mukesh Ambani'] ,'age' : [59, 24, 40, 20, 54],
         'salary' : [30000000.0, 200000.0, 900000.0, 450000.0, 20000.0]}
info2
14/12:
df = pd.DataFrame({"name": ["Tim Cook", "Elon musk", "Jay-Z"],
                   "age": ["59", "24", "40"],
                   "salary": [30000000.0, 200000.0, 900000.0]})
df
14/13:
import pandas as pd
df = pd.DataFrame({"name": ["Tim Cook", "Elon musk", "Jay-Z"],
                   "age": ["59", "24", "40"],
                   "salary": [30000000.0, 200000.0, 900000.0]})
df
14/14:
df = df.rename(columns={"name": "Celebraties",
                        "age": "Achievements ",
                       "salary" : "Networth"})
14/15:
df = df.rename(columns={"name": "Celebraties",
                        "age": "Achievements ",
                       "salary" : "Networth"})
df
11/1:
if name.lower == "name":
    print(f"Name {name} is more than 20 chars long")
    length_description = 'long'
11/2: name = 'Marie Antoinette'
11/3:
name = 'Marie Antoinette'
if len(name)>20:
    print(f"Name {name} is more than 20 chars long")
    length_description = 'long'
11/4:
name = 'Marie Antoinette sdnvkjadinifaifjiajiojlildsfjljlfjlasjlkfjal'
if len(name)>20:
    print(f"Name {name} is more than 20 chars long")
    length_description = 'long'
11/5:

if len(name)>20:
    print(f"Name {name} is more than 20 chars long")
    length_description = 'long'
elif len(name)>18:
    print(f"Name {name} is more than 18 chars long")
    length_description = 'semi long'
elif len(name)>15:
    print(f"Name {name} is more than 15 chars long")
    length_description = 'semi long'
elif len(name) > 9,10,11:
    print(f"Name {name} is 9, 10 or 11 chars long")
    length_description = 'semi short'
else:
    print(f"Name {name} is a short name")
    length_description = 'short'
11/6:
name = 'Marie Antoinette'

if len(name)>20:
    print(f"Name {name} is more than 20 chars long")
    length_description = 'long'
elif len(name)>18:
    print(f"Name {name} is more than 18 chars long")
    length_description = 'semi long'
elif len(name)>15:
    print(f"Name {name} is more than 15 chars long")
    length_description = 'semi long'
11/7:
name = 'Marie Antoinette11'

if len(name)>20:
    print(f"Name {name} is more than 20 chars long")
    length_description = 'long'
elif len(name)>18:
    print(f"Name {name} is more than 18 chars long")
    length_description = 'semi long'
elif len(name)>15:
    print(f"Name {name} is more than 15 chars long")
    length_description = 'semi long'
11/8:
name = 'Marie Antoinette111'

if len(name)>20:
    print(f"Name {name} is more than 20 chars long")
    length_description = 'long'
elif len(name)>18:
    print(f"Name {name} is more than 18 chars long")
    length_description = 'semi long'
elif len(name)>15:
    print(f"Name {name} is more than 15 chars long")
    length_description = 'semi long'
11/9: name = 'Marie Antoinette'
11/10:

if len(name)>20:
    print(f"Name {name} is more than 20 chars long")
    length_description = 'long'
elif len(name)>18:
    print(f"Name {name} is more than 18 chars long")
    length_description = 'semi long'
elif len(name)>15:
    print(f"Name {name} is more than 15 chars long")
    length_description = 'semi long'
elif len(name) > (9,10,11):
    print(f"Name {name} is 9, 10 or 11 chars long")
    length_description = 'semi short'
else:
    print(f"Name {name} is a short name")
    length_description = 'short'
11/11:
name = 'Ma'

if len(name)>20:
    print(f"Name {name} is more than 20 chars long")
    length_description = 'long'
elif len(name)>18:
    print(f"Name {name} is more than 18 chars long")
    length_description = 'semi long'
elif len(name)>15:
    print(f"Name {name} is more than 15 chars long")
    length_description = 'semi long'
elif len(name) >9,10,11):
    print(f"Name {name} is 9, 10 or 11 chars long")
    length_description = 'semi short'
else:
    print(f"Name {name} is a short name")
    length_description = 'short'
11/12:
name = 'Ma'

if len(name)>20:
    print(f"Name {name} is more than 20 chars long")
    length_description = 'long'
elif len(name)>18:
    print(f"Name {name} is more than 18 chars long")
    length_description = 'semi long'
elif len(name)>15:
    print(f"Name {name} is more than 15 chars long")
    length_description = 'semi long'
elif len(name) >(9,10,11):
    print(f"Name {name} is 9, 10 or 11 chars long")
    length_description = 'semi short'
else:
    print(f"Name {name} is a short name")
    length_description = 'short'
11/13:
name = 'Ma'

if len(name)>20:
    print(f"Name {name} is more than 20 chars long")
    length_description = 'long'
elif len(name)>18:
    print(f"Name {name} is more than 18 chars long")
    length_description = 'semi long'
elif len(name)>15:
    print(f"Name {name} is more than 15 chars long")
    length_description = 'semi long'
elif len(name) >  [9,10,11]:
    print(f"Name {name} is 9, 10 or 11 chars long")
    length_description = 'semi short'
else:
    print(f"Name {name} is a short name")
    length_description = 'short'
11/14:
name = 'Ma'

if len(name)>20:
    print(f"Name {name} is more than 20 chars long")
    length_description = 'long'
elif len(name)>18:
    print(f"Name {name} is more than 18 chars long")
    length_description = 'semi long'
elif len(name)>15:
    print(f"Name {name} is more than 15 chars long")
    length_description = 'semi long'
elif len(name) > (9,10,11):
    print(f"Name {name} is 9, 10 or 11 chars long")
    length_description = 'semi short'
else:
    print(f"Name {name} is a short name")
    length_description = 'short'
11/15:
name = 'Ma'

if len(name)>20:
    print(f"Name {name} is more than 20 chars long")
    length_description = 'long'
elif len(name)>18:
    print(f"Name {name} is more than 18 chars long")
    length_description = 'semi long'
elif len(name)>15:
    print(f"Name {name} is more than 15 chars long")
    length_description = 'semi long'
elif len(name) > 9:
    print(f"Name {name} is 9, 10 or 11 chars long")
    length_description = 'semi short'
else:
    print(f"Name {name} is a short name")
    length_description = 'short'
11/16:
name = 'Ma'

if len(name)>20:
    print(f"Name {name} is more than 20 chars long")
    length_description = 'long'
elif len(name)>18:
    print(f"Name {name} is more than 18 chars long")
    length_description = 'semi long'
elif len(name)>15:
    print(f"Name {name} is more than 15 chars long")
    length_description = 'semi long'
elif len(name) > 9 or 10 or 11:
    print(f"Name {name} is 9, 10 or 11 chars long")
    length_description = 'semi short'
else:
    print(f"Name {name} is a short name")
    length_description = 'short'
11/17:
name = 'Ma'

if len(name)>20:
    print(f"Name {name} is more than 20 chars long")
    length_description = 'long'
elif len(name)>18:
    print(f"Name {name} is more than 18 chars long")
    length_description = 'semi long'
elif len(name)>15:
    print(f"Name {name} is more than 15 chars long")
    length_description = 'semi long'
elif len(name) > (9 or 10 or 11):
    print(f"Name {name} is 9, 10 or 11 chars long")
    length_description = 'semi short'
else:
    print(f"Name {name} is a short name")
    length_description = 'short'
11/18:
name = 'Ma1111111'

if len(name)>20:
    print(f"Name {name} is more than 20 chars long")
    length_description = 'long'
elif len(name)>18:
    print(f"Name {name} is more than 18 chars long")
    length_description = 'semi long'
elif len(name)>15:
    print(f"Name {name} is more than 15 chars long")
    length_description = 'semi long'
elif len(name) > (9 or 10 or 11):
    print(f"Name {name} is 9, 10 or 11 chars long")
    length_description = 'semi short'
else:
    print(f"Name {name} is a short name")
    length_description = 'short'
11/19:
name = 'Ma11111111'

if len(name)>20:
    print(f"Name {name} is more than 20 chars long")
    length_description = 'long'
elif len(name)>18:
    print(f"Name {name} is more than 18 chars long")
    length_description = 'semi long'
elif len(name)>15:
    print(f"Name {name} is more than 15 chars long")
    length_description = 'semi long'
elif len(name) > (9 or 10 or 11):
    print(f"Name {name} is 9, 10 or 11 chars long")
    length_description = 'semi short'
else:
    print(f"Name {name} is a short name")
    length_description = 'short'
11/20:
name = 'Ma1111111111111'

if len(name)>20:
    print(f"Name {name} is more than 20 chars long")
    length_description = 'long'
elif len(name)>18:
    print(f"Name {name} is more than 18 chars long")
    length_description = 'semi long'
elif len(name)>15:
    print(f"Name {name} is more than 15 chars long")
    length_description = 'semi long'
elif len(name) > (9 or 10 or 11):
    print(f"Name {name} is 9, 10 or 11 chars long")
    length_description = 'semi short'
else:
    print(f"Name {name} is a short name")
    length_description = 'short'
11/21:
name = 'Ma11111111111111'

if len(name)>20:
    print(f"Name {name} is more than 20 chars long")
    length_description = 'long'
elif len(name)>18:
    print(f"Name {name} is more than 18 chars long")
    length_description = 'semi long'
elif len(name)>15:
    print(f"Name {name} is more than 15 chars long")
    length_description = 'semi long'
elif len(name) > (9 or 10 or 11):
    print(f"Name {name} is 9, 10 or 11 chars long")
    length_description = 'semi short'
else:
    print(f"Name {name} is a short name")
    length_description = 'short'
11/22:
name = 'Ma'

if len(name)>20:
    print(f"Name {name} is more than 20 chars long")
    length_description = 'long'
elif len(name)>18:
    print(f"Name {name} is more than 18 chars long")
    length_description = 'semi long'
elif len(name)>15:
    print(f"Name {name} is more than 15 chars long")
    length_description = 'semi long'
elif len(name) > (9 or 10 or 11):
    print(f"Name {name} is 9, 10 or 11 chars long")
    length_description = 'semi short'
else:
    print(f"Name {name} is a short name")
    length_description = 'short'
11/23:
### Your solution here

n = 10
for i in range(1,n):
    if n>1 :
        print("A" * n)
    else:
        print("A" * (n))
11/24:
### Your solution here

n = 10
for i in range(1,n):
    if 5 > i :
        print("A" * n)
    else:
        print("A" * (n1))
11/25:
### Your solution here

n = 10
for i in range(1,n):
    if 5 > i :
        print("A" * n)
    else:
        print("A1" * (n))
11/26:
n = 10
for i in range(1,n):
11/27:
n = 10
for i in range(1,n)
11/28:
n = 10
for i in range(1,n):
    print(i)
11/29:
### Your solution here

n = 10
for i in range(1,n):
    if (i/2) > 5 :
        print("A" * n)
    else:
        print("A1" * (n))
11/30:
### Your solution here

n = 10
for i in range(1,n):
    if (i/2) > 2 :
        print("A" * n)
    else:
        print("A1" * (n))
11/31:
name = 'Ma'

if len(name)>20:
    print(f"Name {name} is more than 20 chars long")
    length_description = 'long'
elif len(name)>18:
    print(f"Name {name} is more than 18 chars long")
    length_description = 'semi long'
elif len(name)>15:
    print(f"Name {name} is more than 15 chars long")
    length_description = 'semi long'
elif len(name) > (9 or 10 or 11):
    print(f"Name {name} is 9, 10 or 11 chars long")
    length_description = 'semi short'
else:
    print(f"Name {name} is a short name")
    length_description = 'short'
11/32:
### Your solution here

n = 10
for i in range(1,n):
    if i <= n//2 :
        print("A" * i)
    else:
        print("A1" * (n-i))
11/33:
### Your solution here

n = 10
for i in range(1,n):
    if i <= n//2 :
        print("A" * i)
    else:
        print("A" * (n-i))
11/34:
### Your solution here

n = 10
for i in range(1,n):
    if i < n//2 :
        print("A" * i)
    else:
        print("A" * (n-i))
11/35:
### Your solution here

n = 10
for i in range(1,n):
    if i < n/2 :
        print("A" * i)
    else:
        print("A" * (n-i))
11/36:
### Your solution here

n = 10
for i in range(1,n):
    if i < n / 2 :
        print("A" * i)
    else:
        print("A" * (n-i))
11/37:
### Your solution here

n = 10
for i in range(1,n):
    if i < n / 2 :
        print("A" * n)
    else:
        print("A1" * (n-i))
11/38:
### Your solution here

n = 10
for i in range(1,n):
    if i < n / 2 :
        print("A" * n)
    else:
        print("A" * (n-i))
11/39:
### Your solution here

n = 10
for i in range(1,n):
    if i < n / 2 :
        print("A" * i)
    else:
        print("A" * (n-i))
11/40:
name = 'Ma'

if len(name)>20:
    print(f"Name {name} is more than 20 chars long")
    length_description = 'long'
elif len(name)>18:
    print(f"Name {name} is more than 18 chars long")
    length_description = 'semi long'
elif len(name)>15:
    print(f"Name {name} is more than 15 chars long")
    length_description = 'semi long'
elif len(name) > (9 or 10 or 11):
    print(f"Name {name} is 9, 10 or 11 chars long")
    length_description = 'semi short'
else:
    print(f"Name {name} is a short name")
    length_description = 'short'
11/41:
data = [53,9,5,90,63,5,97,40,92,48,53,8,38,63,13,15,66,81,57,79,42,91,25,89,66,4,73,45,80,17]

data[7]
11/42:
data = [53,9,5,90,63,5,97,40,92,48,53,8,38,63,13,15,66,81,57,79,42,91,25,89,66,4,73,45,80,17]

data[7 , 12]
11/43:
data = [53,9,5,90,63,5,97,40,92,48,53,8,38,63,13,15,66,81,57,79,42,91,25,89,66,4,73,45,80,17]

data[7,12]
11/44:
data = [53,9,5,90,63,5,97,40,92,48,53,8,38,63,13,15,66,81,57,79,42,91,25,89,66,4,73,45,80,17]

data[7],[12]
11/45:
data = [53,9,5,90,63,5,97,40,92,48,53,8,38,63,13,15,66,81,57,79,42,91,25,89,66,4,73,45,80,17]

data[7],data[12]
11/46:
data = [53,9,5,90,63,5,97,40,92,48,53,8,38,63,13,15,66,81,57,79,42,91,25,89,66,4,73,45,80,17]

[data[7],data[12]]
11/47:
data = [53,9,5,90,63,5,97,40,92,48,53,8,38,63,13,15,66,81,57,79,42,91,25,89,66,4,73,45,80,17]

[data[7],data[12],data[20]
11/48:
data = [53,9,5,90,63,5,97,40,92,48,53,8,38,63,13,15,66,81,57,79,42,91,25,89,66,4,73,45,80,17]

[data[7],data[12],data[20]]
11/49:
data = [53,9,5,90,63,5,97,40,92,48,53,8,38,63,13,15,66,81,57,79,42,91,25,89,66,4,73,45,80,17]

[data[7],data[12],data[20],data[22]]
11/50:
data = [53,9,5,90,63,5,97,40,92,48,53,8,38,63,13,15,66,81,57,79,42,91,25,89,66,4,73,45,80,17]

[data[7],data[12],data[20],data[22],data[27]]
11/51:
data = [53,9,5,90,63,5,97,40,92,48,53,8,38,63,13,15,66,81,57,79,42,91,25,89,66,4,73,45,80,17]

print(f"The max is: {max(data})
print(f"The min is: {<YOUR_CODE_HERE>}")
print(f"The sum is: {<YOUR_CODE_HERE>}")
print(f"The count is: {<YOUR_CODE_HERE>}")
print(f"The mean is: {<YOUR_CODE_HERE>}")
11/52:
data = [53,9,5,90,63,5,97,40,92,48,53,8,38,63,13,15,66,81,57,79,42,91,25,89,66,4,73,45,80,17]

print(f"The max is: max(data)
print(f"The min is: {<YOUR_CODE_HERE>}")
print(f"The sum is: {<YOUR_CODE_HERE>}")
print(f"The count is: {<YOUR_CODE_HERE>}")
print(f"The mean is: {<YOUR_CODE_HERE>}")
11/53:
data = [53,9,5,90,63,5,97,40,92,48,53,8,38,63,13,15,66,81,57,79,42,91,25,89,66,4,73,45,80,17]

print(f"The max is: max(data))
print(f"The min is: {<YOUR_CODE_HERE>}")
print(f"The sum is: {<YOUR_CODE_HERE>}")
print(f"The count is: {<YOUR_CODE_HERE>}")
print(f"The mean is: {<YOUR_CODE_HERE>}")
11/54:
data = [53,9,5,90,63,5,97,40,92,48,53,8,38,63,13,15,66,81,57,79,42,91,25,89,66,4,73,45,80,17]

print(f"The max is:" max(data))
print(f"The min is: {<YOUR_CODE_HERE>}")
print(f"The sum is: {<YOUR_CODE_HERE>}")
print(f"The count is: {<YOUR_CODE_HERE>}")
print(f"The mean is: {<YOUR_CODE_HERE>}")
11/55:
data = [53,9,5,90,63,5,97,40,92,48,53,8,38,63,13,15,66,81,57,79,42,91,25,89,66,4,73,45,80,17]

print(f"The max is:" , max(data))
print(f"The min is: {<YOUR_CODE_HERE>}")
print(f"The sum is: {<YOUR_CODE_HERE>}")
print(f"The count is: {<YOUR_CODE_HERE>}")
print(f"The mean is: {<YOUR_CODE_HERE>}")
11/56:
data = [53,9,5,90,63,5,97,40,92,48,53,8,38,63,13,15,66,81,57,79,42,91,25,89,66,4,73,45,80,17]

print(f"The max is:" , max(data))
11/57:
data = [53,9,5,90,63,5,97,40,92,48,53,8,38,63,13,15,66,81,57,79,42,91,25,89,66,4,73,45,80,17]

print(f"The max is:" , max(data))
print(f"The min is: " , mmin(data))
11/58:
data = [53,9,5,90,63,5,97,40,92,48,53,8,38,63,13,15,66,81,57,79,42,91,25,89,66,4,73,45,80,17]

print(f"The max is:" , max(data))
print(f"The min is: " , min(data))
11/59:
data = [53,9,5,90,63,5,97,40,92,48,53,8,38,63,13,15,66,81,57,79,42,91,25,89,66,4,73,45,80,17]

print(f"The max is:" , max(data))
print(f"The min is: " ,min(data))
11/60:
data = [53,9,5,90,63,5,97,40,92,48,53,8,38,63,13,15,66,81,57,79,42,91,25,89,66,4,73,45,80,17]

print(f"The max is:" , max(data))
print(f"The min is: " ,min(data))
print(f"The sum is: " , sum(data))
11/61:
data = [53,9,5,90,63,5,97,40,92,48,53,8,38,63,13,15,66,81,57,79,42,91,25,89,66,4,73,45,80,17]

print(f"The max is:" , max(data))
print(f"The min is: " ,min(data))
print(f"The sum is: " , sum(data))
print(f"The count is: " , count(data))
11/62:
data = [53,9,5,90,63,5,97,40,92,48,53,8,38,63,13,15,66,81,57,79,42,91,25,89,66,4,73,45,80,17]

print(f"The max is:" , max(data))
print(f"The min is: " , min(data))
print(f"The sum is: " , sum(data))
print(f"The count is: " , data.count())
print(f"The mean is: {<YOUR_CODE_HERE>}")
11/63:
data = [53,9,5,90,63,5,97,40,92,48,53,8,38,63,13,15,66,81,57,79,42,91,25,89,66,4,73,45,80,17]

print(f"The max is:" , max(data))
print(f"The min is: " ,min(data))
print(f"The sum is: " , sum(data))
print(f"The count is: " , data.count())
11/64:
data = [53,9,5,90,63,5,97,40,92,48,53,8,38,63,13,15,66,81,57,79,42,91,25,89,66,4,73,45,80,17]

print(f"The max is:" , max(data))
print(f"The min is: " ,min(data))
print(f"The sum is: " , sum(data))
print(f"The count is: " , len(data))
11/65:
data = [53,9,5,90,63,5,97,40,92,48,53,8,38,63,13,15,66,81,57,79,42,91,25,89,66,4,73,45,80,17]

print(f"The max is:" , max(data))
print(f"The min is: " , min(data))
print(f"The sum is: " , sum(data))
print(f"The count is: " , len(data))
print(f"The mean is: " , Average(data))
11/66:
data = [53,9,5,90,63,5,97,40,92,48,53,8,38,63,13,15,66,81,57,79,42,91,25,89,66,4,73,45,80,17]

print(f"The max is:" , max(data))
print(f"The min is: " , min(data))
print(f"The sum is: " , sum(data))
print(f"The count is: " , len(data))
print(f"The mean is: " , mean(data))
11/67:
data = [53,9,5,90,63,5,97,40,92,48,53,8,38,63,13,15,66,81,57,79,42,91,25,89,66,4,73,45,80,17]

sum = sum(data)
mean = sum/len(data)

print(f"The max is:" , max(data))
print(f"The min is: " , min(data))
print(f"The sum is: " , sum(data))
print(f"The count is: " , len(data))
print(f"The mean is: " , mean)
11/68:
data = [53,9,5,90,63,5,97,40,92,48,53,8,38,63,13,15,66,81,57,79,42,91,25,89,66,4,73,45,80,17]

tsum = tsum(data)
mean = tsum/len(data)

print(f"The max is:" , max(data))
print(f"The min is: " , min(data))
print(f"The sum is: " , sum(data))
print(f"The count is: " , len(data))
print(f"The mean is: " , mean)
11/69:
data = [53,9,5,90,63,5,97,40,92,48,53,8,38,63,13,15,66,81,57,79,42,91,25,89,66,4,73,45,80,17]

tsum = sum(data)
mean = tsum/len(data)

print(f"The max is:" , max(data))
print(f"The min is: " , min(data))
print(f"The sum is: " , sum(data))
print(f"The count is: " , len(data))
print(f"The mean is: " , mean)
11/70:
data = [53,9,5,90,63,5,97,40,92,48,53,8,38,63,13,15,66,81,57,79,42,91,25,89,66,4,73,45,80,17]

tsum = sum(data)
mean = tsum/len(data)

print(f"The max is:" , max(data))
print(f"The min is: " , min(data))
print(f"The sum is: " , sum(data))
print(f"The count is: " , len(data))
print(f"The mean is: " , mean)
11/71:
data = [53,9,5,90,63,5,97,40,92,48,53,8,38,63,13,15,66,81,57,79,42,91,25,89,66,4,73,45,80,17]

sum = sum(data)
mean = tsum/len(data)

print(f"The max is:" , max(data))
print(f"The min is: " , min(data))
print(f"The sum is: " , sum(data))
print(f"The count is: " , len(data))
print(f"The mean is: " , mean)
11/72:
data = [53,9,5,90,63,5,97,40,92,48,53,8,38,63,13,15,66,81,57,79,42,91,25,89,66,4,73,45,80,17]

sumtotal = sum(data)
mean = tsum/len(data)

print(f"The max is:" , max(data))
print(f"The min is: " , min(data))
print(f"The sum is: " , sum(data))
print(f"The count is: " , len(data))
print(f"The mean is: " , mean)
11/73:
data = [53,9,5,90,63,5,97,40,92,48,53,8,38,63,13,15,66,81,57,79,42,91,25,89,66,4,73,45,80,17]

sumtotal = sum(data)
mean = sumtotal/len(data)

print(f"The max is:" , max(data))
print(f"The min is: " , min(data))
print(f"The sum is: " , sum(data))
print(f"The count is: " , len(data))
print(f"The mean is: " , mean)
11/74:
data = [53,9,5,90,63,5,97,40,92,48,53,8,38,63,13,15,66,81,57,79,42,91,25,89,66,4,73,45,80,17]

sumtotal = sum(data)
mean = sumtotal/len(data)

print(f"The max is:" , max(data))
print(f"The min is: " , min(data))
print(f"The sum is: " , sum(data))
print(f"The count is: " , len(data))
print(f"The mean is: " , mean)
11/75:
data = [53,9,5,90,63,5,97,40,92,48,53,8,38,63,13,15,66,81,57,79,42,91,25,89,66,4,73,45,80,17]

sumtotal = sum(data)
mean = sumtotal/len(data)

print(f"The max is:" , max(data))
print(f"The min is: " , min(data))
print(f"The sum is: " , sum(data))
print(f"The count is: " , len(data))
print(f"The mean is: " , mean)
11/76:
data = [53,9,5,90,63,5,97,40,92,48,53,8,38,63,13,15,66,81,57,79,42,91,25,89,66,4,73,45,80,17]


print(f"The max is:" , max(data))
print(f"The min is: " , min(data))
print(f"The sum is: " , sum(data))
print(f"The count is: " , len(data))
print(f"The mean is: " , mean)
11/77:
data = [53,9,5,90,63,5,97,40,92,48,53,8,38,63,13,15,66,81,57,79,42,91,25,89,66,4,73,45,80,17]

print(f"The max is:" , max(data))
print(f"The min is: " , min(data))
print(f"The sum is: " , (data))
print(f"The count is: " , len(data))
print(f"The mean is: " , mean)
11/78:
data = [53,9,5,90,63,5,97,40,92,48,53,8,38,63,13,15,66,81,57,79,42,91,25,89,66,4,73,45,80,17]

print(f"The max is:" , max(data))
print(f"The min is: " , min(data))
print(f"The sum is: " , sum(data))
print(f"The count is: " , len(data))
print(f"The mean is: " , mean)
11/79:
data = [53,9,5,90,63,5,97,40,92,48,53,8,38,63,13,15,66,81,57,79,42,91,25,89,66,4,73,45,80,17]
sum(data
print(f"The max is:" , max(data))
print(f"The min is: " , min(data))
print(f"The sum is: " , )
print(f"The count is: " , len(data))
print(f"The mean is: " , mean)
11/80:
data = [53,9,5,90,63,5,97,40,92,48,53,8,38,63,13,15,66,81,57,79,42,91,25,89,66,4,73,45,80,17]
sum(data)
print(f"The max is:" , max(data))
print(f"The min is: " , min(data))
print(f"The sum is: " , )
print(f"The count is: " , len(data))
print(f"The mean is: " , mean)
11/81:
data = [53,9,5,90,63,5,97,40,92,48,53,8,38,63,13,15,66,81,57,79,42,91,25,89,66,4,73,45,80,17]


print(f"The max is:" , max(data))
print(f"The min is: " , min(data))
print(f"The sum is: " , sum(data))
print(f"The count is: " , len(data))
print(f"The mean is: " , mean)
11/82:
data = [53,9,5,90,63,5,97,40,92,48,53,8,38,63,13,15,66,81,57,79,42,91,25,89,66,4,73,45,80,17]


print(f"The max is:" , max(data))
print(f"The min is: " , min(data))
print(f"The sum is: " , sum(data))
print(f"The count is: " , len(data))
print(f"The mean is: " , avg(data)
11/83:
data = [53,9,5,90,63,5,97,40,92,48,53,8,38,63,13,15,66,81,57,79,42,91,25,89,66,4,73,45,80,17]

total=sum(data)
mean = total/len(data
print(f"The max is:" , max(data))
print(f"The min is: " , min(data))
print(f"The sum is: " , sum(data))
print(f"The count is: " , len(data))
print(f"The mean is: " , mean)
11/84:
data = [53,9,5,90,63,5,97,40,92,48,53,8,38,63,13,15,66,81,57,79,42,91,25,89,66,4,73,45,80,17]

total=sum(data)
mean = total/len(data)
print(f"The max is:" , max(data))
print(f"The min is: " , min(data))
print(f"The sum is: " , sum(data))
print(f"The count is: " , len(data))
print(f"The mean is: " , mean)
11/85:
data = [53,9,5,90,63,5,97,40,92,48,53,8,38,63,13,15,66,81,57,79,42,91,25,89,66,4,73,45,80,17]

print(f"The max is:" , max(data))
print(f"The min is: " , min(data))
print(f"The sum is: " , sum(data))
print(f"The count is: " , len(data))
print(f"The mean is: " , mean)
11/86:
data = [53,9,5,90,63,5,97,40,92,48,53,8,38,63,13,15,66,81,57,79,42,91,25,89,66,4,73,45,80,17]

print(f"The max is:" , max(data))
print(f"The min is: " , min(data))
print(f"The sum is: " , (data))
print(f"The count is: " , len(data))
print(f"The mean is: " ,)
11/87:
data = [53,9,5,90,63,5,97,40,92,48,53,8,38,63,13,15,66,81,57,79,42,91,25,89,66,4,73,45,80,17]

print(f"The max is:" , max(data))
print(f"The min is: " , min(data))
print(f"The sum is: " , sum(data))
print(f"The count is: " , len(data))
print(f"The mean is: " ,)
11/88:
data = [53,9,5,90,63,5,97,40,92,48,53,8,38,63,13,15,66,81,57,79,42,91,25,89,66,4,73,45,80,17]


print(f"The max is:" , max(data))
print(f"The min is: " , min(data))
print(f"The sum is: " , sum(data))
print(f"The count is: " , len(data))
print(f"The mean is: " )
11/89:
data = [53,9,5,90,63,5,97,40,92,48,53,8,38,63,13,15,66,81,57,79,42,91,25,89,66,4,73,45,80,17]


print(f"The max is:" , max(data))
print(f"The min is: " , min(data))
print(f"The sum is: " , (data))
print(f"The count is: " , len(data))
print(f"The mean is: " )
11/90:
data = [53,9,5,90,63,5,97,40,92,48,53,8,38,63,13,15,66,81,57,79,42,91,25,89,66,4,73,45,80,17]


print(f"The max is:" , max(data))
print(f"The min is: " , min(data))
print(f"The sum is: " , sum(data))
print(f"The count is: " , len(data))
print(f"The mean is: " )
11/91:
data = [53,9,5,90,63,5,97,40,92,48,53,8,38,63,13,15,66,81,57,79,42,91,25,89,66,4,73,45,80,17]


print(f"The max is:" , max(data))
print(f"The min is: " , min(data))
print(f"The sum is: " , sum(data))
print(f"The count is: " , len(data))
print(f"The mean is: " )
11/92:
data = [53,9,5,90,63,5,97,40,92,48,53,8,38,63,13,15,66,81,57,79,42,91,25,89,66,4,73,45,80,17]


print(f"The max is:" , max(data))
print(f"The min is: " , min(data))
print(f"The sum is: " , sum())
print(f"The count is: " , len(data))
print(f"The mean is: " )
11/93:
data = [53,9,5,90,63,5,97,40,92,48,53,8,38,63,13,15,66,81,57,79,42,91,25,89,66,4,73,45,80,17]


print(f"The max is:" , max(data))
print(f"The min is: " , min(data))
print(f"The sum is: " , sum())data

print(f"The count is: " , len(data))
print(f"The mean is: " )
11/94:
data = [53,9,5,90,63,5,97,40,92,48,53,8,38,63,13,15,66,81,57,79,42,91,25,89,66,4,73,45,80,17]


print(f"The max is:" , max(data))
print(f"The min is: " , min(data))
print(f"The sum is: " , sum(data))
print(f"The count is: " , len(data))
print(f"The mean is: " )
11/95:
data = [53,9,5,90,63,5,97,40,92,48,53,8,38,63,13,15,66,81,57,79,42,91,25,89,66,4,73,45,80,17]


print(f"The max is:" , max(data))
print(f"The min is: " , min(data))
print(f"The sum is: " , )
print(f"The count is: " , len(data))
print(f"The mean is: " )
11/96:
data = [53,9,5,90,63,5,97,40,92,48,53,8,38,63,13,15,66,81,57,79,42,91,25,89,66,4,73,45,80,17]


print(f"The max is:" , max(data))
print(f"The min is: " , min(data))
print(f"The sum is: " , sum(data)
print(f"The count is: " , len(data))
print(f"The mean is: " )
11/97:
data = [53,9,5,90,63,5,97,40,92,48,53,8,38,63,13,15,66,81,57,79,42,91,25,89,66,4,73,45,80,17]


print(f"The max is:" , max(data))
print(f"The min is: " , min(data))
print(f"The sum is: " , sum(data))
print(f"The count is: " , len(data))
print(f"The mean is: " )
11/98:
data = [53,9,5,90,63,5,97,40,92,48,53,8,38,63,13,15,66,81,57,79,42,91,25,89,66,4,73,45,80,17]


print(f"The max is:" , max(data))
print(f"The min is: " , min(data))
print(f"The sum is: " , sum(data))
print(f"The count is: " , len(data))
print(f"The mean is: " )
11/99:
data = [53,9,5,90,63,5,97,40,92,48,53,8,38,63,13,15,66,81,57,79,42,91,25,89,66,4,73,45,80,17]

print(f"The max is:" , max(data))
print(f"The min is: " ,min(data))
print(f"The sum is: " , sum(data))
print(f"The count is: " , len(data))
11/100: ### Your solution here
11/101:
data = [53,9,5,90,63,5,97,40,92,48,53,8,38,63,13,15,66,81,57,79,42,91,25,89,66,4,73,45,80,17]


print(f"The max is:" , max(data))
print(f"The min is: " , min(data))
print(f"The sum is: " , sum(data))
print(f"The count is: " , len(data))
print(f"The mean is: " )
11/102:
data = [53,9,5,90,63,5,97,40,92,48,53,8,38,63,13,15,66,81,57,79,42,91,25,89,66,4,73,45,80,17]

sum(data)
print(f"The max is:" , max(data))
print(f"The min is: " , min(data))
print(f"The sum is: " , )
print(f"The count is: " , len(data))
print(f"The mean is: " )
11/103:
data = [53,9,5,90,63,5,97,40,92,48,53,8,38,63,13,15,66,81,57,79,42,91,25,89,66,4,73,45,80,17]

sum(data)

print(f"The max is:" , max(data))
print(f"The min is: " , min(data))
print(f"The sum is: " , )
print(f"The count is: " , len(data))
print(f"The mean is: " )
11/104:
data = [53,9,5,90,63,5,97,40,92,48,53,8,38,63,13,15,66,81,57,79,42,91,25,89,66,4,73,45,80,17]


print(f"The max is:" , max(data))
print(f"The min is: " , min(data))
print(f"The sum is: " , )
print(f"The count is: " , len(data))
print(f"The mean is: " )
11/105:
data = [53,9,5,90,63,5,97,40,92,48,53,8,38,63,13,15,66,81,57,79,42,91,25,89,66,4,73,45,80,17]

print(f"The max is:" , max(data))
print(f"The min is: " , min(data))
print(f"The sum is: " , )
print(f"The count is: " , len(data))
print(f"The mean is: " )
11/106:
data = [53,9,5,90,63,5,97,40,92,48,53,8,38,63,13,15,66,81,57,79,42,91,25,89,66,4,73,45,80,17]

print(f"The max is:" , max(data))
print(f"The min is: " , min(data))
print(f"The sum is: " ,sum(data) )
print(f"The count is: " , len(data))
print(f"The mean is: " )
11/107:
data = [53,9,5,90,63,5,97,40,92,48,53,8,38,63,13,15,66,81,57,79,42,91,25,89,66,4,73,45,80,17]

print(f"The max is:" , max(data))
print(f"The min is: " , min(data))
print(f"The sum is: " ,sum(data) )
print(f"The count is: " , len(data))
print(f"The mean is: " ,mean(data))
11/108:
data = [53,9,5,90,63,5,97,40,92,48,53,8,38,63,13,15,66,81,57,79,42,91,25,89,66,4,73,45,80,17]

sum=sum(data)
print(f"The max is:" , max(data))
print(f"The min is: " , min(data))
print(f"The sum is: " ,sum(data) )
print(f"The count is: " , len(data))
print(f"The mean is: " ,mean(data))
11/109:
data = [53,9,5,90,63,5,97,40,92,48,53,8,38,63,13,15,66,81,57,79,42,91,25,89,66,4,73,45,80,17]

sum(data)=sum(data)
print(f"The max is:" , max(data))
print(f"The min is: " , min(data))
print(f"The sum is: " ,sum(data) )
print(f"The count is: " , len(data))
print(f"The mean is: " ,mean(data))
11/110:
data = [53,9,5,90,63,5,97,40,92,48,53,8,38,63,13,15,66,81,57,79,42,91,25,89,66,4,73,45,80,17]

sum(data)==sum(data)
print(f"The max is:" , max(data))
print(f"The min is: " , min(data))
print(f"The sum is: " ,sum(data) )
print(f"The count is: " , len(data))
print(f"The mean is: " ,mean(data))
11/111:
data = [53,9,5,90,63,5,97,40,92,48,53,8,38,63,13,15,66,81,57,79,42,91,25,89,66,4,73,45,80,17]
sum
print(f"The max is:" , max(data))
print(f"The min is: " , min(data))
print(f"The sum is: " , )
print(f"The count is: " , len(data))
print(f"The mean is: " ,mean(data))
11/112:
data = [53,9,5,90,63,5,97,40,92,48,53,8,38,63,13,15,66,81,57,79,42,91,25,89,66,4,73,45,80,17]

print(sum)

print(f"The max is:" , max(data))
print(f"The min is: " , min(data))
print(f"The sum is: " , )
print(f"The count is: " , len(data))
print(f"The mean is: " ,mean(data))
11/113:
data = [53,9,5,90,63,5,97,40,92,48,53,8,38,63,13,15,66,81,57,79,42,91,25,89,66,4,73,45,80,17]

print(sum)

print(f"The max is:" , max(data))
print(f"The min is: " , min(data))
print(f"The sum is: " , print(sum))
print(f"The count is: " , len(data))
print(f"The mean is: " ,)
11/114:
data = [53,9,5,90,63,5,97,40,92,48,53,8,38,63,13,15,66,81,57,79,42,91,25,89,66,4,73,45,80,17]

print(f"The max is:" , max(data))
print(f"The min is: " , min(data))
print(f"The sum is: " , print(sum))
print(f"The count is: " , len(data))
print(f"The mean is: " ,)
11/115:
data = [53,9,5,90,63,5,97,40,92,48,53,8,38,63,13,15,66,81,57,79,42,91,25,89,66,4,73,45,80,17]

print(f"The max is:" , max(data))
print(f"The min is: " , min(data))
print(f"The sum is: " , (sum))
print(f"The count is: " , len(data))
print(f"The mean is: " ,)
11/116:
data = [53,9,5,90,63,5,97,40,92,48,53,8,38,63,13,15,66,81,57,79,42,91,25,89,66,4,73,45,80,17]

print(f"The max is:" , max(data))
print(f"The min is: " , min(data))
print(f"The sum is: " , (sum))
print(f"The count is: " , len(data))
print(f"The mean is: " , (sum)/len(data))
11/117:
data = [53,9,5,90,63,5,97,40,92,48,53,8,38,63,13,15,66,81,57,79,42,91,25,89,66,4,73,45,80,17]

print(f"The max is:" , max(data))
print(f"The min is: " , min(data))
print(f"The sum is: " , (sum))
print(f"The count is: " , len(data))
print(f"The mean is: " , (sum)/len(data))
15/1:
array = [nan,nan,nan,nan,nan,nan,nan,nan,nan,nan]
vec = np.array(array)
# Sample output: array([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan])
15/2:
array = ["nan","nan","nan","nan","nan","nan","nan","nan","nan","nan"]
vec = np.array(array)
# Sample output: array([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan])
15/3:
import numpy as np 
array = ["nan","nan","nan","nan","nan","nan","nan","nan","nan","nan"]
vec = np.array(array)
# Sample output: array([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan])
15/4:
import numpy as np 
array = ["nan","nan","nan","nan","nan","nan","nan","nan","nan","nan"]
vec = np.array(array)
print(vec)
# Sample output: array([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan])
15/5: vec = np.random.random(size=10)
15/6:
vec = np.random.random(size=10)
print(vec)
15/7:
vec = np.random.random(size=10)

max(vec)
min(vec)
sum(vec)
mean(vec)
15/8:
vec = np.random.random(size=10)

max(vec)
min(vec)
sum(vec)
15/9:
import numpy as np 
vec = np.random.random(size=10)

print(f"The max is:" , max(vec))
print(f"The max is:" , min(vec))
print(f"The max is:" , sum(vec))
print(f"The max is:" , mean(vec))
15/10:
vec = np.random.random(size=10)
print sum
print(f"The max is:" , max(vec))
print(f"The max is:" , min(vec))
print(f"The max is:" , sum(vec))
print(f"The max is:" , )
15/11:
vec = np.random.random(size=10)
print(sum)
print(f"The max is:" , max(vec))
print(f"The max is:" , min(vec))
print(f"The max is:" , sum(vec))
print(f"The max is:" , )
15/12:
vec = np.random.random(size=10)

print(sum)
print(f"The max is:" , max(vec))
print(f"The max is:" , min(vec))
print(f"The max is:" , sum(vec))
print(f"The max is:" , )
15/13:
vec = np.random.random(size=10)

print(sum)
print(f"The max is:" , max(vec))
print(f"The min is:" , min(vec))
print(f"The sum is:" , sum(vec))
print(f"The max is:" , )
15/14:
vec = np.random.random(size=10)

print(sum(vec))
print(f"The max is:" , max(vec))
print(f"The min is:" , min(vec))
print(f"The sum is:" , sum(vec))
print(f"The max is:" , )
15/15:
vec = np.random.random(size=10)


mean == (sum(vec)/len(vec))
print(f"The max is:" , max(vec))
print(f"The min is:" , min(vec))
print(f"The sum is:" , sum(vec))
print(f"The max is:" , )
15/16:
vec = np.random.random(size=10)

mean == (sum(vec)/len(vec))

print(f"The max is:" , max(vec))
print(f"The min is:" , min(vec))
print(f"The sum is:" , sum(vec))
print(f"The max is:" , )
15/17:
vec = np.random.random(size=10)

mean == (sum(vec)/10)

print(f"The max is:" , max(vec))
print(f"The min is:" , min(vec))
print(f"The sum is:" , sum(vec))
print(f"The max is:" , )
15/18:
vec = np.random.random(size=10)

avg == (sum(vec)/10)

print(f"The max is:" , max(vec))
print(f"The min is:" , min(vec))
print(f"The sum is:" , sum(vec))
print(f"The max is:" , )
15/19:
vec = np.random.random(size=10)

avg = (sum(vec)/10)

print(f"The max is:" , max(vec))
print(f"The min is:" , min(vec))
print(f"The sum is:" , sum(vec))
print(f"The max is:" , )
15/20:
vec = np.random.random(size=10)

avg = (sum(vec)/10)

print(f"The max is:" , max(vec))
print(f"The min is:" , min(vec))
print(f"The sum is:" , sum(vec))
print(f"The mean is:" , avg )
15/21: vec = np.random.random(size=15)
15/22: vec = np.random.random(size=15)
15/23:
vec = np.random.random(size=15)
print(vec)
15/24:
vec= np.random.randint(10,90,15)
print(vec)
15/25:
vec= np.random.randint(10,90,15)
print(vec)

vec[vec.argmax()] = 500
15/26:
vec= np.random.randint(10,90,15)
print(vec)

vec[vec.argmax()] = 500
print(vec)
15/27:
vec= np.random.randint(10,90,15)
print(vec)

vec[vec.argmax()] = 500
print(vec)

vec[vec.argmin()] = 500
print(vec)
15/28:
vec= np.random.randint(10,90,15)
print(vec)

vec[vec.argmax()] = 500
print(vec)

vec[vec.argmin()] = -500
print(vec)
15/29:
vec= np.random.randint(10,90,15)
print(vec)

vec[vec.argmax()] = 500
print(vec)

vec[vec.argmin()] = -500
print(vec)
15/30:
vec= np.random.randint(10,90,15)
print(vec)

vec2 = vec[vec.argmax()] = 500
print(vec2)

vec[vec.argmin()] = -500
print(vec)
15/31:
vec= np.random.randint(10,90,15)
print(vec)

vec2 = vec[vec.argmax()] = 500
print(vec2)

vec[vec.argmin()] = -500
print(vec)
15/32:
vec= np.random.randint(10,90,15)
print(vec)

vec2 = vec[vec.argmax()] = 500
print(vec2)

vec[vec.argmin()] = -500
print(vec)
15/33:
vec= np.random.randint(10,90,15)
print(vec)

vec2 = vec[vec.argmax()] = 500
print(vec2)

vec[vec.argmin()] = -500
print(vec)
15/34:
vec= np.random.randint(10,90,15)
print(vec)


vec[vec.argmin()] = -500
print(vec)
15/35:
vec= np.random.randint(10,90,15)
print(vec)


vec[vec.argmin()] = -500
print(vec)
15/36:
vec= np.random.randint(10,90,15)
print(vec)


vec[vec.argmin()] = -500
print(vec)
15/37:
vec= np.random.randint(10,90,15)
print(vec)

vec2 = vec[vec.argmax()] = 500
print(vec2)

vec3 = vec2[vec2.argmin()] = -500
print(vec3)
15/38:
vec= np.random.randint(10,90,15)
print(vec)

vec2 = vec[vec.argmax()] = 500
print(vec2)

vec3 = vec2[vec.argmin()] = -500
print(vec3)
15/39:
vec= np.random.randint(10,90,15)
print(vec)

vec2 = vec[vec.argmax()] = 500
print(vec2)

vec3 = vec[vec.argmin()] = -500
print(vec3)
15/40:
vec= np.random.randint(10,90,15)
print(vec)

vec2 = vec[vec.argmax()] = 500
print(vec2)

vec3 = vec[vec.argmin()] = -500
print(vec3)
15/41:
vec= np.random.randint(10,90,15)
print(vec)

vec[vec.argmax()] = 500
print(vec2)

vec = vec[vec.argmin()] = -500
print(vec3)
15/42:
vec= np.random.randint(10,90,15)
print(vec)

vec[vec.argmax()] = 500
print(vec)
15/43:
vec= np.random.randint(10,90,15)
print(vec)

vec[vec.argmax()] = 500
print(vec)

vec[vec.argmin()] = -500
print(vec)
15/44:
print("Before number replacement")

vec= np.random.randint(10,90,15)
print(vec)

avg = (sum(vec)/15)
print("vector_mean =" , avg)

print("After number replacement")

vec[vec.argmax()] = 500
vec[vec.argmin()] = -500
print(vec)

avg2 = (sum(vec)/15)

print("new_vector_mean = " ,avg2)
15/45:
print("*Before number replacement*")

vec= np.random.randint(10,90,15)
print(vec)

avg = (sum(vec)/15)
print("vector_mean =" , avg)

print("After number replacement")

vec[vec.argmax()] = 500
vec[vec.argmin()] = -500
print(vec)

avg2 = (sum(vec)/15)

print("new_vector_mean = " ,avg2)
15/46:
print(*"Before number replacement*"*)

vec= np.random.randint(10,90,15)
print(vec)

avg = (sum(vec)/15)
print("vector_mean =" , avg)

print("After number replacement")

vec[vec.argmax()] = 500
vec[vec.argmin()] = -500
print(vec)

avg2 = (sum(vec)/15)

print("new_vector_mean = " ,avg2)
15/47:
print(**"Before number replacement*"**)

vec= np.random.randint(10,90,15)
print(vec)

avg = (sum(vec)/15)
print("vector_mean =" , avg)

print("After number replacement")

vec[vec.argmax()] = 500
vec[vec.argmin()] = -500
print(vec)

avg2 = (sum(vec)/15)

print("new_vector_mean = " ,avg2)
15/48:
print("Before number replacement*")

vec= np.random.randint(10,90,15)
print(vec)

avg = (sum(vec)/15)
print("vector_mean =" , avg)

print("After number replacement")

vec[vec.argmax()] = 500
vec[vec.argmin()] = -500
print(vec)

avg2 = (sum(vec)/15)

print("new_vector_mean = " ,avg2)
15/49:
print("Before number replacement*")

vec= np.random.randint(10,90,15)
print(vec)

avg = (sum(vec)/15)
print("vector_mean =" , avg)


print("After number replacement")

vec[vec.argmax()] = 500
vec[vec.argmin()] = -500
print(vec)

avg2 = (sum(vec)/15)

print("new_vector_mean = " ,avg2)
16/1:
list = []
for i in range(0,5):
n = random.randint(12,80)
list.append(n)
print(list)
15/50:
thing = "light"
speed = 299792458  # m/s

print(f"The speed of {thing} is {speed:2e} m/s.")
15/51:
l = [10, [3, 4], [5, [100, 200], [23, ["DATA301"], 27], 11], 1, 7]

l[2][2][1]
# Sample output: 'DATA301'
15/52:
d = {
    "outer": [
        1,
        2,
        3,
        {
            "inner": [
                "this",
                "is",
                "inception",
                {"inner_inner": ["a", "b", "c", "DATA301", 1, 2, 3]},
            ]
        },
    ]
}
15/53:
language = "java"

if language == "java":
   print("I love coffee!")
elif language == "python":
   print("Are you a snake?")
else:
   print(f"What is {language}?")
# If language is "Java", the output would be "I love coffee!"
# If language is "PYTHON", the output would be "Are you a snake?"
# If language is anything else, the output would be anything this language is, for example, if language is "R", output is "R".
# You don't need to display the results of your test for EACH condition, just make sure your code works like this.
19/1:
df = df.rename(columns={"name": "Celebrity Name",
                        "age": "Achievements ",
                       "salary" : "Networth"})
df
19/2:
df = df.rename(columns={"name": "Celebrity Name",
                        "age": "Achievements ",
                       "salary" : "Networth"})
df
19/3:
import pandas as pd
df = pd.DataFrame({"name": ["Tim Cook", "Elon musk", "Jay-Z"],
                   "age": ["59", "24", "40"],
                   "salary": [30000000.0, 200000.0, 900000.0]})
df
19/4:
df = df.rename(columns={"name": "Celebrity Name",
                        "age": "Achievements ",
                       "salary" : "Networth"})
df
15/54:
print("Before number replacement")

#

vec= np.random.randint(10,90,15)
print(vec)

avg = (sum(vec)/15)
print("vector_mean =" , avg)


print("After number replacement")

vec[vec.argmax()] = 500
vec[vec.argmin()] = -500
print(vec)

avg2 = (sum(vec)/15)

print("new_vector_mean = " ,avg2)
15/55:
print("Before number replacement")

#    

vec= np.random.randint(10,90,15)
print(vec)


avg = (sum(vec)/15)
print("vector_mean =" , avg)


print("After number replacement")

vec[vec.argmax()] = 500
vec[vec.argmin()] = -500
print(vec)

avg2 = (sum(vec)/15)

print("new_vector_mean = " ,avg2)
15/56:
print("Before number replacement")  

vec= np.random.randint(10,90,15)
print(vec)

avg = (sum(vec)/15)
print("vector_mean =" , avg)


print("After number replacement")

vec[vec.argmax()] = 500
vec[vec.argmin()] = -500
print(vec)

avg2 = (sum(vec)/15)

print("new_vector_mean = " ,avg2)
15/57:
print(color.BOLD + "Before number replacement")  

vec= np.random.randint(10,90,15)
print(vec)

avg = (sum(vec)/15)
print("vector_mean =" , avg)


print("After number replacement")

vec[vec.argmax()] = 500
vec[vec.argmin()] = -500
print(vec)

avg2 = (sum(vec)/15)

print("new_vector_mean = " ,avg2)
15/58:
print(color.BOLD + "Before number replacement" + color.Bold)  

vec= np.random.randint(10,90,15)
print(vec)

avg = (sum(vec)/15)
print("vector_mean =" , avg)


print("After number replacement")

vec[vec.argmax()] = 500
vec[vec.argmin()] = -500
print(vec)

avg2 = (sum(vec)/15)

print("new_vector_mean = " ,avg2)
15/59:
print('\033[1m' + "Before number replacement")  

vec= np.random.randint(10,90,15)
print(vec)

avg = (sum(vec)/15)
print("vector_mean =" , avg)


print("After number replacement")

vec[vec.argmax()] = 500
vec[vec.argmin()] = -500
print(vec)

avg2 = (sum(vec)/15)

print("new_vector_mean = " ,avg2)
15/60:
print( "\033[1m" + "Before number replacement")  

vec= np.random.randint(10,90,15)
print(vec)

avg = (sum(vec)/15)
print("vector_mean =" , avg)


print("After number replacement")

vec[vec.argmax()] = 500
vec[vec.argmin()] = -500
print(vec)

avg2 = (sum(vec)/15)

print("new_vector_mean = " ,avg2)
15/61:
print("Before number replacement")  

vec= np.random.randint(10,90,15)
print(vec)

avg = (sum(vec)/15)
print("vector_mean =" , avg)


print("After number replacement")

vec[vec.argmax()] = 500
vec[vec.argmin()] = -500
print(vec)

avg2 = (sum(vec)/15)

print("new_vector_mean = " ,avg2)
15/62:
import numpy as np 
arr = ["nan","nan","nan","nan","nan","nan","nan","nan","nan","nan"]
vec = np.array(arr)
print(vec)
# Sample output: array([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan])
15/63:
import numpy as np 
vec = np.array()
print(vec)
# Sample output: array([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan])
15/64:
import numpy as np 
vec = np.array[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan])
print(vec)
# Sample output: array([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan])
15/65:
import numpy as np 
vec = np.array[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]
print(vec)
# Sample output: array([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan])
15/66:
import numpy as np 
vec = np.array["nan", "nan", "nan", "nan", "nan", "nan", "nan", "nan", "nan", "nan"]
print(vec)
# Sample output: array([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan])
15/67:
import numpy as np 
vec = np.array([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan])
print(vec)
# Sample output: array([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan])
15/68:
import numpy as np 
vec = np.array(["nan", nan, nan, nan, nan, nan, nan, nan, nan, nan])
print(vec)
# Sample output: array([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan])
15/69:
import numpy as np 
vec = np.array(["nan", "nan","nan", "nan","nan", "nan", "nan", "nan", "nan", "nan"])
print(vec)
# Sample output: array([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan])
15/70:
import numpy as np 
vec = np.array([NaN,NaN)
print(vec)
# Sample output: array([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan])
15/71:
import numpy as np 
vec = np.array([NaN,NaN])
print(vec)
# Sample output: array([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan])
15/72:
import numpy as np 
vec = np.array([0,0])
print(vec)
# Sample output: array([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan])
15/73:
import numpy as np 
vec = np.array([0,0])
vec
# Sample output: array([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan])
15/74:
import numpy as np 
vec = np.array([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan])
vec
# Sample output: array([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan])
15/75:
import numpy as np 
vec = np.array(["nan", "nan", "nan", "nan", "nan", "nan", "nan", "nan", "nan", "nan"])
vec
# Sample output: array([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan])
15/76:
import numpy as np 
vec = np.array(["nan", "nan", "nan", "nan", "nan", "nan", "nan", "nan", "nan", "nan"])
vec
# Sample output: array([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan])
15/77:
print("Before number replacement")  

vec= np.random.random(10,90,15)
print(vec)

avg = (sum(vec)/15)
print("vector_mean =" , avg)


print("After number replacement")

vec[vec.argmax()] = 500
vec[vec.argmin()] = -500
print(vec)

avg2 = (sum(vec)/15)

print("new_vector_mean = " ,avg2)
15/78:
print("Before number replacement")  

vec= np.random.randint(10,90,15)
print(vec)

avg = (sum(vec)/15)
print("vector_mean =" , avg)


print("After number replacement")

vec[vec.argmax()] = 500
vec[vec.argmin()] = -500
print(vec)

avg2 = (sum(vec)/15)

print("new_vector_mean = " ,avg2)
15/79:
import numpy as np 
vec = np.array(["nan", "nan", "nan", "nan", "nan", "nan", "nan", "nan", "nan", "nan"])
vec
# Sample output: array([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan])
15/80:

vec = np.array(["nan", "nan", "nan", "nan", "nan", "nan", "nan", "nan", "nan", "nan"])
vec
# Sample output: array([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan])
15/81:
vec = np.array(["nan", "nan", "nan", "nan", "nan", "nan", "nan", "nan", "nan", "nan"])
vec
# Sample output: array([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan])
15/82:
vec = np.array(["nan", "nan", "nan", "nan", "nan", "nan", "nan", "nan", "nan", "nan"])
vec

# Sample output: array([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan])
16/2: random.randint(12,80)
16/3:
import random
random.randint(12,80)
16/4:
import random
random.randint(12,80,20)
16/5:
import random
random.randint(12,80,2)
16/6:
vec= np.random.randint(10,90,15)
print(vec)
15/83:
vec = np.random.random(size=10)

avg = (sum(vec)/len(vec))

print(f"The max is:" , max(vec))
print(f"The min is:" , min(vec))
print(f"The sum is:" , sum(vec))
print(f"The mean is:" , avg )
15/84:
vec = np.empty((3,3))
vec[:] = np.NaN
# Sample output: array([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan])
15/85:
vec = np.empty((3,3))
vec[:] = np.NaN
# Sample output: array([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan])
15/86:
vec = np.empty((3,3))
vec[:] = np.NaN
vec
# Sample output: array([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan])
15/87:
print("Before number replacement")  

vec= np.random.randint(10,90,15)
print(vec)

avg = (sum(vec)/len(vec))
print("vector_mean =" , avg)


print("After number replacement")

vec[vec.argmax()] = 500
vec[vec.argmin()] = -500
print(vec)

avg2 = (sum(vec)/len(vec))

print("new_vector_mean = " ,avg2)
15/88:
print("Before number replacement")  

vec= np.random.randint(10,90,15)
vec.sort()
print(vec)

avg = (sum(vec)/len(vec))
print("vector_mean =" , avg)


print("After number replacement")

vec[vec.argmax()] = 500
vec[vec.argmin()] = -500
print(vec)

avg2 = (sum(vec)/len(vec))

print("new_vector_mean = " ,avg2)
15/89:
print("Before number replacement")  

vec= np.random.randint(10,90,15)
vec.sort()
print(vec)

avg = (sum(vec)/len(vec))
print("vector_mean =" , avg)


print("After number replacement")

vec[vec.argmax()] = 500
vec[vec.argmin()] = -500
vec.sort()
print(vec)

avg2 = (sum(vec)/len(vec))

print("new_vector_mean = " ,avg2)
16/7:
data = [53,9,5,90,63,5,97,40,92,48,53,8,38,63,13,15,66,81,57,79,42,91,25,89,66,4,73,45,80,17]

newlist=[]
for x in fruits:
  if 25<x<45 in x:
    newlist.append(x)

print(newlist)
16/8:
data = [53,9,5,90,63,5,97,40,92,48,53,8,38,63,13,15,66,81,57,79,42,91,25,89,66,4,73,45,80,17]

newlist=[]
for x in data:
  if 25<x<45 in x:
    newlist.append(x)

print(newlist)
16/9:
data = [53,9,5,90,63,5,97,40,92,48,53,8,38,63,13,15,66,81,57,79,42,91,25,89,66,4,73,45,80,17]

newlist=[]
for x in data:
  if 25 < x < 45 in x:
    newlist.append(x)

print(newlist)
16/10:
data = [53,9,5,90,63,5,97,40,92,48,53,8,38,63,13,15,66,81,57,79,42,91,25,89,66,4,73,45,80,17]

newlist=[]
for x in data:
  if 25 < x < 45 in x:
    newlist.append(x)

print(newlist)
16/11: squares = [i * i for i in range(10)]
16/12:
squares = [i * i for i in range(10)]

squares
16/13:
squares = [i * i for i in range(10)]

squares
16/14:
squares = [i * i for i in range(80)]

squares
16/15:
squares = [i * i for i in range(15)]

squares
16/16:
data = [53,9,5,90,63,5,97,40,92,48,53,8,38,63,13,15,66,81,57,79,42,91,25,89,66,4,73,45,80,17]

newlist=[]
for x in data:
  if 25 <x < 45:
    newlist.append(x)

print(newlist)
16/17:
data = [53,9,5,90,63,5,97,40,92,48,53,8,38,63,13,15,66,81,57,79,42,91,25,89,66,4,73,45,80,17]

newlist=[]
for x in data:
  if 25 <= x <= 45:
    newlist.append(x)

print(newlist)
16/18:
data = [53,9,5,90,63,5,97,40,92,48,53,8,38,63,13,15,66,81,57,79,42,91,25,89,66,4,73,45,80,17]

newdata=[]
for x in data:
  if 25 <= x <= 45:
    newlist.append(x)

print(newdata)
16/19:
data = [53,9,5,90,63,5,97,40,92,48,53,8,38,63,13,15,66,81,57,79,42,91,25,89,66,4,73,45,80,17]

newlist=[]
for x in data:
  if 25 <= x <= 45:
    newlist.append(x)

print(newlist)
16/20:
data = [53,9,5,90,63,5,97,40,92,48,53,8,38,63,13,15,66,81,57,79,42,91,25,89,66,4,73,45,80,17]

newdata=[]
for x in data:
  if 25 <= x <= 45:
    newdata.append(x)

print(newdata)
16/21: data = [53,9,5,90,63,5,97,40,92,48,53,8,38,63,13,15,66,81,57,79,42,91,25,89,66,4,73,45,80,17]
16/22:
data = [53,9,5,90,63,5,97,40,92,48,53,8,38,63,13,15,66,81,57,79,42,91,25,89,66,4,73,45,80,17]
newdata = [x for x in fruits if 12< x <80 in x]
16/23:
data = [53,9,5,90,63,5,97,40,92,48,53,8,38,63,13,15,66,81,57,79,42,91,25,89,66,4,73,45,80,17]
newdata = [x for x in data if 12< x <80 in x]
16/24:
data = [53,9,5,90,63,5,97,40,92,48,53,8,38,63,13,15,66,81,57,79,42,91,25,89,66,4,73,45,80,17]

newdat = [x for x in data if 12< x <80 in x]
16/25:
data = [53,9,5,90,63,5,97,40,92,48,53,8,38,63,13,15,66,81,57,79,42,91,25,89,66,4,73,45,80,17]

newdata = [x for in data if 12 < x <80 in x]
16/26:
data = [53,9,5,90,63,5,97,40,92,48,53,8,38,63,13,15,66,81,57,79,42,91,25,89,66,4,73,45,80,17]

newdata = [x for x in data if 12 < x <80 in x]
16/27:
data = [53,9,5,90,63,5,97,40,92,48,53,8,38,63,13,15,66,81,57,79,42,91,25,89,66,4,73,45,80,17]

newdata = [x for x in data if 12 < x <80 in x]
16/28:
data = [53,9,5,90,63,5,97,40,92,48,53,8,38,63,13,15,66,81,57,79,42,91,25,89,66,4,73,45,80,17]

newdata = [ for x in data if 12 <= x <80 in x]
16/29:
data = [53,9,5,90,63,5,97,40,92,48,53,8,38,63,13,15,66,81,57,79,42,91,25,89,66,4,73,45,80,17]

newdata = [ x for x in data if 12 <= x <80 in x]
16/30:
data = [53,9,5,90,63,5,97,40,92,48,53,8,38,63,13,15,66,81,57,79,42,91,25,89,66,4,73,45,80,17]

newdata = [ x for x in data if 12 <= x <80]
16/31:
data = [53,9,5,90,63,5,97,40,92,48,53,8,38,63,13,15,66,81,57,79,42,91,25,89,66,4,73,45,80,17]

newdata = [ x for x in data if 12 <= x <80]
newdata
16/32:
data = [53,9,5,90,63,5,97,40,92,48,53,8,38,63,13,15,66,81,57,79,42,91,25,89,66,4,73,45,80,17]

newdata = [ x for x in data if 12 <= x <= 80]
newdata
15/90:
vec = np.empty((10))
vec[:] = np.NaN
vec
# Sample output: array([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan])
16/33:
data = [53,9,5,90,63,5,97,40,92,48,53,8,38,63,13,15,66,81,57,79,42,91,25,89,66,4,73,45,80,17]

newdata=[]
for x in data:
  if 25 <= x <= 45:
    newdata.append(x)

print(newdata)
16/34:
data = [53,9,5,90,63,5,97,40,92,48,53,8,38,63,13,15,66,81,57,79,42,91,25,89,66,4,73,45,80,17]

print(f"The max is:" , max(data))
print(f"The min is: " , min(data))
print(f"The sum is: " , (sum))
print(f"The count is: " , len(data))
print(f"The mean is: " , (sum)/len(data))

sum
16/35:
data = [53,9,5,90,63,5,97,40,92,48,53,8,38,63,13,15,66,81,57,79,42,91,25,89,66,4,73,45,80,17]

print(f"The max is:" , max(data))
print(f"The min is: " , min(data))
print(f"The sum is: " , (sum))
print(f"The count is: " , len(data))
print(f"The mean is: " , (sum)/len(data))
16/36:
data = [53,9,5,90,63,5,97,40,92,48,53,8,38,63,13,15,66,81,57,79,42,91,25,89,66,4,73,45,80,17]

print(f"The max is:" , max(data))
print(f"The min is: " , min(data))
print(f"The sum is: " , sum(data))
print(f"The count is: " , len(data))
print(f"The mean is: " , (sum)/len(data))
16/37:
data = [53,9,5,90,63,5,97,40,92,48,53,8,38,63,13,15,66,81,57,79,42,91,25,89,66,4,73,45,80,17]

print(f"The max is:" , max(data))
print(f"The min is: " , min(data))
print(f"The sum is: " , sum(data))
print(f"The count is: " , len(data))
print(f"The mean is: " , sum(data)/len(data))
19/5:
import pandas as pd
df = pd.DataFrame.from_dict(info2)
df
19/6:
import pandas as pd
info2 = {'name' : ['Tim Cook', 'Elon musk ' , 'Jayz' , 'Donald Trump' , 'Mukesh Ambani'] ,'age' : [59, 24, 40, 20, 54],
         'salary' : [30000000.0, 200000.0, 900000.0, 450000.0, 20000.0]}
df = pd.DataFrame.from_dict(info2)
df
19/7:
df = df.rename(columns={"name": "Celebrity Name",
                        "age": "Achievements ",
                       "salary" : "Networth"})
df
17/1:
info2 = {'name' : ['Tim Cook', 'Elon musk ' , 'Jayz' , 'Donald Trump' , 'Mukesh Ambani'] ,'age' : [59, 24, 40, 20, 54],
         'salary' : [30000000.0, 200000.0, 900000.0, 450000.0, 20000.0]}
print(info2)
18/1: df2[[mean('HP')]]
18/2: df3 = d2[["HP","Attack","Defense","Speed"]].mean()
18/3: df3 = df2[["HP","Attack","Defense","Speed"]].mean()
18/4: df2 = df[["HP","Attack","Defense","Speed"]].mean()
18/5:
df2 = df[df["Generation"] == 1]
df2
18/6:
# Usually all the import statements are at the top of the file

import pandas as pd
import seaborn as sns
import numpy as np
import os
import matplotlib.pyplot as plt
18/7:
import pandas as pd
df = pd.read_csv('/Users/poojalal/Desktop/DATA301/lab04-DARTH-LAL/data/pokemon.csv')
df
18/8: df.count()
18/9:
df2 = df[df["Generation"] == 1]
df2
18/10: df3 = df2[["HP","Attack","Defense","Speed"]].mean()
18/11:
df3 = df2[["HP","Attack","Defense","Speed"]].mean()
df3
15/91:
l = [10, [3, 4], [5, [100, 200], [23, ["DATA301"], 27], 11], 1, 7]

l[2][2]
# Sample output: 'DATA301'
15/92:
l = [10, [3, 4], [5, [100, 200], [23, ["DATA301"], 27], 11], 1, 7]

l[2][2][2]
# Sample output: 'DATA301'
15/93:
l = [10, [3, 4], [5, [100, 200], [23, ["DATA301"], 27], 11], 1, 7]

l[2][1][2]
# Sample output: 'DATA301'
15/94:
l = [10, [3, 4], [5, [100, 200], [23, ["DATA301"], 27], 11], 1, 7]

l[3][2][2]
# Sample output: 'DATA301'
15/95:
s = "Learning Python is so much fun!"

s.split()
# Sample output: ['Learning', 'Python', 'is', 'so', 'much', 'fun!']
15/96:
thing = "light"
speed = 299792458  # m/s

print(f"The speed of {thing} is {speed:2e} m/s.")
15/97:
l = [10, [3, 4], [5, [100, 200], [23, ["DATA301"], 27], 11], 1, 7]

l[3][2][2]
# Sample output: 'DATA301'
15/98:
l = [10, [3, 4], [5, [100, 200], [23, ["DATA301"], 27], 11], 1, 7]

l[2][2][1]
# Sample output: 'DATA301'
15/99:
l = [10, [3, 4], [5, [100, 200], [23, ["DATA301"], 27], 11], 1, 7]

l[2][1][1]
# Sample output: 'DATA301'
15/100:
l = [10, [3, 4], [5, [100, 200], [23, ["DATA301"], 27], 11], 1, 7]

l[2][2][2]
# Sample output: 'DATA301'
15/101:
l = [10, [3, 4], [5, [100, 200], [23, ["DATA301"], 27], 11], 1, 7]

l[2][2][1]
# Sample output: 'DATA301'
15/102:
l = [10, [3, 4], [5, [100, 200], [23, ["DATA301"], 27], 11], 1, 7]

l[2][1][2]
# Sample output: 'DATA301'
15/103:
l = [10, [3, 4], [5, [100, 200], [23, ["DATA301"], 27], 11], 1, 7]

l[2][2][2]
# Sample output: 'DATA301'
15/104:
l = [10, [3, 4], [5, [100, 200], [23, ["DATA301"], 27], 11], 1, 7]

l[2][2][1]
# Sample output: 'DATA301'
15/105:
l = [10, [3, 4], [5, [100, 200], [23, ["DATA301"], 27], 11], 1, 7]

l[2][2][0]
# Sample output: 'DATA301'
15/106:
l = [10, [3, 4], [5, [100, 200], [23, ["DATA301"], 27], 11], 1, 7]

l[2][2][1]
# Sample output: 'DATA301'
16/38:
### Your solution here

n = 10
for i in range(1,n):
    if i < n / 2 :
        print("A" * i)
    else:
        print("A" * (n+i))
16/39:
### Your solution here

n = 10
for i in range(1,n):
    if i < n / 2 :
        print("A" * i)
    else:
        print("A" * (n-i))
16/40:
data = [53,9,5,90,63,5,97,40,92,48,53,8,38,63,13,15,66,81,57,79,42,91,25,89,66,4,73,45,80,17]

newdata=[]
for x in data:
  if 25 <= x <= 45:
    newdata.append(x)

print(newdata)
16/41:
data = [53,9,5,90,63,5,97,40,92,48,53,8,38,63,13,15,66,81,57,79,42,91,25,89,66,4,73,45,80,17]

print(f"The max is:" , max(data))
print(f"The min is: " , min(data))
print(f"The sum is: " , sum(data))
print(f"The count is: " , len(data))
print(f"The mean is: " , sum(data)/len(data))
16/42:
data = [53,9,5,90,63,5,97,40,92,48,53,8,38,63,13,15,66,81,57,79,42,91,25,89,66,4,73,45,80,17]

newdata = [ x for x in data if 12 <= x <= 80]
newdata
15/107:
l = [10, [3, 4], [5, [100, 200], [23, ["DATA301"], 27], 11], 1, 7]

l[3][2][1]
# Sample output: 'DATA301'
15/108:
l = [10, [3, 4], [5, [100, 200], [23, ["DATA301"], 27], 11], 1, 7]

l[3][3][1]
# Sample output: 'DATA301'
15/109:
l = [10, [3, 4], [5, [100, 200], [23, ["DATA301"], 27], 11], 1, 7]

l[2][2][1]
# Sample output: 'DATA301'
15/110:
l = [10, [3, 4], [5, [100, 200], [23, ["DATA301"], 27], 11], 1, 7]

l[2][0][1]
# Sample output: 'DATA301'
15/111:
l = [10, [3, 4], [5, [100, 200], [23, ["DATA301"], 27], 11], 1, 7]

l[2][0][0]
# Sample output: 'DATA301'
15/112:
l = [10, [3, 4], [5, [100, 200], [23, ["DATA301"], 27], 11], 1, 7]

l[2][1][0]
# Sample output: 'DATA301'
15/113:
l = [10, [3, 4], [5, [100, 200], [23, ["DATA301"], 27], 11], 1, 7]

l[2][2][0]
# Sample output: 'DATA301'
15/114:
l = [10, [3, 4], [5, [100, 200], [23, ["DATA301"], 27], 11], 1, 7]

l[2][3][0]
# Sample output: 'DATA301'
15/115:
l = [10, [3, 4], [5, [100, 200], [23, ["DATA301"], 27], 11], 1, 7]

l[3][3][0]
# Sample output: 'DATA301'
15/116:
l = [10, [3, 4], [5, [100, 200], [23, ["DATA301"], 27], 11], 1, 7]

l[3][4][0]
# Sample output: 'DATA301'
15/117:
l = [10, [3, 4], [5, [100, 200], [23, ["DATA301"], 27], 11], 1, 7]

l[3][2][0]
# Sample output: 'DATA301'
15/118:
l = [10, [3, 4], [5, [100, 200], [23, ["DATA301"], 27], 11], 1, 7]

l[3][1][0]
# Sample output: 'DATA301'
15/119:
l = [10, [3, 4], [5, [100, 200], [23, ["DATA301"], 27], 11], 1, 7]

l[3][0][0]
# Sample output: 'DATA301'
15/120:
l = [10, [3, 4], [5, [100, 200], [23, ["DATA301"], 27], 11], 1, 7]

l[0][0][0]
# Sample output: 'DATA301'
15/121:
l = [10, [3, 4], [5, [100, 200], [23, ["DATA301"], 27], 11], 1, 7]

l[1][0][0]
# Sample output: 'DATA301'
15/122:
l = [10, [3, 4], [5, [100, 200], [23, ["DATA301"], 27], 11], 1, 7]

l[1][1][0]
# Sample output: 'DATA301'
15/123:
l = [10, [3, 4], [5, [100, 200], [23, ["DATA301"], 27], 11], 1, 7]

l[1][1][1]
# Sample output: 'DATA301'
15/124:
l = [10, [3, 4], [5, [100, 200], [23, ["DATA301"], 27], 11], 1, 7]

l[2][1][1]
# Sample output: 'DATA301'
15/125:
l = [10, [3, 4], [5, [100, 200], [23, ["DATA301"], 27], 11], 1, 7]

l[3][2][2]
# Sample output: 'DATA301'
15/126:
l = [10, [3, 4], [5, [100, 200], [23, ["DATA301"], 27], 11], 1, 7]

l[2][2][2]
# Sample output: 'DATA301'
15/127:
l = [10, [3, 4], [5, [100, 200], [23, ["DATA301"], 27], 11], 1, 7]

l[2][3][2]
# Sample output: 'DATA301'
15/128:
l = [10, [3, 4], [5, [100, 200], [23, ["DATA301"], 27], 11], 1, 7]

l[2][2][2]
# Sample output: 'DATA301'
15/129:
l = [10, [3, 4], [5, [100, 200], [23, ["DATA301"], 27], 11], 1, 7]

l[2][2][3]
# Sample output: 'DATA301'
15/130:
l = [10, [3, 4], [5, [100, 200], [23, ["DATA301"], 27], 11], 1, 7]

l[2][2][1]
# Sample output: 'DATA301'
15/131:
l = [10, [3, 4], [5, [100, 200], [23, ["DATA301"], 27], 11], 1, 7]

l[2][2]
# Sample output: 'DATA301'
15/132:
l = [10, [3, 4], [5, [100, 200], [23, ["DATA301"], 27], 11], 1, 7]

l[2][1]
# Sample output: 'DATA301'
15/133:
l = [10, [3, 4], [5, [100, 200], [23, ["DATA301"], 27], 11], 1, 7]

l[3][1]
# Sample output: 'DATA301'
15/134:
l = [10, [3, 4], [5, [100, 200], [23, ["DATA301"], 27], 11], 1, 7]

l[3][]
# Sample output: 'DATA301'
15/135:
l = [10, [3, 4], [5, [100, 200], [23, ["DATA301"], 27], 11], 1, 7]

l[3][)]
# Sample output: 'DATA301'
15/136:
l = [10, [3, 4], [5, [100, 200], [23, ["DATA301"], 27], 11], 1, 7]

l[3][0]
# Sample output: 'DATA301'
15/137:
l = [10, [3, 4], [5, [100, 200], [23, ["DATA301"], 27], 11], 1, 7]

l[2][0]
# Sample output: 'DATA301'
15/138:
l = [10, [3, 4], [5, [100, 200], [23, ["DATA301"], 27], 11], 1, 7]

l[2][1]
# Sample output: 'DATA301'
15/139:
l = [10, [3, 4], [5, [100, 200], [23, ["DATA301"], 27], 11], 1, 7]

l[2][2]
# Sample output: 'DATA301'
15/140:
l = [10, [3, 4], [5, [100, 200], [23, ["DATA301"], 27], 11], 1, 7]

l[2][2][1]
# Sample output: 'DATA301'
15/141:
l = [10, [3, 4], [5, [100, 200], [23, ["DATA301"], 27], 11], 1, 7]

l[2][2][1][0]
# Sample output: 'DATA301'
16/43:
data = [53,9,5,90,63,5,97,40,92,48,53,8,38,63,13,15,66,81,57,79,42,91,25,89,66,4,73,45,80,17]

newdata = [ x for x in data if 12 <= x <= 80]
newdata
16/44: name = 'Marie Antoinette'
16/45:
name = 'Ma'

if len(name)>20:
    print(f"Name {name} is more than 20 chars long")
    length_description = 'long'
elif len(name)>18:
    print(f"Name {name} is more than 18 chars long")
    length_description = 'semi long'
elif len(name)>15:
    print(f"Name {name} is more than 15 chars long")
    length_description = 'semi long'
elif len(name) > (9 or 10 or 11):
    print(f"Name {name} is 9, 10 or 11 chars long")
    length_description = 'semi short'
else:
    print(f"Name {name} is a short name")
    length_description = 'short'
16/46:
### Your solution here

n = 10
for i in range(1,n):
    if i < n / 2 :
        print("A" * i)
    else:
        print("A" * (n-i))
16/47:
data = [53,9,5,90,63,5,97,40,92,48,53,8,38,63,13,15,66,81,57,79,42,91,25,89,66,4,73,45,80,17]

newdata=[]
for x in data:
  if 25 <= x <= 45:
    newdata.append(x)

print(newdata)
16/48:
data = [53,9,5,90,63,5,97,40,92,48,53,8,38,63,13,15,66,81,57,79,42,91,25,89,66,4,73,45,80,17]

print(f"The max is:" , max(data))
print(f"The min is: " , min(data))
print(f"The sum is: " , sum(data))
print(f"The count is: " , len(data))
print(f"The mean is: " , sum(data)/len(data))
16/49:
data = [53,9,5,90,63,5,97,40,92,48,53,8,38,63,13,15,66,81,57,79,42,91,25,89,66,4,73,45,80,17]

newdata = [ x for x in data if 12 <= x <= 80]
newdata
17/2:
info = {'name' : 'Jeff Bezoos',
        'age' : 57,
        'salary' : 6746563247}
print(info)
17/3:
info2 = {'name' : ['Tim Cook', 'Elon musk ' , 'Jayz' , 'Donald Trump' , 'Mukesh Ambani'] ,'age' : [59, 24, 40, 20, 54],
         'salary' : [30000000.0, 200000.0, 900000.0, 450000.0, 20000.0]}
print(info2)
18/12:
# Usually all the import statements are at the top of the file

import pandas as pd
import seaborn as sns
import numpy as np
import os
import matplotlib.pyplot as plt
18/13:
import pandas as pd
df = pd.read_csv('/Users/poojalal/Desktop/DATA301/lab04-DARTH-LAL/data/pokemon.csv')
df
18/14: df.count()
18/15:
df2 = df[df["Generation"] == 1]
df2
18/16:
df3 = df2[["HP","Attack","Defense","Speed"]].mean()
df3
19/8:
info = {'name' : 'Tim Cook' ,
        'age' : 59,
        'salary' :3000000.0}
info
19/9:
info2 = {'name' : ['Tim Cook', 'Elon musk ' , 'Jayz' , 'Donald Trump' , 'Mukesh Ambani'] ,'age' : [59, 24, 40, 20, 54],
         'salary' : [30000000.0, 200000.0, 900000.0, 450000.0, 20000.0]}
info2
19/10:
df = pd.DataFrame.from_dict(info2)
df
19/11:
df = df.rename(columns={"name": "Celebrity Name",
                        "age": "Achievements ",
                       "salary" : "Networth"})
df
15/142:
language = "jaVa"

if language == "java":
   print("I love coffee!")
elif language == "python":
   print("Are you a snake?")
else:
   print(f"What is {language}?")
# If language is "Java", the output would be "I love coffee!"
# If language is "PYTHON", the output would be "Are you a snake?"
# If language is anything else, the output would be anything this language is, for example, if language is "R", output is "R".
# You don't need to display the results of your test for EACH condition, just make sure your code works like this.
15/143:
language = "jaVa"

if language.lower() == "java":
   print("I love coffee!")
elif language == "python":
   print("Are you a snake?")
else:
   print(f"What is {language}?")
# If language is "Java", the output would be "I love coffee!"
# If language is "PYTHON", the output would be "Are you a snake?"
# If language is anything else, the output would be anything this language is, for example, if language is "R", output is "R".
# You don't need to display the results of your test for EACH condition, just make sure your code works like this.
15/144:
language = "jaVa"

if language.lower() == "java":
   print("I love coffee!")
elif language.lower() == "python":
   print("Are you a snake?")
else:
   print(f"What is {language}?")
# If language is "Java", the output would be "I love coffee!"
# If language is "PYTHON", the output would be "Are you a snake?"
# If language is anything else, the output would be anything this language is, for example, if language is "R", output is "R".
# You don't need to display the results of your test for EACH condition, just make sure your code works like this.
21/1:
s = "Learning Python is so much fun!"

s.split()
# Sample output: ['Learning', 'Python', 'is', 'so', 'much', 'fun!']
21/2:
thing = "light"
speed = 299792458  # m/s

print(f"The speed of {thing} is {speed:2e} m/s.")
21/3:
l = [10, [3, 4], [5, [100, 200], [23, ["DATA301"], 27], 11], 1, 7]

l[2][2][1][0]
# Sample output: 'DATA301'
21/4:
d = {
    "outer": [
        1,
        2,
        3,
        {
            "inner": [
                "this",
                "is",
                "inception",
                {"inner_inner": ["a", "b", "c", "DATA301", 1, 2, 3]},
            ]
        },
    ]
}
21/5:
d['outer'][3]['inner'][3]['inner_inner'][3]
# Sample output: 'DATA301'
21/6:
language = "java"

if language.lower() == "java":
   print("I love coffee!")
elif language.lower() == "python":
   print("Are you a snake?")
else:
   print(f"What is {language}?")
# If language is "Java", the output would be "I love coffee!"
# If language is "PYTHON", the output would be "Are you a snake?"
# If language is anything else, the output would be anything this language is, for example, if language is "R", output is "R".
# You don't need to display the results of your test for EACH condition, just make sure your code works like this.
21/7: import numpy as np
21/8:
vec = np.empty((10))
vec[:] = np.NaN
vec
# Sample output: array([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan])
21/9:
vec = np.random.random(size=10)

avg = (sum(vec)/len(vec))

print(f"The max is:" , max(vec))
print(f"The min is:" , min(vec))
print(f"The sum is:" , sum(vec))
print(f"The mean is:" , avg )
21/10:
print("Before number replacement")  

vec= np.random.randint(10,90,15)
vec.sort()
print(vec)

avg = (sum(vec)/len(vec))
print("vector_mean =" , avg)


print("After number replacement")

vec[vec.argmax()] = 500
vec[vec.argmin()] = -500
vec.sort()
print(vec)

avg2 = (sum(vec)/len(vec))

print("new_vector_mean = " ,avg2)
23/1: name = 'Marie Antoinette'
23/2:
name = 'Ma'

if len(name)>20:
    print(f"Name {name} is more than 20 chars long")
    length_description = 'long'
elif len(name)>18:
    print(f"Name {name} is more than 18 chars long")
    length_description = 'semi long'
elif len(name)>15:
    print(f"Name {name} is more than 15 chars long")
    length_description = 'semi long'
elif len(name) > (9 or 10 or 11):
    print(f"Name {name} is 9, 10 or 11 chars long")
    length_description = 'semi short'
else:
    print(f"Name {name} is a short name")
    length_description = 'short'
23/3:
### Your solution here

n = 10
for i in range(1,n):
    if i < n / 2 :
        print("A" * i)
    else:
        print("A" * (n-i))
23/4:
data = [53,9,5,90,63,5,97,40,92,48,53,8,38,63,13,15,66,81,57,79,42,91,25,89,66,4,73,45,80,17]

newdata=[]
for x in data:
  if 25 <= x <= 45:
    newdata.append(x)

print(newdata)
23/5:
data = [53,9,5,90,63,5,97,40,92,48,53,8,38,63,13,15,66,81,57,79,42,91,25,89,66,4,73,45,80,17]

print(f"The max is:" , max(data))
print(f"The min is: " , min(data))
print(f"The sum is: " , sum(data))
print(f"The count is: " , len(data))
print(f"The mean is: " , sum(data)/len(data))
23/6:
data = [53,9,5,90,63,5,97,40,92,48,53,8,38,63,13,15,66,81,57,79,42,91,25,89,66,4,73,45,80,17]

newdata = [ x for x in data if 12 <= x <= 80]
newdata
22/1:
info = {'name' : 'Jeff Bezoos',
        'age' : 57,
        'salary' : 6746563247}
print(info)
22/2:
info2 = {'name' : ['Tim Cook', 'Elon musk ' , 'Jayz' , 'Donald Trump' , 'Mukesh Ambani'] ,'age' : [59, 24, 40, 20, 54],
         'salary' : [30000000.0, 200000.0, 900000.0, 450000.0, 20000.0]}
print(info2)
20/1:
# Usually all the import statements are at the top of the file

import pandas as pd
import seaborn as sns
import numpy as np
import os
import matplotlib.pyplot as plt
20/2:
import pandas as pd
df = pd.read_csv('/Users/poojalal/Desktop/DATA301/lab04-DARTH-LAL/data/pokemon.csv')
df
20/3: df.count()
20/4:
df2 = df[df["Generation"] == 1]
df2
20/5:
df3 = df2[["HP","Attack","Defense","Speed"]].mean()
df3
24/1:
info = {'name' : 'Tim Cook' ,
        'age' : 59,
        'salary' :3000000.0}
info
24/2:
info2 = {'name' : ['Tim Cook', 'Elon musk ' , 'Jayz' , 'Donald Trump' , 'Mukesh Ambani'] ,'age' : [59, 24, 40, 20, 54],
         'salary' : [30000000.0, 200000.0, 900000.0, 450000.0, 20000.0]}
info2
24/3:
df = pd.DataFrame.from_dict(info2)
df
24/4:
info = {'name' : 'Tim Cook' ,
        'age' : 59,
        'salary' :3000000.0}
info
24/5:
info2 = {'name' : ['Tim Cook', 'Elon musk ' , 'Jayz' , 'Donald Trump' , 'Mukesh Ambani'] ,'age' : [59, 24, 40, 20, 54],
         'salary' : [30000000.0, 200000.0, 900000.0, 450000.0, 20000.0]}
info2
24/6:
import pandas as pd
df = pd.DataFrame.from_dict(info2)
df
24/7:
df = df.rename(columns={"name": "Celebrity Name",
                        "age": "Achievements ",
                       "salary" : "Networth"})
df
29/1: name = 'Marie Antoinette'
29/2:
name = 'Ma'

if len(name)>20:
    print(f"Name {name} is more than 20 chars long")
    length_description = 'long'
elif len(name)>18:
    print(f"Name {name} is more than 18 chars long")
    length_description = 'semi long'
elif len(name)>15:
    print(f"Name {name} is more than 15 chars long")
    length_description = 'semi long'
elif len(name) > (9 or 10 or 11):
    print(f"Name {name} is 9, 10 or 11 chars long")
    length_description = 'semi short'
else:
    print(f"Name {name} is a short name")
    length_description = 'short'
29/3:
name = 'Ma77777'

if len(name)>20:
    print(f"Name {name} is more than 20 chars long")
    length_description = 'long'
elif len(name)>18:
    print(f"Name {name} is more than 18 chars long")
    length_description = 'semi long'
elif len(name)>15:
    print(f"Name {name} is more than 15 chars long")
    length_description = 'semi long'
elif len(name) > (9 or 10 or 11):
    print(f"Name {name} is 9, 10 or 11 chars long")
    length_description = 'semi short'
else:
    print(f"Name {name} is a short name")
    length_description = 'short'
29/4:
name = 'Ma7777777'

if len(name)>20:
    print(f"Name {name} is more than 20 chars long")
    length_description = 'long'
elif len(name)>18:
    print(f"Name {name} is more than 18 chars long")
    length_description = 'semi long'
elif len(name)>15:
    print(f"Name {name} is more than 15 chars long")
    length_description = 'semi long'
elif len(name) > (9 or 10 or 11):
    print(f"Name {name} is 9, 10 or 11 chars long")
    length_description = 'semi short'
else:
    print(f"Name {name} is a short name")
    length_description = 'short'
29/5:
name = 'Ma777777777'

if len(name)>20:
    print(f"Name {name} is more than 20 chars long")
    length_description = 'long'
elif len(name)>18:
    print(f"Name {name} is more than 18 chars long")
    length_description = 'semi long'
elif len(name)>15:
    print(f"Name {name} is more than 15 chars long")
    length_description = 'semi long'
elif len(name) > (9 or 10 or 11):
    print(f"Name {name} is 9, 10 or 11 chars long")
    length_description = 'semi short'
else:
    print(f"Name {name} is a short name")
    length_description = 'short'
30/1:
s = "Learning Python is so much fun!"

s.split()
# Sample output: ['Learning', 'Python', 'is', 'so', 'much', 'fun!']
30/2:
thing = "light"
speed = 299792458  # m/s

print(f"The speed of {thing} is {speed:2e} m/s.")
30/3:
l = [10, [3, 4], [5, [100, 200], [23, ["DATA301"], 27], 11], 1, 7]

l[2][2][1][0]
# Sample output: 'DATA301'
30/4:
d = {
    "outer": [
        1,
        2,
        3,
        {
            "inner": [
                "this",
                "is",
                "inception",
                {"inner_inner": ["a", "b", "c", "DATA301", 1, 2, 3]},
            ]
        },
    ]
}
30/5:
d['outer'][3]['inner'][3]['inner_inner'][3]
# Sample output: 'DATA301'
30/6:
language = "java"

if language.lower() == "java":
   print("I love coffee!")
elif language.lower() == "python":
   print("Are you a snake?")
else:
   print(f"What is {language}?")
# If language is "Java", the output would be "I love coffee!"
# If language is "PYTHON", the output would be "Are you a snake?"
# If language is anything else, the output would be anything this language is, for example, if language is "R", output is "R".
# You don't need to display the results of your test for EACH condition, just make sure your code works like this.
30/7: import numpy as np
30/8:
vec = np.empty((10))
vec[:] = np.NaN
vec
# Sample output: array([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan])
30/9:
vec = np.random.random(size=10)

avg = (sum(vec)/len(vec))

print(f"The max is:" , max(vec))
print(f"The min is:" , min(vec))
print(f"The sum is:" , sum(vec))
print(f"The mean is:" , avg )
30/10:
print("Before number replacement")  

vec= np.random.randint(10,90,15)
vec.sort()
print(vec)

avg = (sum(vec)/len(vec))
print("vector_mean =" , avg)


print("After number replacement")

vec[vec.argmax()] = 500
vec[vec.argmin()] = -500
vec.sort()
print(vec)

avg2 = (sum(vec)/len(vec))

print("new_vector_mean = " ,avg2)
33/1: name = 'Marie Antoinette'
33/2:
name = 'Ma'

if len(name)>20:
    print(f"Name {name} is more than 20 chars long")
    length_description = 'long'
elif len(name)>18:
    print(f"Name {name} is more than 18 chars long")
    length_description = 'semi long'
elif len(name)>15:
    print(f"Name {name} is more than 15 chars long")
    length_description = 'semi long'
elif len(name) > (9 or 10 or 11):
    print(f"Name {name} is 9, 10 or 11 chars long")
    length_description = 'semi short'
else:
    print(f"Name {name} is a short name")
    length_description = 'short'
33/3:
### Your solution here

n = 10
for i in range(1,n):
    if i < n / 2 :
        print("A" * i)
    else:
        print("A" * (n-i))
33/4:
data = [53,9,5,90,63,5,97,40,92,48,53,8,38,63,13,15,66,81,57,79,42,91,25,89,66,4,73,45,80,17]

newdata=[]
for x in data:
  if 25 <= x <= 45:
    newdata.append(x)

print(newdata)
33/5:
data = [53,9,5,90,63,5,97,40,92,48,53,8,38,63,13,15,66,81,57,79,42,91,25,89,66,4,73,45,80,17]

print(f"The max is:" , max(data))
print(f"The min is: " , min(data))
print(f"The sum is: " , sum(data))
print(f"The count is: " , len(data))
print(f"The mean is: " , sum(data)/len(data))
33/6:
data = [53,9,5,90,63,5,97,40,92,48,53,8,38,63,13,15,66,81,57,79,42,91,25,89,66,4,73,45,80,17]

newdata = [ x for x in data if 12 <= x <= 80]
newdata
34/1:
info = {'name' : 'Jeff Bezoos',
        'age' : 57,
        'salary' : 6746563247}
print(info)
34/2:
info2 = {'name' : ['Tim Cook', 'Elon musk ' , 'Jayz' , 'Donald Trump' , 'Mukesh Ambani'] ,'age' : [59, 24, 40, 20, 54],
         'salary' : [30000000.0, 200000.0, 900000.0, 450000.0, 20000.0]}
print(info2)
32/1:
# Usually all the import statements are at the top of the file

import pandas as pd
import seaborn as sns
import numpy as np
import os
import matplotlib.pyplot as plt
32/2:
import pandas as pd
df = pd.read_csv('/Users/poojalal/Desktop/DATA301/lab04-DARTH-LAL/data/pokemon.csv')
df
32/3: df.count()
32/4:
df2 = df[df["Generation"] == 1]
df2
32/5:
df3 = df2[["HP","Attack","Defense","Speed"]].mean()
df3
31/1:
info = {'name' : 'Tim Cook' ,
        'age' : 59,
        'salary' :3000000.0}
info
31/2:
info2 = {'name' : ['Tim Cook', 'Elon musk ' , 'Jayz' , 'Donald Trump' , 'Mukesh Ambani'] ,'age' : [59, 24, 40, 20, 54],
         'salary' : [30000000.0, 200000.0, 900000.0, 450000.0, 20000.0]}
info2
31/3:
import pandas as pd
df = pd.DataFrame.from_dict(info2)
df
31/4:
df = df.rename(columns={"name": "Celebrity Name",
                        "age": "Achievements ",
                       "salary" : "Networth"})
df
35/1: calculation = 5 ** 2 + 51 / 8 * (7 - 4) % 9
35/2:
calculation = 5 ** 2 + 51 / 8 * (7 - 4) % 9
calculation
36/1: import panads as pd
36/2: import pandas as pd
36/3:
import pandas as pd

df= pd.read_csv('https://github.com/firasm/bits/raw/master/pokemon.csv'
36/4:
import pandas as pd

df= pd.read_csv('https://github.com/firasm/bits/raw/master/pokemon.csv')
36/5:
import pandas as pd

df= pd.read_csv('https://github.com/firasm/bits/raw/master/pokemon.csv')
print(df.head(4))
36/6:
import pandas as pd

df= pd.read_csv('https://github.com/firasm/bits/raw/master/pokemon.csv')
print(df.head(4))
36/7: df.describe()
36/8: df.describe().T
36/9: df.describe(include=all)
36/10: df.describe(include= 'all')
36/11: df.numeric.describe()
36/12: df.numeric.describe().T
36/13:
head(df)
df.numeric.describe().T
36/14:
print(df)
df.numeric.describe().T
36/15: df.describe().T
36/16: df.describe(include=[np.number]).T
36/17: df.describe(include= 'numeric').T
36/18: df.describe(include=['category']).T
36/19: df.head(4)
36/20:
df.head(4)
newdf = df.drop(columns=['Generation','Sp.Atk', 'Sp. Atk', 'Sp. Def', 'Total','#'])
36/21:
df.head(4)
newdf = df.drop(columns=['Generation', 'Sp. Atk', 'Sp. Def', 'Total','#'])
36/22:
df.head(4)
newdf = df.drop(columns=['Generation', 'Sp. Atk', 'Sp. Def', 'Total','#'])
newdf.head(4)
36/23:
df.head(4)
newdf = df.drop(columns=['Generation', 'Sp. Atk', 'Sp. Def', 'Total','#'])
newdf.head(4)
36/24:
df.head(4)
newdf = df.drop(columns=['Generation', 'Sp. Atk', 'Sp. Def', 'Total','#'])
newdf.head(4)
36/25:
df.head(4)
newdf = df.drop(columns=['Generation', 'Sp. Atk', 'Sp. Def', 'Total','#'])
newdf.head(4)
36/26: df.head(4)
36/27: df.head(4)
36/28: df.head(4)
36/29: df.head(4)
36/30: df.head(4)
36/31: df.head(4)
36/32:
import pandas as pd

df= pd.read_csv('https://github.com/firasm/bits/raw/master/pokemon.csv')
print(df.head(4))
36/33: df.head(4)
36/34: newdf = df.drop(columns=['Total'])
36/35:
newdf = df.drop(columns=['Total'])
print(newdf)
36/36:
newdf = df.drop(columns=['Total'])
newdf.head(5)
36/37:
newdf = df.drop(columns=['Generation', 'Sp. Atk', 'Sp. Def', 'Total', '#'])
newdf.head(5)
36/38: df2=newdf.dropna()
36/39:
df2=newdf.dropna()
print(df2)
36/40:
newdf = df.drop(columns=['Generation', 'Sp. Atk', 'Sp. Def', 'Total', '#'])
newdf.head(5)
print(newdf)
36/41:
newdf = df.drop(columns=['Generation', 'Sp. Atk', 'Sp. Def', 'Total', '#'])
newdf.head(5)
print(300:400)
36/42:
newdf = df.drop(columns=['Generation', 'Sp. Atk', 'Sp. Def', 'Total', '#'])
newdf.head(5)
print([300:400])
36/43:
newdf = df.drop(columns=['Generation', 'Sp. Atk', 'Sp. Def', 'Total', '#'])
newdf.head(5)
print(newdf)
36/44:
newdf = df.drop(columns=['Generation', 'Sp. Atk', 'Sp. Def', 'Total', '#'])
print(newdf)
36/45: print(df)
36/46: df2.reset_index(drop=Ture, inplace =True)
36/47: df2.reset_index(drop=True, inplace =True)
36/48:
df2.reset_index(drop=True, inplace =True)
print(df2)
36/49:
df3 =df2.reset_index(drop=True, inplace =True)
print(df3)
36/50:
df3 =df2.reset_index(drop=True, inplace =True)
print(df3)
36/51:
df3 = df2.reset_index(drop=True, inplace =True)
print(df3)
36/52:
df3 =df2.reset_index(drop=True, inplace =True)
print(df3)
36/53:
df3=df2.reset_index(drop=True, inplace =True)
print(df3)
36/54:
df2.reset_index(drop=True, inplace =True)
print(df3)
36/55:
df2.reset_index(drop=True, inplace =True)
df2
36/56:
df2=newdf.dropna()
df2
36/57:
newdf = df.drop(columns=['Generation', 'Sp. Atk', 'Sp. Def', 'Total', '#'])
newdf
36/58:
df2.reset_index(drop=True, inplace =True)
df2
36/59: df4 = df.drop(columns=['index'])
36/60:
df2.reset_index(drop=True)
df2
36/61: df3 = df2.drop(columns=['index'])
36/62: df2.drop(columns=['index'])
40/1:
import pandas as pd

df= pd.read_csv('https://github.com/firasm/bits/raw/master/pokemon.csv')
print(df.head(4))
print(df['Name'])
40/2:
import pandas as pd

df= pd.read_csv('https://github.com/firasm/bits/raw/master/pokemon.csv')
print(df['Name'])
40/3:
import pandas as pd

df= pd.read_csv('https://github.com/firasm/bits/raw/master/pokemon.csv')
print(df.head(4))
40/4:
import pandas as pd

df= pd.read_csv('https://github.com/firasm/bits/raw/master/pokemon.csv')
print(df.head(4))
data.df.iloc[4]
40/5:
import pandas as pd

df= pd.read_csv('https://github.com/firasm/bits/raw/master/pokemon.csv')
print(df.head(4))
df['HP'].mean()
40/6:
import pandas as pd

df= pd.read_csv('https://github.com/firasm/bits/raw/master/pokemon.csv')
print(df.head(4))
df['HP'].mean()
newdf = df[['HP'] > 80]
40/7:
import pandas as pd

df= pd.read_csv('https://github.com/firasm/bits/raw/master/pokemon.csv')
print(df.head(4))
df['HP'].mean()
newdf = df[df['HP'] > 80]
40/8:
import pandas as pd

df= pd.read_csv('https://github.com/firasm/bits/raw/master/pokemon.csv')
print(df.head(4))
df['HP'].mean()
newdf = df[df['Defense'] > 80]
40/9:
import pandas as pd

df= pd.read_csv('https://github.com/firasm/bits/raw/master/pokemon.csv')
print(df.head(4))
df['HP'].mean()
newdf = df[df['Defense'] > 80]
print(newdf)
40/10:
import pandas as pd

df= pd.read_csv('https://github.com/firasm/bits/raw/master/pokemon.csv')
df['HP'].mean()
newdf = df[df['Defense'] > 80]
print(newdf)
40/11:
import pandas as pd

df= pd.read_csv('https://github.com/firasm/bits/raw/master/pokemon.csv')
df['HP'].mean()
print(df.iloc[2,1])
40/12:
import pandas as pd

df= pd.read_csv('https://github.com/firasm/bits/raw/master/pokemon.csv')
print(df.head(4)
print(df.iloc[2,1])
40/13:
import pandas as pd

df= pd.read_csv('https://github.com/firasm/bits/raw/master/pokemon.csv')
print(df.head(4))
print(df.iloc[2,1])
40/14:
import pandas as pd

df= pd.read_csv('https://github.com/firasm/bits/raw/master/pokemon.csv')
print(df.head(4))
print(df.iloc[2,2])
40/15:
import pandas as pd

df= pd.read_csv('https://github.com/firasm/bits/raw/master/pokemon.csv')
print(df.head(4))
df.loc[df['HP'] == "60"]
40/16:
import pandas as pd

df= pd.read_csv('https://github.com/firasm/bits/raw/master/pokemon.csv')
print(df.head(4))
df.loc[df['HP'] == '60']
40/17:
import pandas as pd

df= pd.read_csv('https://github.com/firasm/bits/raw/master/pokemon.csv')
df.loc[df['HP'] == '60']
40/18:
import pandas as pd

df= pd.read_csv('https://github.com/firasm/bits/raw/master/pokemon.csv')
print(df.head(4)
df.loc[df['HP'] == '60']
40/19:
import pandas as pd

df= pd.read_csv('https://github.com/firasm/bits/raw/master/pokemon.csv')
print(df.head(4))
df.loc[df['HP'] == '60']
40/20:
import pandas as pd

df= pd.read_csv('https://github.com/firasm/bits/raw/master/pokemon.csv')
print(df.head(4))
df.loc[df['Attack'] == '100.0']
40/21:
import pandas as pd

df= pd.read_csv('https://github.com/firasm/bits/raw/master/pokemon.csv')
print(df.head(4))
print(df.loc[df['Attack'] == '100.0'])
40/22:
import pandas as pd

df= pd.read_csv('https://github.com/firasm/bits/raw/master/pokemon.csv')
print(df.loc[df['Attack'] == '100.0'])
40/23:
import pandas as pd

df= pd.read_csv('https://github.com/firasm/bits/raw/master/pokemon.csv')
df.loc[df['Attack'] == '100.0']
40/24:
import pandas as pd

df= pd.read_csv('https://github.com/firasm/bits/raw/master/pokemon.csv')
df.loc[df['Attack'] >= '100.0']
40/25:
import pandas as pd

df= pd.read_csv('https://github.com/firasm/bits/raw/master/pokemon.csv')
df.loc[df['Attack'] >= '100.0']
40/26:
import pandas as pd

df= pd.read_csv('https://github.com/firasm/bits/raw/master/pokemon.csv')
df.loc[df['Attack'] => '100.0']
40/27:
import pandas as pd

df= pd.read_csv('https://github.com/firasm/bits/raw/master/pokemon.csv')
df.loc[df['Attack'] == '100.0']
40/28:
import pandas as pd

df= pd.read_csv('https://github.com/firasm/bits/raw/master/pokemon.csv')
df.loc[df['Attack'] > '100.0']
40/29:
import pandas as pd

df= pd.read_csv('https://github.com/firasm/bits/raw/master/pokemon.csv')
df.loc[df['Attack'] > 100.0]
40/30:
import pandas as pd

df= pd.read_csv('https://github.com/firasm/bits/raw/master/pokemon.csv')
df.loc[df['Attack'] == 100.0]
42/1:
import pandas as pd

df= pd.read_csv('https://github.com/firasm/bits/raw/master/pokemon.csv')
print(df)
42/2: df.describe(include=[np.number])
42/3:
import pandas as pd

df= pd.read_csv('https://github.com/firasm/bits/raw/master/pokemon.csv')
print(df)
42/4: df.describe()
42/5: df.describe(include=['category'])
42/6: print(df)
42/7:
newdf = df.drop(columns=['Generation', 'Sp. Atk', 'Sp. Def', 'Total', '#'])
newdf
42/8:
df2=newdf.dropna()
df2
42/9:
df2.reset_index(drop=True)
df2
42/10: df2.drop(columns=['index'])
42/11: df2.reset_index(drop=True)
42/12: df2.drop(columns=['index'])
42/13:
df2.reset_index(drop=True)
df2
42/14: df2 = df2.reset_index()
42/15:
df2 = df2.reset_index()
df2
42/16: df3 = df2.drop(columns=['Generation', 'Sp. Atk', 'Sp. Def', 'Total', '#'])
42/17: df3 = df2.drop(columns=['index'])
42/18:
df3 = df2.drop(columns=['index'])
df3
42/19: df3['Weighted Score']  = df3['HP'] - (0.8*df3['Cost']
42/20: df3['Weighted Score']  = df3['HP'] - (0.8*df3['Cost'])
42/21: df3['Weighted Score']  = df3['HP'] - (0.8*df3['HP'])
42/22:
df3['Weighted Score']  = df3['HP'] - (0.8*df3['HP'])
df3
42/23:
df3['Weighted Score']  = df3['HP'] - (0.8*df3['HP']) + df3['Attack'] - (0.6*df3['Attack'])
df3
42/24:
df3['Weighted Score']  = df3['HP'] - (0.8*df3['HP']) + df3['Attack'] - (0.6*df3['Attack'] + df3['Defense'] -(0.7*df3['Defense'])
df3
42/25:
df3['Weighted Score']  = df3['HP'] - (0.8*df3['HP']) + df3['Attack'] - (0.6*df3['Attack']) + df3['Defense'] - (0.7*df3['Defense'])
df3
42/26:
df3['Weighted Score']  = df3['HP'] - (0.8*df3['HP']) + df3['Attack'] - (0.6*df3['Attack']) + df3['Defense'] - (0.7*df3['Defense']) + df3['Speed'] - (0.9*df3['Speed'])
df3
42/27: df.to_csv('lab05_task2.csv' , index = False)
42/28: df3.to_csv('lab05_task2.csv' , index = False)
44/1:
import pandas as pd
import numpy as np
import matplotlib.pyplot as pl
import seaborn as sns
44/2:
newdf = pd.read_csv('lab05_task2')
print(newdf)
44/3: # Your solution here
47/1: # Your solution here
47/2:
newdf = pd.read_csv('https://github.com/ubco-W2022T2-data301/lab05-DARTH-LAL/blob/main/lab05_task2.csv')
newdf
47/3:
import pandas as pd
import numpy as np
import matplotlib.pyplot as pl
import seaborn as sns
47/4:
newdf = pd.read_csv('https://github.com/ubco-W2022T2-data301/lab05-DARTH-LAL/blob/main/lab05_task2.csv')
newdf
47/5:
newdf = pd.read_csv('lhttps://github.com/ubco-W2022T2-data301/lab05-DARTH-LAL/blob/main/lab05_task2.csv')
newdf
47/6:
newdf = pd.read_csv('https://github.com/ubco-W2022T2-data301/lab05-DARTH-LAL/blob/main/lab05_task2.csv')
newdf
47/7:
url = 'https://github.com/ubco-W2022T2-data301/lab05-DARTH-LAL/blob/main/lab05_task2.csv'
newdf = pd.read_csv(url , index_col = 0)
newdf
47/8:
newdf = pd.read_csv('https://github.com/ubco-W2022T2-data301/lab05-DARTH-LAL/blob/main/lab05_task2.csv')
newdf
47/9:
newdf = pd.read_csv('https://github.com/ubco-W2022T2-data301/lab05-DARTH-LAL/blob/main/lab05_task2.csv')
newdf
47/10:
newdf = pd.read_csv('lab05_task2.csv')
newdf
48/1:
import pandas as pd
import numpy as np
48/2:
df = pd.read_csv('https://github.com/firasm/bits/raw/master/pokemon.csv')
df
48/3:
df = pd.read_csv('https://gist.githubusercontent.com/aakashns/f6a004fa20c84fec53262f9a8bfee775/raw/f309558b1cf5103424cef58e2ecb8704dcd4d74c/italy-covid-daywise.csv')
df
48/4:
df = pd.read_csv('https://gist.githubusercontent.com/aakashns/f6a004fa20c84fec53262f9a8bfee775/raw/f309558b1cf5103424cef58e2ecb8704dcd4d74c/italy-covid-daywise.csv')
df.head(13)
48/5: df.first_valid_index()
48/6: df.apply(pd.Series.first_valid_index)
48/7:
df.apply(pd.Series.first_valid_index)
df.head(111:1115)
48/8:
df.apply(pd.Series.first_valid_index)
df.head([111:1115])
48/9:
df.apply(pd.Series.first_valid_index)
df.iloc[111:115]
48/10:
df.apply(pd.Series.first_valid_index)
df.iloc[111:115]
48/11:
df.apply(pd.Series.first_valid_index)
df.iloc[111:115]
48/12: df.isna()
48/13: df.isna().sum()
48/14: df.isna()
48/15: df.isna().count()
48/16: df.count().isna()
48/17: df.isna().COUNT()
48/18: df.isna().count()
48/19: df['incident_rate']  = df['new_cases']/ df['new_tests]
48/20: df['incident_rate']  = df['new_cases']/ df['new_tests']
48/21:
df['incident_rate']  = df['new_cases']/ df['new_tests']
df
48/22:
df2 = df['incident_rate']  = df['new_cases']/ df['new_tests']
df2
48/23:
df2 = df['incident_rate']  = df['new_cases']/ df['new_tests']
df2
48/24:
df['incident_rate']  = df['new_cases']/ df['new_tests']
df2
48/25:
df['incident_rate']  = df['new_cases']/ df['new_tests']
df
48/26:
df['incident_rate']  = df['new_cases']/ df['new_tests']
df.head(111)
48/27:
df['incident_rate']  = df['new_cases']/ df['new_tests']
df
48/28:
df['incident_rate']  = df['new_cases']/ df['new_tests']
df.head(112)
48/29:
df['incident_rate']  = df['new_cases']/ df['new_tests']
df
48/30: df['incident_rate'].mean()
48/31: datafiltered = datafiltered_df.dropna(axis='columns')
48/32: datafiltered = df.dropna(axis='columns')
48/33:
datafiltered = df.dropna(axis='columns')
datafiltered
48/34:
datafiltered = df.dropna(axis='columns')
datafiltered.head(120)
48/35: datafiltered = df.dropna()
48/36:
datafiltered = df.dropna()
datafiltered
48/37:
datafiltered = df.dropna()
datafiltered
48/38: datafiltered.describe.()
48/39: datafiltered.describe.().T
48/40: datafiltered.describe().T
48/41: datafiltered.to_csv('datafiltered.csv' , index = False)
46/1:
df = pd.read_csv('datafiltered.csv')
df
46/2:
import pandas as pd
import numpy as np
import matplotlib
46/3:
df = pd.read_csv('datafiltered.csv')
df
46/4:
df = df.drop(columns=['index'])
df
46/5: df.sample(10)
46/6: df.groupby(df.date.dt.month)['date'].sum()
46/7: df.groupby(df.date.dt.month)['date']
46/8: df.groupby(df.date.dt.month)['new_cases']
47/11: ax_pokemon_plot1 = sns.scatterplot(x ='Attack' , y ='Speed')
47/12:
import pandas as pd
import numpy as np
import matplotlib.pyplot as pl
import seaborn as sns
47/13:
newdf = pd.read_csv('lab05_task2.csv')
newdf
47/14:
df = pd.read_csv('https://github.com/firasm/bits/raw/master/pokemon.csv')
df
47/15: ax_pokemon_plot1 = sns.scatterplot(df['plot 1'])
47/16: ax_pokemon_plot1 = sns.scatterplot(newdf['plot 1'])
47/17: ax_pokemon_plot1 = sns.scatterplot(newdf['Attack'])
47/18: ax_pokemon_plot1 = sns.scatterplot(x='Attack' , y ='Speed' , data=newdf)
45/1:
import pandas as pd

df= pd.read_csv('https://github.com/firasm/bits/raw/master/pokemon.csv')
print(df)
47/19:
import pandas as pd
import numpy as np
import matplotlib.pyplot as pl
import seaborn as sns
47/20:
newdf = pd.read_csv('lab05_task2.csv')
newdf
47/21:
df = pd.read_csv('https://github.com/firasm/bits/raw/master/pokemon.csv')
df
47/22:
sns.set_style('whitegrid')
ax_pokemon_plot1 = sns.scatterplot(x='Attack' , y ='Speed' , data=newdf , )
47/23:
sns.set_style('whitegrid')
ax_pokemon_plot1 = sns.scatterplot(x='Pokemon Attack Points (0-190 pts)' , y ='Pokemon Speed Points (0-180 pts)' , data=newdf , )
47/24:
sns.set_style('whitegrid')
ax_pokemon_plot1 = sns.scatterplot(x='Pokemon Attack Points (0-190 pts)' , y ='Pokemon Speed Points (0-180 pts)' , data=newdf )
47/25:
sns.set_style('whitegrid')
ax_pokemon_plot1 = sns.scatterplot(x= 'Pokemon Attack Points (0-190 pts)' , y ='Pokemon Speed Points (0-180 pts)' , data=newdf )
47/26:
sns.set_style('whitegrid')
ax_pokemon_plot1 = sns.scatterplot(x= 'PokemonAttack Points (0-190 pts)' , y ='Pokemon Speed Points (0-180 pts)' , data=newdf )
47/27:
sns.set_style('whitegrid')
ax_pokemon_plot1 = sns.scatterplot(x= 'Pokemon)' , y ='Pokemon Speed Points (0-180 pts)' , data=newdf )
47/28:
sns.set_style('whitegrid')
ax_pokemon_plot1 = sns.scatterplot(x= 'Pokemon' , y ='Pokemon Speed Points (0-180 pts)' , data=newdf )
47/29:
sns.set_style('whitegrid')
ax_pokemon_plot2 = sns.scatterplot(x = 'Pokemon Attack Points (0-190 pts)' , y ='Pokemon Speed Points (0-180 pts)' , data=newdf )
47/30:
sns.set_style('whitegrid')
ax_pokemon_plot1 = sns.scatterplot(x = 'Pokemon Attack Points (0-190 pts)' , y ='Pokemon Speed Points (0-180 pts)' , data=newdf )
47/31:
sns.set_style('whitegrid')
ax_pokemon_plot1 = sns.scatterplot(x = "Pokemon Attack Points (0-190 pts)" , y ='Pokemon Speed Points (0-180 pts)' , data=newdf )
47/32:
sns.set_style('whitegrid')
ax_pokemon_plot1 = sns.scatterplot(x='Attack' , y ='Speed' , data=newdf , )
47/33:
sns.set_style('whitegrid')
ax_pokemon_plot1 = sns.scatterplot(x='Attack' , y ='Speed' , data=newdf , xlabel = 'Pokemon Attack Points (0-190 pts)')
47/34:
sns.set_style('whitegrid')
ax_pokemon_plot1 = sns.scatterplot(x='Attack' , y ='Speed' , data=newdf ,)
47/35:
sns.set_style('whitegrid')
ax_pokemon_plot1 = sns.scatterplot(x='Attack' , y ='Speed' , data=newdf ,)
AxesSubplot: xlabel='tip'
47/36:
sns.set_style('whitegrid')
ax_pokemon_plot1 = sns.scatterplot(x='Attack' , y ='Speed' , data=newdf ,).set_title('Relationship between Pokemon Attack and Speed')
47/37:
sns.set_style('whitegrid')
ax_pokemon_plot1 = sns.scatterplot(x='Attack' , y ='Speed' , data=newdf ,).set_title('Relationship between Pokemon Attack and Speed')
ax_pokemon_plot1.set_xlabel('Day of Week', fontdict={'size': 15})
47/38:
sns.set_style('whitegrid')
ax_pokemon_plot1 = sns.scatterplot(x='Attack' , y ='Speed' , data=newdf ,).set_title('Relationship between Pokemon Attack and Speed')

ax_pokemon_plot1.set_xlabel('Day of Week')
47/39:
sns.set_style('whitegrid')
ax_pokemon_plot1 = sns.scatterplot(x='Attack' , y ='Speed' , data=newdf ,).set_title('Relationship between Pokemon Attack and Speed').set_xlabel('Day of Week')
47/40:
import matplotlib.pyplot as plt
sns.set_style('whitegrid')
ax_pokemon_plot1 = sns.scatterplot(x='Attack' , y ='Speed' , data=newdf ,).set_title('Relationship between Pokemon Attack and Speed')

ax_pokemon_plot1.set_xlabel('Day of Week')
47/41:
sns.set_style('whitegrid')
ax_pokemon_plot1 = sns.scatterplot(x='Attack' , y ='Speed' , data=newdf ,).set_title('Relationship between Pokemon Attack and Speed')
51/1:
sns.set_style('whitegrid')
ax_pokemon_plot1 = sns.scatterplot(x='Attack' , y ='Speed' , data=newdf ,).set(title='Sample Title', xlabel='Day', ylabel='Tip')
51/2:
import pandas as pd
import numpy as np
import matplotlib.pyplot as pl
import seaborn as sns
51/3:
newdf = pd.read_csv('lab05_task2.csv')
newdf
51/4:
df = pd.read_csv('https://github.com/firasm/bits/raw/master/pokemon.csv')
df
51/5: # Your Solution Here
51/6: ax_pokemon_plot1 = sns.scatterplot(x='Attack' , y ='Speed' , data=newdf)
51/7:
sns.set_style('whitegrid')
ax_pokemon_plot1 = sns.scatterplot(x='Attack' , y ='Speed' , data=newdf ,).set(title='Sample Title', xlabel='Day', ylabel='Tip')
51/8:
sns.set_style('whitegrid')
ax_pokemon_plot1 = sns.scatterplot(x='Attack' , y ='Speed' , data=newdf ,).set(title='Relationship between Pokemon Attack and Speed', xlabel='Pokemon Attack Points (0-190 pts)', ylabel='Pokemon Speed Points (0-180 pts)')
51/9:
import pandas as pd
import numpy as np
import matplotlib.pyplot as pl
import seaborn as sns
51/10:
newdf = pd.read_csv('lab05_task2.csv')
newdf
51/11:
df = pd.read_csv('https://github.com/firasm/bits/raw/master/pokemon.csv')
df
51/12: # Your Solution Here
51/13: ax_pokemon_plot1 = sns.scatterplot(x='Attack' , y ='Speed' , data=newdf)
51/14:
sns.set_style('whitegrid')
ax_pokemon_plot1 = sns.scatterplot(x='Attack' , y ='Speed' , data=newdf ,fontdict={'size': 30).set(title='Relationship between Pokemon Attack and Speed', xlabel='Pokemon Attack Points (0-190 pts)', ylabel='Pokemon Speed Points (0-180 pts)')
51/15:
sns.set_style('whitegrid')
ax_pokemon_plot1 = sns.scatterplot(x='Attack' , y ='Speed' , data=newdf ,fontdict={'size': 30}).set(title='Relationship between Pokemon Attack and Speed', xlabel='Pokemon Attack Points (0-190 pts)', ylabel='Pokemon Speed Points (0-180 pts)')
51/16:
sns.set_style('whitegrid')
ax_pokemon_plot1 = sns.scatterplot(x='Attack' , y ='Speed' , data=newdf).set(title='Relationship between Pokemon Attack and Speed', xlabel='Pokemon Attack Points (0-190 pts)', ylabel='Pokemon Speed Points (0-180 pts)')
51/17:
sns.set_style('whitegrid')
ax_pokemon_plot1 = sns.scatterplot(x='Attack' , y ='Speed' , data=newdf).set(title='Relationship between Pokemon Attack and Speed', xlabel='Pokemon Attack Points (0-190 pts)', ylabel='Pokemon Speed Points (0-180 pts)')
ax.set_xlim(1, 70)
51/18:
sns.set_style('whitegrid')
ax_pokemon_plot1 = sns.scatterplot(x='Attack' , y ='Speed' , data=newdf).set(title='Relationship between Pokemon Attack and Speed', xlabel='Pokemon Attack Points (0-190 pts)', ylabel='Pokemon Speed Points (0-180 pts)')
ax_pokemon_plot1.set_xlim(1, 70)
51/19:
sns.set_style('whitegrid')
ax_pokemon_plot1 = sns.scatterplot(x='Attack' , y ='Speed' , data=newdf).set(title='Relationship between Pokemon Attack and Speed', xlabel='Pokemon Attack Points (0-190 pts)', ylabel='Pokemon Speed Points (0-180 pts)' , xlim(0))
ax_pokemon_plot1.set_xlim(1, 70)
51/20:
sns.set_style('whitegrid')
ax_pokemon_plot1 = sns.scatterplot(x='Attack' , y ='Speed' , data=newdf).set(title='Relationship between Pokemon Attack and Speed', xlabel='Pokemon Attack Points (0-190 pts)', ylabel='Pokemon Speed Points (0-180 pts)')
ax_pokemon_plot1.set_xlim(1, 70)
51/21:
sns.set_style('whitegrid')
ax_pokemon_plot1 = sns.scatterplot(x='Attack' , y ='Speed' , data=newdf).set(title='Relationship between Pokemon Attack and Speed', xlabel='Pokemon Attack Points (0-190 pts)', ylabel='Pokemon Speed Points (0-180 pts)')
51/22:
# RQ1
ax_pokemon_plot2 = sns.scatterplot(x='Legendary' , y ='Weighted Score' , data=newdf)
51/23:
# RQ1
ax_pokemon_plot2 = sns.scatterplot(x='Legendary' ==True , y ='Weighted Score' , data=newdf)
51/24:
# RQ1
ax_pokemon_plot2 = sns.scatterplot(x='Legendary' ==True , y ='Weighted Score' , data=newdf)
ax_pokemon_plot3 = sns.scatterplot(x='Legendary' ==False , y ='Weighted Score' , data=newdf)
51/25:
# RQ1
ax_pokemon_plot2 = sns.scatterplot(x='Legendary' ==True , y ='Weighted Score' , data=newdf)
ax_pokemon_plot3 = sns.scatterplot(x='Legendary' ==False , y ='Weighted Score' , data=newdf)
51/26:
# RQ1
ax_pokemon_plot2 = sns.scatterplot(x='Legendary', y ='Weighted Score' , data=newdf)
52/1: df.describe().T
52/2: # This data was provided by Rounak Banik who is a Data Science Fellow at Mckinsey & Company. The dataset conatins information on all 802 pokemon from all seven generations of pokemon , the information inlcudes name , type , total , HP , Attcak , Defence etc.
52/3:
import pandas as pd

df= pd.read_csv('https://github.com/firasm/bits/raw/master/pokemon.csv')
print(df)
52/4: df.describe().T
52/5: df.describe(include=[np.number])
52/6:
import random
import numpy as np
df.describe(include=[np.number])
52/7:
import random
import numpy as np
df.describe(include=[np.number])
52/8: df.describe(exclude=[np.number])
51/27:
# RQ1
ax_pokemon_plot2 = sns.barplot(x='Legendary', y ='Weighted Score' , data=newdf)
51/28: ax_pokemon_plot2 = sns.barplot(x='Legendary', y ='Weighted Score' , data=newdf)
51/29: ax_pokemon_plot2 = sns.barplot(x='Legendary', y ='Weighted Score' , data=newdf)set(title='Relationship between Pokemon Attack and Speed', xlabel='Legenday VS Non-Legndary Pokemon', ylabel='Pokemon Speed Points (0-180 pts)')
51/30: ax_pokemon_plot2 = sns.barplot(x='Legendary', y ='Weighted Score' , data=newdf)set(title='Relationship between Pokemon Attack and Speed', xlabel='Pokemon(Legnedary = True , Non-Legendary=False)
51/31: ax_pokemon_plot2 = sns.barplot(x='Legendary', y ='Weighted Score' , data=newdf)set(title='Relationship between Pokemon Attack and Speed', xlabel='Pokemon(Legnedary = True , Non-Legendary=False')
51/32: ax_pokemon_plot2 = sns.barplot(x='Legendary', y ='Weighted Score' , data=newdf).set(title='Relationship between Pokemon Attack and Speed', xlabel='Pokemon(Legnedary = True , Non-Legendary=False')
51/33: ax_pokemon_plot2 = sns.barplot(x='Legendary', y ='Weighted Score' , data=newdf).set(title='Relationship between Pokemon Attack and Speed', xlabel='Pokemon(Legnedary = True , Non-Legendary=False)')
51/34: ax_pokemon_plot2 = sns.barplot(x='Legendary', y ='Weighted Score' , data=newdf).set(title='Relationship between Pokemon Attack and Speed', xlabel='Pokemon(Legnedary = True , Non-Legendary=False)' )
51/35: ax_pokemon_plot2 = sns.barplot(x='Legendary', y ='Weighted Score' , data=newdf).set(title='Legendary VS Non-Legendary', xlabel='Pokemon(Legnedary = True , Non-Legendary=False)' )
51/36: ax_pokemon_plot3 = sns.barplot(x='Legendary', y ='Weighted Score' , data=newdf).set(title='Legendary VS Non-Legendary', xlabel='Pokemon(Legnedary = True , Non-Legendary=False)' )
51/37: ax_pokemon_plot3 = sns.barplot(x='Type', y ='Weighted Score' , data=newdf).set(title='Legendary VS Non-Legendary', xlabel='Pokemon(Legnedary = True , Non-Legendary=False)' )
51/38: ax_pokemon_plot3 = sns.barplot(x='Type 1', y ='Weighted Score' , data=newdf).set(title='Legendary VS Non-Legendary', xlabel='Pokemon(Legnedary = True , Non-Legendary=False)' )
51/39: ax_pokemon_plot3 = sns.barplot(x='Type 1', y ='Weighted Score' , data=newdf).set(title='Comparison of Type 1 Pokemon', xlabel='Pokemon(Legnedary = True , Non-Legendary=False)' )
51/40: ax_pokemon_plot3 = sns.barplot(x='Type 1', y ='Weighted Score' , data=newdf).set(title='Comparison of Type 1 Pokemon', xlabel='' )
51/41: ax_pokemon_plot2 = sns.barplot(x='Legendary', y ='Weighted Score' , data=newdf).set(title='Legendary VS Non-Legendary', xlabel='Pokemon(Legnedary = True , Non-Legendary=False)' )
51/42:
sns.set_style('whitegrid')
ax_pokemon_plot1 = sns.scatterplot(x='Attack' , y ='Speed' , data=newdf)
ax_pokemon_plot1.xlabel('Sales Quarter', size=16, fontstyle='italic', weight=900)
52/9: # This data was provided by Rounak Banik who is a Data Science Fellow at Mckinsey & Company. The dataset conatins information on all 802 pokemon from all seven generations of pokemon , the information inlcudes name , type , total , HP , Attcak , Defence etc.
52/10:
df2 = df.dropna(subset = ['HP', 'Attack', 'Defense', 'Speed'], inplace=True)
df2
52/11:
df2 = df.dropna(subset = ['HP', 'Attack', 'Defense', 'Speed'], inplace=True)
df2
52/12:
df2 = df.dropna(subset = ['HP', 'Attack', 'Defense', 'Speed'], inplace=True)
df2
52/13:
df2 = df.dropna(subset = ['HP', 'Attack', 'Defense', 'Speed'])
df2
52/14:
df2 = df2.reset_index()
df2
52/15:
df3 = df2.drop(columns=['index'])
df3
52/16:
df3['Weighted Score']  = df3['HP'] - (0.8*df3['HP']) + df3['Attack'] - (0.6*df3['Attack']) + df3['Defense'] - (0.7*df3['Defense']) + df3['Speed'] - (0.9*df3['Speed'])
df3
52/17: df3.to_csv('lab05_task2.csv' , index = False)
52/18:
df3['Weighted Score']  = df3['HP'] - (0.8*df3['HP']) + df3['Attack'] - (0.6*df3['Attack']) + df3['Defense'] - (0.7*df3['Defense']) + df3['Speed'] - (0.9*df3['Speed'])
df3
52/19: df3.to_csv('lab05_task2.csv' , index = False)
51/43:
import pandas as pd
import numpy as np
import matplotlib.pyplot as pl
import seaborn as sns
51/44:
sns.set_style('whitegrid')
ax_pokemon_plot1 = sns.scatterplot(x='Attack' , y ='Speed' , data=newdf)
ax_pokemon_plot1.set_title('Sample Title', fontdict={'size': 30, 'weight': 'bold'})
51/45:
sns.set_style('whitegrid')
ax_pokemon_plot1 = sns.scatterplot(x='Attack' , y ='Speed' , data=newdf)
ax_pokemon_plot1.set_title('Relationship between Pokemon Attack and Speed', fontdict={'size': 30, 'weight': 'bold'})
51/46:
sns.set_style('whitegrid')
ax_pokemon_plot1 = sns.scatterplot(x='Attack' , y ='Speed' , data=newdf)
ax_pokemon_plot1.set_title('Relationship between Pokemon Attack and Speed', fontdict={'size': 10, 'weight': 'bold'})
51/47:
sns.set_style('whitegrid')
ax_pokemon_plot1.set_title('Relationship between Pokemon Attack and Speed', fontdict={'size': 10, 'weight': 'bold'})
51/48:
sns.set_style('whitegrid')
ax_pokemon_plot1.set_title('Relationship between Pokemon Attack and Speed', fontdict={'size': 10, 'weight': 'bold'})
51/49:
sns.set_style('whitegrid')
ax_pokemon_plot1.set_title('Relationship between Pokemon Attack and Speed', fontdict={'size': 10})
51/50:
sns.set_style('whitegrid')
ax_pokemon_plot1.set_title('Relationship between Pokemon Attack and Speed', fontdict={'size': 10})
51/51:
sns.set_style('whitegrid')
ax_pokemon_plot1.set(title = 'Relationship between Pokemon Attack and Speed', fontdict={'size': 10})
51/52:
sns.set_style('whitegrid')
ax_pokemon_plot1.set(title = 'Relationship between Pokemon Attack and Speed')
51/53:
sns.set_style('whitegrid')
ax_pokemon_plot1 = sns.scatterplot(x='Attack' , y ='Speed' , data=newdf)
ax_pokemon_plot1.set_title('Relationship between Pokemon Attack and Speed', fontdict={'size': 10, 'weight': 'bold'})
51/54:
sns.set_style('whitegrid')
ax_pokemon_plot1.set(xlabel='x-axis label', ylabel='y-axis label')
51/55: sns.set_style('whitegrid')
51/56:
sns.set_style('whitegrid')
ax_pokemon_plot1.set(xlabel ="GFG X", ylabel = "GFG Y", title ='some title')
51/57: ax_pokemon_plot1.set(xlabel ="GFG X", ylabel = "GFG Y", title ='some title')
51/58: ax_pokemon_plot1.set(xlabel ="Pokemon Attack Points (0-190 pts)", ylabel = "Pokemon Speed Points (0-180 pts)", title ='Relationship between Pokemon Attack and Speed')
49/1:
import random
import numpy as np
datafiltered.describe(include=[np.number])
49/2:
import pandas as pd
import numpy as np
49/3:
df = pd.read_csv('https://gist.githubusercontent.com/aakashns/f6a004fa20c84fec53262f9a8bfee775/raw/f309558b1cf5103424cef58e2ecb8704dcd4d74c/italy-covid-daywise.csv')
df.head(13)
49/4:
df.apply(pd.Series.first_valid_index)
df.iloc[111:115]
49/5: df.isna().count()
49/6:
df['incident_rate']  = df['new_cases']/ df['new_tests']
df
49/7: df['incident_rate'].mean()
49/8:
datafiltered = df.dropna()
datafiltered
49/9:
import random
import numpy as np
datafiltered.describe(include=[np.number])
49/10: datafiltered.describe(exclude=[np.number])
51/59: ax_pokemon_plot1.set(xlabel ="Pokemon Attack Points (0-190 pts)", ylabel = "Pokemon Speed Points (0-180 pts)", title ='Relationship between Pokemon Attack and Speed')
52/20:
df2 = newdf.dropna(subset = ['HP', 'Attack', 'Defense', 'Speed'])
df2
52/21:
newdf = df.drop(columns=['Generation', 'Sp. Atk', 'Sp. Def', 'Total', '#'])
newdf
52/22:
df2 = newdf.dropna(subset = ['HP', 'Attack', 'Defense', 'Speed'])
df2
52/23: df3.to_csv('data/lab05_task2.csv' , index = False)
51/60:
ax_pokemon_plot1.set(xlabel ="Pokemon Attack Points (0-190 pts)", ylabel = "Pokemon Speed Points (0-180 pts)", title ='Relationship between Pokemon Attack and Speed')
ax_pokemon_plot1.figure
51/61:
ax_pokemon_plot1.set(title ='Relationship between Pokemon Attack and Speed' , fontdict ={'size':15})
ax_pokemon_plot1.set_xlabel('Pokemon Attack Points (0-190 pts)', fontdict={'size': 15})
chart.set_ylabel('Pokemon Speed Points (0-180 pts)', fontdict={'size': 15})
ax_pokemon_plot1.figure
51/62:
import pandas as pd
import numpy as np
import matplotlib.pyplot as pl
import seaborn as sns
51/63:
newdf = pd.read_csv('data/lab05_task2.csv')
newdf
51/64:
df = pd.read_csv('https://github.com/firasm/bits/raw/master/pokemon.csv')
df
51/65: # Your Solution Here
51/66: ax_pokemon_plot1 = sns.scatterplot(x='Attack' , y ='Speed' , data=newdf)
51/67:
ax_pokemon_plot1.set(title ='Relationship between Pokemon Attack and Speed' , fontdict ={'size':15})
ax_pokemon_plot1.set_xlabel('Pokemon Attack Points (0-190 pts)', fontdict={'size': 15})
chart.set_ylabel('Pokemon Speed Points (0-180 pts)', fontdict={'size': 15})
ax_pokemon_plot1.figure
51/68:
ax_pokemon_plot1.set(title ='Relationship between Pokemon Attack and Speed' , fontdict ={'size':15})
ax_pokemon_plot1.set_xlabel('Pokemon Attack Points (0-190 pts)', fontdict={'size': 15})
ax_pokemon_plot1.set_ylabel('Pokemon Speed Points (0-180 pts)', fontdict={'size': 15})
ax_pokemon_plot1.figure
51/69:
ax_pokemon_plot1.set_title(title ='Relationship between Pokemon Attack and Speed' , fontdict ={'size':15})
ax_pokemon_plot1.set_xlabel('Pokemon Attack Points (0-190 pts)', fontdict={'size': 15})
ax_pokemon_plot1.set_ylabel('Pokemon Speed Points (0-180 pts)', fontdict={'size': 15})
ax_pokemon_plot1.figure
51/70:
ax_pokemon_plot1.set_title('Relationship between Pokemon Attack and Speed' , fontdict ={'size':15})
ax_pokemon_plot1.set_xlabel('Pokemon Attack Points (0-190 pts)', fontdict={'size': 15})
ax_pokemon_plot1.set_ylabel('Pokemon Speed Points (0-180 pts)', fontdict={'size': 15})
ax_pokemon_plot1.figure
51/71:
ax_pokemon_plot1.set_title('Relationship between Pokemon Attack and Speed' , fontdict ={'size':15})
ax_pokemon_plot1.set_xlabel('Pokemon Attack Points (0-190 pts)', fontdict={'size': 10})
ax_pokemon_plot1.set_ylabel('Pokemon Speed Points (0-180 pts)', fontdict={'size': 15})
ax_pokemon_plot1.figure
51/72:
ax_pokemon_plot1.set_title('Relationship between Pokemon Attack and Speed' , fontdict ={'size':15})
ax_pokemon_plot1.set_xlabel('Pokemon Attack Points (0-190 pts)', fontdict={'size': 14})
ax_pokemon_plot1.set_ylabel('Pokemon Speed Points (0-180 pts)', fontdict={'size': 15})
ax_pokemon_plot1.figure
51/73:
ax_pokemon_plot1.set_title('Relationship between Pokemon Attack and Speed' , fontdict ={'size':15})
ax_pokemon_plot1.set_xlabel('Pokemon Attack Points (0-190 pts)', fontdict={'size': 14})
ax_pokemon_plot1.set_ylabel('Pokemon Speed Points (0-180 pts)', fontdict={'size': 14})
ax_pokemon_plot1.figure
51/74:
ax_pokemon_plot1.set_title('Relationship between Pokemon Attack and Speed' , fontdict ={'size':15})
ax_pokemon_plot1.set_xlabel('Pokemon Attack Points (0-190 pts)', fontdict={'size': 14})
ax_pokemon_plot1.set_ylabel('Pokemon Speed Points (0-180 pts)', fontdict={'size': 14})
ax_pokemon_plot1.set_xlim(1, 70)
ax_pokemon_plot1.figure
51/75:
ax_pokemon_plot1.set_title('Relationship between Pokemon Attack and Speed' , fontdict ={'size':15})
ax_pokemon_plot1.set_xlabel('Pokemon Attack Points (0-190 pts)', fontdict={'size': 14})
ax_pokemon_plot1.set_ylabel('Pokemon Speed Points (0-180 pts)', fontdict={'size': 14})
ax_pokemon_plot1.set_xlim(1, 800)
ax_pokemon_plot1.figure
51/76:
ax_pokemon_plot1.set_title('Relationship between Pokemon Attack and Speed' , fontdict ={'size':15})
ax_pokemon_plot1.set_xlabel('Pokemon Attack Points (0-190 pts)', fontdict={'size': 14})
ax_pokemon_plot1.set_ylabel('Pokemon Speed Points (0-180 pts)', fontdict={'size': 14})
ax_pokemon_plot1.set_xlim(1,)
ax_pokemon_plot1.figure
51/77:
ax_pokemon_plot1.set_title('Relationship between Pokemon Attack and Speed' , fontdict ={'size':15})
ax_pokemon_plot1.set_xlabel('Pokemon Attack Points (0-190 pts)', fontdict={'size': 14})
ax_pokemon_plot1.set_ylabel('Pokemon Speed Points (0-180 pts)', fontdict={'size': 14})
ax_pokemon_plot1.set_xlim(1,)
ax_pokemon_plot1.figure
51/78:
ax_pokemon_plot1.set_title('Relationship between Pokemon Attack and Speed' , fontdict ={'size':15})
ax_pokemon_plot1.set_xlabel('Pokemon Attack Points (0-190 pts)', fontdict={'size': 14})
ax_pokemon_plot1.set_ylabel('Pokemon Speed Points (0-180 pts)', fontdict={'size': 14})
ax_pokemon_plot1.set_xlim(1,200)
ax_pokemon_plot1.figure
51/79:
ax_pokemon_plot1.set_title('Relationship between Pokemon Attack and Speed' , fontdict ={'size':15})
ax_pokemon_plot1.set_xlabel('Pokemon Attack Points (0-190 pts)', fontdict={'size': 14})
ax_pokemon_plot1.set_ylabel('Pokemon Speed Points (0-180 pts)', fontdict={'size': 14})
ax_pokemon_plot1.set_xlim(1,200)
ax_pokemon_plot1.set_ylim(1,200)
ax_pokemon_plot1.figure
51/80:
ax_pokemon_plot1.set_title('Relationship between Pokemon Attack and Speed' , fontdict ={'size':15})
ax_pokemon_plot1.set_xlabel('Pokemon Attack Points (0-190 pts)', fontdict={'size': 14})
ax_pokemon_plot1.set_ylabel('Pokemon Speed Points (0-180 pts)', fontdict={'size': 14})
ax_pokemon_plot1.set_xlim(0,200)
ax_pokemon_plot1.set_ylim(1,200)
ax_pokemon_plot1.figure
51/81:
ax_pokemon_plot1.set_title('Relationship between Pokemon Attack and Speed' , fontdict ={'size':15})
ax_pokemon_plot1.set_xlabel('Pokemon Attack Points (0-190 pts)', fontdict={'size': 14})
ax_pokemon_plot1.set_ylabel('Pokemon Speed Points (0-180 pts)', fontdict={'size': 14})
ax_pokemon_plot1.set_xlim(0,200)
ax_pokemon_plot1.set_ylim(0,200)
ax_pokemon_plot1.figure
51/82:
ax_pokemon_plot3 = sns.barplot(x='Type 1', y ='Weighted Score' , data=newdf)
ax_pokemon_plot3.set_xlabel('Pokemon Type)', fontdict={'size': 14})
ax_pokemon_plot3.set_ylabel('Weighted Score', fontdict={'size': 14})
ax_pokemon_plot3.set_xlim(0,200)
ax_pokemon_plot3.set_ylim(0,200)
ax_pokemon_plot3.figure
51/83:
ax_pokemon_plot3 = sns.barplot(x='Type 1', y ='Weighted Score' , data=newdf)
ax_pokemon_plot3.set_xlabel('Pokemon Type)', fontdict={'size': 14})
ax_pokemon_plot3.set_ylabel('Weighted Score', fontdict={'size': 14})
ax_pokemon_plot3.set_xlim(0,50)
ax_pokemon_plot3.set_ylim(0,50)
ax_pokemon_plot3.figure
51/84:
ax_pokemon_plot3 = sns.barplot(x='Type 1', y ='Weighted Score' , data=newdf)
ax_pokemon_plot3.set_xlabel('Pokemon Type)', fontdict={'size': 5})
ax_pokemon_plot3.set_ylabel('Weighted Score', fontdict={'size': 14})
ax_pokemon_plot3.set_xlim(0,50)
ax_pokemon_plot3.set_ylim(0,50)
ax_pokemon_plot3.figure
51/85:
ax_pokemon_plot3 = sns.barplot(x='Type 1', y ='Weighted Score' , data=newdf)
ax_pokemon_plot3.set_xlabel('Pokemon Type)', fontdict={'size': 5})
ax_pokemon_plot3.set_ylabel('Weighted Score', fontdict={'size': 14})
ax_pokemon_plot3.set_xlim(0,80)
ax_pokemon_plot3.set_ylim(0,50)
ax_pokemon_plot3.figure
51/86:
ax_pokemon_plot3 = sns.barplot(x='Type 1', y ='Weighted Score' , data=newdf)
ax_pokemon_plot3.set_xlabel('Pokemon Type)', fontdict={'size': 5})
ax_pokemon_plot3.set_ylabel('Weighted Score', fontdict={'size': 14})
ax_pokemon_plot3.set_xlim(0,100)
ax_pokemon_plot3.set_ylim(0,50)
ax_pokemon_plot3.figure
51/87:
ax_pokemon_plot3 = sns.barplot(x='Type 1', y ='Weighted Score' , data=newdf)
ax_pokemon_plot3.set_xlabel('Pokemon Type)', fontdict={'size': 5})
ax_pokemon_plot3.set_ylabel('Weighted Score', fontdict={'size': 14})
ax_pokemon_plot3.set_xlim(0,100)
ax_pokemon_plot3.set_ylim(0,100)
ax_pokemon_plot3.figure
51/88:
ax_pokemon_plot3 = sns.barplot(x='Type 1', y ='Weighted Score' , data=newdf)
ax_pokemon_plot3.set_xlabel('Pokemon Type)', fontdict={'size': 5})
ax_pokemon_plot3.set_ylabel('Weighted Score', fontdict={'size': 14})
ax_pokemon_plot3.set_xlim(0,200)
ax_pokemon_plot3.set_ylim(0,100)
ax_pokemon_plot3.figure
51/89:
ax_pokemon_plot3 = sns.barplot(x='Type 1', y ='Weighted Score' , data=newdf)
ax_pokemon_plot3.set_xlabel('Pokemon Type)', fontdict={'size': 5})
ax_pokemon_plot3.set_ylabel('Weighted Score', fontdict={'size': 14})
ax_pokemon_plot3.set_xlim(0,200)
ax_pokemon_plot3.set_ylim(0,200)
ax_pokemon_plot3.figure
51/90:
ax_pokemon_plot3 = sns.barplot(x='Type 1', y ='Weighted Score' , data=newdf)
ax_pokemon_plot3.set_xlabel('Pokemon Type)', fontdict={'size': 5})
ax_pokemon_plot3.set_ylabel('Weighted Score', fontdict={'size': 14})
ax_pokemon_plot3.set_xlim(0,125)
ax_pokemon_plot3.set_ylim(0,200)
ax_pokemon_plot3.figure
51/91:
ax_pokemon_plot3 = sns.barplot(x='Type 1', y ='Weighted Score' , data=newdf)
ax_pokemon_plot3.set_xlabel('Pokemon Type)', fontdict={'size': 5})
ax_pokemon_plot3.set_ylabel('Weighted Score', fontdict={'size': 14})
ax_pokemon_plot3.set_xlim(0,125)
ax_pokemon_plot3.set_ylim(0,125)
ax_pokemon_plot3.figure
51/92:
ax_pokemon_plot3 = sns.barplot(x='Type 1', y ='Weighted Score' , data=newdf)
ax_pokemon_plot3.set_xlabel('Pokemon Type)', fontdict={'size': 5})
ax_pokemon_plot3.set_ylabel('Weighted Score', fontdict={'size': 14})
ax_pokemon_plot3.set_xlim(0,50)
ax_pokemon_plot3.set_ylim(0,125)
ax_pokemon_plot3.figure
51/93:
ax_pokemon_plot3 = sns.barplot(x='Type 1', y ='Weighted Score' , data=newdf)
ax_pokemon_plot3.set_xlabel('Pokemon Type)', fontdict={'size': 5})
ax_pokemon_plot3.set_ylabel('Weighted Score', fontdict={'size': 14})
ax_pokemon_plot3.set_xlim(0,40)
ax_pokemon_plot3.set_ylim(0,125)
ax_pokemon_plot3.figure
51/94:
ax_pokemon_plot3 = sns.barplot(x='Type 1', y ='Weighted Score' , data=newdf)
ax_pokemon_plot3.set_xlabel('Pokemon Type)', fontdict={'size': 5})
ax_pokemon_plot3.set_ylabel('Weighted Score', fontdict={'size': 14})
ax_pokemon_plot3.set_xlim(0,10)
ax_pokemon_plot3.set_ylim(0,125)
ax_pokemon_plot3.figure
51/95:
ax_pokemon_plot3 = sns.barplot(x='Type 1', y ='Weighted Score' , data=newdf)
ax_pokemon_plot3.set_xlabel('Pokemon Type)', fontdict={'size': 5})
ax_pokemon_plot3.set_ylabel('Weighted Score', fontdict={'size': 14})
ax_pokemon_plot3.set_xlim(0,11)
ax_pokemon_plot3.set_ylim(0,125)
ax_pokemon_plot3.figure
51/96:
ax_pokemon_plot3 = sns.barplot(x='Type 1', y ='Weighted Score' , data=newdf)
ax_pokemon_plot3.set_xlabel('Pokemon Type)', fontdict={'size': 5})
ax_pokemon_plot3.set_ylabel('Weighted Score', fontdict={'size': 14})
ax_pokemon_plot3.set_xlim(0,14)
ax_pokemon_plot3.set_ylim(0,125)
ax_pokemon_plot3.figure
51/97:
ax_pokemon_plot3 = sns.barplot(x='Type 1', y ='Weighted Score' , data=newdf)
ax_pokemon_plot3.set_xlabel('Pokemon Type)', fontdict={'size': 5})
ax_pokemon_plot3.set_ylabel('Weighted Score', fontdict={'size': 14})
ax_pokemon_plot3.set_xlim(0,16)
ax_pokemon_plot3.set_ylim(0,125)
ax_pokemon_plot3.figure
51/98:
ax_pokemon_plot3 = sns.barplot(x='Type 1', y ='Weighted Score' , data=newdf)
ax_pokemon_plot3.set_xlabel('Pokemon Type)', fontdict={'size': 5})
ax_pokemon_plot3.set_ylabel('Weighted Score', fontdict={'size': 14})
ax_pokemon_plot3.set_xlim(0,20)
ax_pokemon_plot3.set_ylim(0,125)
ax_pokemon_plot3.figure
51/99:
ax_pokemon_plot3 = sns.barplot(x='Type 1', y ='Weighted Score' , data=newdf)
ax_pokemon_plot3.set_xlabel('Pokemon Type)', fontdict={'size': 5})
ax_pokemon_plot3.set_ylabel('Weighted Score', fontdict={'size': 14})
ax_pokemon_plot3.set_xlim(0,19)
ax_pokemon_plot3.set_ylim(0,125)
ax_pokemon_plot3.figure
51/100:
ax_pokemon_plot3 = sns.barplot(x='Type 1', y ='Weighted Score' , data=newdf)
ax_pokemon_plot3.set_xlabel('Pokemon Type)', fontdict={'size': 5})
ax_pokemon_plot3.set_ylabel('Weighted Score', fontdict={'size': 14})
ax_pokemon_plot3.set_xlim(0,18)
ax_pokemon_plot3.set_ylim(0,125)
ax_pokemon_plot3.figure
51/101:
ax_pokemon_plot3 = sns.barplot(x='Type 1', y ='Weighted Score' , data=newdf)
ax_pokemon_plot3.set_xlabel('Pokemon Type)', fontdict={'size': 5})
ax_pokemon_plot3.set_ylabel('Weighted Score', fontdict={'size': 14})
ax_pokemon_plot3.set_xlim(0,17)
ax_pokemon_plot3.set_ylim(0,125)
ax_pokemon_plot3.figure
51/102:
ax_pokemon_plot3 = sns.barplot(x='Type 1', y ='Weighted Score' , data=newdf)
ax_pokemon_plot3.set_xlabel('Pokemon Type)', fontdict={'size': 5})
ax_pokemon_plot3.set_ylabel('Weighted Score', fontdict={'size': 14})
ax_pokemon_plot3.set_xlim(0,18)
ax_pokemon_plot3.set_ylim(0,125)
ax_pokemon_plot3.figure
51/103:
ax_pokemon_plot3 = sns.barplot(x='Type 1', y ='Weighted Score' , data=newdf)
ax_pokemon_plot3.set_xlabel('Pokemon Type)', fontdict={'size': 4})
ax_pokemon_plot3.set_ylabel('Weighted Score', fontdict={'size': 14})
ax_pokemon_plot3.set_xlim(0,18)
ax_pokemon_plot3.set_ylim(0,125)
ax_pokemon_plot3.figure
51/104:
ax_pokemon_plot3 = sns.barplot(x='Type 1', y ='Weighted Score' , data=newdf)
ax_pokemon_plot3.set_xlabel('Pokemon Type)', fontdict={'size': 3})
ax_pokemon_plot3.set_ylabel('Weighted Score', fontdict={'size': 14})
ax_pokemon_plot3.set_xlim(0,18)
ax_pokemon_plot3.set_ylim(0,125)
ax_pokemon_plot3.figure
51/105:
ax_pokemon_plot3 = sns.barplot(x='Type 1', y ='Weighted Score' , data=newdf)
ax_pokemon_plot3.set_xlabel('Pokemon Type)', fontdict={'size': 2})
ax_pokemon_plot3.set_ylabel('Weighted Score', fontdict={'size': 14})
ax_pokemon_plot3.set_xlim(0,18)
ax_pokemon_plot3.set_ylim(0,125)
ax_pokemon_plot3.figure
51/106:
ax_pokemon_plot3 = sns.barplot(x='Type 1', y ='Weighted Score' , data=newdf)
ax_pokemon_plot3.set_xlabel('Pokemon Type)', fontdict={'size': 1})
ax_pokemon_plot3.set_ylabel('Weighted Score', fontdict={'size': 14})
ax_pokemon_plot3.set_xlim(0,18)
ax_pokemon_plot3.set_ylim(0,125)
ax_pokemon_plot3.figure
51/107:
ax_pokemon_plot3 = sns.barplot(x='Type 1', y ='Weighted Score' , data=newdf)
ax_pokemon_plot3.set_xlabel('Pokemon Type)', fontdict={'size': 0.9})
ax_pokemon_plot3.set_ylabel('Weighted Score', fontdict={'size': 14})
ax_pokemon_plot3.set_xlim(0,18)
ax_pokemon_plot3.set_ylim(0,125)
ax_pokemon_plot3.figure
51/108:
ax_pokemon_plot3 = sns.barplot(x='Type 1', y ='Weighted Score' , data=newdf)
ax_pokemon_plot3.set_xlabel('Pokemon Type)', fontdict={'size': 0.5})
ax_pokemon_plot3.set_ylabel('Weighted Score', fontdict={'size': 14})
ax_pokemon_plot3.set_xlim(0,18)
ax_pokemon_plot3.set_ylim(0,125)
ax_pokemon_plot3.figure
51/109:
ax_pokemon_plot3 = sns.barplot(x='Type 1', y ='Weighted Score' , data=newdf)
ax_pokemon_plot3.set_xlabel('Pokemon Type)', fontdict={'size': 0.1})
ax_pokemon_plot3.set_ylabel('Weighted Score', fontdict={'size': 14})
ax_pokemon_plot3.set_xlim(0,18)
ax_pokemon_plot3.set_ylim(0,125)
ax_pokemon_plot3.figure
51/110:
ax_pokemon_plot3 = sns.barplot(x='Type 1', y ='Weighted Score' , data=newdf)
ax_pokemon_plot3.set_xlabel('Pokemon Type)', fontdict={'size': 0.1})
ax_pokemon_plot3.set_ylabel('Weighted Score', fontdict={'size': 14})
ax_pokemon_plot3.set_xlim(-1,18)
ax_pokemon_plot3.set_ylim(0,125)
ax_pokemon_plot3.figure
51/111:
ax_pokemon_plot3 = sns.barplot(x='Type 1', y ='Weighted Score' , data=newdf)
ax_pokemon_plot3.set_xlabel('Pokemon Type)', fontdict={'size': 0.1})
ax_pokemon_plot3.set_ylabel('Weighted Score', fontdict={'size': 14})
ax_pokemon_plot3.set_xlim(0,18)
ax_pokemon_plot3.set_ylim(0,125)
ax_pokemon_plot3.figure
51/112:
ax_pokemon_plot3 = sns.barplot(x='Type 1', y ='Weighted Score' , data=newdf)
ax_pokemon_plot3.set_xlabel('Pokemon Type)', fontdict={'size': 0.1})
ax_pokemon_plot3.set_ylabel('Weighted Score', fontdict={'size': 14})
ax_pokemon_plot3.set_xlim(-1,18)
ax_pokemon_plot3.set_ylim(0,125)
ax_pokemon_plot3.figure
51/113:
newdf = pd.read_csv('data/lab05_task2.csv')
newdf
52/24:
newdf = df.drop(columns=['Generation', 'Sp. Atk', 'Sp. Def', 'Total', '#'])
newdf
52/25:
# This data was provided by Rounak Banik who is a Data Science Fellow at Mckinsey & Company. 
#The dataset conatins information on all 802 pokemon from all seven generations of pokemon , the information inlcudes name , type , total , HP , Attcak , Defence etc.
#The date when this data was collected is not given.
#The purpose of this dataset was for fun and learning by anazlsing and exploring the popular pokemon game.
#The data about all 802 pokemon was taken from the website http://serebii.net/.
52/26:
import pandas as pd

df= pd.read_csv('https://github.com/firasm/bits/raw/master/pokemon.csv')
print(df)
52/27:
import random
import numpy as np
df.describe(include=[np.number])
52/28: df.describe(exclude=[np.number])
52/29: print(df)
52/30:
newdf = df.drop(columns=['Generation', 'Sp. Atk', 'Sp. Def', 'Total', '#'])
newdf
52/31:
df2 = newdf.dropna(subset = ['HP', 'Attack', 'Defense', 'Speed'])
df2
52/32:
df2 = df2.reset_index()
df2
52/33:
df3 = df2.drop(columns=['index'])
df3
52/34:
df3['Weighted Score']  = df3['HP'] - (0.8*df3['HP']) + df3['Attack'] - (0.6*df3['Attack']) + df3['Defense'] - (0.7*df3['Defense']) + df3['Speed'] - (0.9*df3['Speed'])
df3
52/35: df3.to_csv('data/lab05_task2.csv' , index = False)
51/114:
import pandas as pd
import numpy as np
import matplotlib.pyplot as pl
import seaborn as sns
51/115:
newdf = pd.read_csv('data/lab05_task2.csv')
newdf
51/116:
df = pd.read_csv('https://github.com/firasm/bits/raw/master/pokemon.csv')
df
51/117: # Your Solution Here
51/118: ax_pokemon_plot1 = sns.scatterplot(x='Attack' , y ='Speed' , data=newdf)
51/119:
ax_pokemon_plot1.set_title('Relationship between Pokemon Attack and Speed' , fontdict ={'size':15})
ax_pokemon_plot1.set_xlabel('Pokemon Attack Points (0-190 pts)', fontdict={'size': 14})
ax_pokemon_plot1.set_ylabel('Pokemon Speed Points (0-180 pts)', fontdict={'size': 14})
ax_pokemon_plot1.set_xlim(0,200)
ax_pokemon_plot1.set_ylim(0,200)
ax_pokemon_plot1.figure
51/120: ax_pokemon_plot2 = sns.barplot(x='Legendary', y ='Weighted Score' , data=newdf).set(title='Legendary VS Non-Legendary', xlabel='Pokemon(Legnedary = True , Non-Legendary=False)' )
51/121:
ax_pokemon_plot3 = sns.barplot(x='Type 1', y ='Weighted Score' , data=newdf)
ax_pokemon_plot3.set_xlabel('Pokemon Type)', fontdict={'size': 0.1})
ax_pokemon_plot3.set_ylabel('Weighted Score', fontdict={'size': 14})
ax_pokemon_plot3.set_xlim(-1,18)
ax_pokemon_plot3.set_ylim(0,125)
ax_pokemon_plot3.figure
51/122:
ax_pokemon_plot3 = sns.barplot(x='Type 1', y ='Weighted Score' , data=newdf ,width = 40)
ax_pokemon_plot3.set_xlabel('Pokemon Type)', fontdict={'size': 0.1})
ax_pokemon_plot3.set_ylabel('Weighted Score', fontdict={'size': 14})
ax_pokemon_plot3.set_xlim(-1,18)
ax_pokemon_plot3.set_ylim(0,125)
ax_pokemon_plot3.figure
51/123:
ax_pokemon_plot3 = sns.barplot(x='Type 1', y ='Weighted Score' , data=newdf ,width = 10)
ax_pokemon_plot3.set_xlabel('Pokemon Type)', fontdict={'size': 0.1})
ax_pokemon_plot3.set_ylabel('Weighted Score', fontdict={'size': 14})
ax_pokemon_plot3.set_xlim(-1,18)
ax_pokemon_plot3.set_ylim(0,125)
ax_pokemon_plot3.figure
51/124:
ax_pokemon_plot3 = sns.barplot(x='Type 1', y ='Weighted Score' , data=newdf ,width = 1)
ax_pokemon_plot3.set_xlabel('Pokemon Type)', fontdict={'size': 0.1})
ax_pokemon_plot3.set_ylabel('Weighted Score', fontdict={'size': 14})
ax_pokemon_plot3.set_xlim(-1,18)
ax_pokemon_plot3.set_ylim(0,125)
ax_pokemon_plot3.figure
51/125:
ax_pokemon_plot3 = sns.barplot(x='Type 1', y ='Weighted Score' , data=newdf ,width = 0.1)
ax_pokemon_plot3.set_xlabel('Pokemon Type)', fontdict={'size': 0.1})
ax_pokemon_plot3.set_ylabel('Weighted Score', fontdict={'size': 14})
ax_pokemon_plot3.set_xlim(-1,18)
ax_pokemon_plot3.set_ylim(0,125)
ax_pokemon_plot3.figure
51/126:
ax_pokemon_plot3 = sns.barplot(x='Type 1', y ='Weighted Score' , data=newdf ,)
ax_pokemon_plot3.set_xlabel('Pokemon Type)', fontdict={'size': 0.1})
ax_pokemon_plot3.set_ylabel('Weighted Score', fontdict={'size': 14})
ax_pokemon_plot3.set_xlim(-1,18)
ax_pokemon_plot3.set_ylim(0,125)
ax_pokemon_plot3.figure
51/127:
ax_pokemon_plot3 = sns.barplot(x='Type 1', y ='Weighted Score' , data=newdf)
ax_pokemon_plot3.set_xlabel('Pokemon Type)', fontdict={'size': 0.1})
ax_pokemon_plot3.set_ylabel('Weighted Score', fontdict={'size': 14})
ax_pokemon_plot3.set_xlim(-1,18)
ax_pokemon_plot3.set_ylim(0,125)
ax_pokemon_plot3.figure
49/11: df['date'].isna().count()
49/12: df['date' , 'new_cases','new_deaths','new_tests'].isna().count()
49/13: df.isna().count()
49/14: df['date' , 'new_cases','new_deaths','new_tests'].isna().count()
49/15: df.isna().count()
49/16: df.isna()
49/17: [df.isna()].count()
49/18: df['new_test'].isna().count()
49/19: df['new_tests'].isna().count()
49/20: df['new_tests'].isna()
49/21: df['new_tests'].isna()
49/22: df.isna()
49/23: df.isna().sum()
49/24: df.isna().count()
49/25: df.isna().sum().sum()
49/26: df.count(axis=1).isnA()
49/27: df.count
49/28: df.count()
50/1:
df = pd.read_csv('datafiltered.csv')
df
49/29: datafiltered.to_csv('data/datafiltered.csv' , index = False)
50/2:
df = pd.read_csv('data/datafiltered.csv')
df
50/3:
import pandas as pd
import numpy as np
import matplotlib
50/4:
df = pd.read_csv('data/datafiltered.csv')
df
50/5:
df = pd.read_csv('data/datafiltered.csv')
df
49/30: datafiltered.to_csv('data/datafiltered.csv' , index = False)
49/31: datafiltered.to_csv('data/datafiltered.csv' , index = True)
49/32:
df.apply(pd.Series.first_valid_index)
df.iloc[111:116]
49/33:
datafiltered = df.dropna(subset = ['new_tests'])
datafiltered
49/34:
import random
import numpy as np
datafiltered.describe(include=[np.number])
49/35: datafiltered.describe(exclude=[np.number])
49/36: datafiltered.to_csv('data/datafiltered.csv' , index = True)
50/6:
df = pd.read_csv('data/datafiltered.csv')
df
51/128:
newdf = pd.read_csv('data/lab05_task2.csv')
newdf
51/129:
ax_pokemon_plot3 = sns.barplot(x='Type 2', y ='Weighted Score' , data=newdf)
ax_pokemon_plot3.set_xlabel('Pokemon Type)', fontdict={'size': 0.1})
ax_pokemon_plot3.set_ylabel('Weighted Score', fontdict={'size': 14})
ax_pokemon_plot3.set_xlim(-1,18)
ax_pokemon_plot3.set_ylim(0,125)
ax_pokemon_plot3.figure
51/130:
ax_pokemon_plot3 = sns.lineplot(x='Type 2', y ='Weighted Score' , data=newdf)
ax_pokemon_plot3.set_xlabel('Pokemon Type)', fontdict={'size': 0.1})
ax_pokemon_plot3.set_ylabel('Weighted Score', fontdict={'size': 14})
ax_pokemon_plot3.set_xlim(-1,18)
ax_pokemon_plot3.set_ylim(0,125)
ax_pokemon_plot3.figure
51/131:
ax_pokemon_plot3 = sns.lineplot(x='Attack', y ='Defence' , data=newdf)
ax_pokemon_plot3.set_xlabel('Pokemon Type)', fontdict={'size': 0.1})
ax_pokemon_plot3.set_ylabel('Weighted Score', fontdict={'size': 14})
ax_pokemon_plot3.set_xlim(-1,18)
ax_pokemon_plot3.set_ylim(0,125)
ax_pokemon_plot3.figure
51/132:
ax_pokemon_plot3 = sns.lineplot(x='Attack', y ='Defense' , data=newdf)
ax_pokemon_plot3.set_xlabel('Pokemon Type)', fontdict={'size': 0.1})
ax_pokemon_plot3.set_ylabel('Weighted Score', fontdict={'size': 14})
ax_pokemon_plot3.set_xlim(-1,18)
ax_pokemon_plot3.set_ylim(0,125)
ax_pokemon_plot3.figure
51/133:
ax_pokemon_plot3 = sns.scatterplot(x='Attack', y ='Defense' , data=newdf)
ax_pokemon_plot3.set_xlabel('Pokemon Type)', fontdict={'size': 0.1})
ax_pokemon_plot3.set_ylabel('Weighted Score', fontdict={'size': 14})
ax_pokemon_plot3.set_xlim(-1,18)
ax_pokemon_plot3.set_ylim(0,125)
ax_pokemon_plot3.figure
51/134:
ax_pokemon_plot3 = sns.scatterplot(x='Attack', y ='Defense' , data=newdf)
ax_pokemon_plot3.set_xlabel('Pokemon Attack Points(0 -1 90 pts)', fontdict={'size': 14})
ax_pokemon_plot3.set_ylabel('Pokemon Defense Points(0 -1 90 pts)', fontdict={'size': 14})
ax_pokemon_plot3.set_xlim(-1,18)
ax_pokemon_plot3.set_ylim(0,125)
ax_pokemon_plot3.figure
51/135:
ax_pokemon_plot3 = sns.scatterplot(x='Attack', y ='Defense' , data=newdf)
ax_pokemon_plot3.set_xlabel('Pokemon Attack Points(0 -1 90 pts)', fontdict={'size': 14})
ax_pokemon_plot3.set_ylabel('Pokemon Defense Points(0 -1 90 pts)', fontdict={'size': 14})
ax_pokemon_plot3.set_xlim(-1,190)
ax_pokemon_plot3.set_ylim(0,125)
ax_pokemon_plot3.figure
51/136:
ax_pokemon_plot3 = sns.scatterplot(x='Attack', y ='Defense' , data=newdf)
ax_pokemon_plot3.set_xlabel('Pokemon Attack Points(0 - 190 pts)', fontdict={'size': 14})
ax_pokemon_plot3.set_ylabel('Pokemon Defense Points(0 - 190 pts)', fontdict={'size': 14})
ax_pokemon_plot3.set_xlim(-1,190)
ax_pokemon_plot3.set_ylim(0,125)
ax_pokemon_plot3.figure
51/137:
ax_pokemon_plot3 = sns.scatterplot(x='Attack', y ='Defense' , data=newdf)
ax_pokemon_plot3.set_xlabel('Pokemon Attack Points(0 - 190 pts)', fontdict={'size': 14})
ax_pokemon_plot3.set_ylabel('Pokemon Defense Points(0 - 190 pts)', fontdict={'size': 14})
ax_pokemon_plot3.set_xlim(-1,190)
ax_pokemon_plot3.set_ylim(0,190)
ax_pokemon_plot3.figure
51/138:
ax_pokemon_plot3 = sns.scatterplot(x='Attack', y ='Defense' , data=newdf)
ax_pokemon_plot3.set_xlabel('Pokemon Attack Points(0 - 190 pts)', fontdict={'size': 14})
ax_pokemon_plot3.set_ylabel('Pokemon Defense Points(0 - 190 pts)', fontdict={'size': 14})
ax_pokemon_plot3.set_xlim(0,190)
ax_pokemon_plot3.set_ylim(0,190)
ax_pokemon_plot3.figure
51/139:
ax_pokemon_plot3 = sns.scatterplot(x='Attack', y ='Defense' , data=newdf)
ax_pokemon_plot3.set_xlabel('Pokemon Attack Points(0 - 190 pts)', fontdict={'size': 14})
ax_pokemon_plot3.set_ylabel('Pokemon Defense Points(0 - 190 pts)', fontdict={'size': 14})
ax_pokemon_plot3.set_xlim(0,200)
ax_pokemon_plot3.set_ylim(0,190)
ax_pokemon_plot3.figure
51/140:
ax_pokemon_plot3 = sns.scatterplot(x='Attack', y ='Defense' , data=newdf)
ax_pokemon_plot3.set_xlabel('Pokemon Attack Points(0 - 190 pts)', fontdict={'size': 14})
ax_pokemon_plot3.set_ylabel('Pokemon Defense Points(0 - 190 pts)', fontdict={'size': 14})
ax_pokemon_plot3.set_xlim(0,200)
ax_pokemon_plot3.set_ylim(0,200)
ax_pokemon_plot3.figure
51/141:
ax_pokemon_plot3 = sns.scatterplot(x='Attack', y ='Defense' , data=newdf)
ax_pokemon_plot3.set_xlabel('Pokemon Attack Points(0 - 190 pts)', fontdict={'size': 14})
ax_pokemon_plot3.set_ylabel('Pokemon Defense Points(0 - 190 pts)', fontdict={'size': 14})
ax_pokemon_plot3.set_xlim(0,200)
ax_pokemon_plot3.set_ylim(0,250)
ax_pokemon_plot3.figure
51/142:
ax_pokemon_plot3 = sns.scatterplot(x='Attack', y ='Defense' , data=newdf)
ax_pokemon_plot3.set_xlabel('Pokemon Attack Points(0 - 190 pts)', fontdict={'size': 14})
ax_pokemon_plot3.set_ylabel('Pokemon Defense Points(0 - 190 pts)', fontdict={'size': 14})
ax_pokemon_plot3.set_xlim(0,200)
ax_pokemon_plot3.set_ylim(0,280)
ax_pokemon_plot3.figure
51/143:
ax_pokemon_plot3 = sns.scatterplot(x='Attack', y ='Defense' , data=newdf)
ax_pokemon_plot3.set_xlabel('Pokemon Attack Points(0 - 190 pts)', fontdict={'size': 14})
ax_pokemon_plot3.set_ylabel('Pokemon Defense Points(0 - 190 pts)', fontdict={'size': 14})
ax_pokemon_plot3.set_xlim(0,200)
ax_pokemon_plot3.set_ylim(0,250)
ax_pokemon_plot3.figure
51/144:
ax_pokemon_plot3 = sns.scatterplot(x='Attack', y ='Defense' , data=newdf)
ax_pokemon_plot3.set_title= ('Relationship between Pokemon Attack and Speed' , fontdict ={'size':15})
ax_pokemon_plot3.set_xlabel('Pokemon Attack Points(0 - 190 pts)', fontdict={'size': 14})
ax_pokemon_plot3.set_ylabel('Pokemon Defense Points(0 - 190 pts)', fontdict={'size': 14})
ax_pokemon_plot3.set_xlim(0,200)
ax_pokemon_plot3.set_ylim(0,250)
ax_pokemon_plot3.figure
51/145:
ax_pokemon_plot3 = sns.scatterplot(x='Attack', y ='Defense' , data=newdf)
ax_pokemon_plot3.set_title('Relationship between Pokemon Attack and Speed' , fontdict ={'size':15})
ax_pokemon_plot3.set_xlabel('Pokemon Attack Points(0 - 190 pts)', fontdict={'size': 14})
ax_pokemon_plot3.set_ylabel('Pokemon Defense Points(0 - 190 pts)', fontdict={'size': 14})
ax_pokemon_plot3.set_xlim(0,200)
ax_pokemon_plot3.set_ylim(0,250)
ax_pokemon_plot3.figure
51/146:
ax_pokemon_plot3 = sns.scatterplot(x='Attack', y ='Defense' , data=newdf)
ax_pokemon_plot3.set_title('Relationship between Pokemon Attack and Defense' , fontdict ={'size':15})
ax_pokemon_plot3.set_xlabel('Pokemon Attack Points(0 - 190 pts)', fontdict={'size': 14})
ax_pokemon_plot3.set_ylabel('Pokemon Defense Points(0 - 190 pts)', fontdict={'size': 14})
ax_pokemon_plot3.set_xlim(0,200)
ax_pokemon_plot3.set_ylim(0,250)
ax_pokemon_plot3.figure
51/147:
### From the graph above it can be seen that most pokemon with very high attack points(175+) 
### have a defence below 150 points.Therefore , pokemon with the highest attacks points do not have 
### equal or higher defence points.
49/37: datafiltered.to_csv('data/datafiltered.csv' , index = True)
50/7:
import pandas as pd
import numpy as np
import matplotlib
50/8:
df = pd.read_csv('data/datafiltered.csv')
df
49/38: datafiltered.to_csv('data/datafiltered.csv')
50/9:
import pandas as pd
import numpy as np
import matplotlib
50/10:
df = pd.read_csv('data/datafiltered.csv')
df
49/39: datafiltered.to_csv('data/datafiltered.csv')
50/11:
df = pd.read_csv('data/datafiltered.csv')
df
50/12: newdf = df.drop(columns=['Unnamed:0'])
50/13: newdf = df.drop(columns=['index'])
50/14: newdf = df.drop(columns=['Unnamed: 0'])
50/15: df.sample(10)
50/16: newdf = df.drop(columns=['Unnamed: 0'])
50/17: newdf.sample(10)
53/1: newdf.sample(10)
53/2:
import pandas as pd
import numpy as np
import matplotlib
53/3:
df = pd.read_csv('data/datafiltered.csv')
df
53/4: newdf = df.drop(columns=['Unnamed: 0'])
53/5: newdf.sample(10)
53/6: newdf.groupby(newdf.date.dt.month)['sales'].sum()
53/7: newdf.groupby(newdf.date.dt.month)
53/8: newdf.groupby(newdf.'date'.dt.month)
53/9: df['Cumulative Frequency'] = df['new_cases'].cumsum()
53/10:
df['Cumulative Frequency'] = df['new_cases'].cumsum()
df
53/11:
df['Cumulative Frequency'] = df['new_cases'].cumsum()
df['Cumulative Frequency'] = df['new_tests'].cumsum()
df
53/12:
df['Cumulative Frequency'] = df['new_cases'].cumsum()
df['Cumulative Frequency'] = df['new_tests'].cumsum()
df
53/13:
df['Cumulative Frequency'] = df['new_cases'].cumsum()
df['Cumulative Frequency2'] = df['new_tests'].cumsum()
df
53/14:
df['cumulative_new_cases'] = df['new_cases'].cumsum()
df['cumulative_new_tests'] = df['new_tests'].cumsum()
df
53/15:
df['cumulative_new_cases'] = df['new_cases'].cumsum()
df['cumulative_new_tests'] = df['new_tests'].cumsum()
df
53/16:
df['Cumulative Frequency'] = df['new_cases'].cumsum()
df['Cumulative Frequency2'] = df['new_tests'].cumsum()
newdf = df.drop(columns=['C'])
df
53/17:
df['cumulative_new_cases'] = df['new_cases'].cumsum()
df['cumulative_new_tests'] = df['new_tests'].cumsum()
newdf = df.drop(columns=['Cumulative Frequency'])
df
53/18:
df['cumulative_new_cases'] = df['new_cases'].cumsum()
df['cumulative_new_tests'] = df['new_tests'].cumsum()
newdf = df.drop(columns=['Cumulative Frequency'])
df
53/19:
df['cumulative_new_cases'] = df['new_cases'].cumsum()
df['cumulative_new_tests'] = df['new_tests'].cumsum()
newdf = df.drop(columns=['Cumulative Frequenc'])
df
53/20:
df['cumulative_new_cases'] = df['new_cases'].cumsum()
df['cumulative_new_tests'] = df['new_tests'].cumsum()
newdf = df.drop(columns=['Cumulative FrequencY'])
df
53/21:
df['cumulative_new_cases'] = df['new_cases'].cumsum()
df['cumulative_new_tests'] = df['new_tests'].cumsum()
newdf = df.drop(columns=['Cumulative Frequency'])
df
53/22:
df['cumulative_new_cases'] = df['new_cases'].cumsum()
df['cumulative_new_tests'] = df['new_tests'].cumsum()
newdf = df.drop(columns=['Cumulative Frequency'])
df
53/23:
df['cumulative_new_cases'] = df['new_cases'].cumsum()
df['cumulative_new_tests'] = df['new_tests'].cumsum()
newdf = df.drop(columns=['Cumulative Frequency','Cumulative Frequency2'])
df
53/24:
df['cumulative_new_cases'] = df['new_cases'].cumsum()
df['cumulative_new_tests'] = df['new_tests'].cumsum()
newdf = df.drop(columns=['Cumulative Frequency','Cumulative Frequency2'])
df
53/25:
df = pd.read_csv('data/datafiltered.csv')
df
53/26:
import pandas as pd
import numpy as np
import matplotlib
53/27:
df = pd.read_csv('data/datafiltered.csv')
df
53/28: newdf = df.drop(columns=['Unnamed: 0'])
53/29: newdf.sample(10)
53/30:
df['cumulative_new_cases'] = df['new_cases'].cumsum()
df['cumulative_new_tests'] = df['new_tests'].cumsum()
newdf = df.drop(columns=['Cumulative Frequency','Cumulative Frequency2'])
df
53/31:
df['cumulative_new_cases'] = df['new_cases'].cumsum()
df['cumulative_new_tests'] = df['new_tests'].cumsum()
df
53/32:
import pandas as pd
import numpy as np
import matplotlib
53/33:
df = pd.read_csv('data/datafiltered.csv')
df
53/34: newdf = df.drop(columns=['Unnamed: 0'])
53/35: newdf.sample(10)
53/36:
df['cumulative_new_cases'] = df['new_cases'].cumsum()
df['cumulative_new_tests'] = df['new_tests'].cumsum()
df
53/37: newdf.groupby(newdf.your_date_column.dt.month)['values_column'].sum()
53/38: newdf.groupby(newdf.date.dt.month)['values_column'].sum()
53/39: newdf.groupby('date)['values_column'].sum()
53/40: newdf.groupby('date')[values_column'].sum()
53/41: newdf.groupby('date')['values_column'].sum()
53/42: newdf.groupby('date')['date'].sum()
53/43: newdf.groupby(date)['date'].sum()
53/44: newdf.groupby('date')['date'].sum()
53/45:
newdf = pd.t_datetime(newdf['date',format='%y/%m/%d')
newdf.groupby(by=[newdf.index.month , newdf.index.year])
53/46:
newdf = pd.t_datetime(newdf['date',format='%y/%m/%d'])
newdf.groupby(by=[newdf.index.month , newdf.index.year])
53/47:
newdf = pd.t_datetime(newdf['date'],format='%y/%m/%d')
newdf.groupby(by=[newdf.index.month , newdf.index.year])
53/48:
newdf = pd.to_datetime(newdf['date'],format='%y/%m/%d')
newdf.groupby(by=[newdf.index.month , newdf.index.year])
53/49:
newdf = pd.to_datetime(newdf['date'],format='%y/%m/%d %I')
newdf.groupby(by=[newdf.index.month , newdf.index.year])
53/50:
newdf = pd.to_datetime(newdf['date'],format='%y/%m/%d %I:)
newdf.groupby(by=[newdf.index.month , newdf.index.year])
53/51:
newdf = pd.to_datetime(newdf['date'],format='%y/%m/%d %I:')
newdf.groupby(by=[newdf.index.month , newdf.index.year])
53/52:
newdf = pd.to_datetime(newdf['date'],format='%y/%m/%d %I:%m:%s')
newdf.groupby(by=[newdf.index.month , newdf.index.year])
53/53:
newdf = pd.to_datetime(newdf['date'],format='%y/%m/%d %I:%m:%s')
newdf.groupby(by=[newdf.index.month , newdf.index.year])
53/54:
newdf = pd.to_datetime(newdf['date'],format='%y-%m-%d')
newdf.groupby(by=[newdf.index.month , newdf.index.year])
53/55:
newdf = pd.to_datetime(newdf['date'],format='%Y-%m-%d')
newdf.groupby(by=[newdf.index.month , newdf.index.year])
53/56:
newdf = pd.to_datetime(newdf['date'],format='%Y-%m-%d')
newdf.groupby(by=[newdf.index.month, newdf.index.year])
53/57:
newdf = pd.to_datetime(newdf['date'],format='%Y-%m-%d')
newdf.groupby(by=[newdf.index.month, newdf.index.year])
53/58:
newdf = pd.to_datetime(newdf[date],format='%Y-%m-%d')
newdf.groupby(by=[newdf.index.month, newdf.index.year])
53/59:
newdf = pd.to_datetime(newdf['date'],format='%Y-%m-%d')
newdf.groupby(by=[newdf.index.month, newdf.index.year])
53/60:
newdf = pd.to_datetime(newdf['date'],format='%Y-%m-%d')
newdf.groupby(by=[newdf.index.month, newdf.index.year])
53/61: newdf.groupby(pd.Grouper(FREG='M'))
53/62: newdf.groupby(pd.Grouper(FREQ='M'))
53/63: newdf.groupby(pd.Grouper(freq='M'))
53/64:
import pandas as pd
import numpy as np
import matplotlib
53/65:
df = pd.read_csv('data/datafiltered.csv')
df
53/66: newdf = df.drop(columns=['Unnamed: 0'])
53/67: newdf.sample(10)
53/68: newdf.groupby(pd.Grouper(freq='M'))
53/69: newdf['date']=pd.to_datetime(df['date'])
53/70:
newdf['date']=pd.to_datetime(df['date'])
df
53/71:
newdf['date']=pd.to_datetime(df['date'])
newdf
53/72:
newdf['date']=pd.to_datetime(df['date'])
newdf
df.groupby(df['date'].dt.strftime('%B'))['date']sum().sort_values()
53/73:
newdf['date']=pd.to_datetime(df['date'])
newdf
df.groupby(df['date'].dt.strftime('%B'))['date'].sum().sort_values()
53/74:
newdf['date']=pd.to_datetime(df['date'],errors='coerce')
newdf
df.groupby(df['date'].dt.strftime('%B'))['date'].sum().sort_values()
53/75:
newdf['date']= pd.to_datetime(df['date'],errors='coerce')
newdf
df.groupby(df['date'].dt.strftime('%B'))['date'].sum().sort_values()
53/76:
newdf['Date'] = pd.to_datetime(df.Date, format='%Y-%m-%d')
newdf['date']= pd.to_datetime(df['date'],errors='coerce')
newdf
df.groupby(df['date'].dt.strftime('%B'))['date'].sum().sort_values()
53/77:
newdf['date'] = pd.to_datetime(df.date, format='%Y-%m-%d')
newdf['date']= pd.to_datetime(df['date'],errors='coerce')
newdf
df.groupby(df['date'].dt.strftime('%B'))['date'].sum().sort_values()
53/78:
newdf['date'] = pd.to_datetime(df.date, format='%Y-%m-%d',errors='coerce')
df['Date'] = df['Date'].dt.strftime('%Y-%m-%d')
newdf
df.groupby(df['date'].dt.strftime('%B'))['date'].sum().sort_values()
53/79:
newdf['date'] = pd.to_datetime(df.date, format='%Y-%m-%d',errors='coerce')
df['Date'] = df['Date'].dt.strftime('%Y-%m-%d')
newdf
df.groupby(df['date'].dt.strftime('%B'))['date'].sum().sort_values()
53/80:
df_dates = df.index
newdf['date'] = pd.to_datetime(df.date, format='%Y-%m-%d',errors='coerce')
df['Date'] = df['Date'].dt.strftime('%Y-%m-%d')
newdf
df.groupby(df['date'].dt.strftime('%B'))['date'].sum().sort_values()
53/81:
df_dates = df.index
newdf['date'] = pd.to_datetime(df.date, format='%Y-%m-%d',errors='coerce')
df['Date'] = df['Date'].dt.strftime('%Y-%m-%d')
newdf
df.groupby(df['date'].dt.strftime('%B'))['date'].sum().sort_values()
53/82:
newdf_dates = newdf.index
newdf['date'] = pd.to_datetime(df.date, format='%Y-%m-%d',errors='coerce')
df['Date'] = df['Date'].dt.strftime('%Y-%m-%d')
newdf
df.groupby(df['date'].dt.strftime('%B'))['date'].sum().sort_values()
53/83:
newdf_dates = newdf.index
newdf['date'] = pd.to_datetime(df.date, format='%Y-%m-%d',errors='coerce')
df['Date'] = df['Date'].dt.strftime('%Y-%m-%d')
newdf
df.groupby(df['date'].dt.strftime('%B'))['date'].sum().sort_values()
53/84:
newdf['date'] = pd.to_datetime(df.date, format='%Y-%m-%d',errors='coerce')
newdf
df.groupby(df['date'].dt.strftime('%B'))['date'].sum().sort_values()
53/85:
newdf['date'] = pd.to_datetime(newdf.date, format='%Y-%m-%d',errors='coerce')
newdf['Date'] = newdf['Date'].dt.strftime('%Y-%m-%d')
newdf
df.groupby(df['date'].dt.strftime('%B'))['date'].sum().sort_values()
53/86:
newdf['date'] = pd.to_datetime(newdf.date, format='%Y-%m-%d',errors='coerce')
newdf['date'] = newdf['date'].dt.strftime('%Y-%m-%d')
newdf
df.groupby(df['date'].dt.strftime('%B'))['date'].sum().sort_values()
53/87:
newdf['date'] = pd.to_datetime(newdf.date, format='%Y-%m-%d',errors='coerce')
newdf['date'] = newdf['date'].dt.strftime('%Y-%m-%d')
newdf
df.groupby(newdf['date'].dt.strftime('%B'))['date'].sum().sort_values()
53/88:
newdf['date'] = pd.to_datetime(newdf.date, format='%Y-%m-%d',errors='coerce')
newdf['date'] = newdf['date'].dt.strftime('%Y-%m-%d')
newdf
newdf.groupby(newdf['date'].dt.strftime('%B'))['date'].sum().sort_values()
53/89:
newdf['date'] = pd.to_datetime(newdf['date']),errors='coerce')
newdf
newdf.groupby(newdf['date'].dt.strftime('%B'))['date'].sum().sort_values()
53/90:
newdf['date'] = pd.to_datetime(newdf['date'],errors='coerce')
newdf
newdf.groupby(newdf['date'].dt.strftime('%B'))['date'].sum().sort_values()
53/91:
newdf['date'] = pd.to_datetime(newdf['date'],errors='coerce')
newdf
newdf.groupby(newdf['date'].dt.strftime('%B'))['date']
53/92:
newdf['date'] = pd.to_datetime(newdf['date'],errors='coerce')
newdf
newdf.groupby(newdf['date'].dt.strftime('%B'))['date'].sum()
53/93:
newdf['date'] = pd.to_datetime(newdf['date'],errors='coerce')
newdf
newdf.groupby(newdf['date'].dt.strftime('%B'))['date'].sum().sort_values()
53/94:
newdf['date'] = pd.to_datetime(newdf['date'],errors='coerce')
newdf.groupby(newdf['date'].dt.strftime('%B'))['date'].sum().sort_values()
53/95:
from datetime import datetime
newdf['date'] = pd.to_datetime(newdf['date'],errors='coerce')
newdf.groupby(newdf['date'].dt.strftime('%B'))['date'].sum().sort_values()
53/96:
from datetime import datetime
newdf['date'] = pd.to_datetime(newdf['date'],errors='coerce')
newdf.groupby(newdf['date'].dt.strftime('%B'))['date'].sum().sort_values()
53/97:
newdf['Time'] = df['Time'].astype('datetime64')
newdf['date'] = pd.to_datetime(newdf['date'],errors='coerce')
newdf.groupby(newdf['date'].dt.strftime('%B'))['date'].sum().sort_values()
53/98:
newdf['Time'] = newdf['Time'].astype('datetime64')
newdf['date'] = pd.to_datetime(newdf['date'],errors='coerce')
newdf.groupby(newdf['date'].dt.strftime('%B'))['date'].sum().sort_values()
53/99:
newdf['date'] = newdf['date'].astype('datetime64')
newdf['date'] = pd.to_datetime(newdf['date'],errors='coerce')
newdf.groupby(newdf['date'].dt.strftime('%B'))['date'].sum().sort_values()
53/100:
newdf['date'] = newdf['date'].astype('datetime64')
newdf['date'] = pd.to_datetime(newdf['date'],errors='coerce')
newdf.groupby(newdf['date'].dt.strftime('%B'))['date'].sum().sort_values()
53/101: newdf.groupby(['date']).sum()
53/102:
newdf.groupby(['date']).sum()
newdf
53/103:
newdf.groupby(['date'])
['new_cases' , 'newdeaths'].mean().sort_values
53/104:
newdf.groupby(['date'])
newdf['new_cases' , 'newdeaths'].mean().sort_values
53/105:
newdf.groupby(['date'])
newdf['new_cases' , 'new_deaths'].mean().sort_values
53/106:
newdf.groupby(['date'])
newdf['new_cases' , 'new_deaths'].mean()
53/107:
newdf.groupby(['date'])
newdf['new_cases' , 'new_deaths']
53/108:
newdf.groupby(['date'])
newdf[['new_cases','new_deaths']].mean()
57/1:
import pandas as pd
import numpy as np
import matplotlib
57/2:
df = pd.read_csv('data/datafiltered.csv')
df
57/3: newdf = df.drop(columns=['Unnamed: 0'])
57/4: newdf.sample(10)
57/5:
newdf.groupby(['date'])
newdf[['new_cases','new_deaths']].mean()
57/6: newdf[['date','new_cases','new_deaths']].groupby('date').mean()
57/7:
newdf.loc[:,'month']=newdf.date.month()
newdf[['month','new_cases','new_deaths']].groupby(['month']).mean()
57/8:
newdf.loc[:,'month']=newdf.date.month()
newdf[['month','new_cases','new_deaths']].groupby(['month']).mean()
57/9: newdf[['date','new_cases','new_deaths']].groupby('date').mean()
57/10:
newdf.loc[:,'month']=newdf.date.month()
newdf[['month','new_cases','new_deaths']].groupby(['month']).mean()
newdf[['date','new_cases','new_deaths']].groupby('date').mean()
57/11:
newdf.loc[:,'month']=newdf.date.month()
newdf[['month','new_cases','new_deaths']].groupby(['month']).mean()
newdf[['date','new_cases','new_deaths']].groupby('date').mean()
newdf.date.describe()
57/12:
newdf.date.describe()
newdf.loc[:,'month']=newdf.date.month()
newdf[['month','new_cases','new_deaths']].groupby(['month']).mean()
newdf[['date','new_cases','new_deaths']].groupby('date').mean()
57/13:
newdf.date.describe()

newdf[['date','new_cases','new_deaths']].groupby('date').mean()
57/14: newdf.date.describe()
57/15:
my_numbers = [3,4,5,6,7,8,9,10,11,12,13,14,15]
for i in my_numbers:  
    if i > 10:
          print(i,"is bigger than 10!")
    else:
        print(i,"is smaller than, or equal to 10.")
64/1: newdf[['date','new_cases','new_deaths']].groupby('date').mean()
64/2:
import pandas as pd
import numpy as np
import matplotlib
64/3:
df = pd.read_csv('data/datafiltered.csv')
df
64/4: newdf = df.drop(columns=['Unnamed: 0'])
64/5: newdf.sample(10)
64/6: newdf[['date','new_cases','new_deaths']].groupby('date').mean()
69/1: p = ["BC"]
69/2: p = p + "Yukon Territory" + "Newfoundland and Labrador"
69/3: p = [p,"Yukon Territory","Newfoundland and Labrador"]
69/4: p
69/5: list(range(0, 53))
69/6:
(g)
list(range(2, 51))
69/7:

list(range(2, 51))
69/8: list(range(2, 52))
69/9: list(range([2, 52]))
69/10: mylist = ['a','x','h','d','e']
69/11: mylist[1:2]
69/12: mylist[0,3]
69/13: mylist[0,2]
69/14:
mylist = ['a','x','h','d','e']
mylist[0,2]
69/15:

mylist[0:2]
69/16: mylist[0:3]
69/17: mylist[1,2]
69/18: mylist[3:]
69/19: mylist[-5:]
69/20: mylist[:4]
69/21: mylist[4:]
69/22: mylist[:3]
69/23: mylist[-3:]
69/24: mylist[-5:]
69/25: greeting = ["Hello", "my", "name", "is", "Earl"]
69/26: f"{greeting}"
69/27: " ".join(greeting, "_")
69/28: greeting.join()
69/29: greeting.join("_")
69/30:
def print_some_characters(word):
    for i in range(len(word)):
        if i % 2 == 0: 
            print(word[i])

print_some_characters("WATERMELON")
69/31: good_fruit = "Raspberry"
69/32: good_fruit[4]
69/33: good_fruit(4)
69/34: good_fruit[2]
69/35: good_fruit[3]
69/36: test_list = [2, 3, 4, 5, 6, 7, 8, 9, 10]
69/37: demo_list = [2,3,4,5,6,7,8,9,10]
69/38: result = test_list*demo_list
69/39: result = test_list^2
69/40: result = test_list*test_list
69/41: result = test_list * test_list
69/42: result = square(test_list)
69/43:
def square(n):
    n_squared = n**2
    return n_squared
result = square(test_list)
69/44:
def square(n):
    n_squared = n*2
    return n_squared
result = square(test_list)
69/45:
def square(n):
    n_squared = n*2
    return n_squared
result = square(test_list)
69/46:
def square(n):
    n_squared = n*2
    return n_squared
result = square(test_list)
69/47:
def square(n):
    n_squared = n*2
    return n_squared
result = square(test_list)
result
69/48:
def square(n):
    n_squared = n*2
    return n_squared
result = square(test_list)
result
70/1: word_list = ['alpha','beta','gamma','delta','phi','kappa']
70/2: test_list = [2, 3, 4, 5, 6, 7, 8, 9, 10]
70/3:
def square(list):
      n_squared = n**2
        return n_squared
70/4:
def square(list):
      n_squared = n**2
    return [i ** 2 for i in list]
70/6:
def square(list):
      n_squared = n**2
    return [i ** 2 for i in list]
70/8:
def square(list):
      n_squared = n**2
   return n_squared
70/10:
def square(list):
      n_squared = n**2
    return n_squared
70/12:
def square(list):
    return n_squared
70/13:
def square(list):
        return [i ** 2 for i in list]
70/14: square(test_list)
70/15:
def square(list):
        return [i ** 2]
70/16: square(test_list)
70/17:
def square(list):
        return [n ** 2]
70/18: square(test_list)
70/19:
def square(list):
        return [n ** 2 for n in list]
70/20: square(test_list)
70/21:
def square(list):
    for n in list
        return [n ** 2]
70/22:
def square(list):
    for n in list:
        return [n ** 2]
70/23: square(test_list)
70/24:
def square(list):
        return [n ** 2 for n in list]
70/25: square(test_list)
70/26: word_list = ['alpha','beta','gamma','delta','phi','kappa']
70/27:
def square(list):
    n=n**2
        return [ n for n in list]
70/28:
def square(list):
        return [n ** 2 for n in list]
70/29: square(test_list)
70/30: result = list(np.multiply(test_list,test_list)
70/31: result = list(np.multiply(test_list,test_list))
70/32:
import numpy as np
result = list(np.multiply(test_list,test_list))
70/33: print(result)
70/34: print(result)
70/35:
import numpy as np
if n / 2 :
result = list(np.multiply(test_list,test_list))
70/36:
import numpy as np
if n / 2 :
print(list(np.multiply(test_list,test_list))
73/1: df = pd.read_csv('BankChurners.csv')
73/2:
import pandas as pd
df = pd.read_csv('BankChurners.csv')
73/3:
import pandas as pd
df = pd.read_csv('BankChurners.csv')
df
74/1: newdf = df.drop(columns=['Naive_Bayes_Classifier_Attrition_Flag_Card_Category_Contacts_Count_12_mon_Dependent_count_Education_Level_Months_Inactive_12_mon_1', 'Naive_Bayes_Classifier_Attrition_Flag_Card_Category_Contacts_Count_12_mon_Dependent_count_Education_Level_Months_Inactive_12_mon_2'])
74/2:
import pandas as pd
df = pd.read_csv('BankChurners.csv')
df
74/3: newdf = df.drop(columns=['Naive_Bayes_Classifier_Attrition_Flag_Card_Category_Contacts_Count_12_mon_Dependent_count_Education_Level_Months_Inactive_12_mon_1', 'Naive_Bayes_Classifier_Attrition_Flag_Card_Category_Contacts_Count_12_mon_Dependent_count_Education_Level_Months_Inactive_12_mon_2'])
74/4: newdf
77/1:
import pandas as pd
df = pd.read_csv('BankChurners.csv')
df
77/2: df2=df.drop(columns=['Naive_Bayes_Classifier_Attrition_Flag_Card_Category_Contacts_Count_12_mon_Dependent_count_Education_Level_Months_Inactive_12_mon_1','Naive_Bayes_Classifier_Attrition_Flag_Card_Category_Contacts_Count_12_mon_Dependent_count_Education_Level_Months_Inactive_12_mon_2'])
77/3: newdf=df.drop(columns=['Naive_Bayes_Classifier_Attrition_Flag_Card_Category_Contacts_Count_12_mon_Dependent_count_Education_Level_Months_Inactive_12_mon_1','Naive_Bayes_Classifier_Attrition_Flag_Card_Category_Contacts_Count_12_mon_Dependent_count_Education_Level_Months_Inactive_12_mon_2'])
77/4: newdf
79/1:
#Research Question:
#Do personal aspects such as marital status and education level contribute to credit limits of consumers? 
#Explantaion and analysis plan :
#Which of these said factors affect the credit limit most? Does this work towards consumers retorting to credit card churning? To examine the research question, I intend to calculate the differences in the frequencies, ranging from 1.44k to 34.5k,
#Finally, I aim to link these aspects to the research question and analyze the trends.
79/2:
#Research Question:
#Do personal aspects such as marital status and education level contribute to credit limits of consumers? 
#Explantaion and analysis plan :
#Which of these said factors affect the credit limit most? Does this work towards consumers retorting to credit card churning? To examine the research question, I intend to calculate the differences in the frequencies, ranging from 1.44k to 34.5k,
#Finally, I aim to link these aspects to the research question and analyze the trends.
83/1:
import pandas as pd
df = pd.read_csv('BankChurners.csv')
df
85/1:
import pandas as pd
df = pd.read_csv('BankChurners.csv')
df
85/2:
import pandas as pd
df = pd.read_csv('BankChurners.csv')
df
85/3: newdf=df.drop(columns=['Naive_Bayes_Classifier_Attrition_Flag_Card_Category_Contacts_Count_12_mon_Dependent_count_Education_Level_Months_Inactive_12_mon_1','Naive_Bayes_Classifier_Attrition_Flag_Card_Category_Contacts_Count_12_mon_Dependent_count_Education_Level_Months_Inactive_12_mon_2'])
85/4: newdf
85/5:
#Research Question:
#Do personal aspects such as marital status and education level contribute to credit limits of consumers? 
#Explantaion and analysis plan :
#Which of these said factors affect the credit limit most? Does this work towards consumers retorting to credit card churning? To examine the research question, I intend to calculate the differences in the frequencies, ranging from 1.44k to 34.5k,
#Finally, I aim to link these aspects to the research question and analyze the trends.
88/1:
import pandas as pd
import numpy as np
import matplotlib
88/2:
df = pd.read_csv('data/datafiltered.csv')
df
88/3: newdf = df.drop(columns=['Unnamed: 0'])
88/4: newdf.sample(10)
88/5: newdf[['date','new_cases','new_deaths']].groupby('date').mean()
88/6:
newdf.loc[:,'month']=newdf.date.month()
newdf[['date','new_cases','new_deaths']].groupby('date').mean()
88/7:
newdf.loc[:,'month']=newdf['date'].month()
newdf[['date','new_cases','new_deaths']].groupby('date').mean()
88/8:
newdf.loc[:,'month']=newdf['date'].month()
newdf[['date','new_cases','new_deaths']].groupby('date').mean()
88/9:

newdf[['date','new_cases','new_deaths']].groupby('date').mean()
88/10:
newdf.loc[:,'month']=newdf['date'].month()
newdf[['date','new_cases','new_deaths']].groupby('date').mean()
88/11:
newdf.loc[:,'month']=newdf['date'].apply(lambda x: x.month())
newdf[['date','new_cases','new_deaths']].groupby('date').mean()
88/12:
from datetime import datetime
dateparse = lambda x: datetime.strptime(x, '%Y-%m-%d')

df = pd.read_csv('data/datafiltered.csv', parse_dates=['datetime'], date_parser=dateparse)
88/13:
from datetime import datetime
dateparse = lambda x: datetime.strptime(x, '%Y-%m-%d')

df = pd.read_csv('data/datafiltered.csv', parse_dates=['date'], date_parser=dateparse)
88/14: newdf = df.drop(columns=['Unnamed: 0'])
88/15: newdf.sample(10)
88/16:
newdf.loc[:,'month']=newdf['date'].apply(lambda x: x.month())
newdf[['date','new_cases','new_deaths']].groupby('date').mean()
88/17:
newdf.loc[:,'month']=newdf['date'].apply(lambda x: x.month())
newdf[['date','new_cases','new_deaths']].groupby('date').mean()
88/18:
newdf.loc[:,'month']=newdf.date.month()
newdf[['date','new_cases','new_deaths']].groupby('date').mean()
88/19:
newdf.loc[:,'month']=newdf['date'].month()
newdf[['date','new_cases','new_deaths']].groupby('date').mean()
88/20:
newdf.loc[:,'month']=newdf['date'].month()
newdf[['date','new_cases','new_deaths']].groupby('date').mean()
88/21:
newdf.loc[:,'month']=newdf['date'].datetime.month
newdf[['date','new_cases','new_deaths']].groupby('date').mean()
88/22:
newdf.loc[:,'month']=newdf['date'].datetime.month
newdf[['date','new_cases','new_deaths']].groupby('date').mean()
88/23:
newdf.loc[:,'month']=newdf['date'].month
newdf[['date','new_cases','new_deaths']].groupby('date').mean()
88/24:
newdf.loc[:,'MONTH']=newdf['date'].month
newdf[['date','new_cases','new_deaths']].groupby('date').mean()
88/25:
newdf.loc[:,'MONTH']=newdf['date'].apply(lambda x: x.month)
newdf[['date','new_cases','new_deaths']].groupby('date').mean()
88/26:
newdf.loc[:,'MONTH']=newdf['date'].apply(lambda x: x.month)
newdf[['MONTH','new_cases','new_deaths']].groupby('MONTH').mean()
88/27:
newdf.loc[:,'MONTH']=newdf['date'].apply(lambda x: x.month)
newdf[['MONTH','new_cases','new_deaths']].groupby('MONTH').mean()
88/28:
import pandas as pd
import numpy as np
import matplotlib
88/29:
from datetime import datetime
dateparse = lambda x: datetime.strptime(x, '%Y-%m-%d')

df = pd.read_csv('data/datafiltered.csv', parse_dates=['date'], date_parser=dateparse)
88/30: newdf = df.drop(columns=['Unnamed: 0'])
88/31: newdf.sample(10)
88/32:
newdf.loc[:,'MONTH']=newdf['date'].apply(lambda x: x.month)
newdf[['MONTH','new_cases','new_deaths']].groupby('MONTH').mean()
89/1:
import pandas as pd
import numpy as np
import matplotlib
89/2:
from datetime import datetime
dateparse = lambda x: datetime.strptime(x, '%Y-%m-%d')

df = pd.read_csv('data/datafiltered.csv', parse_dates=['date'], date_parser=dateparse)
89/3: newdf = df.drop(columns=['Unnamed: 0'])
89/4: newdf.sample(10)
89/5:
newdf.loc[:,'MONTH']=newdf['date'].apply(lambda x: x.month)
newdf[['MONTH','new_cases','new_deaths']].groupby('MONTH').mean()
89/6:
df['cumulative_new_cases'] = df['new_cases'].cumsum()
df['cumulative_new_tests'] = df['new_tests'].cumsum()
df
89/7: # Your solution here
89/8:
newdf.loc[:,'MONTH']=newdf['date'].apply(lambda x: x.month)
newdf[['MONTH','new_cases','new_deaths']].groupby('MONTH').mean()
89/9:
df['cumulative_new_cases'] = df['new_cases'].cumsum()
df['cumulative_new_tests'] = df['new_tests'].cumsum()
df
89/10:
newdf['cumulative_new_cases'] = newdf['new_cases'].cumsum()
newdf['cumulative_new_tests'] = newdf['new_tests'].cumsum()
df
89/11:
newdf['cumulative_new_cases'] = newdf['new_cases'].cumsum()
newdf['cumulative_new_tests'] = newdf['new_tests'].cumsum()
newdf
89/12: plot1 = sns.graphplot(x='MONTH' , y ='cumulative_new_cases' , data=newdf)
89/13:
import seaborn as sns
plot1 = sns.graphplot(x='MONTH' , y ='cumulative_new_cases' , data=newdf)
89/14:
import seaborn as sns
plot1 = sns.graphplot(x='MONTH' , y ='cumulative_new_cases' , data=newdf)
89/15:
import seaborn as sns
plot1 = sns.plot(x='MONTH' , y ='cumulative_new_cases' , data=newdf)
89/16:
import seaborn as sns
plot1 = sns.relplot(x='MONTH' , y ='cumulative_new_cases' , data=newdf)
89/17:
import seaborn as sns
plot1 = sns.lioneplot(x='MONTH' , y ='cumulative_new_cases' , data=newdf)
89/18:
import seaborn as sns
plot1 = sns.lineplot(x='MONTH' , y ='cumulative_new_cases' , data=newdf)
89/19:
newdf['cumulative_new_cases'] = newdf['new_cases'].cumsum()
newdf['cumulative_new_tests'] = newdf['new_tests'].cumsum()
newdf
89/20:
import seaborn as sns
plot1 = sns.lineplot(x='new_deaths' , y ='cumulative_new_cases' , data=newdf)
89/21:
import seaborn as sns
plot1 = sns.lineplot(x='new_cases' , y ='cumulative_new_cases' , data=newdf)
89/22:
import seaborn as sns
plot1 = sns.lineplot(x='date' , y ='cumulative_new_cases' , data=newdf)
89/23:
import seaborn as sns
plot1 = sns.lineplot(x='MONTH' , y ='cumulative_new_cases' , data=newdf)
89/24:
import seaborn as sns
plot1 = sns.lineplot(x='date' , y ='cumulative_new_cases' , data=newdf)
89/25:
newdf.loc[:,'MONTH']=newdf['date'].apply(lambda x: x.day)
newdf[['MONTH','new_cases','new_deaths']].groupby('MONTH').mean()
89/26:
newdf.loc[:,'MONTH']=newdf['date'].apply(lambda x: x.month)
newdf[['MONTH','new_cases','new_deaths']].groupby('MONTH').mean()
89/27:
newdf.loc[:,'DAY']=newdf['date'].apply(lambda x: x.day)
newdf[['DAY','new_cases','new_deaths']].groupby('DAY').mean()
89/28:
newdf.loc[:,'MONTH']=newdf['date'].apply(lambda x: x.month)
newdf[['MONTH','new_cases','new_deaths']].groupby('MONTH').mean()
89/29:
newdf['cumulative_new_cases'] = newdf['new_cases'].cumsum()
newdf['cumulative_new_tests'] = newdf['new_tests'].cumsum()
newdf = df.drop(columns=['MONTH'])
newdf
89/30:
newdf['cumulative_new_cases'] = newdf['new_cases'].cumsum()
newdf['cumulative_new_tests'] = newdf['new_tests'].cumsum()
newdf = df.drop(columns=['MONTH'])
newdf
89/31:
newdf['cumulative_new_cases'] = newdf['new_cases'].cumsum()
newdf['cumulative_new_tests'] = newdf['new_tests'].cumsum()
newdf = df.drop(columns=['MONTH'])
newdf
89/32:
newdf['cumulative_new_cases'] = newdf['new_cases'].cumsum()
newdf['cumulative_new_tests'] = newdf['new_tests'].cumsum()
newdf = df.drop(columns=[' MONTH'])
newdf
89/33:
newdf['cumulative_new_cases'] = newdf['new_cases'].cumsum()
newdf['cumulative_new_tests'] = newdf['new_tests'].cumsum()
newdf = df.drop(columns=[''])
newdf
89/34:
newdf['cumulative_new_cases'] = newdf['new_cases'].cumsum()
newdf['cumulative_new_tests'] = newdf['new_tests'].cumsum()
newdf
89/35:
newdf = df.drop(columns=['MONTH'])
newdf['cumulative_new_cases'] = newdf['new_cases'].cumsum()
newdf['cumulative_new_tests'] = newdf['new_tests'].cumsum()
newdf
89/36:

newdf['cumulative_new_cases'] = newdf['new_cases'].cumsum()
newdf['cumulative_new_tests'] = newdf['new_tests'].cumsum()
newdf
89/37:
newdf.loc[:,'MONTH']=newdf['date'].apply(lambda x: x.month)
newdf[['MONTH','new_cases','new_deaths']].groupby('MONTH').mean()
89/38:
newdf.loc[:,'DAY']=newdf['date'].apply(lambda x: x.day)
newdf[['DAY','new_cases','new_deaths']].groupby('DAY').mean()
89/39:
newdf.loc[:,'DAY']=newdf['date'].apply(lambda x: x.day)
newdf[['DAY','new_cases','new_deaths']].groupby('DAY').mean()
newdf
89/40:
import seaborn as sns
plot1 = sns.lineplot(x='DAY' , y ='cumulative_new_cases' , data=newdf)
89/41:
import seaborn as sns
plot1 = sns.lineplot(x='date' , y ='cumulative_new_cases' , data=newdf)
89/42:
df['cumulative_new_cases'] = df['new_cases'].cumsum()
df['cumulative_new_tests'] = df['new_tests'].cumsum()
df
89/43:
df['cumulative_new_cases'] = df['new_cases'].cumsum()
df['cumulative_new_tests'] = df['new_tests'].cumsum()
df.drop(columns=['Unnamed: 0'])
df
89/44:
df= df.drop(columns=['Unnamed: 0'])
df['cumulative_new_cases'] = df['new_cases'].cumsum()
df['cumulative_new_tests'] = df['new_tests'].cumsum()
df
92/1:
# This data was provided by Rounak Banik who is a Data Science Fellow at Mckinsey & Company. 
#The dataset conatins information on all 802 pokemon from all seven generations of pokemon , the information inlcudes name , type , total , HP , Attcak , Defence etc.
#The date when this data was collected is not given.
#The purpose of this dataset was for fun and learning by anazlsing and exploring the popular pokemon game.
#The data about all 802 pokemon was taken from the website http://serebii.net/.
92/2:
import pandas as pd

df= pd.read_csv('https://github.com/firasm/bits/raw/master/pokemon.csv')
print(df)
92/3:
import random
import numpy as np
df.describe(include=[np.number])
92/4: df.describe(exclude=[np.number])
92/5: print(df)
92/6:
newdf = df.drop(columns=['Generation', 'Sp. Atk', 'Sp. Def', 'Total', '#'])
newdf
92/7:
df2 = newdf.dropna(subset = ['HP', 'Attack', 'Defense', 'Speed'])
df2
92/8:
df2 = df2.reset_index()
df2
92/9:
df3 = df2.drop(columns=['index'])
df3
92/10:
df3['Weighted Score']  = df3['HP'] - (0.8*df3['HP']) + df3['Attack'] - (0.6*df3['Attack']) + df3['Defense'] - (0.7*df3['Defense']) + df3['Speed'] - (0.9*df3['Speed'])
df3
92/11: df3.to_csv('data/lab05_task2.csv' , index = False)
91/1:
import pandas as pd
import numpy as np
import matplotlib.pyplot as pl
import seaborn as sns
91/2:
newdf = pd.read_csv('data/lab05_task2.csv')
newdf
91/3:
df = pd.read_csv('https://github.com/firasm/bits/raw/master/pokemon.csv')
df
91/4: # Your Solution Here
91/5: ax_pokemon_plot1 = sns.scatterplot(x='Attack' , y ='Speed' , data=newdf)
91/6:
ax_pokemon_plot1.set_title('Relationship between Pokemon Attack and Speed' , fontdict ={'size':15})
ax_pokemon_plot1.set_xlabel('Pokemon Attack Points (0-190 pts)', fontdict={'size': 14})
ax_pokemon_plot1.set_ylabel('Pokemon Speed Points (0-180 pts)', fontdict={'size': 14})
ax_pokemon_plot1.set_xlim(0,200)
ax_pokemon_plot1.set_ylim(0,200)
ax_pokemon_plot1.figure
91/7: ax_pokemon_plot2 = sns.barplot(x='Legendary', y ='Weighted Score' , data=newdf).set(title='Legendary VS Non-Legendary', xlabel='Pokemon(Legnedary = True , Non-Legendary=False)' )
91/8:
ax_pokemon_plot3 = sns.scatterplot(x='Attack', y ='Defense' , data=newdf)
ax_pokemon_plot3.set_title('Relationship between Pokemon Attack and Defense' , fontdict ={'size':15})
ax_pokemon_plot3.set_xlabel('Pokemon Attack Points(0 - 190 pts)', fontdict={'size': 14})
ax_pokemon_plot3.set_ylabel('Pokemon Defense Points(0 - 190 pts)', fontdict={'size': 14})
ax_pokemon_plot3.set_xlim(0,200)
ax_pokemon_plot3.set_ylim(0,250)
ax_pokemon_plot3.figure
91/9:
### From the graph above it can be seen that pokemon with very high attack points(175+) 
### have a defence below 150 points.Therefore , pokemon with the highest attacks points do not have 
### equal or higher defence points.
90/1: df.count()
90/2:
import pandas as pd
import numpy as np
90/3:
df = pd.read_csv('https://gist.githubusercontent.com/aakashns/f6a004fa20c84fec53262f9a8bfee775/raw/f309558b1cf5103424cef58e2ecb8704dcd4d74c/italy-covid-daywise.csv')
df.head(13)
90/4:
df.apply(pd.Series.first_valid_index)
df.iloc[111:116]
90/5: df.count()
90/6: df.count()
90/7:
df['incident_rate']  = df['new_cases']/ df['new_tests']
df
90/8:
df['incident_rate']  = df['new_cases']/ df['new_tests']
df.head(111)
90/9:
df['incident_rate']  = df['new_cases']/ df['new_tests']
df.head(1112)
90/10:
df['incident_rate']  = df['new_cases']/ df['new_tests']
df.head(112)
90/11:
df['incident_rate']  = df['new_cases']/ df['new_tests']
df.head(114)
89/45:
import seaborn as sns
sns.set_style("whitegrid")
plot1 = sns.lineplot(x='date' , y ='cumulative_new_cases' , data=newdf)
89/46:
import seaborn as sns
sns.set_style("blackgrid")
plot1 = sns.lineplot(x='date' , y ='cumulative_new_cases' , data=newdf)
89/47:
import seaborn as sns
sns.set_style("whitegrid")
plot1 = sns.lineplot(x='date' , y ='cumulative_new_cases' , data=newdf)
89/48:
import seaborn as sns
sns.set_style("whitegrid")
plot1 = sns.lineplot(x='date' , y ='cumulative_new_cases' , data=newdf)
plot1.set_xlabel('Number of Days', fontdict={'size': 10})
plot1.set_ylabel('Cumulative New Cases', fontdict={'size': 10})
91/10:
ax_pokemon_plot3 = sns.scatterplot(x='Attack', y ='Defense' , data=newdf)
ax_pokemon_plot3.set_xlabel('Pokemon Attack Points(0 - 190 pts)', fontdict={'size': 14})
ax_pokemon_plot3.set_ylabel('Pokemon Defense Points(0 - 190 pts)', fontdict={'size': 14})
ax_pokemon_plot3.set_xlim(0,200)
ax_pokemon_plot3.set_ylim(0,250)
ax_pokemon_plot3.figure
91/11:
ax_pokemon_plot3 = sns.scatterplot(x='Attack', y ='Defense' , data=newdf)
ax_pokemon_plot3.set_title('Relationship between Pokemon Attack and Defense' , fontdict ={'size':15})
ax_pokemon_plot3.set_xlabel('Pokemon Attack Points(0 - 190 pts)', fontdict={'size': 14})
ax_pokemon_plot3.set_ylabel('Pokemon Defense Points(0 - 190 pts)', fontdict={'size': 14})
ax_pokemon_plot3.set_xlim(0,200)
ax_pokemon_plot3.set_ylim(0,250)
ax_pokemon_plot3.figure
89/49:
import seaborn as sns
sns.set_style("whitegrid")
plot1 = sns.lineplot(x='date' , y ='cumulative_new_cases' , data=newdf)
plot1.set_title('Cumulative Cases' , fontdict ={'size':15})
plot1.set_xlabel('Number of Days', fontdict={'size': 10})
plot1.set_ylabel('Cumulative New Cases', fontdict={'size': 10})
89/50:
import seaborn as sns
sns.set_style("whitegrid")
plot1 = sns.lineplot(x='date' , y ='cumulative_new_cases' , data=newdf)
plot1.set_title('Cumulative Cases' , fontdict ={'size':15})
plot1.set_xlabel('Number of Days', fontdict={'size': 12})
plot1.set_ylabel('Cumulative New Cases', fontdict={'size': 12})
94/1:
# Usually all the import statements are at the top of the file

import pandas as pd
import seaborn as sns
import numpy as np
import os
94/2:
# Themes and colours in Seaborn

# There are five preset seaborn themes: darkgrid, whitegrid, dark, white, and ticks. 
# They are each suited to different applications and personal preferences.
# You can see what they look like [here](https://seaborn.pydata.org/tutorial/aesthetics.html#seaborn-figure-styles)

# Just for fun, we're going to set the theme to be a nice one:
sns.set_theme(style="ticks",
              font_scale=1.3, # This scales the fonts slightly higher
             )
# And we're going to remove the top and right axis lines
import matplotlib.pyplot as plt
plt.rc("axes.spines", top=False, right=False)
94/3: df = pd.read_csv('BCCDC_COVID19_Dashboard_Case_Details.csv')
99/1:
newdf.daynumber = newdf.date.day
import seaborn as sns
sns.set_style("whitegrid")
plot1 = sns.lineplot(x='date' , y ='cumulative_new_cases' , data=newdf)
plot1.set_title('Cumulative Cases' , fontdict ={'size':15})
plot1.set_xlabel('Number of Days', fontdict={'size': 12})
plot1.set_ylabel('Cumulative New Cases', fontdict={'size': 12})
99/2:
import pandas as pd
import numpy as np
import matplotlib
99/3:
from datetime import datetime
dateparse = lambda x: datetime.strptime(x, '%Y-%m-%d')

df = pd.read_csv('data/datafiltered.csv', parse_dates=['date'], date_parser=dateparse)
99/4: newdf = df.drop(columns=['Unnamed: 0'])
99/5: newdf.sample(10)
99/6:
newdf.loc[:,'MONTH']=newdf['date'].apply(lambda x: x.month)
newdf[['MONTH','new_cases','new_deaths']].groupby('MONTH').mean()
99/7:
df = df.drop(columns=['Unnamed: 0'])
df['cumulative_new_cases'] = df['new_cases'].cumsum()
df['cumulative_new_tests'] = df['new_tests'].cumsum()
df
99/8:
newdf.daynumber = newdf.date.day
import seaborn as sns
sns.set_style("whitegrid")
plot1 = sns.lineplot(x='date' , y ='cumulative_new_cases' , data=newdf)
plot1.set_title('Cumulative Cases' , fontdict ={'size':15})
plot1.set_xlabel('Number of Days', fontdict={'size': 12})
plot1.set_ylabel('Cumulative New Cases', fontdict={'size': 12})
99/9: newdf.daynumber = newdf.date.day
99/10: newdf.daynumber = newdf['date'].apply(lambda x: x.day)
99/11: newdf.loc[:,'daynumber']=newdf['date'].apply(lambda x: x.day)
99/12:
newdf.loc[:,'daynumber']=newdf['date'].apply(lambda x: x.day)
newdf
99/13:
newdf.loc[:,'daynumber']=newdf['date'].apply(lambda x: x.dayofyear)
newdf
99/14:
import seaborn as sns
sns.set_style("whitegrid")
plot1 = sns.lineplot(x='daynumber' , y ='cumulative_new_cases' , data=newdf)
plot1.set_title('Cumulative Cases' , fontdict ={'size':15})
plot1.set_xlabel('Number of Days', fontdict={'size': 12})
plot1.set_ylabel('Cumulative New Cases', fontdict={'size': 12})
99/15:
import seaborn as sns
sns.set_style("whitegrid")
plot1 = sns.lineplot(x='daynumber' , y ='cumulative_new_cases' , data=newdf)
plot1.set_title('Cumulative Cases' , fontdict ={'size':15})
plot1.set_xlabel('Number of Days', fontdict={'size': 12})
plot1.set_ylabel('Cumulative New Cases', fontdict={'size': 12})
99/16:
import pandas as pd
import numpy as np
import matplotlib
99/17:
from datetime import datetime
dateparse = lambda x: datetime.strptime(x, '%Y-%m-%d')

df = pd.read_csv('data/datafiltered.csv', parse_dates=['date'], date_parser=dateparse)
99/18: newdf = df.drop(columns=['Unnamed: 0'])
99/19: newdf.sample(10)
99/20:
newdf.loc[:,'MONTH']=newdf['date'].apply(lambda x: x.month)
newdf[['MONTH','new_cases','new_deaths']].groupby('MONTH').mean()
99/21:
df = df.drop(columns=['Unnamed: 0'])
df['cumulative_new_cases'] = df['new_cases'].cumsum()
df['cumulative_new_tests'] = df['new_tests'].cumsum()
df
99/22:
df.loc[:,'daynumber']=newdf['date'].apply(lambda x: x.dayofyear)
df
99/23:
import seaborn as sns
sns.set_style("whitegrid")
plot1 = sns.lineplot(x='daynumber' , y ='cumulative_new_cases' , data=newdf)
plot1.set_title('Cumulative Cases' , fontdict ={'size':15})
plot1.set_xlabel('Number of Days', fontdict={'size': 12})
plot1.set_ylabel('Cumulative New Cases', fontdict={'size': 12})
99/24:
import seaborn as sns
sns.set_style("whitegrid")
plot1 = sns.lineplot(x='daynumber' , y ='cumulative_new_cases' , data=df)
plot1.set_title('Cumulative Cases' , fontdict ={'size':15})
plot1.set_xlabel('Number of Days', fontdict={'size': 12})
plot1.set_ylabel('Cumulative New Cases', fontdict={'size': 12})
99/25:
df.loc[:,'daynumber']=newdf['date'].apply(lambda x: x.dayofyear-100)
df
99/26:
import seaborn as sns
sns.set_style("whitegrid")
plot1 = sns.lineplot(x='daynumber' , y ='cumulative_new_cases' , data=df)
plot1.set_title('Cumulative Cases' , fontdict ={'size':15})
plot1.set_xlabel('Number of Days', fontdict={'size': 12})
plot1.set_ylabel('Cumulative New Cases', fontdict={'size': 12})
99/27:
import seaborn as sns
sns.set_style("whitegrid")
plot1 = sns.lineplot(x='daynumber' , y ='cumulative_new_cases' , data=df)
plot1.set_title('Cumulative Cases' , fontdict ={'size':15})
plot1.set_xlabel('Number of Days', fontdict={'size': 12})
plot1.set_ylabel('Cumulative New Cases', fontdict={'size': 12})
ax_pokemon_plot1.set_ylim(0,140)
99/28:
import seaborn as sns
sns.set_style("whitegrid")
plot1 = sns.lineplot(x='daynumber' , y ='cumulative_new_cases' , data=df)
plot1.set_title('Cumulative Cases' , fontdict ={'size':15})
plot1.set_xlabel('Number of Days', fontdict={'size': 12})
plot1.set_ylabel('Cumulative New Cases', fontdict={'size': 12})
plot1.set_ylim(0,140)
99/29:
import seaborn as sns
sns.set_style("whitegrid")
plot1 = sns.lineplot(x='daynumber' , y ='cumulative_new_cases' , data=df)
plot1.set_title('Cumulative Cases' , fontdict ={'size':15})
plot1.set_xlabel('Number of Days', fontdict={'size': 12})
plot1.set_ylabel('Cumulative New Cases', fontdict={'size': 12})
plot1.set_xlim(0,140)
99/30:
import seaborn as sns
sns.set_style("whitegrid")
plot1 = sns.lineplot(x='daynumber' , y ='cumulative_new_cases' , data=df)
plot1.set_title('Cumulative Cases' , fontdict ={'size':15})
plot1.set_xlabel('Number of Days', fontdict={'size': 12})
plot1.set_ylabel('Cumulative New Cases', fontdict={'size': 12})
plot1.set_xlim(0,150)
99/31:
df.loc[:,'daynumber']=newdf['date'].apply(lambda x: x.dayofyear-120)
df
99/32:
import seaborn as sns
sns.set_style("whitegrid")
plot1 = sns.lineplot(x='daynumber' , y ='cumulative_new_cases' , data=df)
plot1.set_title('Cumulative Cases' , fontdict ={'size':15})
plot1.set_xlabel('Number of Days', fontdict={'size': 12})
plot1.set_ylabel('Cumulative New Cases', fontdict={'size': 12})
plot1.set_xlim(0,150)
99/33:
df.loc[:,'daynumber']=newdf['date'].apply(lambda x: x.dayofyear-110)
df
99/34:
import seaborn as sns
sns.set_style("whitegrid")
plot1 = sns.lineplot(x='daynumber' , y ='cumulative_new_cases' , data=df)
plot1.set_title('Cumulative Cases' , fontdict ={'size':15})
plot1.set_xlabel('Number of Days', fontdict={'size': 12})
plot1.set_ylabel('Cumulative New Cases', fontdict={'size': 12})
plot1.set_xlim(-10,150)
99/35:
import seaborn as sns
sns.set_style("whitegrid")
plot1 = sns.lineplot(x='daynumber' , y ='cumulative_new_cases' , data=df)
plot1.set_title('Cumulative Cases' , fontdict ={'size':15})
plot1.set_xlabel('Number of Days', fontdict={'size': 12})
plot1.set_ylabel('Cumulative New Cases', fontdict={'size': 12})
plot1.set_xlim(-10,150)
99/36:
import seaborn as sns
import matplotlib.pyplot as pl
sns.set_style("whitegrid")
plot1 = sns.lineplot(x='daynumber' , y ='cumulative_new_cases' , data=df)
plot1.set_title('Cumulative Cases' , fontdict ={'size':15})
plot1.set_xlabel('Number of Days', fontdict={'size': 12})
plot1.set_ylabel('Cumulative New Cases', fontdict={'size': 12})
plot1.set_xlim(-10,150)
pl.show
99/37:
import seaborn as sns
import matplotlib.pyplot as pl
sns.set_style("whitegrid")
plot1 = sns.lineplot(x='daynumber' , y ='cumulative_new_cases' , data=df)
plot1.set_title('Cumulative Cases' , fontdict ={'size':15})
plot1.set_xlabel('Number of Days', fontdict={'size': 12})
plot1.set_ylabel('Cumulative New Cases', fontdict={'size': 12})
plot1.set_xlim(-10,150)
pl.show()
99/38:
import seaborn as sns
import matplotlib.pyplot as pl
sns.set_style("whitegrid")
plot1 = sns.lineplot(x='daynumber' , y ='cumulative_new_cases' , data=df)
plot1.set_title('Cumulative Cases' , fontdict ={'size':15})
plot1.set_xlabel('Number of Days', fontdict={'size': 12})
plot1.set_ylabel('Cumulative New Cases', fontdict={'size': 12})
plot1.set_xlim(-10,150)
pl.show()
99/39:
df.loc[:,'daynumber']=newdf['date'].apply(lambda x: x.dayofyear-110)
df
99/40:
import seaborn as sns
import matplotlib.pyplot as pl
sns.set_style("whitegrid")
plot1 = sns.lineplot(x='daynumber' , y ='cumulative_new_cases' , data=df)
plot1.set_title('Cumulative Cases' , fontdict ={'size':15})
plot1.set_xlabel('Number of Days', fontdict={'size': 12})
plot1.set_ylabel('Cumulative New Cases', fontdict={'size': 12})
plot1.set_xlim(-10,150)
pl.show()
99/41:
import seaborn as sns
import matplotlib.pyplot as pl
sns.set_style("whitegrid")
plot1 = sns.lineplot(x='daynumber' , y ='cumulative_new_cases' , data=df)
plot1.set_title('Cumulative Cases over days' , fontdict ={'size':15})
plot1.set_xlabel('Number of Days', fontdict={'size': 12})
plot1.set_ylabel('Cumulative New Cases', fontdict={'size': 12})
plot1.set_xlim(-10,150)
pl.show()
99/42:
import seaborn as sns
import matplotlib.pyplot as pl
sns.set_style("whitegrid")
plot1 = sns.lineplot(x='daynumber' , y ='cumulative_new_cases' , data=df)
plot1.set_title('Cumulative Cases' , fontdict ={'size':15})
plot1.set_xlabel('Number of Days', fontdict={'size': 12})
plot1.set_ylabel('Cumulative New Cases', fontdict={'size': 12})
plot1.set_xlim(-10,150)
pl.show()
99/43:
import seaborn as sns
import matplotlib.pyplot as pl
sns.set_style("whitegrid")
plot1 = sns.lineplot(x='daynumber' , y ='cumulative_new_cases' , data=df)
plot1.set_title('Increase of Cumulative Cases' , fontdict ={'size':15})
plot1.set_xlabel('Number of Days', fontdict={'size': 12})
plot1.set_ylabel('Cumulative New Cases', fontdict={'size': 12})
plot1.set_xlim(-10,150)
pl.show()
101/1: df = pd.read_csv('http://www.bccdc.ca/Health-Info-Site/Documents/BCCDC_COVID19_Dashboard_Case_Details.csv')
101/2:
# Usually all the import statements are at the top of the file

import pandas as pd
import seaborn as sns
import numpy as np
import os
101/3: df = pd.read_csv('http://www.bccdc.ca/Health-Info-Site/Documents/BCCDC_COVID19_Dashboard_Case_Details.csv')
101/4:
df = pd.read_csv('http://www.bccdc.ca/Health-Info-Site/Documents/BCCDC_COVID19_Dashboard_Case_Details.csv')
head.df(4)
101/5:
df = pd.read_csv('http://www.bccdc.ca/Health-Info-Site/Documents/BCCDC_COVID19_Dashboard_Case_Details.csv')
df
101/6:
# Usually all the import statements are at the top of the file

import pandas as pd
import seaborn as sns
import numpy as np
import os
101/7:
# Usually all the import statements are at the top of the file

import pandas as pd
import seaborn as sns
import numpy as np
import os
101/8:
# Themes and colours in Seaborn

# There are five preset seaborn themes: darkgrid, whitegrid, dark, white, and ticks. 
# They are each suited to different applications and personal preferences.
# You can see what they look like [here](https://seaborn.pydata.org/tutorial/aesthetics.html#seaborn-figure-styles)

# Just for fun, we're going to set the theme to be a nice one:
sns.set_theme(style="ticks",
              font_scale=1.3, # This scales the fonts slightly higher
             )
# And we're going to remove the top and right axis lines
import matplotlib.pyplot as plt
plt.rc("axes.spines", top=False, right=False)
101/9:
df = pd.read_csv('http://www.bccdc.ca/Health-Info-Site/Documents/BCCDC_COVID19_Dashboard_Case_Details.csv')
df
101/10:
df = pd.read_csv('http://www.bccdc.ca/Health-Info-Site/Documents/BCCDC_COVID19_Dashboard_Case_Details.csv')
df
101/11:
df = pd.read_csv('http://www.bccdc.ca/Health-Info-Site/Documents/BCCDC_COVID19_Dashboard_Case_Details.csv')
df
101/12:
# Usually all the import statements are at the top of the file

import pandas as pd
import seaborn as sns
import numpy as np
import os
101/13:
# Themes and colours in Seaborn

# There are five preset seaborn themes: darkgrid, whitegrid, dark, white, and ticks. 
# They are each suited to different applications and personal preferences.
# You can see what they look like [here](https://seaborn.pydata.org/tutorial/aesthetics.html#seaborn-figure-styles)

# Just for fun, we're going to set the theme to be a nice one:
sns.set_theme(style="ticks",
              font_scale=1.3, # This scales the fonts slightly higher
             )
# And we're going to remove the top and right axis lines
import matplotlib.pyplot as plt
plt.rc("axes.spines", top=False, right=False)
101/14:
df = pd.read_csv('http://www.bccdc.ca/Health-Info-Site/Documents/BCCDC_COVID19_Dashboard_Case_Details.csv')
df
101/15: plot_1 = sns.countplot(y='Sex')
101/16: plot_1 = sns.countplot(y='Sex' , data = df)
101/17: plot1 = sns.countplot(y='Sex' , data = df)
101/18:
plot1 = sns.countplot(y='Sex' , data = df)
plot1.set_title('Number of COVID-19 cases by Sex' , fontdict ={'size':15})
101/19:
plot1 = sns.countplot(y='Sex' , data = df)
plot1.set_title('Number of COVID-19 cases by Sex' , fontdict ={'size':15})
plot1.show()
101/20:
plot1 = sns.countplot(y='Sex' , data = df)
plot1.set_title('Number of COVID-19 cases by Sex' , fontdict ={'size':15})
101/21:
plot1 = sns.countplot(y='Sex' , data = df)
plot1.set_title('Number of COVID-19 cases by Sex' , fontdict ={'size':15})
101/22: plot2 = sns.countplot(y='Age_Group' , data = df)
101/23:
plot2 = sns.countplot(y='Age_Group' , data = df)
plot2.set_xlabel('Count of Cases', fontdict={'size': 12})
plot1.set_ylabel('Age Group', fontdict={'size': 12})
101/24:
plot2 = sns.countplot(y='Age_Group' , data = df)
plot2.set_xlabel('Count of Cases', fontdict={'size': 12})
plot2.set_ylabel('Age Group', fontdict={'size': 12})
101/25:
plot2 = sns.countplot(y='Age_Group' , data = df)
plot2.set_xlabel('Count of Cases', fontdict={'size': 14})
plot2.set_ylabel('Age Group', fontdict={'size': 14})
101/26:
plot2 = sns.countplot(y='Age_Group' , data = df)
plot1.set_title('Number of COVID-19 cases by Age Group' , fontdict ={'size':15})
plot2.set_xlabel('Count of Cases', fontdict={'size': 14})
plot2.set_ylabel('Age Group', fontdict={'size': 14})
104/1:
plot2 = sns.countplot(y='Age_Group' , data = df , order=df['column'].value_counts().index))
plot1.set_title('Number of COVID-19 cases by Age Group' , fontdict ={'size':15})
plot2.set_xlabel('Count of Cases', fontdict={'size': 14})
plot2.set_ylabel('Age Group', fontdict={'size': 14})
104/2:
plot2 = sns.countplot(y='Age_Group' , data = df , order=df['column'].value_counts().index))
plot1.set_title('Number of COVID-19 cases by Age Group' , fontdict ={'size':15})
plot2.set_xlabel('Count of Cases', fontdict={'size': 14})
plot2.set_ylabel('Age Group', fontdict={'size': 14})
104/3:
plot2 = sns.countplot(y='Age_Group' , data = df , order=df['column'].value_counts().index)
plot1.set_title('Number of COVID-19 cases by Age Group' , fontdict ={'size':15})
plot2.set_xlabel('Count of Cases', fontdict={'size': 14})
plot2.set_ylabel('Age Group', fontdict={'size': 14})
104/4:
# Usually all the import statements are at the top of the file

import pandas as pd
import seaborn as sns
import numpy as np
import os
104/5:
# Themes and colours in Seaborn

# There are five preset seaborn themes: darkgrid, whitegrid, dark, white, and ticks. 
# They are each suited to different applications and personal preferences.
# You can see what they look like [here](https://seaborn.pydata.org/tutorial/aesthetics.html#seaborn-figure-styles)

# Just for fun, we're going to set the theme to be a nice one:
sns.set_theme(style="ticks",
              font_scale=1.3, # This scales the fonts slightly higher
             )
# And we're going to remove the top and right axis lines
import matplotlib.pyplot as plt
plt.rc("axes.spines", top=False, right=False)
104/6:
df = pd.read_csv('http://www.bccdc.ca/Health-Info-Site/Documents/BCCDC_COVID19_Dashboard_Case_Details.csv')
df
104/7:
plot1 = sns.countplot(y='Sex' , data = df)
plot1.set_title('Number of COVID-19 cases by Sex' , fontdict ={'size':15})
104/8:
plot2 = sns.countplot(y='Age_Group' , data = df , order=df['column'].value_counts().index)
plot1.set_title('Number of COVID-19 cases by Age Group' , fontdict ={'size':15})
plot2.set_xlabel('Count of Cases', fontdict={'size': 14})
plot2.set_ylabel('Age Group', fontdict={'size': 14})
104/9:
plot2 = sns.countplot(y='Age_Group' , data = df , order=df['column'].value_counts().index)
plot2.set_title('Number of COVID-19 cases by Age Group' , fontdict ={'size':15})
plot2.set_xlabel('Count of Cases', fontdict={'size': 14})
plot2.set_ylabel('Age Group', fontdict={'size': 14})
pl.show()
104/10:
plot2 = sns.countplot(y='Age_Group' , data = df , order=df['column'].value_counts().index)
plot2.set_title('Number of COVID-19 cases by Age Group' , fontdict ={'size':15})
plot2.set_xlabel('Count of Cases', fontdict={'size': 14})
plot2.set_ylabel('Age Group', fontdict={'size': 14})
plot2.show()
104/11:
plot2 = sns.countplot(y='Age_Group' , data = df , order=df['Age_Group'].value_counts().index)
plot2.set_title('Number of COVID-19 cases by Age Group' , fontdict ={'size':15})
plot2.set_xlabel('Count of Cases', fontdict={'size': 14})
plot2.set_ylabel('Age Group', fontdict={'size': 14})
plot2.show()
104/12:
plot2 = sns.countplot(y='Age_Group' , data = df , order=df['Age_Group'].value_counts().index)
plot2.set_title('Number of COVID-19 cases by Age Group' , fontdict ={'size':15})
plot2.set_xlabel('Count of Cases', fontdict={'size': 14})
plot2.set_ylabel('Age Group', fontdict={'size': 14})
104/13:
plot2 = sns.countplot(y='Age_Group' , data = df , order=df['Age_Group'].value_counts())
plot2.set_title('Number of COVID-19 cases by Age Group' , fontdict ={'size':15})
plot2.set_xlabel('Count of Cases', fontdict={'size': 14})
plot2.set_ylabel('Age Group', fontdict={'size': 14})
104/14:
plot2 = sns.countplot(y='Age_Group' , data = df , order=df['Age_Group'].value_counts().index)
plot2.set_title('Number of COVID-19 cases by Age Group' , fontdict ={'size':15})
plot2.set_xlabel('Count of Cases', fontdict={'size': 14})
plot2.set_ylabel('Age Group', fontdict={'size': 14})
104/15:
plot2 = sns.countplot(y='Age_Group' , data = df , order=df['Age_Group'].value_counts().index)
plot2.set_title('Number of COVID-19 cases by Age Group' , fontdict ={'size':15})
plot2.set_xlabel('Count of Cases', fontdict={'size': 14})
plot2.set_ylabel('Age Group', fontdict={'size': 14})
104/16:
plot2 = sns.countplot(y='Age_Group' , data = df , order=df.sort_values('Age_Group').Count)
plot2.set_title('Number of COVID-19 cases by Age Group' , fontdict ={'size':15})
plot2.set_xlabel('Count of Cases', fontdict={'size': 14})
plot2.set_ylabel('Age Group', fontdict={'size': 14})
104/17:
plot2 = sns.countplot(y='Age_Group' , data = df , order=df.sort_values('Age_Group'))
plot2.set_title('Number of COVID-19 cases by Age Group' , fontdict ={'size':15})
plot2.set_xlabel('Count of Cases', fontdict={'size': 14})
plot2.set_ylabel('Age Group', fontdict={'size': 14})
104/18:
plot2 = sns.countplot(y='Age_Group' , data = df , order=df.sort_values('Age_Group').count())
plot2.set_title('Number of COVID-19 cases by Age Group' , fontdict ={'size':15})
plot2.set_xlabel('Count of Cases', fontdict={'size': 14})
plot2.set_ylabel('Age Group', fontdict={'size': 14})
104/19:
plot2 = sns.countplot(y='Age_Group' , data = df , order=df.sort_values('Age_Group').count)
plot2.set_title('Number of COVID-19 cases by Age Group' , fontdict ={'size':15})
plot2.set_xlabel('Count of Cases', fontdict={'size': 14})
plot2.set_ylabel('Age Group', fontdict={'size': 14})
104/20:
plot2 = sns.countplot(y='Age_Group' , data = df , order=df['Age_Group'].value_counts().index)
plot2.set_title('Number of COVID-19 cases by Age Group' , fontdict ={'size':15})
plot2.set_xlabel('Count of Cases', fontdict={'size': 14})
plot2.set_ylabel('Age Group', fontdict={'size': 14})
104/21: plot3 = sns.countplot(y='HA' , data = df)
103/1:
import pandas as pd

df= pd.read_csv('https://github.com/firasm/bits/raw/master/pokemon.csv')
print(df)
103/2:
df= pd.read_csv('https://github.com/firasm/bits/raw/master/pokemon.csv')
print(df)
103/3: newdf = pd.read_csv('data/lab05_task2.csv')
103/4: df = pd.read_csv('data/lab05_task2.csv')
103/5: df = pd.read_csv('/Users/poojalal/Desktop/DATA301/lab05-DARTH-LAL/data/lab05_task2.csv')
103/6:
df = pd.read_csv('/Users/poojalal/Desktop/DATA301/lab05-DARTH-LAL/data/lab05_task2.csv')
df
103/7: df.groupby("Type 1")
103/8: df.groupby("Type 1")
103/9:
df.groupby("Type 1")
df
104/22: set(df['HA'])
104/23: plot3 = sns.countplot(y='HA' , data = df)
104/24: plot3 = sns.countplot(y='HA' ,hue = 'Sex' , data = df)
104/25: df['Reported_Date(datetime)']  = pd.to_datetime(df.Reported_Date)
104/26:
df['Reported_Date(datetime)']  = pd.to_datetime(df.Reported_Date)
df
104/27:
df['Reported_Date(datetime)']  = pd.to_datetime(df.Reported_Date)
df.info()
103/10: sel = ['Type 1' , 'Weighted Score']
103/11:
sel = ['Type 1' , 'Weighted Score']
df[sel]
103/12:
sel = ['Type 1' , 'Weighted Score']
df[sel].sort_values(by= 'Weighted Score)
103/13:
sel = ['Type 1' , 'Weighted Score']
df[sel].sort_values(by= 'Weighted Score')
103/14:
sel = ['Type 1' , 'Weighted Score']
df[sel].groupby('Type 1').sort_values(by= 'Weighted Score')
103/15:
sel = ['Type 1' , 'Weighted Score']
df[sel].groupby('Type 1').mean().sort_values(by= 'Weighted Score')
103/16:
sel = ['Type 1' , 'Weighted Score']
df[sel].groupby('Type 1').mean().sort_values(by= 'Weighted Score' , ascending = False)
104/28:
plot2 = sns.countplot(y='Age_Group' , data = df )
plot2.set_title('Number of COVID-19 cases by Age Group' , fontdict ={'size':15})
plot2.set_xlabel('Count of Cases', fontdict={'size': 14})
plot2.set_ylabel('Age Group', fontdict={'size': 14})
104/29:
plot2 = sns.countplot(y='Age_Group' , data = df , order = [ '<10' , '10-19' )
plot2.set_title('Number of COVID-19 cases by Age Group' , fontdict ={'size':15})
plot2.set_xlabel('Count of Cases', fontdict={'size': 14})
plot2.set_ylabel('Age Group', fontdict={'size': 14})
104/30:
plot2 = sns.countplot(y='Age_Group' , data = df , order = [ '<10' , '10-19'] )
plot2.set_title('Number of COVID-19 cases by Age Group' , fontdict ={'size':15})
plot2.set_xlabel('Count of Cases', fontdict={'size': 14})
plot2.set_ylabel('Age Group', fontdict={'size': 14})
104/31: df.Age_Group.unique()
104/32: df.Age_Group.unique().sorted()
104/33: df.Age_Group.unique().sort()
104/34:
plot2 = sns.countplot(y='Age_Group' , data = df , )
plot2.set_title('Number of COVID-19 cases by Age Group' , fontdict ={'size':15})
plot2.set_xlabel('Count of Cases', fontdict={'size': 14})
plot2.set_ylabel('Age Group', fontdict={'size': 14})
104/35: df.Age_Group.unique().sort()
104/36:
df2 = df.Age_Group.unique().sort()
df2
104/37:
df2 = df.Age_Group.unique().sort()
df2
104/38:
df2 = df.Age_Group.unique().sort()
print(df20
104/39:
df2 = df.Age_Group.unique().sort()
print(df2)
104/40:
plot2 = sns.countplot(y='Age_Group' , data = df ,  '<10' , '10-19' , '20-29' ,'30-39' , '40-49' , '50-59' , '60-69' , '70-79' , '80-89' , '90+' , 'Unknown' ])
plot2.set_title('Number of COVID-19 cases by Age Group' , fontdict ={'size':15})
plot2.set_xlabel('Count of Cases', fontdict={'size': 14})
plot2.set_ylabel('Age Group', fontdict={'size': 14})
104/41:
plot2 = sns.countplot(y='Age_Group' , data = df , order = [ '<10' , '10-19' , '20-29' ,'30-39' , '40-49' , '50-59' , '60-69' , '70-79' , '80-89' , '90+' , 'Unknown' ])
plot2.set_title('Number of COVID-19 cases by Age Group' , fontdict ={'size':15})
plot2.set_xlabel('Count of Cases', fontdict={'size': 14})
plot2.set_ylabel('Age Group', fontdict={'size': 14})
104/42:
set(df['HA'])

plot3 = sns.countplot(y='HA' ,hue = 'Sex' , data = df)
104/43: set(df['HA'])
104/44: plot3 = sns.countplot(y='HA' ,hue = 'Sex' , data = df)
104/45:
df['Reported_Date(datetime)']  = pd.to_datetime(df.Reported_Date)
df.info()
104/46: df['Reported_Date(datetime)'].min()
104/47: df['Reported_Date(datetime)'].max()
104/48: df['Reported_Date(datetime)'].max()
107/1:
sel = ['Type 1' , 'Weighted Score']
df['Weighted_Score']=df[sel].groupby('Type 1').mean().sort_values(by= 'Weighted Score' , ascending = False)
107/2:
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
107/3: # Your Solution Here
107/4:
df = pd.read_csv('/Users/poojalal/Desktop/DATA301/lab05-DARTH-LAL/data/lab05_task2.csv')
df
107/5:
sel = ['Type 1' , 'Weighted Score']
df['Weighted_Score']=df[sel].groupby('Type 1').mean().sort_values(by= 'Weighted Score' , ascending = False)
107/6:
sel = ['Type 1' , 'Weighted Score']
df['Weighted_Score']=df[sel].groupby('Type 1').mean().sort_values(by= 'Weighted Score' , ascending = False)
df
107/7:
sel = ['Type 1' , 'Weighted Score']
df[sel].groupby('Type 1').mean().sort_values(by= 'Weighted Score' , ascending = False)
107/8: seaborn.violinplot(data=df, x='Type 1', y='Weighted Score' ]
107/9: seaborn.violinplot(data=df, x='Type 1', y='Weighted Score' )
107/10:
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
107/11: # Your Solution Here
107/12:
df = pd.read_csv('/Users/poojalal/Desktop/DATA301/lab05-DARTH-LAL/data/lab05_task2.csv')
df
107/13:
sel = ['Type 1' , 'Weighted Score']
df[sel].groupby('Type 1').mean().sort_values(by= 'Weighted Score' , ascending = False)
107/14: seaborn.violinplot(data=df, x='Type 1', y='Weighted Score' )
107/15: sns.violinplot(data=df, x='Type 1', y='Weighted Score' )
106/1: plt.figure(figsize=(3,7))
108/1:
plot3 = sns.countplot(y='HA' ,hue = 'Sex' , data = df)
plot3.color_palette()
108/2:
# Usually all the import statements are at the top of the file

import pandas as pd
import seaborn as sns
import numpy as np
import os
108/3:
# Themes and colours in Seaborn

# There are five preset seaborn themes: darkgrid, whitegrid, dark, white, and ticks. 
# They are each suited to different applications and personal preferences.
# You can see what they look like [here](https://seaborn.pydata.org/tutorial/aesthetics.html#seaborn-figure-styles)

# Just for fun, we're going to set the theme to be a nice one:
sns.set_theme(style="ticks",
              font_scale=1.3, # This scales the fonts slightly higher
             )
# And we're going to remove the top and right axis lines
import matplotlib.pyplot as plt
plt.rc("axes.spines", top=False, right=False)
108/4:
df = pd.read_csv('http://www.bccdc.ca/Health-Info-Site/Documents/BCCDC_COVID19_Dashboard_Case_Details.csv')
df
108/5:
plot1 = sns.countplot(y='Sex' , data = df)
plot1.set_title('Number of COVID-19 cases by Sex' , fontdict ={'size':15})
108/6:
plot2 = sns.countplot(y='Age_Group' , data = df , order = [ '<10' , '10-19' , '20-29' ,'30-39' , '40-49' , '50-59' , '60-69' , '70-79' , '80-89' , '90+' , 'Unknown' ])
plot2.set_title('Number of COVID-19 cases by Age Group' , fontdict ={'size':15})
plot2.set_xlabel('Count of Cases', fontdict={'size': 14})
plot2.set_ylabel('Age Group', fontdict={'size': 14})
108/7: set(df['HA'])
108/8:
plot3 = sns.countplot(y='HA' ,hue = 'Sex' , data = df)
plot3.color_palette()
108/9:
plot3 = sns.countplot(y='HA' ,hue = 'Sex' , data = df)
plot3.color_palette("tab10")
108/10:
sns.set_palette("Paired")
plot3 = sns.countplot(y='HA' ,hue = 'Sex' , data = df)
108/11:
sns.set_palette("tab10")
plot3 = sns.countplot(y='HA' ,hue = 'Sex' , data = df)
108/12:
sns.set_palette("hls", 8)
plot3 = sns.countplot(y='HA' ,hue = 'Sex' , data = df)
108/13:
sns.set_palette("hls", 1)
plot3 = sns.countplot(y='HA' ,hue = 'Sex' , data = df)
108/14:
sns.set_palette("hls", 2)
plot3 = sns.countplot(y='HA' ,hue = 'Sex' , data = df)
108/15:
sns.set_palette("hls", 3)
plot3 = sns.countplot(y='HA' ,hue = 'Sex' , data = df)
108/16:
sns.set_palette("hls", 4)
plot3 = sns.countplot(y='HA' ,hue = 'Sex' , data = df)
108/17:
sns.set_palette("hls", 5)
plot3 = sns.countplot(y='HA' ,hue = 'Sex' , data = df)
108/18:
sns.set_palette("hls", 6)
plot3 = sns.countplot(y='HA' ,hue = 'Sex' , data = df)
108/19:
sns.set_palette("hls", 7)
plot3 = sns.countplot(y='HA' ,hue = 'Sex' , data = df)
108/20:
sns.set_palette("hls", 10)
plot3 = sns.countplot(y='HA' ,hue = 'Sex' , data = df)
108/21:
sns.set_palette("hls", 14)
plot3 = sns.countplot(y='HA' ,hue = 'Sex' , data = df)
108/22:
sns.set_palette("hls", 17)
plot3 = sns.countplot(y='HA' ,hue = 'Sex' , data = df)
108/23:
sns.set_palette("hls", 20)
plot3 = sns.countplot(y='HA' ,hue = 'Sex' , data = df)
108/24:
sns.set_palette("husl", 20)
plot3 = sns.countplot(y='HA' ,hue = 'Sex' , data = df)
108/25:
sns.set_palette("husl", 1)
plot3 = sns.countplot(y='HA' ,hue = 'Sex' , data = df)
108/26:
sns.set_palette("husl", 2)
plot3 = sns.countplot(y='HA' ,hue = 'Sex' , data = df)
108/27:
sns.set_palette("husl", 3)
plot3 = sns.countplot(y='HA' ,hue = 'Sex' , data = df)
108/28:
sns.set_palette("husl")
plot3 = sns.countplot(y='HA' ,hue = 'Sex' , data = df)
108/29:
sns.set_palette("Set1")
plot3 = sns.countplot(y='HA' ,hue = 'Sex' , data = df)
108/30:
sns.set_palette("Set2")
plot3 = sns.countplot(y='HA' ,hue = 'Sex' , data = df)
108/31: df['Reported_Date_Objec'].min()
108/32: df['Reported_Date_Object'].min()
108/33:
df['Reported_Date_Object']  = pd.to_datetime(df.Reported_Date)
df.info()
108/34: df['Reported_Date_Object'].min()
108/35: df['Reported_Date_Object'].max()
108/36: df['Reported_Date_Object'].max()
108/37: df['Reported_Date_Object'].min()
108/38: df['Reported_Date_Object'].min()
108/39: df['Reported_Date_Object'].max()
108/40: df['days_since']  =df['Reported_Date_Object'].min() - df['Reported_date']
108/41: df['days_since']  =df['Reported_Date_Object'].min() - df['Reported_Date']
108/42:
# Usually all the import statements are at the top of the file

import pandas as pd
import seaborn as sns
import numpy as np
import os
108/43:
# Themes and colours in Seaborn

# There are five preset seaborn themes: darkgrid, whitegrid, dark, white, and ticks. 
# They are each suited to different applications and personal preferences.
# You can see what they look like [here](https://seaborn.pydata.org/tutorial/aesthetics.html#seaborn-figure-styles)

# Just for fun, we're going to set the theme to be a nice one:
sns.set_theme(style="ticks",
              font_scale=1.3, # This scales the fonts slightly higher
             )
# And we're going to remove the top and right axis lines
import matplotlib.pyplot as plt
plt.rc("axes.spines", top=False, right=False)
108/44:
df = pd.read_csv('http://www.bccdc.ca/Health-Info-Site/Documents/BCCDC_COVID19_Dashboard_Case_Details.csv')
df
108/45:
plot1 = sns.countplot(y='Sex' , data = df)
plot1.set_title('Number of COVID-19 cases by Sex' , fontdict ={'size':15})
108/46:
plot2 = sns.countplot(y='Age_Group' , data = df , order = [ '<10' , '10-19' , '20-29' ,'30-39' , '40-49' , '50-59' , '60-69' , '70-79' , '80-89' , '90+' , 'Unknown' ])
plot2.set_title('Number of COVID-19 cases by Age Group' , fontdict ={'size':15})
plot2.set_xlabel('Count of Cases', fontdict={'size': 14})
plot2.set_ylabel('Age Group', fontdict={'size': 14})
108/47: set(df['HA'])
108/48:
sns.set_palette("Set2")
plot3 = sns.countplot(y='HA' ,hue = 'Sex' , data = df)
108/49:
df['Reported_Date_Object']  = pd.to_datetime(df.Reported_Date)
df.info()
108/50: df['Reported_Date_Object'].min()
108/51: df['Reported_Date_Object'].max()
106/2: sns.hexbinplot(data = df , x = 'Attack' , y = 'Defense')
106/3:
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
106/4: # Your Solution Here
106/5:
df = pd.read_csv('/Users/poojalal/Desktop/DATA301/lab05-DARTH-LAL/data/lab05_task2.csv')
df
106/6:
sel = ['Type 1' , 'Weighted Score']
df[sel].groupby('Type 1').mean().sort_values(by= 'Weighted Score' , ascending = False)
106/7: # Your Solution here
106/8: sns.hexbinplot(data = df , x = 'Attack' , y = 'Defense')
106/9: sns.jointplot(data = df , x = 'Attack' , y = 'Defense')
106/10: sns.jointplot(data = df , x = 'Attack' , y = 'Defense' ,  kind="hex")
106/11: sns.pairlot(data= df0
106/12: sns.pairlot(data= df)
106/13: sns.pairplot(data= df)
106/14: sns.pairplot(data= df)
106/15: sns.pairplot(data= df , corner=True))
106/16: sns.pairplot(data= df , corner=True)
106/17:
df2 = df.drop(['Legendary']
sns.pairplot(data= df , corner=True)
106/18:
df2 = df.drop(['Legendary'])
sns.pairplot(data= df , corner=True)
106/19:
df2 = df.drop('Legendary')
sns.pairplot(data= df , corner=True)
106/20:
df2 = df.drop('Legendary' , axis=1))
sns.pairplot(data= df , corner=True)
106/21:
df2 = df.drop('Legendary' , axis=1)
sns.pairplot(data= df , corner=True)
106/22: sns.pairplot(data= df , corner=True)
109/1:
df = pd.read_csv('/Users/poojalal/Desktop/DATA301/lab05-DARTH-LAL/data/lab05_task2.csv')
df
109/2:
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
109/3: # Your Solution here
109/4:
df = pd.read_csv('/Users/poojalal/Desktop/DATA301/lab05-DARTH-LAL/data/lab05_task2.csv')
df
110/1: sns.pairplot(data= df , corner=True , x_vars = ['HP' , 'Attack' , 'Defense' , 'Speed' , 'Weighted Score'] , y_vars = ['Attack' , 'Defense' , 'Speed' , 'Weighted Score'])
112/1:
# Usually all the import statements are at the top of the file

import pandas as pd
import seaborn as sns
import numpy as np
import os
112/2:
# Themes and colours in Seaborn

# There are five preset seaborn themes: darkgrid, whitegrid, dark, white, and ticks. 
# They are each suited to different applications and personal preferences.
# You can see what they look like [here](https://seaborn.pydata.org/tutorial/aesthetics.html#seaborn-figure-styles)

# Just for fun, we're going to set the theme to be a nice one:
sns.set_theme(style="ticks",
              font_scale=1.3, # This scales the fonts slightly higher
             )
# And we're going to remove the top and right axis lines
import matplotlib.pyplot as plt
plt.rc("axes.spines", top=False, right=False)
112/3:
df = pd.read_csv('http://www.bccdc.ca/Health-Info-Site/Documents/BCCDC_COVID19_Dashboard_Case_Details.csv')
df
110/2:
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
110/3: # Your Solution Here
110/4:
df = pd.read_csv('/Users/poojalal/Desktop/DATA301/lab05-DARTH-LAL/data/lab05_task2.csv')
df
110/5:
sel = ['Type 1' , 'Weighted Score']
df[sel].groupby('Type 1').mean().sort_values(by= 'Weighted Score' , ascending = False)
110/6: # Your Solution here
110/7: sns.jointplot(data = df , x = 'Attack' , y = 'Defense' ,  kind="hex")
110/8: sns.pairplot(data= df , corner=True , x_vars = ['HP' , 'Attack' , 'Defense' , 'Speed' , 'Weighted Score'] , y_vars = ['Attack' , 'Defense' , 'Speed' , 'Weighted Score'])
112/4:
plot1 = sns.countplot(y='Sex' , data = df)
plot1.set_title('Number of COVID-19 cases by Sex' , fontdict ={'size':15})
112/5:
plot2 = sns.countplot(y='Age_Group' , data = df , order = [ '<10' , '10-19' , '20-29' ,'30-39' , '40-49' , '50-59' , '60-69' , '70-79' , '80-89' , '90+' , 'Unknown' ])
plot2.set_title('Number of COVID-19 cases by Age Group' , fontdict ={'size':15})
plot2.set_xlabel('Count of Cases', fontdict={'size': 14})
plot2.set_ylabel('Age Group', fontdict={'size': 14})
110/9: sns.pairplot(data= df , x_vars = ['HP' , 'Attack' , 'Defense' , 'Speed' , 'Weighted Score'] , y_vars = ['Attack' , 'Defense' , 'Speed' , 'Weighted Score'] , corner=True)
110/10: sns.pairplot(data= df , x_vars = ['HP' , 'Attack' , 'Defense' , 'Speed' , 'Weighted Score'] , y_vars = ['Attack' , 'Defense' , 'Speed' , 'Weighted Score'])
110/11: sns.pairplot(data= df , x_vars = ['HP' , 'Attack' , 'Defense' , 'Speed' , 'Weighted Score'] , y_vars = ['Attack' , 'Defense' , 'Speed' , 'Weighted Score'] , corner =Ture)
110/12: sns.pairplot(data= df , x_vars = ['HP' , 'Attack' , 'Defense' , 'Speed' , 'Weighted Score'] , y_vars = ['Attack' , 'Defense' , 'Speed' , 'Weighted Score'] , corner =True)
111/1:
sns.set_theme(style = 'white' , rc = {'axes.facecolor';(0,0,0,0)})
pal = sns.sns.cubehelix_palette(10, rot=-.25, light=.7)
g = sns.FacetGrid(df, row='Weighted Score', hue='Type 1', aspect=15, height=.5, palette=pal)

g.map(sns.kdeplot, 'Weighted Score',
      bw_adjust=.5, clip_on=False,
      fill=True, alpha=1, linewidth=1.5)
g.map(sns.kdeplot, 'Weighhted Score', clip_on=False, color="w", lw=2, bw_adjust=.5)

g.refline(y=0, linewidth=2, linestyle="-", color=None, clip_on=False)

def label(x, color, label):
    ax = plt.gca()
    ax.text(0, .2, label, fontweight="bold", color=color,
            ha="left", va="center", transform=ax.transAxes)
    
g.map(label, 'Weighted Score')
111/2:
sns.set_theme(style = 'white' , rc = {'axes.facecolor';(0,0,0,0)})
pal = sns.sns.cubehelix_palette(10, rot=-.25, light=.7)
g = sns.FacetGrid(df, row='Weighted Score', hue='Type 1', aspect=15, height=.5, palette=pal)

g.map(sns.kdeplot, 'Weighted Score',
      bw_adjust=.5, clip_on=False,
      fill=True, alpha=1, linewidth=1.5)
g.map(sns.kdeplot, 'Weighhted Score', clip_on=False, color="w", lw=2, bw_adjust=.5)

g.refline(y=0, linewidth=2, linestyle="-", color=None, clip_on=False)

def label(x, color, label):
    ax = plt.gca()
    ax.text(0, .2, label, fontweight="bold", color=color,
            ha="left", va="center", transform=ax.transAxes)
    
g.map(label, 'Weighted Score')

g.figure.subplots_adjust(hspace=-.25)

g.set_titles("")
g.set(yticks=[], ylabel="")
g.despine(bottom=True, left=True)
111/3:
sns.set_theme(style = 'white' , rc = {'axes.facecolor':(0,0,0,0)})
pal = sns.sns.cubehelix_palette(10, rot=-.25, light=.7)
g = sns.FacetGrid(df, row='Weighted Score', hue='Type 1', aspect=15, height=.5, palette=pal)

g.map(sns.kdeplot, 'Weighted Score',
      bw_adjust=.5, clip_on=False,
      fill=True, alpha=1, linewidth=1.5)
g.map(sns.kdeplot, 'Weighhted Score', clip_on=False, color="w", lw=2, bw_adjust=.5)

g.refline(y=0, linewidth=2, linestyle="-", color=None, clip_on=False)

def label(x, color, label):
    ax = plt.gca()
    ax.text(0, .2, label, fontweight="bold", color=color,
            ha="left", va="center", transform=ax.transAxes)
    
g.map(label, 'Weighted Score')

g.figure.subplots_adjust(hspace=-.25)

g.set_titles("")
g.set(yticks=[], ylabel="")
g.despine(bottom=True, left=True)
111/4:
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
111/5: # Your Solution here
111/6:
df = pd.read_csv('/Users/poojalal/Desktop/DATA301/lab05-DARTH-LAL/data/lab05_task2.csv')
df
111/7:
sns.set_theme(style = 'white' , rc = {'axes.facecolor':(0,0,0,0)})
pal = sns.sns.cubehelix_palette(10, rot=-.25, light=.7)
g = sns.FacetGrid(df, row='Weighted Score', hue='Type 1', aspect=15, height=.5, palette=pal)

g.map(sns.kdeplot, 'Weighted Score',
      bw_adjust=.5, clip_on=False,
      fill=True, alpha=1, linewidth=1.5)
g.map(sns.kdeplot, 'Weighhted Score', clip_on=False, color="w", lw=2, bw_adjust=.5)

g.refline(y=0, linewidth=2, linestyle="-", color=None, clip_on=False)

def label(x, color, label):
    ax = plt.gca()
    ax.text(0, .2, label, fontweight="bold", color=color,
            ha="left", va="center", transform=ax.transAxes)
    
g.map(label, 'Weighted Score')

g.figure.subplots_adjust(hspace=-.25)

g.set_titles("")
g.set(yticks=[], ylabel="")
g.despine(bottom=True, left=True)
111/8:
sns.set_theme(style = 'white' , rc = {'axes.facecolor':(0,0,0,0)})
pal = sns.cubehelix_palette(10, rot=-.25, light=.7)
g = sns.FacetGrid(df, row='Weighted Score', hue='Type 1', aspect=15, height=.5, palette=pal)

g.map(sns.kdeplot, 'Weighted Score',
      bw_adjust=.5, clip_on=False,
      fill=True, alpha=1, linewidth=1.5)
g.map(sns.kdeplot, 'Weighhted Score', clip_on=False, color="w", lw=2, bw_adjust=.5)

g.refline(y=0, linewidth=2, linestyle="-", color=None, clip_on=False)

def label(x, color, label):
    ax = plt.gca()
    ax.text(0, .2, label, fontweight="bold", color=color,
            ha="left", va="center", transform=ax.transAxes)
    
g.map(label, 'Weighted Score')

g.figure.subplots_adjust(hspace=-.25)

g.set_titles("")
g.set(yticks=[], ylabel="")
g.despine(bottom=True, left=True)
111/9:
sns.set_theme(style = 'white' , rc = {'axes.facecolor':(0,0,0,0)})
pal = sns.cubehelix_palette(10, rot=-.25, light=.7)
g = sns.FacetGrid(df, row='Type 1', hue='Type 1', aspect=15, height=.5, palette=pal)

g.map(sns.kdeplot, 'Weighted Score',
      bw_adjust=.5, clip_on=False,
      fill=True, alpha=1, linewidth=1.5)
g.map(sns.kdeplot, 'Weighhted Score', clip_on=False, color="w", lw=2, bw_adjust=.5)

g.refline(y=0, linewidth=2, linestyle="-", color=None, clip_on=False)

def label(x, color, label):
    ax = plt.gca()
    ax.text(0, .2, label, fontweight="bold", color=color,
            ha="left", va="center", transform=ax.transAxes)
    
g.map(label, 'Weighted Score')

g.figure.subplots_adjust(hspace=-.25)

g.set_titles("")
g.set(yticks=[], ylabel="")
g.despine(bottom=True, left=True)
110/13: sns.pairplot(data= df , x_vars = ['HP' , 'Attack' , 'Defense' , 'Speed' , 'Weighted Score'] , y_vars = ['Attack' , 'Defense' , 'Speed' , 'Weighted Score'] , corner =True)
112/6: df['days_since'] = df['Reported_Date_Object'].min() - df['Reported_Date_Object']
112/7:
# Usually all the import statements are at the top of the file

import pandas as pd
import seaborn as sns
import numpy as np
import os
112/8:
# Themes and colours in Seaborn

# There are five preset seaborn themes: darkgrid, whitegrid, dark, white, and ticks. 
# They are each suited to different applications and personal preferences.
# You can see what they look like [here](https://seaborn.pydata.org/tutorial/aesthetics.html#seaborn-figure-styles)

# Just for fun, we're going to set the theme to be a nice one:
sns.set_theme(style="ticks",
              font_scale=1.3, # This scales the fonts slightly higher
             )
# And we're going to remove the top and right axis lines
import matplotlib.pyplot as plt
plt.rc("axes.spines", top=False, right=False)
112/9:
df = pd.read_csv('http://www.bccdc.ca/Health-Info-Site/Documents/BCCDC_COVID19_Dashboard_Case_Details.csv')
df
112/10:
plot1 = sns.countplot(y='Sex' , data = df)
plot1.set_title('Number of COVID-19 cases by Sex' , fontdict ={'size':15})
112/11:
plot2 = sns.countplot(y='Age_Group' , data = df , order = [ '<10' , '10-19' , '20-29' ,'30-39' , '40-49' , '50-59' , '60-69' , '70-79' , '80-89' , '90+' , 'Unknown' ])
plot2.set_title('Number of COVID-19 cases by Age Group' , fontdict ={'size':15})
plot2.set_xlabel('Count of Cases', fontdict={'size': 14})
plot2.set_ylabel('Age Group', fontdict={'size': 14})
112/12: set(df['HA'])
112/13:
sns.set_palette("Set2")
plot3 = sns.countplot(y='HA' ,hue = 'Sex' , data = df)
112/14:
df['Reported_Date_Object']  = pd.to_datetime(df.Reported_Date)
df.info()
112/15: df['Reported_Date_Object'].min()
112/16: df['Reported_Date_Object'].max()
112/17: df['days_since'] = df['Reported_Date_Object'].min() - df['Reported_Date_Object']
112/18:
df['days_since'] = df['Reported_Date_Object'].min() - df['Reported_Date_Object']
df
112/19:
df['days_since'] = (df['Reported_Date_Object'].min() - df['Reported_Date_Object']).days
df
112/20:
df['days_since'] = (df['Reported_Date_Object'].min() - df['Reported_Date_Object']).day
df
112/21:
df['days_since'] = (df['Reported_Date_Object'].min() - df['Reported_Date_Object']).days
df
112/22:
df['days_since'] = (df['Reported_Date_Object'].min() - df['Reported_Date_Object'])
df
112/23:
df['days_since'] = (df['Reported_Date_Object'].min() - df['Reported_Date_Object']).day
df
112/24:
df['days_since'] = (df['Reported_Date_Object'].min() - df['Reported_Date_Object']).apply(lambda x:x.days)
df
112/25:
df['days_since'] = (df['Reported_Date_Object'] - df['Reported_Date_Object'].min()).apply(lambda x:x.days)
df
110/14:
sel = ['Type 1' , 'Weighted Score']
df2 = df[sel].groupby('Type 1').mean().sort_values(by= 'Weighted Score' , ascending = False)
110/15:
sel = ['Type 1' , 'Weighted Score']
df2 = df[sel].groupby('Type 1').mean().sort_values(by= 'Weighted Score' , ascending = False)
110/16:
sel = ['Type 1' , 'Weighted Score']
df2 = df[sel].groupby('Type 1').mean().sort_values(by= 'Weighted Score' , ascending = False)
df2
110/17: sns.violinplot(data =df2 )
110/18: sns.violinplot(data =df , y ='Type 1' , x = 'Weighted Score' )
110/19: sns.pairplot(data= df , x_vars = ['HP' , 'Attack' , 'Defense' , 'Speed' , 'Weighted Score'] , y_vars = ['Attack' , 'Defense' , 'Speed' , 'Weighted Score'] )
110/20:
sel = ['Type 1' , 'Weighted Score']
df2 = df[sel].groupby('Type 1').mean().sort_values(by= 'Weighted Score' , ascending = False)
df2
110/21: sns.violinplot(data =df , y ='Type 1' , x = 'Weighted Score' )
110/22: # Your Solution here
110/23: sns.jointplot(data = df , x = 'Attack' , y = 'Defense' ,  kind="hex")
110/24: sns.pairplot(data= df , x_vars = ['HP' , 'Attack' , 'Defense' , 'Speed' , 'Weighted Score'] , y_vars = ['Attack' , 'Defense' , 'Speed' , 'Weighted Score'] )
110/25: sns.pairplot(data= df , x_vars = ['HP' , 'Attack' , 'Defense' , 'Speed' , 'Weighted Score'] , y_vars = ['Attack' , 'Defense' , 'Speed' , 'Weighted Score'] ,  corner =True)
110/26: sns.pairplot(data= df , x_vars = ['HP' , 'Attack' , 'Defense' , 'Speed' , 'Weighted Score'] , y_vars = ['Attack' , 'Defense' , 'Speed' , 'Weighted Score'])
110/27: sns.pairplot(data= df ,corner =True, x_vars = ['HP' , 'Attack' , 'Defense' , 'Speed' , 'Weighted Score'] , y_vars = ['Attack' , 'Defense' , 'Speed' , 'Weighted Score'])
110/28:
sns.pairplot(data= df ,corner =True)
#, x_vars = ['HP' , 'Attack' , 'Defense' , 'Speed' , 'Weighted Score'] , y_vars = ['Attack' , 'Defense' , 'Speed' , 'Weighted Score'])
110/29:
sns.pairplot(data= df.loc[:,['HP' , 'Attack' , 'Defense' , 'Speed' , 'Weighted Score']],corner =True)
#, x_vars = ['HP' , 'Attack' , 'Defense' , 'Speed' , 'Weighted Score'] , y_vars = ['Attack' , 'Defense' , 'Speed' , 'Weighted Score'])
110/30: sns.pairplot(data= df.loc[:,['HP' , 'Attack' , 'Defense' , 'Speed' , 'Weighted Score']],corner =True)
111/10:
sns.set_theme(style = 'white' , rc = {'axes.facecolor':(0,0,0,0)})
pal = sns.cubehelix_palette(10, rot=-.25, light=.7)
g = sns.FacetGrid(df, row='Type 1', hue='Type 1', aspect=15, height=.5, palette=pal)

g.map(sns.kdeplot, 'Weighted Score',
      bw_adjust=.5, clip_on=False,
      fill=True, alpha=1, linewidth=1.5)
g.map(sns.kdeplot, 'Weighted Score', clip_on=False, color="w", lw=2, bw_adjust=.5)

g.refline(y=0, linewidth=2, linestyle="-", color=None, clip_on=False)

def label(x, color, label):
    ax = plt.gca()
    ax.text(0, .2, label, fontweight="bold", color=color,
            ha="left", va="center", transform=ax.transAxes)
    
g.map(label, 'Weighted Score')

g.figure.subplots_adjust(hspace=-.25)

g.set_titles("")
g.set(yticks=[], ylabel="")
g.despine(bottom=True, left=True)
111/11:
sns.set_theme(style = 'white' , rc = {'axes.facecolor':(0,0,0,0)})
pal = sns.cubehelix_palette(10, rot=-.25, light=.7)
g = sns.FacetGrid(df, row='Type 1', hue='Type 1', aspect=15, height=.5, palette=pal)

g.map(sns.kdeplot, 'Weighted Score',
      bw_adjust=.5, clip_on=False,
      fill=True, alpha=1, linewidth=1.5)
g.map(sns.kdeplot, 'Weighted Score', clip_on=False, color="w", lw=2, bw_adjust=.5)

g.refline(y=0, linewidth=2, linestyle="-", color=None, clip_on=False)

def label(x, color, label):
    ax = plt.gca()
    ax.text(0, .2, label, fontweight="bold", color=color,
            ha="left", va="center", transform=ax.transAxes)
    
g.map(label, 'Weighted Score')

g.figure.subplots_adjust(hspace=-.25)

g.set_titles("")
g.set(yticks=[], ylabel="")
g.despine(bottom=True, left=True)
111/12:
sns.set_theme(style = 'white' , rc = {'axes.facecolor':(0,0,0,0)})
pal = sns.cubehelix_palette(10, rot=-.25, light=.7)
g = sns.FacetGrid(df, row=['Steel', 'Dragon'], hue='Type 1', aspect=15, height=.5, palette=pal)

g.map(sns.kdeplot, 'Weighted Score',
      bw_adjust=.5, clip_on=False,
      fill=True, alpha=1, linewidth=1.5)
g.map(sns.kdeplot, 'Weighted Score', clip_on=False, color="w", lw=2, bw_adjust=.5)

g.refline(y=0, linewidth=2, linestyle="-", color=None, clip_on=False)

def label(x, color, label):
    ax = plt.gca()
    ax.text(0, .2, label, fontweight="bold", color=color,
            ha="left", va="center", transform=ax.transAxes)
    
g.map(label, 'Weighted Score')

g.figure.subplots_adjust(hspace=-.25)

g.set_titles("")
g.set(yticks=[], ylabel="")
g.despine(bottom=True, left=True)
111/13:
sns.set_theme(style = 'white' , rc = {'axes.facecolor':(0,0,0,0)})
pal = sns.cubehelix_palette(10, rot=-.25, light=.7)
sorter = ['Steel' , 'Dragon' , 'Rock' , 'Ground' , 'Fighting' , 'Dark' , 'Fire' , 'Poison' , 'Water' , 'Grass' , 'Ice' , 'Electric' , 'Bug' , 'Ghost' , 'Fairy' , 'Psychic']
sorterIndex = dict(zip(sorter, range(len(sorter))))
df['Type 1 Rank'] = df['Type 1'].map(sorterIndex)

g = sns.FacetGrid(df, row=, hue='Type 1 Rank', aspect=15, height=.5, palette=pal)

g.map(sns.kdeplot, 'Weighted Score',
      bw_adjust=.5, clip_on=False,
      fill=True, alpha=1, linewidth=1.5)
g.map(sns.kdeplot, 'Weighted Score', clip_on=False, color="w", lw=2, bw_adjust=.5)

g.refline(y=0, linewidth=2, linestyle="-", color=None, clip_on=False)

def label(x, color, label):
    ax = plt.gca()
    ax.text(0, .2, label, fontweight="bold", color=color,
            ha="left", va="center", transform=ax.transAxes)
    
g.map(label, 'Weighted Score')

g.figure.subplots_adjust(hspace=-.25)

g.set_titles("")
g.set(yticks=[], ylabel="")
g.despine(bottom=True, left=True)
111/14:
sns.set_theme(style = 'white' , rc = {'axes.facecolor':(0,0,0,0)})
pal = sns.cubehelix_palette(10, rot=-.25, light=.7)
sorter = ['Steel' , 'Dragon' , 'Rock' , 'Ground' , 'Fighting' , 'Dark' , 'Fire' , 'Poison' , 'Water' , 'Grass' , 'Ice' , 'Electric' , 'Bug' , 'Ghost' , 'Fairy' , 'Psychic']
sorterIndex = dict(zip(sorter, range(len(sorter))))
df['Type 1 Rank'] = df['Type 1'].map(sorterIndex)

g = sns.FacetGrid(df, row= 'Type 1 Rank', hue='Type 1 Rank', aspect=15, height=.5, palette=pal)

g.map(sns.kdeplot, 'Weighted Score',
      bw_adjust=.5, clip_on=False,
      fill=True, alpha=1, linewidth=1.5)
g.map(sns.kdeplot, 'Weighted Score', clip_on=False, color="w", lw=2, bw_adjust=.5)

g.refline(y=0, linewidth=2, linestyle="-", color=None, clip_on=False)

def label(x, color, label):
    ax = plt.gca()
    ax.text(0, .2, label, fontweight="bold", color=color,
            ha="left", va="center", transform=ax.transAxes)
    
g.map(label, 'Weighted Score')

g.figure.subplots_adjust(hspace=-.25)

g.set_titles("")
g.set(yticks=[], ylabel="")
g.despine(bottom=True, left=True)
111/15:
sns.set_theme(style = 'white' , rc = {'axes.facecolor':(0,0,0,0)})
pal = sns.cubehelix_palette(10, rot=-.25, light=.7)
sorter = ['Steel' , 'Dragon' , 'Rock' , 'Ground' , 'Fighting' , 'Dark' , 'Fire' , 'Poison' , 'Water' , 'Grass' , 'Ice' , 'Electric' , 'Bug' , 'Ghost' , 'Fairy' , 'Psychic']
sorterIndex = dict(zip(sorter, range(len(sorter))))
df['Type 1 Rank'] = df['Type 1'].map(sorterIndex)

g = sns.FacetGrid(df.sort_values(by = 'Type 1 Rank' , ascending= True), row= 'Type 1', hue='Type 1', aspect=15, height=.5, palette=pal)

g.map(sns.kdeplot, 'Weighted Score',
      bw_adjust=.5, clip_on=False,
      fill=True, alpha=1, linewidth=1.5)
g.map(sns.kdeplot, 'Weighted Score', clip_on=False, color="w", lw=2, bw_adjust=.5)

g.refline(y=0, linewidth=2, linestyle="-", color=None, clip_on=False)

def label(x, color, label):
    ax = plt.gca()
    ax.text(0, .2, label, fontweight="bold", color=color,
            ha="left", va="center", transform=ax.transAxes)
    
g.map(label, 'Weighted Score')

g.figure.subplots_adjust(hspace=-.25)

g.set_titles("")
g.set(yticks=[], ylabel="")
g.despine(bottom=True, left=True)
111/16:
sns.set_theme(style = 'white' , rc = {'axes.facecolor':(0,0,0,0)})
pal = sns.cubehelix_palette(10, rot=-.25, light=.7)
sorter = ['Steel' , 'Dragon' , 'Rock' , 'Ground' , 'Fighting' , 'Dark' , 'Fire' , 'Poison' , 'Water' ,'Normal' , 'Grass' , 'Ice' , 'Electric' , 'Bug' , 'Ghost' , 'Fairy' , 'Psychic']
sorterIndex = dict(zip(sorter, range(len(sorter))))
df['Type 1 Rank'] = df['Type 1'].map(sorterIndex)

g = sns.FacetGrid(df.sort_values(by = 'Type 1 Rank' , ascending= True), row= 'Type 1', hue='Type 1', aspect=15, height=.5, palette=pal)

g.map(sns.kdeplot, 'Weighted Score',
      bw_adjust=.5, clip_on=False,
      fill=True, alpha=1, linewidth=1.5)
g.map(sns.kdeplot, 'Weighted Score', clip_on=False, color="w", lw=2, bw_adjust=.5)

g.refline(y=0, linewidth=2, linestyle="-", color=None, clip_on=False)

def label(x, color, label):
    ax = plt.gca()
    ax.text(0, .2, label, fontweight="bold", color=color,
            ha="left", va="center", transform=ax.transAxes)
    
g.map(label, 'Weighted Score')

g.figure.subplots_adjust(hspace=-.25)

g.set_titles("")
g.set(yticks=[], ylabel="")
g.despine(bottom=True, left=True)
111/17:
sns.set_theme(style = 'white' , rc = {'axes.facecolor':(0,0,0,0)})
pal = sns.color_helix_palette(10, rot=-.25, light=.7)
sorter = ['Steel' , 'Dragon' , 'Rock' , 'Ground' , 'Fighting' , 'Dark' , 'Fire' , 'Poison' , 'Water' ,'Normal' , 'Grass' , 'Ice' , 'Electric' , 'Bug' , 'Ghost' , 'Fairy' , 'Psychic']
sorterIndex = dict(zip(sorter, range(len(sorter))))
df['Type 1 Rank'] = df['Type 1'].map(sorterIndex)

g = sns.FacetGrid(df.sort_values(by = 'Type 1 Rank' , ascending= True), row= 'Type 1', hue='Type 1', aspect=15, height=.5, palette=pal)

g.map(sns.kdeplot, 'Weighted Score',
      bw_adjust=.5, clip_on=False,
      fill=True, alpha=1, linewidth=1.5)
g.map(sns.kdeplot, 'Weighted Score', clip_on=False, color="w", lw=2, bw_adjust=.5)

g.refline(y=0, linewidth=2, linestyle="-", color=None, clip_on=False)

def label(x, color, label):
    ax = plt.gca()
    ax.text(0, .2, label, fontweight="bold", color=color,
            ha="left", va="center", transform=ax.transAxes)
    
g.map(label, 'Weighted Score')

g.figure.subplots_adjust(hspace=-.25)

g.set_titles("")
g.set(yticks=[], ylabel="")
g.despine(bottom=True, left=True)
111/18:
sns.set_theme(style = 'white' , rc = {'axes.facecolor':(0,0,0,0)})
pal = sns.colour_helix_palette(10, rot=-.25, light=.7)
sorter = ['Steel' , 'Dragon' , 'Rock' , 'Ground' , 'Fighting' , 'Dark' , 'Fire' , 'Poison' , 'Water' ,'Normal' , 'Grass' , 'Ice' , 'Electric' , 'Bug' , 'Ghost' , 'Fairy' , 'Psychic']
sorterIndex = dict(zip(sorter, range(len(sorter))))
df['Type 1 Rank'] = df['Type 1'].map(sorterIndex)

g = sns.FacetGrid(df.sort_values(by = 'Type 1 Rank' , ascending= True), row= 'Type 1', hue='Type 1', aspect=15, height=.5, palette=pal)

g.map(sns.kdeplot, 'Weighted Score',
      bw_adjust=.5, clip_on=False,
      fill=True, alpha=1, linewidth=1.5)
g.map(sns.kdeplot, 'Weighted Score', clip_on=False, color="w", lw=2, bw_adjust=.5)

g.refline(y=0, linewidth=2, linestyle="-", color=None, clip_on=False)

def label(x, color, label):
    ax = plt.gca()
    ax.text(0, .2, label, fontweight="bold", color=color,
            ha="left", va="center", transform=ax.transAxes)
    
g.map(label, 'Weighted Score')

g.figure.subplots_adjust(hspace=-.25)

g.set_titles("")
g.set(yticks=[], ylabel="")
g.despine(bottom=True, left=True)
111/19:
sns.set_theme(style = 'white' , rc = {'axes.facecolor':(0,0,0,0)})
pal = sns.color_helix_palette(10, rot=-.25, light=.7)
sorter = ['Steel' , 'Dragon' , 'Rock' , 'Ground' , 'Fighting' , 'Dark' , 'Fire' , 'Poison' , 'Water' ,'Normal' , 'Grass' , 'Ice' , 'Electric' , 'Bug' , 'Ghost' , 'Fairy' , 'Psychic']
sorterIndex = dict(zip(sorter, range(len(sorter))))
df['Type 1 Rank'] = df['Type 1'].map(sorterIndex)

g = sns.FacetGrid(df.sort_values(by = 'Type 1 Rank' , ascending= True), row= 'Type 1', hue='Type 1', aspect=15, height=.5, palette=pal)

g.map(sns.kdeplot, 'Weighted Score',
      bw_adjust=.5, clip_on=False,
      fill=True, alpha=1, linewidth=1.5)
g.map(sns.kdeplot, 'Weighted Score', clip_on=False, color="w", lw=2, bw_adjust=.5)

g.refline(y=0, linewidth=2, linestyle="-", color=None, clip_on=False)

def label(x, color, label):
    ax = plt.gca()
    ax.text(0, .2, label, fontweight="bold", color=color,
            ha="left", va="center", transform=ax.transAxes)
    
g.map(label, 'Weighted Score')

g.figure.subplots_adjust(hspace=-.25)

g.set_titles("")
g.set(yticks=[], ylabel="")
g.despine(bottom=True, left=True)
111/20:
sns.set_theme(style = 'white' , rc = {'axes.facecolor':(0,0,0,0)})
pal = sns.color_palette(10, rot=-.25, light=.7)
sorter = ['Steel' , 'Dragon' , 'Rock' , 'Ground' , 'Fighting' , 'Dark' , 'Fire' , 'Poison' , 'Water' ,'Normal' , 'Grass' , 'Ice' , 'Electric' , 'Bug' , 'Ghost' , 'Fairy' , 'Psychic']
sorterIndex = dict(zip(sorter, range(len(sorter))))
df['Type 1 Rank'] = df['Type 1'].map(sorterIndex)

g = sns.FacetGrid(df.sort_values(by = 'Type 1 Rank' , ascending= True), row= 'Type 1', hue='Type 1', aspect=15, height=.5, palette=pal)

g.map(sns.kdeplot, 'Weighted Score',
      bw_adjust=.5, clip_on=False,
      fill=True, alpha=1, linewidth=1.5)
g.map(sns.kdeplot, 'Weighted Score', clip_on=False, color="w", lw=2, bw_adjust=.5)

g.refline(y=0, linewidth=2, linestyle="-", color=None, clip_on=False)

def label(x, color, label):
    ax = plt.gca()
    ax.text(0, .2, label, fontweight="bold", color=color,
            ha="left", va="center", transform=ax.transAxes)
    
g.map(label, 'Weighted Score')

g.figure.subplots_adjust(hspace=-.25)

g.set_titles("")
g.set(yticks=[], ylabel="")
g.despine(bottom=True, left=True)
111/21:
sns.set_theme(style = 'white' , rc = {'axes.facecolor':(0,0,0,0)})
pal = sns.color_palette(10, light=.7)
sorter = ['Steel' , 'Dragon' , 'Rock' , 'Ground' , 'Fighting' , 'Dark' , 'Fire' , 'Poison' , 'Water' ,'Normal' , 'Grass' , 'Ice' , 'Electric' , 'Bug' , 'Ghost' , 'Fairy' , 'Psychic']
sorterIndex = dict(zip(sorter, range(len(sorter))))
df['Type 1 Rank'] = df['Type 1'].map(sorterIndex)

g = sns.FacetGrid(df.sort_values(by = 'Type 1 Rank' , ascending= True), row= 'Type 1', hue='Type 1', aspect=15, height=.5, palette=pal)

g.map(sns.kdeplot, 'Weighted Score',
      bw_adjust=.5, clip_on=False,
      fill=True, alpha=1, linewidth=1.5)
g.map(sns.kdeplot, 'Weighted Score', clip_on=False, color="w", lw=2, bw_adjust=.5)

g.refline(y=0, linewidth=2, linestyle="-", color=None, clip_on=False)

def label(x, color, label):
    ax = plt.gca()
    ax.text(0, .2, label, fontweight="bold", color=color,
            ha="left", va="center", transform=ax.transAxes)
    
g.map(label, 'Weighted Score')

g.figure.subplots_adjust(hspace=-.25)

g.set_titles("")
g.set(yticks=[], ylabel="")
g.despine(bottom=True, left=True)
111/22:
sns.set_theme(style = 'white' , rc = {'axes.facecolor':(0,0,0,0)})
pal = sns.color_palette(10)
sorter = ['Steel' , 'Dragon' , 'Rock' , 'Ground' , 'Fighting' , 'Dark' , 'Fire' , 'Poison' , 'Water' ,'Normal' , 'Grass' , 'Ice' , 'Electric' , 'Bug' , 'Ghost' , 'Fairy' , 'Psychic']
sorterIndex = dict(zip(sorter, range(len(sorter))))
df['Type 1 Rank'] = df['Type 1'].map(sorterIndex)

g = sns.FacetGrid(df.sort_values(by = 'Type 1 Rank' , ascending= True), row= 'Type 1', hue='Type 1', aspect=15, height=.5, palette=pal)

g.map(sns.kdeplot, 'Weighted Score',
      bw_adjust=.5, clip_on=False,
      fill=True, alpha=1, linewidth=1.5)
g.map(sns.kdeplot, 'Weighted Score', clip_on=False, color="w", lw=2, bw_adjust=.5)

g.refline(y=0, linewidth=2, linestyle="-", color=None, clip_on=False)

def label(x, color, label):
    ax = plt.gca()
    ax.text(0, .2, label, fontweight="bold", color=color,
            ha="left", va="center", transform=ax.transAxes)
    
g.map(label, 'Weighted Score')

g.figure.subplots_adjust(hspace=-.25)

g.set_titles("")
g.set(yticks=[], ylabel="")
g.despine(bottom=True, left=True)
111/23:
sns.set_theme(style = 'white' , rc = {'axes.facecolor':(0,0,0,0)})
pal = sns.color_palette()
sorter = ['Steel' , 'Dragon' , 'Rock' , 'Ground' , 'Fighting' , 'Dark' , 'Fire' , 'Poison' , 'Water' ,'Normal' , 'Grass' , 'Ice' , 'Electric' , 'Bug' , 'Ghost' , 'Fairy' , 'Psychic']
sorterIndex = dict(zip(sorter, range(len(sorter))))
df['Type 1 Rank'] = df['Type 1'].map(sorterIndex)

g = sns.FacetGrid(df.sort_values(by = 'Type 1 Rank' , ascending= True), row= 'Type 1', hue='Type 1', aspect=15, height=.5, palette=pal)

g.map(sns.kdeplot, 'Weighted Score',
      bw_adjust=.5, clip_on=False,
      fill=True, alpha=1, linewidth=1.5)
g.map(sns.kdeplot, 'Weighted Score', clip_on=False, color="w", lw=2, bw_adjust=.5)

g.refline(y=0, linewidth=2, linestyle="-", color=None, clip_on=False)

def label(x, color, label):
    ax = plt.gca()
    ax.text(0, .2, label, fontweight="bold", color=color,
            ha="left", va="center", transform=ax.transAxes)
    
g.map(label, 'Weighted Score')

g.figure.subplots_adjust(hspace=-.25)

g.set_titles("")
g.set(yticks=[], ylabel="")
g.despine(bottom=True, left=True)
117/1:
# Usually all the import statements are at the top of the file

import pandas as pd
import seaborn as sns
import numpy as np
import os
117/2:
# Themes and colours in Seaborn

# There are five preset seaborn themes: darkgrid, whitegrid, dark, white, and ticks. 
# They are each suited to different applications and personal preferences.
# You can see what they look like [here](https://seaborn.pydata.org/tutorial/aesthetics.html#seaborn-figure-styles)

# Just for fun, we're going to set the theme to be a nice one:
sns.set_theme(style="ticks",
              font_scale=1.3, # This scales the fonts slightly higher
             )
# And we're going to remove the top and right axis lines
import matplotlib.pyplot as plt
plt.rc("axes.spines", top=False, right=False)
117/3:
df = pd.read_csv('http://www.bccdc.ca/Health-Info-Site/Documents/BCCDC_COVID19_Dashboard_Case_Details.csv')
df
117/4:
plot1 = sns.countplot(y='Sex' , data = df)
plot1.set_title('Number of COVID-19 cases by Sex' , fontdict ={'size':15})
117/5:
plot2 = sns.countplot(y='Age_Group' , data = df , order = [ '<10' , '10-19' , '20-29' ,'30-39' , '40-49' , '50-59' , '60-69' , '70-79' , '80-89' , '90+' , 'Unknown' ])
plot2.set_title('Number of COVID-19 cases by Age Group' , fontdict ={'size':15})
plot2.set_xlabel('Count of Cases', fontdict={'size': 14})
plot2.set_ylabel('Age Group', fontdict={'size': 14})
117/6: set(df['HA'])
117/7:
sns.set_palette("Set2")
plot3 = sns.countplot(y='HA' ,hue = 'Sex' , data = df)
117/8:
df['Reported_Date_Object']  = pd.to_datetime(df.Reported_Date)
df.info()
117/9: df['Reported_Date_Object'].min()
117/10: df['Reported_Date_Object'].max()
117/11:
df['days_since'] = (df['Reported_Date_Object'] - df['Reported_Date_Object'].min()).apply(lambda x:x.days)
df
117/12: sns.displot(data = df , x = 'days_since' )
117/13: sns.displot(data = df , x = 'days_since' , hue ='Sex' )
117/14:
plot3 = sns.displot(data = df , x = 'days_since' , hue ='Sex' )
plot3.set_title('Reported COVID-19 cases by sex' , fontdict ={'size':15})
plot3.set_xlabel('Days since first reported case', fontdict={'size': 14})
plot3.set_ylabel('Number of reported cases', fontdict={'size': 14})
117/15:
plot3 = sns.displot(data = df , x = 'days_since' , hue ='Sex' )
plot3.set_title('Reported COVID-19 cases by sex' , fontdict ={'size':15})
plot3.set_xlabel('Days since first reported case', fontdict={'size': 14})
plot3.set_ylabel('Number of reported cases', fontdict={'size': 14})
117/16:
# Usually all the import statements are at the top of the file

import pandas as pd
import seaborn as sns
import numpy as np
import os
117/17:
# Themes and colours in Seaborn

# There are five preset seaborn themes: darkgrid, whitegrid, dark, white, and ticks. 
# They are each suited to different applications and personal preferences.
# You can see what they look like [here](https://seaborn.pydata.org/tutorial/aesthetics.html#seaborn-figure-styles)

# Just for fun, we're going to set the theme to be a nice one:
sns.set_theme(style="ticks",
              font_scale=1.3, # This scales the fonts slightly higher
             )
# And we're going to remove the top and right axis lines
import matplotlib.pyplot as plt
plt.rc("axes.spines", top=False, right=False)
117/18:
df = pd.read_csv('http://www.bccdc.ca/Health-Info-Site/Documents/BCCDC_COVID19_Dashboard_Case_Details.csv')
df
117/19:
plot1 = sns.countplot(y='Sex' , data = df)
plot1.set_title('Number of COVID-19 cases by Sex' , fontdict ={'size':15})
117/20:
plot2 = sns.countplot(y='Age_Group' , data = df , order = [ '<10' , '10-19' , '20-29' ,'30-39' , '40-49' , '50-59' , '60-69' , '70-79' , '80-89' , '90+' , 'Unknown' ])
plot2.set_title('Number of COVID-19 cases by Age Group' , fontdict ={'size':15})
plot2.set_xlabel('Count of Cases', fontdict={'size': 14})
plot2.set_ylabel('Age Group', fontdict={'size': 14})
117/21: set(df['HA'])
117/22:
sns.set_palette("Set2")
plot3 = sns.countplot(y='HA' ,hue = 'Sex' , data = df)
117/23:
df['Reported_Date_Object']  = pd.to_datetime(df.Reported_Date)
df.info()
117/24: df['Reported_Date_Object'].min()
117/25: df['Reported_Date_Object'].max()
117/26:
df['days_since'] = (df['Reported_Date_Object'] - df['Reported_Date_Object'].min()).apply(lambda x:x.days)
df
117/27:
plot3 = sns.displot(data = df , x = 'days_since' , hue ='Sex' )
plot3.set_title('Reported COVID-19 cases by sex' , fontdict ={'size':15})
plot3.set_xlabel('Days since first reported case', fontdict={'size': 14})
plot3.set_ylabel('Number of reported cases', fontdict={'size': 14})
117/28:
plot3 = sns.displot(data = df , x = 'days_since' , hue ='Sex' , title = 'Reported COVID-19 cases by sex' )

plot3.set_xlabel('Days since first reported case', fontdict={'size': 14})
plot3.set_ylabel('Number of reported cases', fontdict={'size': 14})
117/29:
plot3 = sns.displot(data = df , x = 'days_since' , hue ='Sex'  )
plot3.set_xlabel('Days since first reported case', fontdict={'size': 14})
plot3.set_ylabel('Number of reported cases', fontdict={'size': 14})
117/30:
plot3 = sns.displot(data = df , x = 'days_since' , hue ='Sex'  )
plot3.set(title ='Reported COVID-19 cases by sex' , fontdict ={'size':15})
117/31:
plot3 = sns.displot(data = df , x = 'days_since' , hue ='Sex'  )
plot3.set(title ='Reported COVID-19 cases by sex')
117/32:
plot3 = sns.displot(data = df , x = 'days_since' , hue ='Sex'  )
plot3.set(title ='Reported COVID-19 cases by sex' , xlabel = 'Days since first reported case' , ylabel = 'Number of reported cases')
117/33:
sns.set_palette("Set2")
plot3 = sns.displot(data = df , x = 'days_since' , hue ='Sex'  )
plot3.set(title ='Reported COVID-19 cases by sex' , xlabel = 'Days since first reported case' , ylabel = 'Number of reported cases')
117/34:
sns.set_palette("tab10")
plot3 = sns.displot(data = df , x = 'days_since' , hue ='Sex'  )
plot3.set(title ='Reported COVID-19 cases by sex' , xlabel = 'Days since first reported case' , ylabel = 'Number of reported cases')
117/35:
sns.set_palette("tab10")
plot3 = sns.displot(data = df , x = 'days_since' , hue ='Sex'  )
plot3.set(title ='Reported COVID-19 cases by sex' , xlabel = 'Days since first reported case' , ylabel = 'Number of reported cases')
plot3.set_xlim(0,900)
117/36:
sns.set_palette("tab10")
plot3 = sns.displot(data = df , x = 'days_since' , hue ='Sex'  )
plot3.set(title ='Reported COVID-19 cases by sex' , xlabel = 'Days since first reported case' , ylabel = 'Number of reported cases' , xlim = (0,900)
117/37:
sns.set_palette("tab10")
plot3 = sns.displot(data = df , x = 'days_since' , hue ='Sex'  )
plot3.set(title ='Reported COVID-19 cases by sex' , xlabel = 'Days since first reported case' , ylabel = 'Number of reported cases' , xlim = (0,900))
117/38:
sns.set_palette("tab10")
plot3 = sns.displot(data = df , x = 'days_since' , hue ='Sex'  )
plot3.set(title ='Reported COVID-19 cases by sex' , xlabel = 'Days since first reported case' , ylabel = 'Number of reported cases' , xlim = (0,1000))
117/39:
sns.set_palette("tab10")
plot3 = sns.displot(data = df , x = 'days_since' , hue ='Sex'  )
plot3.set(title ='Reported COVID-19 cases by sex' , xlabel = 'Days since first reported case' , ylabel = 'Number of reported cases' , xlim = (0,999))
117/40:
sns.set_palette("tab10")
plot3 = sns.displot(data = df , x = 'days_since' , hue ='Sex'  )
plot3.set(title ='Reported COVID-19 cases by sex' , xlabel = 'Days since first reported case' , ylabel = 'Number of reported cases' , xlim = (0,999), ylim = (0,15000))
117/41: plt.legend(loc='upper left')
117/42:
sns.set_palette("tab10")
plot3 = sns.displot(data = df , x = 'days_since' , hue ='Sex'  )
plot3.set(title ='Reported COVID-19 cases by sex' , xlabel = 'Days since first reported case' , ylabel = 'Number of reported cases' , xlim = (0,999), ylim = (0,15000))
plt.legend(loc='upper left')
117/43:
sns.set_palette("tab10")
plot3 = sns.displot(data = df , x = 'days_since' , hue ='Sex'  )
plot3.set(title ='Reported COVID-19 cases by sex' , xlabel = 'Days since first reported case' , ylabel = 'Number of reported cases' , xlim = (0,999), ylim = (0,15000))
plot3.legend(loc='upper left')
117/44:
sns.set_palette("tab10")
plot3 = sns.displot(data = df , x = 'days_since' , hue ='Sex'  )
plot3.set(title ='Reported COVID-19 cases by sex' , xlabel = 'Days since first reported case' , ylabel = 'Number of reported cases' , xlim = (0,999), ylim = (0,15000))
sns.move_legend( "upper left")
117/45:
sns.set_palette("tab10")
plot3 = sns.displot(data = df , x = 'days_since' , hue ='Sex'  )
plot3.set(title ='Reported COVID-19 cases by sex' , xlabel = 'Days since first reported case' , ylabel = 'Number of reported cases' , xlim = (0,999), ylim = (0,15000))
sns.move_legend(loc = "upper left")
117/46:
sns.set_palette("tab10")
plot3 = sns.displot(data = df , x = 'days_since' , hue ='Sex'  )
plot3.set(title ='Reported COVID-19 cases by sex' , xlabel = 'Days since first reported case' , ylabel = 'Number of reported cases' , xlim = (0,999), ylim = (0,15000))
sns.move_legend(ax ,loc = "upper left")
117/47:
sns.set_palette("tab10")
plot3 = sns.displot(data = df , x = 'days_since' , hue ='Sex'  )
plot3.set(title ='Reported COVID-19 cases by sex' , xlabel = 'Days since first reported case' , ylabel = 'Number of reported cases' , xlim = (0,999), ylim = (0,15000))
sns.move_legend(plot3,loc = "upper left")
117/48:
sns.set_palette("tab10")
plot3 = sns.displot(data = df , x = 'days_since' , hue ='Sex'  )
plot3.set(title ='Reported COVID-19 cases by sex' , xlabel = 'Days since first reported case' , ylabel = 'Number of reported cases' , xlim = (0,999), ylim = (0,15000))
sns.move_legend(plot3,loc = " left")
117/49:
sns.set_palette("tab10")
plot3 = sns.displot(data = df , x = 'days_since' , hue ='Sex'  )
plot3.set(title ='Reported COVID-19 cases by sex' , xlabel = 'Days since first reported case' , ylabel = 'Number of reported cases' , xlim = (0,999), ylim = (0,15000))
sns.move_legend(plot3,loc = "best left")
117/50:
sns.set_palette("tab10")
plot3 = sns.displot(data = df , x = 'days_since' , hue ='Sex'  )
plot3.set(title ='Reported COVID-19 cases by sex' , xlabel = 'Days since first reported case' , ylabel = 'Number of reported cases' , xlim = (0,999), ylim = (0,15000))
sns.move_legend(plot3,loc = " center left")
117/51:
sns.set_palette("tab10")
plot3 = sns.displot(data = df , x = 'days_since' , hue ='Sex'  )
plot3.set(title ='Reported COVID-19 cases by sex' , xlabel = 'Days since first reported case' , ylabel = 'Number of reported cases' , xlim = (0,999), ylim = (0,15000))
sns.move_legend(plot3,loc = "center left")
117/52:
sns.set_palette("tab10")
plot3 = sns.displot(data = df , x = 'days_since' , hue ='Sex'  )
plot3.set(title ='Reported COVID-19 cases by sex' , xlabel = 'Days since first reported case' , ylabel = 'Number of reported cases' , xlim = (0,999), ylim = (0,15000))
sns.move_legend(plot3,loc = "upper left")
117/53:
sns.set_palette("tab10")
plot3 = sns.displot(data = df , x = 'days_since' , hue ='Sex'  )
plot3.set(title ='Reported COVID-19 cases by sex' , xlabel = 'Days since first reported case' , ylabel = 'Number of reported cases' , xlim = (0,999), ylim = (0,15000))
sns.move_legend(plot3,loc = " upper left")
117/54:
sns.set_palette("tab10")
plot3 = sns.displot(data = df , x = 'days_since' , hue ='Sex'  )
plot3.set(title ='Reported COVID-19 cases by sex' , xlabel = 'Days since first reported case' , ylabel = 'Number of reported cases' , xlim = (0,999), ylim = (0,15000))
sns.move_legend(plot3,loc = "upper left")
117/55:
sns.set_palette("tab10")
plot3 = sns.displot(data = df , x = 'days_since' , hue ='Sex'  )
plot3.set(title ='Reported COVID-19 cases by sex' , xlabel = 'Days since first reported case' , ylabel = 'Number of reported cases' , xlim = (0,999), ylim = (0,15000))
plt.legend(plot3,loc = "upper left")
117/56:
sns.set_palette("tab10")
plot3 = sns.displot(data = df , x = 'days_since' , hue ='Sex'  )
plot3.set(title ='Reported COVID-19 cases by sex' , xlabel = 'Days since first reported case' , ylabel = 'Number of reported cases' , xlim = (0,999), ylim = (0,15000))
sns.move_legend(plot3,loc = "upper left")
117/57:
sns.set_palette("Set2")
plot3 = sns.countplot(y='HA' ,hue = 'Sex' , data = df)
117/58:
sns.set_palette("Set2")
plot3 = sns.countplot(y='HA' ,hue = 'Sex' , data = df , order = ascending)
117/59:
sns.set_palette("Set2")
plot3 = sns.countplot(y='HA' ,hue = 'Sex' , data = df , order=df.sort_values('HA').Sex)
116/1:
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
116/2: # Your Solution Here
120/1:
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
120/2: # Your Solution Here
120/3:
df = pd.read_csv('/Users/poojalal/Desktop/DATA301/lab05-DARTH-LAL/data/lab05_task2.csv')
df
120/4:
sel = ['Type 1' , 'Weighted Score']
df2 = df[sel].groupby('Type 1').mean().sort_values(by= 'Weighted Score' , ascending = False)
df2
120/5: sns.violinplot(data =df , y ='Type 1' , x = 'Weighted Score' )
120/6: # Your Solution here
120/7: sns.jointplot(data = df , x = 'Attack' , y = 'Defense' ,  kind="hex")
120/8: sns.pairplot(data= df.loc[:,['HP' , 'Attack' , 'Defense' , 'Speed' , 'Weighted Score']],corner =True)
120/9: # Your Solution Here
121/1:
# Usually all the import statements are at the top of the file

import pandas as pd
import seaborn as sns
import numpy as np
import os
121/2:
# Themes and colours in Seaborn

# There are five preset seaborn themes: darkgrid, whitegrid, dark, white, and ticks. 
# They are each suited to different applications and personal preferences.
# You can see what they look like [here](https://seaborn.pydata.org/tutorial/aesthetics.html#seaborn-figure-styles)

# Just for fun, we're going to set the theme to be a nice one:
sns.set_theme(style="ticks",
              font_scale=1.3, # This scales the fonts slightly higher
             )
# And we're going to remove the top and right axis lines
import matplotlib.pyplot as plt
plt.rc("axes.spines", top=False, right=False)
121/3:
df = pd.read_csv('http://www.bccdc.ca/Health-Info-Site/Documents/BCCDC_COVID19_Dashboard_Case_Details.csv')
df
121/4:
plot1 = sns.countplot(y='Sex' , data = df)
plot1.set_title('Number of COVID-19 cases by Sex' , fontdict ={'size':15})
121/5:
plot2 = sns.countplot(y='Age_Group' , data = df , order = [ '<10' , '10-19' , '20-29' ,'30-39' , '40-49' , '50-59' , '60-69' , '70-79' , '80-89' , '90+' , 'Unknown' ])
plot2.set_title('Number of COVID-19 cases by Age Group' , fontdict ={'size':15})
plot2.set_xlabel('Count of Cases', fontdict={'size': 14})
plot2.set_ylabel('Age Group', fontdict={'size': 14})
121/6: set(df['HA'])
121/7:
sns.set_palette("Set2")
plot3 = sns.countplot(y='HA' ,hue = 'Sex' , data = df)
121/8:
df['Reported_Date_Object']  = pd.to_datetime(df.Reported_Date)
df.info()
121/9: df['Reported_Date_Object'].min()
121/10: df['Reported_Date_Object'].max()
121/11:
df['days_since'] = (df['Reported_Date_Object'] - df['Reported_Date_Object'].min()).apply(lambda x:x.days)
df
121/12:
sns.set_palette("tab10")
plot3 = sns.displot(data = df , x = 'days_since' , hue ='Sex'  )
plot3.set(title ='Reported COVID-19 cases by sex' , xlabel = 'Days since first reported case' , ylabel = 'Number of reported cases' , xlim = (0,999), ylim = (0,15000))
121/13:
sns.set_palette("tab10")
plot3 = sns.displot(data = df , x = 'days_since' , hue ='Sex'  )
plot3.set(title ='Reported COVID-19 cases by sex' , xlabel = 'Days since first reported case' , ylabel = 'Number of reported cases' , xlim = (0,999), ylim = (0,15000))
sns.move_legend(plot3,loc = "upper left")
121/14:
sns.set_palette("Set2")
plot3 = sns.countplot(y='HA' ,hue = 'Sex' , data = df)
121/15:
sns.set_palette("Set2")
plot3 = sns.countplot(y='HA' ,hue = 'Sex' , data = df , order=df['HA'].value_counts().index)
120/10:
plt.figure(figsize=(3,7))
sns.violinplot(data =df , y ='Type 1' , x = 'Weighted Score' )
120/11:
plt.figure(figsize=(3,7))
plot1 = sns.violinplot(data =df , y ='Type 1' , x = 'Weighted Score' )
plot1.set(title ='Pokemon Types sorted by Cumulative Scores' , xlabel = 'Cumulative Score(20%HP,40% Attack , 30% Defense , 10% Speed')
120/12:
plt.figure(figsize=(3,7))
plot1 = sns.violinplot(data =df , y ='Type 1' , x = 'Weighted Score' )
plot1.set(title ='Pokemon Types sorted by Cumulative Scores' , xlabel = 'Cumulative Score(20% HP,40% Attack , 30% Defense , 10% Speed')
120/13:
plt.figure(figsize=(3,7))
plot1 = sns.violinplot(data =df , y ='Type 1' , x = 'Weighted Score' )
plot1.set(title ='Pokemon Types sorted by Cumulative Scores' , xlabel = 'Cumulative Score(20% HP,40% Attack , 30% Defense , 10% Speed' , ylabel ='')
120/14:
plt.figure(figsize=(10,10))
plot1 = sns.violinplot(data =df , y ='Type 1' , x = 'Weighted Score' )
plot1.set(title ='Pokemon Types sorted by Cumulative Scores' , xlabel = 'Cumulative Score(20% HP,40% Attack , 30% Defense , 10% Speed' , ylabel ='')
120/15:
plt.figure(figsize=(4,7))
plot1 = sns.violinplot(data =df , y ='Type 1' , x = 'Weighted Score' )
plot1.set(title ='Pokemon Types sorted by Cumulative Scores' , xlabel = 'Cumulative Score(20% HP,40% Attack , 30% Defense , 10% Speed' , ylabel ='')
120/16:
plt.figure(figsize=(4,6))
plot1 = sns.violinplot(data =df , y ='Type 1' , x = 'Weighted Score' )
plot1.set(title ='Pokemon Types sorted by Cumulative Scores' , xlabel = 'Cumulative Score(20% HP,40% Attack , 30% Defense , 10% Speed' , ylabel ='')
120/17:
plt.figure(figsize=(4,7))
plot1 = sns.violinplot(data =df , y ='Type 1' , x = 'Weighted Score' )
plot1.set(title ='Pokemon Types sorted by Cumulative Scores' , xlabel = 'Cumulative Score(20% HP,40% Attack , 30% Defense , 10% Speed' , ylabel ='')
120/18:
ns.color_palette('blue')
plt.figure(figsize=(4,7))
plot1 = sns.violinplot(data =df , y ='Type 1' , x = 'Weighted Score' )
plot1.set(title ='Pokemon Types sorted by Cumulative Scores' , xlabel = 'Cumulative Score(20% HP,40% Attack , 30% Defense , 10% Speed' , ylabel ='')
120/19:
sns.color_palette('blue')
plt.figure(figsize=(4,7))
plot1 = sns.violinplot(data =df , y ='Type 1' , x = 'Weighted Score' )
plot1.set(title ='Pokemon Types sorted by Cumulative Scores' , xlabel = 'Cumulative Score(20% HP,40% Attack , 30% Defense , 10% Speed' , ylabel ='')
120/20:
sns.color_palette("hls", 8)
plt.figure(figsize=(4,7))
plot1 = sns.violinplot(data =df , y ='Type 1' , x = 'Weighted Score' )
plot1.set(title ='Pokemon Types sorted by Cumulative Scores' , xlabel = 'Cumulative Score(20% HP,40% Attack , 30% Defense , 10% Speed' , ylabel ='')
120/21:
sns.color_palette("hls", 3)
plt.figure(figsize=(4,7))
plot1 = sns.violinplot(data =df , y ='Type 1' , x = 'Weighted Score' )
plot1.set(title ='Pokemon Types sorted by Cumulative Scores' , xlabel = 'Cumulative Score(20% HP,40% Attack , 30% Defense , 10% Speed' , ylabel ='')
120/22:
plt.figure(figsize=(4,7))
plot1 = sns.violinplot(data =df , y ='Type 1' , x = 'Weighted Score' )
plot1.set(title ='Pokemon Types sorted by Cumulative Scores' , xlabel = 'Cumulative Score(20% HP,40% Attack , 30% Defense , 10% Speed' , ylabel ='')
120/23: plot2 = sns.boxplot(data =df , y ='Type 1' , x = 'Weighted Score' )
120/24:
plt.figure(figsize=(4,7))
plot1 = sns.violinplot(data =df , y ='Type 1' , x = 'Weighted Score' , color = 'blue' )
plot1.set(title ='Pokemon Types sorted by Cumulative Scores' , xlabel = 'Cumulative Score(20% HP,40% Attack , 30% Defense , 10% Speed' , ylabel ='')
120/25:
plt.figure(figsize=(4,7))
plot1 = sns.violinplot(data =df , y ='Type 1' , x = 'Weighted Score' , color = ' light blue' )
plot1.set(title ='Pokemon Types sorted by Cumulative Scores' , xlabel = 'Cumulative Score(20% HP,40% Attack , 30% Defense , 10% Speed' , ylabel ='')
120/26:
plt.figure(figsize=(4,7))
plot1 = sns.violinplot(data =df , y ='Type 1' , x = 'Weighted Score' , color = 'blue' )
plot1.set(title ='Pokemon Types sorted by Cumulative Scores' , xlabel = 'Cumulative Score(20% HP,40% Attack , 30% Defense , 10% Speed' , ylabel ='')
120/27:
plot2 = sns.boxplot(data =df , y ='Type 1' , x = 'Weighted Score' )
plot2 = sns.stripplot(data =df , y ='Type 1' , x = 'Weighted Score' )
120/28:
plot2 = sns.boxplot(data =df , y ='Type 1' , x = 'Weighted Score' )
plot2 = sns.stripplot(data =df , y ='Type 1' , x = 'Weighted Score' , color = 'black' )
120/29:
plt.figure(figsize=(4,7))
plot1 = sns.violinplot(data =df , y ='Type 1' , x = 'Weighted Score' , color = 'setosa' )
plot1.set(title ='Pokemon Types sorted by Cumulative Scores' , xlabel = 'Cumulative Score(20% HP,40% Attack , 30% Defense , 10% Speed' , ylabel ='')
120/30:
plt.figure(figsize=(4,7))
plot1 = sns.violinplot(data =df , y ='Type 1' , x = 'Weighted Score' , color = 'skyblue' )
plot1.set(title ='Pokemon Types sorted by Cumulative Scores' , xlabel = 'Cumulative Score(20% HP,40% Attack , 30% Defense , 10% Speed' , ylabel ='')
120/31:
plot2 = sns.boxplot(data =df , y ='Type 1' , x = 'Weighted Score' )
plot2 = sns.stripplot(data =df , y ='Type 1' , x = 'Weighted Score' , color = 'black' )
plot2.set(title ='Pokemon Types sorted by Cumulative Scores' , xlabel = 'Cumulative Score(20% HP,40% Attack , 30% Defense , 10% Speed' , ylabel ='')
120/32:
plt.figure(figsize=(4,7))
plot2 = sns.boxplot(data =df , y ='Type 1' , x = 'Weighted Score' )
plot2 = sns.stripplot(data =df , y ='Type 1' , x = 'Weighted Score' , color = 'black' )
plot2.set(title ='Pokemon Types sorted by Cumulative Scores' , xlabel = 'Cumulative Score(20% HP,40% Attack , 30% Defense , 10% Speed' , ylabel ='')
120/33:
plt.figure(figsize=(4,8))
plot2 = sns.boxplot(data =df , y ='Type 1' , x = 'Weighted Score' )
plot2 = sns.stripplot(data =df , y ='Type 1' , x = 'Weighted Score' , color = 'black' )
plot2.set(title ='Pokemon Types sorted by Cumulative Scores' , xlabel = 'Cumulative Score(20% HP,40% Attack , 30% Defense , 10% Speed' , ylabel ='')
120/34:
plt.figure(figsize=(4,7))
plot2 = sns.boxplot(data =df , y ='Type 1' , x = 'Weighted Score' )
plot2 = sns.stripplot(data =df , y ='Type 1' , x = 'Weighted Score' , color = 'black' )
plot2.set(title ='Pokemon Types sorted by Cumulative Scores' , xlabel = 'Cumulative Score(20% HP,40% Attack , 30% Defense , 10% Speed' , ylabel ='')
120/35:
plt.figure(figsize=(5,7))
plot2 = sns.boxplot(data =df , y ='Type 1' , x = 'Weighted Score' )
plot2 = sns.stripplot(data =df , y ='Type 1' , x = 'Weighted Score' , color = 'black' )
plot2.set(title ='Pokemon Types sorted by Cumulative Scores' , xlabel = 'Cumulative Score(20% HP,40% Attack , 30% Defense , 10% Speed' , ylabel ='')
120/36:
plt.figure(figsize=(5,7))
s.color_palette("vlag", as_cmap=True)
plot2 = sns.boxplot(data =df , y ='Type 1' , x = 'Weighted Score' )
plot2 = sns.stripplot(data =df , y ='Type 1' , x = 'Weighted Score' , color = 'black' )
plot2.set(title ='Pokemon Types sorted by Cumulative Scores' , xlabel = 'Cumulative Score(20% HP,40% Attack , 30% Defense , 10% Speed' , ylabel ='')
120/37:
plt.figure(figsize=(5,7))
sns.color_palette("vlag", as_cmap=True)
plot2 = sns.boxplot(data =df , y ='Type 1' , x = 'Weighted Score' )
plot2 = sns.stripplot(data =df , y ='Type 1' , x = 'Weighted Score' , color = 'black' )
plot2.set(title ='Pokemon Types sorted by Cumulative Scores' , xlabel = 'Cumulative Score(20% HP,40% Attack , 30% Defense , 10% Speed' , ylabel ='')
120/38:
plt.figure(figsize=(5,7))
pal = sns.color_palette("vlag", as_cmap=True)
plot2 = sns.boxplot(data =df , y ='Type 1' , x = 'Weighted Score' , pallete = pal )
plot2 = sns.stripplot(data =df , y ='Type 1' , x = 'Weighted Score' , color = 'black' )
plot2.set(title ='Pokemon Types sorted by Cumulative Scores' , xlabel = 'Cumulative Score(20% HP,40% Attack , 30% Defense , 10% Speed' , ylabel ='')
120/39:
plt.figure(figsize=(5,7))
pal = sns.color_palette("vlag", as_cmap=True)
plot2 = sns.boxplot(data =df , y ='Type 1' , x = 'Weighted Score' , palette = pal )
plot2 = sns.stripplot(data =df , y ='Type 1' , x = 'Weighted Score' , color = 'black' )
plot2.set(title ='Pokemon Types sorted by Cumulative Scores' , xlabel = 'Cumulative Score(20% HP,40% Attack , 30% Defense , 10% Speed' , ylabel ='')
120/40:
plt.figure(figsize=(5,7))
pal = sns.color_palette("vlag")
plot2 = sns.boxplot(data =df , y ='Type 1' , x = 'Weighted Score' , palette = pal )
plot2 = sns.stripplot(data =df , y ='Type 1' , x = 'Weighted Score' , color = 'black' )
plot2.set(title ='Pokemon Types sorted by Cumulative Scores' , xlabel = 'Cumulative Score(20% HP,40% Attack , 30% Defense , 10% Speed' , ylabel ='')
120/41:
plt.figure(figsize=(5,7))
pal = sns.color_palette("vlag")
sorter = ['Steel' , 'Dragon' , 'Rock' , 'Ground' , 'Fighting' , 'Dark' , 'Fire' , 'Poison' , 'Water' ,'Normal' , 'Grass' , 'Ice' , 'Electric' , 'Bug' , 'Ghost' , 'Fairy' , 'Psychic']
sorterIndex = dict(zip(sorter, range(len(sorter))))
df['Type 1 Rank'] = df['Type 1'].map(sorterIndex)
plot2 = sns.boxplot(data =df , y ='Type 1' , x = 'Weighted Score' , palette = pal )
plot2 = sns.stripplot(data =df , y ='Type 1' , x = 'Weighted Score' , color = 'black' )
plot2.set(title ='Pokemon Types sorted by Cumulative Scores' , xlabel = 'Cumulative Score(20% HP,40% Attack , 30% Defense , 10% Speed' , ylabel ='')
120/42:
plt.figure(figsize=(5,7))
pal = sns.color_palette("vlag")

plot2 = sns.boxplot(data =df , y ='Type 1' , x = 'Weighted Score' , palette = pal )
plot2 = sns.stripplot(data =df , y ='Type 1' , x = 'Weighted Score' , color = 'black' )
plot2.set(title ='Pokemon Types sorted by Cumulative Scores' , xlabel = 'Cumulative Score(20% HP,40% Attack , 30% Defense , 10% Speed' , ylabel ='')
sorter = ['Steel' , 'Dragon' , 'Rock' , 'Ground' , 'Fighting' , 'Dark' , 'Fire' , 'Poison' , 'Water' ,'Normal' , 'Grass' , 'Ice' , 'Electric' , 'Bug' , 'Ghost' , 'Fairy' , 'Psychic']
sorterIndex = dict(zip(sorter, range(len(sorter))))
df['Type 1 Rank'] = df['Type 1'].map(sorterIndex)
120/43:
plt.figure(figsize=(5,7))
pal = sns.color_palette("vlag")
plot2 = sns.boxplot(data =df , y ='Type 1' , x = 'Weighted Score' , palette = pal )
plot2 = sns.stripplot(data =df , y ='Type 1' , x = 'Weighted Score' , color = 'black' )
plot2.set(title ='Pokemon Types sorted by Cumulative Scores' , xlabel = 'Cumulative Score(20% HP,40% Attack , 30% Defense , 10% Speed' , ylabel ='')
120/44: df
120/45:
sel = ['Type 2' , 'Weighted Score']
df2 = df[sel].groupby('Type 2').mean().sort_values(by= 'Weighted Score' , ascending = False)
df2
120/46:
sel = ['Type 2' , 'Weighted Score']
df3 = df[sel].groupby('Type 2').mean().sort_values(by= 'Weighted Score' , ascending = False)
df3
120/47:
plt.figure(figsize=(4,7))
plot1 = sns.violinplot(data =df3 , y ='Type 2' , x = 'Weighted Score' , color = 'skyblue' )
plot1.set(title ='Pokemon Types sorted by Cumulative Scores' , xlabel = 'Cumulative Score(20% HP,40% Attack , 30% Defense , 10% Speed' , ylabel ='')
120/48:
plt.figure(figsize=(4,7))
plot1 = sns.violinplot(data =df , y ='Type 2' , x = 'Weighted Score' , color = 'skyblue' )
plot1.set(title ='Pokemon Types sorted by Cumulative Scores' , xlabel = 'Cumulative Score(20% HP,40% Attack , 30% Defense , 10% Speed' , ylabel ='')
120/49:
plt.figure(figsize=(5,7))
pal = sns.color_palette("vlag")
plot4 = sns.boxplot(data =df , y ='Type 2' , x = 'Weighted Score' , palette = pal )
plot4 = sns.stripplot(data =df , y ='Type 2' , x = 'Weighted Score' , color = 'black' )
plot4.set(title ='Pokemon Types sorted by Cumulative Scores' , xlabel = 'Cumulative Score(20% HP,40% Attack , 30% Defense , 10% Speed' , ylabel ='')
120/50:
plt.figure(figsize=(4,7))
plot3 = sns.violinplot(data =df , y ='Type 2' , x = 'Weighted Score' , color = 'skyblue' )
plot3.set(title ='Pokemon Types sorted by Cumulative Scores' , xlabel = 'Cumulative Score(20% HP,40% Attack , 30% Defense , 10% Speed' , ylabel ='')
120/51:
plt.figure(figsize=(4,7))
plot3 = sns.violinplot(data =df , y ='Type 2' , x = 'Weighted Score' , color = 'red' )
plot3.set(title ='Pokemon Types sorted by Cumulative Scores' , xlabel = 'Cumulative Score(20% HP,40% Attack , 30% Defense , 10% Speed' , ylabel ='')
121/16:
sns.set_palette("tab10")
plot3 = sns.displot(data = df , x = 'days_since' , hue ='Sex'  )
plot3.set(title ='Reported COVID-19 cases by sex' , xlabel = 'Days since first reported case' , ylabel = 'Number of reported cases' , xlim = (0,999), ylim = (0,15000))
sns.move_legend(plot3,loc = "left")
121/17:
sns.set_palette("tab10")
plot3 = sns.displot(data = df , x = 'days_since' , hue ='Sex'  )
plot3.set(title ='Reported COVID-19 cases by sex' , xlabel = 'Days since first reported case' , ylabel = 'Number of reported cases' , xlim = (0,999), ylim = (0,15000))
sns.move_legend(plot3,loc = " center left")
121/18:
sns.set_palette("tab10")
plot3 = sns.displot(data = df , x = 'days_since' , hue ='Sex'  )
plot3.set(title ='Reported COVID-19 cases by sex' , xlabel = 'Days since first reported case' , ylabel = 'Number of reported cases' , xlim = (0,999), ylim = (0,15000))
sns.move_legend(plot3,loc = "center left")
121/19:
sns.set_palette("tab10")
plot3 = sns.displot(data = df , x = 'days_since' , hue ='Sex'  )
plot3.set(title ='Reported COVID-19 cases by sex' , xlabel = 'Days since first reported case' , ylabel = 'Number of reported cases' , xlim = (0,999), ylim = (0,15000))
sns.move_legend(plot3,loc = "upper left")
119/1: plot1 = sns.load_dataset("df")
119/2:
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
119/3: # Your Solution here
119/4:
df = pd.read_csv('/Users/poojalal/Desktop/DATA301/lab05-DARTH-LAL/data/lab05_task2.csv')
df
119/5:
sns.set_theme(style = 'white' , rc = {'axes.facecolor':(0,0,0,0)})
pal = sns.color_palette()
sorter = ['Steel' , 'Dragon' , 'Rock' , 'Ground' , 'Fighting' , 'Dark' , 'Fire' , 'Poison' , 'Water' ,'Normal' , 'Grass' , 'Ice' , 'Electric' , 'Bug' , 'Ghost' , 'Fairy' , 'Psychic']
sorterIndex = dict(zip(sorter, range(len(sorter))))
df['Type 1 Rank'] = df['Type 1'].map(sorterIndex)

g = sns.FacetGrid(df.sort_values(by = 'Type 1 Rank' , ascending= True), row= 'Type 1', hue='Type 1', aspect=15, height=.5, palette=pal)

g.map(sns.kdeplot, 'Weighted Score',
      bw_adjust=.5, clip_on=False,
      fill=True, alpha=1, linewidth=1.5)
g.map(sns.kdeplot, 'Weighted Score', clip_on=False, color="w", lw=2, bw_adjust=.5)

g.refline(y=0, linewidth=2, linestyle="-", color=None, clip_on=False)

def label(x, color, label):
    ax = plt.gca()
    ax.text(0, .2, label, fontweight="bold", color=color,
            ha="left", va="center", transform=ax.transAxes)
    
g.map(label, 'Weighted Score')

g.figure.subplots_adjust(hspace=-.25)

g.set_titles("")
g.set(yticks=[], ylabel="")
g.despine(bottom=True, left=True)
119/6: plot1 = sns.load_dataset("df")
119/7:
plot1 = sns.load_dataset("df")
 = sns.PairGrid(iris)
g.map_diag(sns.histplot)
119/8:
g = sns.FacetGrid(df, col="size", height=2.5, col_wrap=3)
g.map(sns.histplot, "total_bill")
119/9:
g = sns.FacetGrid(df, col="Type 2", height=2.5, col_wrap=3)
g.map(sns.histplot, "total_bill")
119/10:
g = sns.FacetGrid(df, col="Type 2", height=2.5, col_wrap=3)
g.map(sns.histplot, "Weighted Scores")
119/11:
g = sns.FacetGrid(df, col="Type 2", height=2.5, col_wrap=3)
g.map(sns.histplot, "Weighted Score")
122/1: list(range([5, 61]))
122/2: list(range(0, 62))
122/3: list(range(5, 61))
122/4: mylist = ['a','b','k','d','e']
122/5:

mylist[0,3]
122/6:

mylist[0,3]
122/7:


mylist[1:2]
122/8: mylist[1:2]
122/9: mylist[1,2]
122/10: mylist[-7:]
122/11: mylist = ['a','b','k','d','e' ,'f','g','h','i']
122/12: mylist[-7:]
122/13: mylist[:7]
122/14: user_name = "::::::::Eloise :::::::::::"
122/15: user_name.strip().strip(":")
122/16:

user_name.split(' : ')
122/17:

user_name.strip()
122/18:

user_name.split('Eloise')
122/19:


user_name.split(':')
122/20:


user_name.strip(":").strip()
122/21: user_name.strip(":")
122/22: user_name.split('::::')
122/23: greeting = ["Hello", "my", "name", "is", "Earl"]
122/24: f"{greeting}"
122/25: f"{greeting}"
122/26: f"{greeting}"
122/27: "_".join(greeting)
122/28: greeting.join("_")
122/29: " ".join(greeting, "_")
122/30: "_".join(greeting)
122/31:
def print_some_characters(word):
    for i in range(len(word)):
        if i % 2 == 0: 
            print(word[i])

print_some_characters("WATERMELON")
122/32:  good_fruit = "Raspberry"
122/33: good_fruit(4)
122/34: good_fruit(3)
122/35: good_fruit[3]
122/36: "a" in "banana"
122/37:

"cherry" in "cherry"
122/38: "s" in "watermelon"
122/39: "cran" in "cranberry"
122/40: "d" not in "guava"
122/41:
try:
    print("hi!")
    num = 'three' 
    if num%3 != 0 :
        print("nope")
    else:
        print("yep")
except:
    print("huh?")
finally:
    print("ok")
122/42:
try:
    print("hi!")
    num = 'three' 
    if num%3 != 0 :
        print("nope")
    else:
        print("yep")
except:
    print("huh?")
finally:
    print("ok")
122/43:
try:
    num1 = 8
    num2 = 0 
    print(num1*num2) 
    print(num1/num2)
    print("a")
except:
    print("b")
else:
    print("c")
finally:
    print("d")
122/44:
my_list = [1,2,3,4,5,6,7,8,9]
for x in range(100):
    if x % 3 == 0:
        numbers.append(x)
122/45:
my_list = [1,2,3,4,5,6,7,8,9]
for x in range(100):
    if x % 3 == 0:
        my_list.append(x)
122/46:
my_list = [1,2,3,4,5,6,7,8,9]
for x in range(100):
    if x % 3 == 0:
        my_list.append(x)
122/47:
my_list = [1,2,3,4,5,6,7,8,9]
for x in range(10):
    if x % 3 == 0:
        my_list.append(x)
122/48:
my_list = [1,2,3,4,5,6,7,8,9]
for x in range(10):
    if x % 3 == 0:
        my_list.append(x)
122/49: my_list = [x for x in range(100) if x % 3 == 0]
122/50:
my_list = [1,2,3,4,5,6,7,8,9]
for x in range(10):
    if x % 3 == 0:
        my_list.append(x)
122/51:
my_list = [1,2,3,4,5,6,7,8,9]
for x in range(10):
    if x % 3 == 0:
        my_list.append(x)
        print(my_list)
122/52:
my_list = [1,2,3,4,5,6,7,8,9]
for x in range(10):
    if x % 3 == 0:
        my_list.append(x)
        print(my_list)
122/53:
my_list = [1,2,3,4,5,6,7,8,9]
for x in range(100):
    if x % 3 == 0:
        my_list.append(x)
        print(my_list)
122/54:
my_list = [1,2,3,4,5,6,7,8,9]
for x in range(1):
    if x % 3 == 0:
        my_list.append(x)
        print(my_list)
122/55:
my_list = [1,2,3,4,5,6,7,8,9]
my_list = [x for x in range(100) if x % 3 == 0]
  print(my_list)
122/56: my_list = [1,2,3,4,5,6,7,8,9]
122/57:
my_list = [1,2,3,4,5,6,7,8,9]
my_list = [x for x in range(100) if x % 3 == 0]
  print(my_list)
122/58:
my_list = [1,2,3,4,5,6,7,8,9]
my_list = [x for x in range(100) if x % 3 == 0]
print(my_list)
122/59:
my_list = [1,2,3,4,5,6,7,8,9]
my_list = [x for x in range(1) if x % 3 == 0]
print(my_list)
122/60:
my_list = [1,2,3,4,5,6,7,8,9]
my_list = [x for x in range(1) if x % 3 == 0]
print(my_list)
122/61:
my_list = [1,2,3,4,5,6,7,8,9]
my_list = [x for x in range(1,9) if x % 3 == 0]
print(my_list)
122/62:
my_list = [1,2,3,4,5,6,7,8,9]
my_list = [x for x in range(1,10) if x % 3 == 0]
print(my_list)
122/63:
my_list = [1,2,3,4,5,6,7,8,9]
my_list = [x for x in range(1,10) if x % 3 == 0]
print(my_list)
result = my_list * 10
122/64:
my_list = [1,2,3,4,5,6,7,8,9]
my_list = [x for x in range(1,10) if x % 3 == 0]
print(my_list)
result = my_list * 10
print(result)
122/65:
my_list = [1,2,3,4,5,6,7,8,9]
my_list = [x for x in range(1,10) if x % 3 == 0]
print(my_list)
122/66:
my_list = [1,2,3,4,5,6,7,8,9]
reuslt = [x for x in range(1,10) if x % 3 == 0]
print(my_list)
122/67:
my_list = [1,2,3,4,5,6,7,8,9]
reuslt = [x for x in range(1,10) if x % 3 == 0]
print(result)
122/68:
my_list = [1,2,3,4,5,6,7,8,9]
result = [x for x in range(1,10) if x % 3 == 0]
print(result)
122/69:
my_list = [1,2,3,4,5,6,7,8,9]
new_list = [x for x in range(1,10) if x % 3 == 0]
print(new_list)
122/70:
my_list = [1,2,3,4,5,6,7,8,9]
new_list = [x for x in range(1,10) if x % 3 == 0]
print(new_list)

result = new_list*10 + my_list
122/71:
my_list = [1,2,3,4,5,6,7,8,9]
new_list = [x for x in range(1,10) if x % 3 == 0]
print(new_list)

result = new_list*10 + my_list
print(result)
122/72:
my_list = [1,2,3,4,5,6,7,8,9]
new_list = [x for x in range(1,10) if x % 3 == 0]
print(new_list)

result = new_list**10 + my_list
print(result)
122/73:
my_list = [1,2,3,4,5,6,7,8,9]
new_list = [x for x in range(1,10) if x % 3 == 0]
print(new_list)

new_list**2 for new_list in my_list
122/74:
my_list = [1,2,3,4,5,6,7,8,9]
new_list = [x for x in range(1,10) if x % 3 == 0]
print(new_list)

result = [i * 10 for i in new_list]
122/75:
my_list = [1,2,3,4,5,6,7,8,9]
new_list = [x for x in range(1,10) if x % 3 == 0]
print(new_list)

result = [i * 10 for i in new_list]
print(result)
122/76:
my_list = [1,2,3,4,5,6,7,8,9]
new_list = [x for x in range(1,10) if x % 3 == 0]
print(new_list)

result = [i * 10 for i in new_list]
print(result)
122/77:
my_list = [1,2,3,4,5,6,7,8,9]
new_list = [x for x in range(1,10) if x % 3 == 0]
print(new_list)

result = [x * 10 for x in new_list]
print(result)
123/1: my_list = [1, 10, 4, 2, 7]
123/2:
my_list = [1, 10, 4, 2, 7]
sum(l[2:])
123/3:
my_list = [1, 10, 4, 2, 7]
sum(my_list[2:])
123/4:
my_list = [1, 10, 4, 2, 7]
sum(my_list[-2:])
123/5:
my_list = [1, 10, 4, 2, 7]
sum(my_list[-2:])
my_list.append()
123/6:
my_list = [1, 10, 4, 2, 7]
my_list.append(sum(my_list[-2:]))
123/7:
my_list = [1, 10, 4, 2, 7]
my_list.append(sum(my_list[-2:]))
123/8:
my_list = [1, 10, 4, 2, 7]
my_list.append(sum(my_list[-2:]))
print(my_list)
123/9:
my_list = [1, 10, 4, 2, 7]
my_list.append(sum(my_list[-2:])*4)
print(my_list)
123/10:
my_list = [1, 10, 4, 2, 7]
my_list.append(sum(my_list[-2:])*4)
print(my_list)
123/11:
my_list = [1, 10, 4, 2, 7]
my_list.append(sum(my_list[-2:]))
print(my_list)
123/12:
my_list = [1, 10, 4, 2, 7]
my_list.append(sum(my_list[-2:]))
my_list.append(sum(my_list[-2:]))
print(my_list)
123/13:
my_list = [1, 10, 4, 2, 7]
my_list.append(sum(my_list[-2:]))
my_list.append(sum(my_list[-2:]))
my_list.append(sum(my_list[-2:]))
print(my_list)
123/14:
my_list = [1, 10, 4, 2, 7]
my_list.append(sum(my_list[-2:]))
my_list.append(sum(my_list[-2:]))
my_list.append(sum(my_list[-2:]))
my_list.append(sum(my_list[-2:]))
print(my_list)
123/15:
my_list = [1, 10, 4, 2, 7]
for i in my_list:
    numbers.append(sum(my_list[-2:]))
123/16:
my_list = [1, 10, 4, 2, 7]
for i in my_list:
    my_list.append(sum(my_list[-2:]))
124/1:
my_list2 = [1, 10, 4, 2, 7]
for i in my_list2:
    my_list2.append(sum(my_list2[-2:]))
    print(my_list2)
126/1:
my_list = [1,2,3,4,5,6,7,8,9]
[x * 10 for x in my_list if x % 3 == 0]
126/2:
my_list = [1,2,3,4,5,6,7,8,9]
[x * 10 for x in my_list if x % 3 == 0]
126/3:
my_list = [1,2,3,4,5,6,7,8,9]
result = [num * 10 for num in my_list if num % 3 == 0]
126/4:
my_list = [1,2,3,4,5,6,7,8,9]
result = [num * 10 for num in my_list if num % 3 == 0]
126/5:
my_list = [1,2,3,4,5,6,7,8,9]
result = [num * 10 for num in my_list if num % 3 == 0]
print(result)
126/6:
my_list = [1,2,3,4,5,6,7,8,9]
result = [num * 10 for num in my_list if num % 3 == 0]
print(result)
122/78: my_list=[1, 10, 4, 2, 7]
122/79:
my_list=[1, 10, 4, 2, 7]
for i in range(4): 
    my_list.append(my_list[-1] + my_list[-2])
122/80:
my_list=[1, 10, 4, 2, 7]
for i in range(4): 
    my_list.append(my_list[-1] + my_list[-2])
122/81:
my_list=[1, 10, 4, 2, 7]
for i in range(4): 
    my_list.append(my_list[-1] + my_list[-2])
    print(my_list)
122/82:
my_list=[1, 10, 4, 2, 7]
for i in range(4): 
    my_list.append(my_list[-2])
    print(my_list)
122/83:
my_list=[1, 10, 4, 2, 7]
for i in range(4): 
    my_list.append(my_list[-1] + my_list[-2])
    print(my_list)
122/84: assert my_list == [1, 10, 4, 2, 7, 9, 16, 25, 41]
126/7:
my_list = [1,2,3,4,5,6,7,8,9]
result = [x*10 if x%3==0 else x for x in my_list]
print(result)
126/8:
my_list = [1,2,3,4,5,6,7,8,9]
result = [x*10 if x%3==0 else x for x in my_list]
print(result)
127/1:
import pandas as pd
df = pd.read_csv('data/grades1a.csv')
127/2:
import pandas as pd
df = pd.read_csv('data/grades1a.csv')
df2 = pd.read_csv('data/grades1b.csv')
df3 = pd.read_csv('data/grades1c.csv')
127/3:
import pandas as pd
df = pd.read_csv('data/grades1a.csv')
df2 = pd.read_csv('data/grades1b.csv')
df3 = pd.read_csv('data/grades1c.csv')
head(df)
127/4:
import pandas as pd
df = pd.read_csv('data/grades1a.csv')
df2 = pd.read_csv('data/grades1b.csv')
df3 = pd.read_csv('data/grades1c.csv')
head.df
127/5:
import pandas as pd
df = pd.read_csv('data/grades1a.csv')
df2 = pd.read_csv('data/grades1b.csv')
df3 = pd.read_csv('data/grades1c.csv')
df
127/6:
import pandas as pd
df = pd.read_csv('data/grades1a.csv')
df2 = pd.read_csv('data/grades1b.csv')
df3 = pd.read_csv('data/grades1c.csv')
df
df2
df3
127/7:
import pandas as pd
df = pd.read_csv('data/grades1a.csv')
df2 = pd.read_csv('data/grades1b.csv')
df3 = pd.read_csv('data/grades1c.csv')
df
df2
df3
127/8:
import pandas as pd
df = pd.read_csv('data/grades1a.csv')
df2 = pd.read_csv('data/grades1b.csv')
df3 = pd.read_csv('data/grades1c.csv')
df
df2
127/9:
import pandas as pd
df = pd.read_csv('data/grades1a.csv')
df2 = pd.read_csv('data/grades1b.csv')
df3 = pd.read_csv('data/grades1c.csv')
df
127/10: df2
127/11: df3
127/12: frames = [df,df2,df3]
127/13:
frames = [df,df2,df3]
result = pd.concat(frames)
127/14:
frames = [df,df2,df3]
result = pd.concat(frames)
result
127/15: pd.merge(df, df2 , df3)
127/16: pd.merge(df, df2 , df3 , how ='outer')
127/17: pd.concat(df, df2 , df3)
127/18: newdf = pd.concat(df, df2 , df3)
127/19: result = pd.concat([df, df2 , df3], axis=1, join="inner")
127/20:
result = pd.concat([df, df2 , df3], axis=1, join="inner")
result
127/21:
result = pd.concat([df, df2 , df3], axis=1, join="outer")
result
127/22:
result = pd.concat([df, df2 , df3])
result
127/23:
result = pd.concat([df, df2 , df3], axis=1, join="outer")
result
127/24:
result = pd.concat([df, df2 , df3], axis=1, join="inner")
result
127/25:
frames = [df,df1,df2]
result = pd.concat(frames, keys=["Student ID", "Chemistry ", "Physics" , "Math])
127/26:
frames = [df,df1,df2]
result = pd.concat(frames, keys=["Student ID", "Chemistry ", "Physics" , "Math"])
127/27:
frames = [df,df2,df3]
result = pd.concat(frames, keys=["Student ID", "Chemistry ", "Physics" , "Math"])
127/28:
frames = [df,df2,df3]
result = pd.concat(frames, keys=["Student ID", "Chemistry ", "Physics" , "Math"])
result
127/29:
frames = [df,df2,df3]
result = pd.concat(frames)
result
127/30:
frames = [df,df2,df3]
result = pd.concat(frames ,axis=1)
result
133/1:
import pandas as pd
df = pd.read_csv('BankChurners.csv')
df
133/2: newdf=df.drop(columns=['Naive_Bayes_Classifier_Attrition_Flag_Card_Category_Contacts_Count_12_mon_Dependent_count_Education_Level_Months_Inactive_12_mon_1','Naive_Bayes_Classifier_Attrition_Flag_Card_Category_Contacts_Count_12_mon_Dependent_count_Education_Level_Months_Inactive_12_mon_2'])
133/3: newdf
133/4: newdf.shape()
133/5: newdf.shape
133/6: newdf.columns
133/7: newdf.nunique(axis=0)
133/8: newdf.describe().apply(lambda s: s.apply(lambda x: format(x, 'f')))
133/9: newdf.describe()
133/10: newdf=df.drop(columns=['Naive_Bayes_Classifier_Attrition_Flag_Card_Category_Contacts_Count_12_mon_Dependent_count_Education_Level_Months_Inactive_12_mon_1','Naive_Bayes_Classifier_Attrition_Flag_Card_Category_Contacts_Count_12_mon_Dependent_count_Education_Level_Months_Inactive_12_mon_2'])
133/11:
import pandas as pd
df = pd.read_csv('BankChurners.csv')
df
133/12: df.shape
133/13: df.columns
133/14: df.nunique(axis=0)
133/15: df.describe()
133/16: newdf=df.drop(columns=['Naive_Bayes_Classifier_Attrition_Flag_Card_Category_Contacts_Count_12_mon_Dependent_count_Education_Level_Months_Inactive_12_mon_1','Naive_Bayes_Classifier_Attrition_Flag_Card_Category_Contacts_Count_12_mon_Dependent_count_Education_Level_Months_Inactive_12_mon_2'])
133/17: newdf.head()
133/18: newdf=df.drop(columns=['Naive_Bayes_Classifier_Attrition_Flag_Card_Category_Contacts_Count_12_mon_Dependent_count_Education_Level_Months_Inactive_12_mon_1','Naive_Bayes_Classifier_Attrition_Flag_Card_Category_Contacts_Count_12_mon_Dependent_count_Education_Level_Months_Inactive_12_mon_2','Attrition_Flag','Months_Inactive_12_mon','Contacts_Count_12_mon','Avg_Open_To_Buy','Total_Amt_Chng_Q4_Q1','Total_Trans_Amt','Total_Trans_Ct','Total_Ct_Chng_Q4_Q1')
133/19: newdf=df.drop(columns=['Naive_Bayes_Classifier_Attrition_Flag_Card_Category_Contacts_Count_12_mon_Dependent_count_Education_Level_Months_Inactive_12_mon_1','Naive_Bayes_Classifier_Attrition_Flag_Card_Category_Contacts_Count_12_mon_Dependent_count_Education_Level_Months_Inactive_12_mon_2','Attrition_Flag','Months_Inactive_12_mon','Contacts_Count_12_mon','Avg_Open_To_Buy','Total_Amt_Chng_Q4_Q1','Total_Trans_Amt','Total_Trans_Ct','Total_Ct_Chng_Q4_Q1')]
133/20: newdf=df.drop(columns=['Naive_Bayes_Classifier_Attrition_Flag_Card_Category_Contacts_Count_12_mon_Dependent_count_Education_Level_Months_Inactive_12_mon_1','Naive_Bayes_Classifier_Attrition_Flag_Card_Category_Contacts_Count_12_mon_Dependent_count_Education_Level_Months_Inactive_12_mon_2','Attrition_Flag','Months_Inactive_12_mon','Contacts_Count_12_mon','Avg_Open_To_Buy','Total_Amt_Chng_Q4_Q1','Total_Trans_Amt','Total_Trans_Ct','Total_Ct_Chng_Q4_Q1']
133/21: newdf=df.drop(columns=['Naive_Bayes_Classifier_Attrition_Flag_Card_Category_Contacts_Count_12_mon_Dependent_count_Education_Level_Months_Inactive_12_mon_1','Naive_Bayes_Classifier_Attrition_Flag_Card_Category_Contacts_Count_12_mon_Dependent_count_Education_Level_Months_Inactive_12_mon_2','Attrition_Flag','Months_Inactive_12_mon','Contacts_Count_12_mon','Avg_Open_To_Buy','Total_Amt_Chng_Q4_Q1','Total_Trans_Amt','Total_Trans_Ct','Total_Ct_Chng_Q4_Q1')]
133/22: newdf=df.drop(columns=['Naive_Bayes_Classifier_Attrition_Flag_Card_Category_Contacts_Count_12_mon_Dependent_count_Education_Level_Months_Inactive_12_mon_1','Naive_Bayes_Classifier_Attrition_Flag_Card_Category_Contacts_Count_12_mon_Dependent_count_Education_Level_Months_Inactive_12_mon_2','Attrition_Flag','Months_Inactive_12_mon','Contacts_Count_12_mon','Avg_Open_To_Buy','Total_Amt_Chng_Q4_Q1','Total_Trans_Amt','Total_Trans_Ct','Total_Ct_Chng_Q4_Q1'])
133/23: newdf.head()
133/24: newdf2 = newdf.dropna(subset = ['CLIENTNUM', 'Customer_Age', 'Gender', 'Dependent_count','Education_Level','Marital_Status','Income_Category' ,'Card_Category','Months_on_book','Total_Relationship_Count','Credit_Limit','Total_Revolving_Bal','Avg_Utilization_Ratio')
133/25: newdf2 = newdf.dropna(subset = ['CLIENTNUM', 'Customer_Age', 'Gender', 'Dependent_count','Education_Level','Marital_Status','Income_Category' ,'Card_Category','Months_on_book','Total_Relationship_Count','Credit_Limit','Total_Revolving_Bal','Avg_Utilization_Ratio'])
133/26: newdf2
133/27:
plot_1 = newdf2.corr()
sns.heatmap(plot_1, xticklabels=corr.columns, yticklabels=corr.columns, annot=True, cmap=sns.diverging_palette(220, 20, as_cmap=True))
133/28:
import numpy as np
import pandas as pd
import matplotlib.pylab as plt
import seaborn as sns
df.shape
df.head()
df.columns
df = pd.read_csv('BankChurners.csv')
df
133/29:
plot_1 = newdf2.corr()
sns.heatmap(plot_1, xticklabels=corr.columns, yticklabels=corr.columns, annot=True, cmap=sns.diverging_palette(220, 20, as_cmap=True))
133/30:
plot_1 = newdf2.corr()
sns.heatmap(plot_1, xticklabels=newdf2.columns, yticklabels=newdf2.columns, annot=True, cmap=sns.diverging_palette(220, 20, as_cmap=True))
133/31: ## Understanding my Variables
133/32:
#The first relationship I will be analzying is the relationship between age and income category , 
# in order to do this I will be using a histogram.
133/33:
sns.histplot(
    data=newdf2,
    x="Customer_Age", y="Income_Category",
    style="smoker", size="size",
)
133/34: sns.histplot(data=newdf2,x="Customer_Age", y="Income_Category",)
133/35: sns.scatterplot(data=newdf2,x="Customer_Age", y="Income_Category",)
133/36: sns.distplot(data=newdf2,x="Customer_Age", y="Income_Category",)
133/37: sns.distplot(data = newdf2,x="Customer_Age", y="Income_Category",)
133/38: sns.kdeplot(data = newdf2,x="Customer_Age", y="Income_Category",)
133/39: sns.barplot(data = newdf2,x="Customer_Age", y="Income_Category",)
133/40: sns.countplot(data = newdf2,x="Customer_Age", y="Income_Category",)
133/41: sns.boxplot(data = newdf2,x="Customer_Age", y="Income_Category",)
141/1:
import pandas as pd

df= pd.read_csv('https://github.com/firasm/bits/raw/master/pokemon.csv')
141/2: df
141/3: df[0:10]['HP'].mean(skipna=False)
141/4: df[0:10]['HP'].dropna(axis=1)
141/5: df = sns.load_dataset("penguins")
141/6:
import seaborn as sns
df = sns.load_dataset("penguins")
141/7: df
141/8: groupby = df[sel].groupby('island').mean()
141/9: groupby = df.groupby('island').mean()
141/10:
sel = ['island' , 'species']
groupby = df[sel].groupby('island').mean()
141/11:
sel = ['island' , 'species']
groupby = df[sel].groupby('island').mean()
141/12: df.drop(['flipper_length_mm','bill_depth_mm','island'])
141/13: newdf = df.drop(['flipper_length_mm','bill_depth_mm','island'])
141/14: newdf = df.drop(columns =['flipper_length_mm','bill_depth_mm','island'])
141/15: sns.jointplot(data=df, x="flipper_length_mm", y="bill_length_mm", hue="species")
141/16: sns.jointplot(data=df, x="flipper_length_mm", y="bill_length_mm", hue="sex")
141/17: sns.jointplot(data=df, x="flipper_length_mm", y="bill_depth_mm", hue="sex")
141/18: sns.jointplot(data=df, x="bill_length_mm", y="bill_depth_mm", hue="sex")
141/19: sns.jointplot(data=df, x="bill_depth_mm", y="bill_length_mm", hue="sex")
141/20: plot1 = sns.jointplot(data=df, x="bill_depth_mm", y="bill_length_mm", hue="sex")
141/21:
plot1 = sns.jointplot(data=df, x="bill_depth_mm", y="bill_length_mm", hue="sex")
plot1.set(title ='Penguin Bill Length vs Bill Depth by sex' , xlabel = 'Bill Depth(mm)' , ylabel ='Bill Length (mm)')
141/22:
plot1 = sns.jointplot(data=df, x="bill_depth_mm", y="bill_length_mm", hue="sex")
plot1.set_title('Penguin Bill Length vs Bill Depth by sex' , fontdict ={'size':15})
plot1.set_xlabel('Bill Depth(mm)', fontdict={'size': 12})
plot1.set_ylabel('Bill Length (mm)', fontdict={'size': 12})
141/23:
import seaborn as sns
import matplotlib.pyplot as pl
plot1 = sns.jointplot(data=df, x="bill_depth_mm", y="bill_length_mm", hue="sex")
plot1.set_title('Penguin Bill Length vs Bill Depth by sex' , fontdict ={'size':15})
plot1.set_xlabel('Bill Depth(mm)', fontdict={'size': 12})
plot1.set_ylabel('Bill Length (mm)', fontdict={'size': 12})
141/24:
import seaborn as sns
import matplotlib.pyplot as pl

plot1 = sns.jointplot(data=df, x="bill_depth_mm", y="bill_length_mm", hue="sex")
matplotlib.pyplot.suptitle('Penguin Bill Length vs Bill Depth by sex')
plot1.set_xlabel('Bill Depth(mm)', fontdict={'size': 12})
plot1.set_ylabel('Bill Length (mm)', fontdict={'size': 12})
141/25:
import seaborn as sns
import matplotlib.pyplot as pl

plot1 = sns.jointplot(data=df, x="bill_depth_mm", y="bill_length_mm", hue="sex")
plot1.pyplot.suptitle('Penguin Bill Length vs Bill Depth by sex')
plot1.set_xlabel('Bill Depth(mm)', fontdict={'size': 12})
plot1.set_ylabel('Bill Length (mm)', fontdict={'size': 12})
141/26:
import seaborn as sns
import matplotlib.pyplot as pl

plot1 = sns.jointplot(data=df, x="bill_depth_mm", y="bill_length_mm", hue="sex")
plot1.suptitle('Penguin Bill Length vs Bill Depth by sex')
plot1.set_xlabel('Bill Depth(mm)', fontdict={'size': 12})
plot1.set_ylabel('Bill Length (mm)', fontdict={'size': 12})
141/27:
import seaborn as sns
import matplotlib.pyplot as pl

plot1 = sns.jointplot(data=df, x="bill_depth_mm", y="bill_length_mm", hue="sex")
plot1.suptitle('Penguin Bill Length vs Bill Depth by sex')
plot1.set_xlabel('Bill Depth(mm)', fontdict={'size': 12})
plot1.set_ylabel('Bill Length (mm)', fontdict={'size': 12})
141/28:
import seaborn as sns
import matplotlib.pyplot as pl

plot1 = sns.jointplot(data=df, x="bill_depth_mm", y="bill_length_mm", hue="sex")pyplot
plot1.set_title('Penguin Bill Length vs Bill Depth by sex' , fontdict ={'size':15})
plot1.set_xlabel('Bill Depth(mm)', fontdict={'size': 12})
plot1.set_ylabel('Bill Length (mm)', fontdict={'size': 12})
141/29:
import seaborn as sns
import matplotlib.pyplot as pl

plot1 = sns.jointplot(data=df, x="bill_depth_mm", y="bill_length_mm", hue="sex")
plot1.set_title('Penguin Bill Length vs Bill Depth by sex' , fontdict ={'size':15})
plot1.set_xlabel('Bill Depth(mm)', fontdict={'size': 12})
plot1.set_ylabel('Bill Length (mm)', fontdict={'size': 12})
141/30:
import seaborn as sns
import matplotlib.pyplot as pl

plot1 = sns.jointplot(data=df, x="bill_depth_mm", y="bill_length_mm", hue="sex")
plot1.suptitle("Penguin Bill Length vs Bill Depth by sex")
plot1.set_xlabel('Bill Depth(mm)', fontdict={'size': 12})
plot1.set_ylabel('Bill Length (mm)', fontdict={'size': 12})
141/31:
import seaborn as sns
import matplotlib.pyplot as pl

plot1 = sns.jointplot(data=df, x="bill_depth_mm", y="bill_length_mm", hue="sex")
plot1.suptitle("Penguin Bill Length vs Bill Depth by sex")
141/32:
import seaborn as sns
import matplotlib.pyplot as pl

plot1 = sns.jointplot(data=df, x="bill_depth_mm", y="bill_length_mm", hue="sex")
plot1.fig.suptitle("Penguin Bill Length vs Bill Depth by sex")
141/33:
import seaborn as sns
import matplotlib.pyplot as pl

plot1 = sns.jointplot(data=df, x="bill_depth_mm", y="bill_length_mm", hue="sex")
plot1.fig.suptitle("Penguin Bill Length vs Bill Depth by sex" , fontdict ={'size':15})
141/34:
import seaborn as sns
import matplotlib.pyplot as pl

plot1 = sns.jointplot(data=df, x="bill_depth_mm", y="bill_length_mm", hue="sex")
plot1.fig.suptitle("Penguin Bill Length vs Bill Depth by sex" , fontdict ={'size':118})
141/35:
import seaborn as sns
import matplotlib.pyplot as pl

plot1 = sns.jointplot(data=df, x="bill_depth_mm", y="bill_length_mm", hue="sex")
plot1.fig.suptitle("Penguin Bill Length vs Bill Depth by sex" , fontdict ={'size':18})
141/36:
import seaborn as sns
import matplotlib.pyplot as pl

plot1 = sns.jointplot(data=df, x="bill_depth_mm", y="bill_length_mm", hue="sex")
plot1.fig.suptitle("Penguin Bill Length vs Bill Depth by sex" , fontsize =18)
141/37:
import seaborn as sns
import matplotlib.pyplot as pl

plot1 = sns.jointplot(data=df, x="bill_depth_mm", y="bill_length_mm", hue="sex")
plot1.fig.suptitle("Penguin Bill Length vs Bill Depth by sex" , fontsize =18)

plot1.set_xlabel('Number of Days', fontdict={'size': 12})
plot1.set_ylabel('Cumulative New Cases', fontdict={'size': 12})
141/38:
import seaborn as sns
import matplotlib.pyplot as pl

plot1 = sns.jointplot(data=df, x="bill_depth_mm", y="bill_length_mm", hue="sex")
plot1.fig.suptitle("Penguin Bill Length vs Bill Depth by sex" , fontsize =18)
plot1.fig.set_xlabel('Number of Days', fontdict={'size': 12})
plot1.set_ylabel('Cumulative New Cases', fontdict={'size': 12})
141/39:
import seaborn as sns
import matplotlib.pyplot as pl

plot1 = sns.jointplot(data=df, x="bill_depth_mm", y="bill_length_mm", hue="sex")
plot1.fig.suptitle("Penguin Bill Length vs Bill Depth by sex" , fontsize =18)
141/40:
import seaborn as sns
import matplotlib.pyplot as pl

plot1 = sns.jointplot(data=df, x="bill_depth_mm", y="bill_length_mm", hue="sex")
plot1.fig.suptitle("Penguin Bill Length vs Bill Depth by sex" , fontsize =18)
plot1.set_axis_labels('x', 'y', fontsize=16)
141/41:
import seaborn as sns
import matplotlib.pyplot as pl

plot1 = sns.jointplot(data=df, x="bill_depth_mm", y="bill_length_mm", hue="sex")
plot1.fig.suptitle("Penguin Bill Length vs Bill Depth by sex" , fontsize =18)
plot1.set_axis_labels('Bill Depth (mm)', 'Bill Length (mm)', fontsize=16)
141/42:
import seaborn as sns
import matplotlib.pyplot as pl

plot1 = sns.jointplot(data=df, x="bill_depth_mm", y="bill_length_mm", hue="sex")
plot1.fig.suptitle("Penguin Bill Length vs Bill Depth by sex" , fontsize =18)
plot1.set_axis_labels('Bill Depth (mm)', 'Bill Length (mm)', fontsize=16)
sns.move_legend(plot1, "center right")
141/43:
import seaborn as sns
import matplotlib.pyplot as pl

plot1 = sns.jointplot(data=df, x="bill_depth_mm", y="bill_length_mm", hue="sex")
plot1.fig.suptitle("Penguin Bill Length vs Bill Depth by sex" , fontsize =18)
plot1.set_axis_labels('Bill Depth (mm)', 'Bill Length (mm)', fontsize=16)
sns.move_legend(plot1, "upper left")
141/44:
import seaborn as sns
import matplotlib.pyplot as pl

plot1 = sns.jointplot(data=df, x="bill_depth_mm", y="bill_length_mm", hue="sex")
plot1.fig.suptitle("Penguin Bill Length vs Bill Depth by sex" , fontsize =18)
plot1.set_axis_labels('Bill Depth (mm)', 'Bill Length (mm)', fontsize=16)
sns.move_legend(plot1,loc = "upper left")
141/45:
import seaborn as sns
import matplotlib.pyplot as pl

plot1 = sns.jointplot(data=df, x="bill_depth_mm", y="bill_length_mm", hue="sex")
plot1.fig.suptitle("Penguin Bill Length vs Bill Depth by sex" , fontsize =18)
plot1.set_axis_labels('Bill Depth (mm)', 'Bill Length (mm)', fontsize=16)
sns.move_legend(plot1 ,loc = "upper right")
142/1:
import seaborn as sns
import matplotlib.pyplot as pl

plot1 = sns.jointplot(data=df, x="bill_depth_mm", y="bill_length_mm", hue="sex")
plot1.fig.suptitle("Penguin Bill Length vs Bill Depth by sex" , fontsize =18)
plot1.set_axis_labels('Bill Depth (mm)', 'Bill Length (mm)', fontsize=16)
sns.move_legend(plot1 ,loc = "upper right")
142/2:
import seaborn as sns
import matplotlib.pyplot as pl

df = sns.load_dataset("penguins")

plot1 = sns.jointplot(data=df, x="bill_depth_mm", y="bill_length_mm", hue="sex")
plot1.fig.suptitle("Penguin Bill Length vs Bill Depth by sex" , fontsize =18)
plot1.set_axis_labels('Bill Depth (mm)', 'Bill Length (mm)', fontsize=16)
sns.move_legend(plot1 ,loc = "upper right")
142/3:
import seaborn as sns
import matplotlib.pyplot as pl

df = sns.load_dataset("penguins")

plot1 = sns.jointplot(data=df, x="bill_depth_mm", y="bill_length_mm", hue="sex")
plot1.fig.suptitle("Penguin Bill Length vs Bill Depth by sex" , fontsize =18)
plot1.set_axis_labels('Bill Depth (mm)', 'Bill Length (mm)', fontsize=16)
plot1.savefig("sns-heatmap.png")
142/4:
import seaborn as sns
import matplotlib.pyplot as pl

df = sns.load_dataset("penguins")

plot1 = sns.jointplot(data=df, x="bill_depth_mm", y="bill_length_mm", hue="sex")
plot1.fig.suptitle("Penguin Bill Length vs Bill Depth by sex" , fontsize =18)
plot1.set_axis_labels('Bill Depth (mm)', 'Bill Length (mm)', fontsize=16)
plot1.savefig("viz2.png")
141/46: df
141/47: df[0:10]['HP'].dropna(axis=1)
141/48:
import pandas as pd

df= pd.read_csv('https://github.com/firasm/bits/raw/master/pokemon.csv')
141/49: df
141/50: df[0:10]['HP'].mean(skipna=False)
141/51: df[0:10]['HP'].dropna(axis=1)
146/1: # Vaishali Raju
146/2: # Vaishali Raju
146/3: # Ajneya Lal
151/1:
import pandas as pd
df = pd.read_csv('BankChurners.csv')
df
151/2:
import pandas as pd
df = pd.read_csv('BankChurners.csv')
df
151/3:
import pandas as pd
df = pd.read_csv('BankChurners.csv')
df
151/4: df0 = df.drop(columns=['Naive_Bayes_Classifier_Attrition_Flag_Card_Category_Contacts_Count_12_mon_Dependent_count_Education_Level_Months_Inactive_12_mon_1','Naive_Bayes_Classifier_Attrition_Flag_Card_Category_Contacts_Count_12_mon_Dependent_count_Education_Level_Months_Inactive_12_mon_2'])
151/5: df0
151/6:
import numpy as np
import pandas as pd
import matplotlib.pylab as plt
import seaborn as sns
151/7:
df_cleaned = df0.copy().drop(['Avg_Utilization_Ratio','Avg_Open_To_Buy', 'Total_Trans_Ct', 'Total_Amt_Chng_Q4_Q1','Total_Ct_Chng_Q4_Q1','Total_Trans_Amt'], axis=1)
df_cleaned
#dropping unwanted columns
151/8:
dropNA = df_cleaned.dropna(axis=0)
dropNA
#dropping columns that contain null values
151/9:
#My research question explores the ethical implications of credit churning. 
#In order to present some interesting observations, I will be using columns Attrition Flag, Card Category, Credit limit, and months on book. 
#My first plot is a simple count plot to identify the differences in the two types of bank customers: attrited and existing. Attrited customers are those that have churned and existing customers are those that are still using the card services. 
#Credit card churning is only a minor issue with banks so far. Thus, the plot below suggests that atleast roughly 25% of their customers churn.
151/10:
sns.set_theme(style="white", font_scale= 1)
sns.countplot(data=df, y = 'Attrition_Flag')
plt.title("Number of Customers by Attrition Flag")
plt.xlabel("Total number of Bank Customers")
plt.ylabel("Attrition Flag")
151/11:
#Furthermore, I used card category and credit limit to show the density of data using a violin plot. 
#There are 4 types of card types in credit cards: blue, sliver, platinum and gold. Credit limit is the maximum the bank allows you to spend using the credit card. If the borrower exceeds their limit, fees and other charges will be applied. 
#It is recommended to use a maximum 30% of your credit limit to maintain your credit score. 
    #The plot: the white dot is the median, the top end and bottom end represents the maximum and minimum, the width represents the frequency (density). 
#There is a higher frequency of customers in blue category. Platinum and Gold customers have the highest credit limits.
151/12:
sns.violinplot(x='Card_Category', y= 'Credit_Limit', data=df)
plt.xticks(rotation =45)
plt.title("Credit Scores sorted by Card category")
plt.xlabel("Card Category")
plt.ylabel("Credit Limit")
151/13:
#The box plot represents the data between months on book and card category. 
#I intend to analyze how long customers remain on the books based on each category. As you can see, customers in the blue category has a higher frequency of customers in this plot as well.
151/14:
sns.set_theme(style="white", font_scale= 1)
sns.boxplot(data=df, x = 'Card_Category', y = 'Months_on_book')
plt.xticks(rotation=45)
151/15:
import pandas as pd
import numpy as np
import matplotlib.pylab as plt
import seaborn as sns
df = pd.read_csv('BankChurners.csv')
df
151/16: df.shape
151/17: df.head()
151/18: df.columns
151/19: df.nunique(axis=0)
151/20: df.describe().apply(lambda s: s.apply(lambda x: format(x, 'f')))
151/21: df.describe()
151/22:
#We can see all the names of the columns in the dataset , there are a lot of columns some of which are not needed in my research.
#Therefore , I will be  remooving them in further steps.
151/23: df.condition.unique()
151/24: newdf = df.drop(columns=['Naive_Bayes_Classifier_Attrition_Flag_Card_Category_Contacts_Count_12_mon_Dependent_count_Education_Level_Months_Inactive_12_mon_1','Naive_Bayes_Classifier_Attrition_Flag_Card_Category_Contacts_Count_12_mon_Dependent_count_Education_Level_Months_Inactive_12_mon_2'])
151/25: df
151/26:
import pandas as pd
import numpy as np
import matplotlib.pylab as plt
import seaborn as sns
df = pd.read_csv('BankChurners.csv')
df
151/27: newdf = df.drop(columns=['Naive_Bayes_Classifier_Attrition_Flag_Card_Category_Contacts_Count_12_mon_Dependent_count_Education_Level_Months_Inactive_12_mon_1','Naive_Bayes_Classifier_Attrition_Flag_Card_Category_Contacts_Count_12_mon_Dependent_count_Education_Level_Months_Inactive_12_mon_2','CLIENTNUM' ,'Months_on_book',])
151/28: df
151/29: newdf
151/30: newdf = df.drop(columns=['Naive_Bayes_Classifier_Attrition_Flag_Card_Category_Contacts_Count_12_mon_Dependent_count_Education_Level_Months_Inactive_12_mon_1','Naive_Bayes_Classifier_Attrition_Flag_Card_Category_Contacts_Count_12_mon_Dependent_count_Education_Level_Months_Inactive_12_mon_2','CLIENTNUM' ,'Months_on_book','Total_Relationship_Count'])
151/31: newdf
151/32: newdf = df.drop(columns=['Naive_Bayes_Classifier_Attrition_Flag_Card_Category_Contacts_Count_12_mon_Dependent_count_Education_Level_Months_Inactive_12_mon_1','Naive_Bayes_Classifier_Attrition_Flag_Card_Category_Contacts_Count_12_mon_Dependent_count_Education_Level_Months_Inactive_12_mon_2','CLIENTNUM' ,'Months_on_book','Total_Relationship_Count','Contacts_Count_12_mon'])
151/33: newdf = df.drop(columns=['Naive_Bayes_Classifier_Attrition_Flag_Card_Category_Contacts_Count_12_mon_Dependent_count_Education_Level_Months_Inactive_12_mon_1','Naive_Bayes_Classifier_Attrition_Flag_Card_Category_Contacts_Count_12_mon_Dependent_count_Education_Level_Months_Inactive_12_mon_2','CLIENTNUM' ,'Months_on_book',,'Contacts_Count_12_mon'])
151/34: newdf = df.drop(columns=['Naive_Bayes_Classifier_Attrition_Flag_Card_Category_Contacts_Count_12_mon_Dependent_count_Education_Level_Months_Inactive_12_mon_1','Naive_Bayes_Classifier_Attrition_Flag_Card_Category_Contacts_Count_12_mon_Dependent_count_Education_Level_Months_Inactive_12_mon_2','CLIENTNUM' ,'Months_on_book','Contacts_Count_12_mon'])
151/35: newdf
151/36: newdf = df.drop(columns=['Naive_Bayes_Classifier_Attrition_Flag_Card_Category_Contacts_Count_12_mon_Dependent_count_Education_Level_Months_Inactive_12_mon_1','Naive_Bayes_Classifier_Attrition_Flag_Card_Category_Contacts_Count_12_mon_Dependent_count_Education_Level_Months_Inactive_12_mon_2','CLIENTNUM' ,'Total_Relationship_Count   ','Contacts_Count_12_mon'])
151/37: newdf = df.drop(columns=['Naive_Bayes_Classifier_Attrition_Flag_Card_Category_Contacts_Count_12_mon_Dependent_count_Education_Level_Months_Inactive_12_mon_1','Naive_Bayes_Classifier_Attrition_Flag_Card_Category_Contacts_Count_12_mon_Dependent_count_Education_Level_Months_Inactive_12_mon_2','CLIENTNUM' ,'Total_Relationship_Count','Contacts_Count_12_mon'])
151/38: newdf
151/39: newdf = df.drop(columns=['Avg_Open_To_Buy','Naive_Bayes_Classifier_Attrition_Flag_Card_Category_Contacts_Count_12_mon_Dependent_count_Education_Level_Months_Inactive_12_mon_1','Naive_Bayes_Classifier_Attrition_Flag_Card_Category_Contacts_Count_12_mon_Dependent_count_Education_Level_Months_Inactive_12_mon_2','CLIENTNUM' ,'Total_Relationship_Count','Contacts_Count_12_mon'])
151/40: newdf
151/41: newdf = df.drop(columns=['Avg_Open_To_Buy','Naive_Bayes_Classifier_Attrition_Flag_Card_Category_Contacts_Count_12_mon_Dependent_count_Education_Level_Months_Inactive_12_mon_1','Naive_Bayes_Classifier_Attrition_Flag_Card_Category_Contacts_Count_12_mon_Dependent_count_Education_Level_Months_Inactive_12_mon_2','CLIENTNUM' ,'Total_Relationship_Count','Contacts_Count_12_mon','Total_Trans_Ct','Total_Ct_Chng_Q4_Q1'])
151/42: newdf
151/43:
#The second step in cleaning my dataset is remvoing null values
df_cleaned = df_cleaned.dropna(axis=0)
df_cleaned.shape
151/44:
#The second step in cleaning my dataset is remvoing null values
df_cleaned = df_cleaned.dropna(axis=0)
151/45:
#The second step in cleaning my dataset is remvoing null values
df_cleaned = df_cleaned.dropna(axis=0)
151/46: df_cleaned.shape
151/47:
#The second step in cleaning my dataset is remvoing null values
newdf_cleaned = newdf.dropna(axis=0)
151/48: newdf_cleaned.shape
151/49:
#The second step in cleaning my dataset is remvoing null values
newdf_cleaned = newdf.dropna(axis=0)
151/50: newdf.shape
151/51: newdf.shape
151/52: print(df.dtypes)
151/53: df = pd.get_dummies(df, columns=['Gender', 'Education_Level', 'Marital_Status', 'Income_Category', 'Card_Category'], drop_first=True)
151/54: newdf_cleaned = pd.get_dummies(newdf_cleaned, columns=['Gender', 'Education_Level', 'Marital_Status', 'Income_Category', 'Card_Category'], drop_first=True)
151/55: print(newdf_cleaned.dtypes)
151/56:
print(newdf_cleaned.dtypes)
# Checking the data types of each column
151/57:
sns.countplot(x='Attrition_Flag', data=df)
plt.show()
151/58:
sns.countplot(x='Attrition_Flag', data=df)
plt.show()
151/59:
sns.histplot(x='Customer_Age', data=df, bins=20)
plt.show()
151/60:
sns.boxplot(x='Attrition_Flag', y='Customer_Age', data=df)
plt.show()
151/61: # Exploring the distribution of income
151/62:
sns.histplot(x='Credit_Limit', data=df, bins=20)
plt.show()
151/63: # Explore the relationship between income and churn rates
151/64:
sns.boxplot(x='Attrition_Flag', y='Credit_Limit', data=df)
plt.show()
151/65:
sns.countplot(x='Attrition_Flag', data=df)
plt.title('Churn Rate')
plt.show()
151/66:
sns.countplot(x='Attrition_Flag', data=df)
plt.title('Churn Rates')
plt.show()
151/67:
sns.countplot(x='Attrition_Flag', data=df)
plt.title('Churn Rates')
151/68:
sns.countplot(x='Attrition_Flag', data=df)
plt.title('Churn Rates')
plt.show()
151/69:
sns.histplot(x='Customer_Age', data=df, bins=20)
plt.title('Distribution of Age')
plt.show()
151/70:
sns.countplot(x='Attrition_Flag', data=newdf_cleaned)
plt.title('Churn Rates')
plt.show()
151/71:
sns.histplot(x='Customer_Age', data=newdf_cleaned, bins=20)
plt.title('Distribution of Age')
plt.show()
151/72:
sns.boxplot(x='Attrition_Flag', y='Customer_Age', data=newdf_cleaned)
plt.show()
151/73:
sns.boxplot(x='Attrition_Flag', y='Customer_Age', data=newdf_cleaned)
plt.title('Relationship between Age and Churn Rate')
plt.show()
151/74:
sns.histplot(x='Credit_Limit', data=data=newdf_cleaned, bins=20)
plt.title('Distribution of Credit Limit')
plt.show()
151/75:
sns.histplot(x='Credit_Limit', data=newdf_cleaned, bins=20)
plt.title('Distribution of Credit Limit')
plt.show()
151/76:
sns.boxplot(x='Attrition_Flag', y='Credit_Limit', data=df
plt.title('Relationship between Credit Limit and Churn Rate')
plt.show()
151/77:
sns.boxplot(x='Attrition_Flag', y='Credit_Limit', data=df)
plt.title('Relationship between Credit Limit and Churn Rate')
plt.show()
151/78:
sns.boxplot(x='Attrition_Flag', y='Credit_Limit', data=newdf_cleaned)
plt.title('Relationship between Credit Limit and Churn Rate')
plt.show()
151/79:
sns.countplot(x='Gender_M', data=df)
plt.title('Distribution of Gender')
plt.show()
151/80: # Exploring the relationship between gender and churn rates
151/81:
sns.countplot(x='Gender_M', hue='Attrition_Flag', data=df)
plt.title('Relationship between Gender and Churn Rate')
plt.show()
151/82:
sns.countplot(x='Gender_M', hue='Attrition_Flag', data=newdf_cleaned)
plt.title('Relationship between Gender and Churn Rate')
plt.show()
151/83: # Exploring the distribution of education level
151/84:
sns.countplot(x='Education_Level_High School', data=df)
plt.title('Distribution of Education Level')
plt.show()
151/85: # Exploring the relationship between education level and churn rates
151/86:
sns.countplot(x='Education_Level_High School', hue='Attrition_Flag', data=df)
plt.title('Relationship between Education Level and Churn Rate')
plt.show()
151/87:
sns.countplot(x='Marital_Status_Married', data=df)
plt.title('Distribution of Marital Status')
plt.show()
151/88:
sns.countplot(x='Marital_Status_Married', hue='Attrition_Flag', data=df)
plt.title('Relationship between Marital Status and Churn Rate')
plt.show(
151/89:
sns.countplot(x='Marital_Status_Married', hue='Attrition_Flag', data=df)
plt.title('Relationship between Marital Status and Churn Rate')
plt.show()
151/90:
sns.countplot(x='Marital_Status_Married', hue='Attrition_Flag', data=newdf_cleaned)
plt.title('Relationship between Marital Status and Churn Rate')
plt.show()
151/91: # Exploring the distribution of income category
151/92:
sns.countplot(x='Income_Category_Less than $40K', data=df)
plt.title('Distribution of Income Category')
plt.show()
151/93:
sns.countplot(x='Income_Category_Less than $40K', hue='Attrition_Flag', data=df)
plt.title('Relationship between Income Category and Churn Rate')
plt.show()
151/94:
sns.countplot(x='Card_Category_Silver', data=df)
plt.title('Distribution of Card Category')
plt.show()
151/95:
sns.countplot(x='Card_Category_Silver', hue='Attrition_Flag', data=df)
plt.title('Relationship between Card Category and Churn Rate')
151/96:
sns.countplot(x='Attrition_Flag', data=newdf_cleaned)
plt.title('Churn Rates')
plt.set_xlabel('Number of Days', fontdict={'size': 12})
plt.show()
151/97:
sns.countplot(x='Attrition_Flag', data=newdf_cleaned)
plt.title('Churn Rates')
plt.x_label('Number of Days', fontdict={'size': 12})
plt.show()
151/98:
sns.countplot(x='Attrition_Flag', data=newdf_cleaned)
plt.title('Churn Rates')
plt.xlabel('Number of Days', fontdict={'size': 12})
plt.show()
151/99:
sns.countplot(x='Attrition_Flag', data=newdf_cleaned)
plt.title('Churn Rates')
plt.xlabel('Customer Type', fontdict={'size': 12})
plt.show()
151/100:
sns.countplot(x='Attrition_Flag', data=newdf_cleaned)
plt.title('Churn Rates')
plt.xlabel('Customer Type', fontdict={'size': 18})
plt.show()
151/101:
sns.countplot(x='Attrition_Flag', data=newdf_cleaned)
plt.title('Churn Rates')
plt.xlabel('Customer Type', fontdict={'size': 12})
plt.show()
151/102:
sns.countplot(x='Attrition_Flag', data=newdf_cleaned)
plt.title('Churn Rates',fontdict={'size': 15})
plt.xlabel('Customer Type', fontdict={'size': 12})
plt.show()
151/103:
sns.countplot(x='Attrition_Flag', data=newdf_cleaned)
plt.title('Churn Rates',fontdict={'size': 18})
plt.xlabel('Customer Type', fontdict={'size': 12})
plt.show()
151/104:
sns.countplot(x='Attrition_Flag', data=newdf_cleaned)
plt.title('Churn Rates',fontdict={'size': 17})
plt.xlabel('Customer Type', fontdict={'size': 12})
plt.show()
151/105:
sns.histplot(x='Customer_Age', data=newdf_cleaned, bins=20)
plt.title('Distribution of Age',fontdict={'size': 17})
plt.xlabel('Customer Age', fontdict={'size': 12})
plt.show()
151/106:
sns.boxplot(x='Attrition_Flag', y='Customer_Age', data=newdf_cleaned)
plt.title('Relationship between Age and Churn Rate',fontdict={'size': 17})
plt.show()
151/107:
sns.boxplot(x='Attrition_Flag', y='Customer_Age', data=newdf_cleaned)
plt.title('Relationship between Age and Churn Rate',fontdict={'size': 17})
plt.xlabel('Customer Type', fontdict={'size': 12})
plt.ylabel('Customer Age', fontdict={'size': 12})
plt.show()
151/108:
sns.histplot(x='Credit_Limit', data=newdf_cleaned, bins=20)
plt.title('Distribution of Credit Limit',fontdict={'size': 17})
plt.xlabel('Customer Credit Limit', fontdict={'size': 12})
plt.show()
151/109:
sns.boxplot(x='Attrition_Flag', y='Credit_Limit', data=newdf_cleaned)
plt.title('Relationship between Credit Limit and Churn Rate',fontdict={'size': 17})
plt.show()
151/110:
sns.boxplot(x='Attrition_Flag', y='Credit_Limit', data=newdf_cleaned)
plt.title('Relationship between Credit Limit and Churn Rate',fontdict={'size': 17})
plt.xlabel('Customer Type', fontdict={'size': 12})
plt.show()
151/111:
sns.boxplot(x='Attrition_Flag', y='Credit_Limit', data=newdf_cleaned)
plt.title('Relationship between Credit Limit and Churn Rate',fontdict={'size': 17})
plt.xlabel('Customer Type', fontdict={'size': 12})
plt.ylabel('Customer Credit Limit', fontdict={'size': 12})
plt.show()
151/112:
sns.countplot(x='Gender_M', data=newdf_cleaned)
plt.title('Distribution of Gender',fontdict={'size': 17})
plt.show()
151/113:
sns.countplot(x='Gender_M', data=newdf_cleaned)
plt.title('Distribution of Gender',fontdict={'size': 17})
plt.xlabel('Customer Gender(Male = 0 , Female = 1)', fontdict={'size': 12})
plt.show()
151/114:
sns.countplot(x='Gender_M', data=newdf_cleaned)
plt.title('Distribution of Gender',fontdict={'size': 17})
plt.xlabel('Customer Gender (Male = 0 , Female = 1)', fontdict={'size': 12})
plt.show()
151/115:
sns.countplot(x='Gender_M', hue='Attrition_Flag', data=newdf_cleaned)
plt.title('Relationship between Gender and Churn Rate',fontdict={'size': 17})
plt.show()
151/116:
sns.countplot(x='Gender_M', hue='Attrition_Flag', data=newdf_cleaned)
plt.title('Relationship between Gender and Churn Rate',fontdict={'size': 17})
plt.xlabel('Customer Gender (Male = 0 , Female = 1)', fontdict={'size': 12})
plt.show()
151/117:
sns.countplot(x='Gender_M', hue='Attrition_Flag', data=newdf_cleaned)
plt.title('Relationship between Gender and Churn Rate',fontdict={'size': 17})
plt.xlabel('Customer Gender (Male = 0 , Female = 1)', fontdict={'size': 12})
plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left')
plt.show()
151/118:
sns.countplot(x='Gender_M', hue='Attrition_Flag', data=newdf_cleaned)
plt.title('Relationship between Gender and Churn Rate',fontdict={'size': 17})
plt.xlabel('Customer Gender (Male = 0 , Female = 1)', fontdict={'size': 12})
plt.ylabel('Customer Type', fontdict={'size': 12})
plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left')
plt.show()
151/119:
sns.countplot(x='Education_Level_High School', data=newdf_cleaned)
plt.title('Distribution of Education Level',fontdict={'size': 17})
plt.show()
151/120:
sns.countplot(x='Education_Level', data=newdf_cleaned)
plt.title('Distribution of Education Level',fontdict={'size': 17})

plt.show()
151/121:
sns.countplot(x='Education_Level_High School', data=newdf_cleaned)
plt.title('Distribution of Education Level',fontdict={'size': 17})

plt.show()
151/122:
sns.countplot(x='Education_Level', data=df, order=df['Education_Level'].value_counts().index)
plt.xlabel('Education Level')
plt.ylabel('Count')
plt.show()
151/123: print(newdf_cleaned)
151/124: newdf_cleaned
151/125: print(newdf_cleaned)
151/126:
print(newdf_cleaned.dtypes)
# Checking the data types of each column
151/127: print(newdf_cleaned)
151/128: # Exploring the distrubution of churn rates.
151/129:
sns.countplot(x='Attrition_Flag', data=newdf_cleaned)
plt.title('Churn Rates',fontdict={'size': 17})
plt.xlabel('Customer Type', fontdict={'size': 12})
plt.show()
151/130: # Exploring the distrubution of age
151/131:
sns.histplot(x='Customer_Age', data=newdf_cleaned, bins=20)
plt.title('Distribution of Age',fontdict={'size': 17})
plt.xlabel('Customer Age', fontdict={'size': 12})
plt.show()
151/132: # Exploring the relationship between age and churn rates
151/133:
sns.boxplot(x='Attrition_Flag', y='Customer_Age', data=newdf_cleaned)
plt.title('Relationship between Age and Churn Rate',fontdict={'size': 17})
plt.xlabel('Customer Type', fontdict={'size': 12})
plt.ylabel('Customer Age', fontdict={'size': 12})
plt.show()
151/134: # Exploring the distribution of income
151/135:
sns.histplot(x='Credit_Limit', data=newdf_cleaned, bins=20)
plt.title('Distribution of Credit Limit',fontdict={'size': 17})
plt.xlabel('Customer Credit Limit', fontdict={'size': 12})
plt.show()
151/136: # Exploring the relationship between income and churn rates
151/137:
sns.boxplot(x='Attrition_Flag', y='Credit_Limit', data=newdf_cleaned)
plt.title('Relationship between Credit Limit and Churn Rate',fontdict={'size': 17})
plt.xlabel('Customer Type', fontdict={'size': 12})
plt.ylabel('Customer Credit Limit', fontdict={'size': 12})
plt.show()
151/138: #Exploring the distribution of gender
151/139:
sns.countplot(x='Gender_M', data=newdf_cleaned)
plt.title('Distribution of Gender',fontdict={'size': 17})
plt.xlabel('Customer Gender (Male = 0 , Female = 1)', fontdict={'size': 12})
plt.show()
151/140: # Exploring the relationship between gender and churn rates
151/141:
sns.countplot(x='Gender_M', hue='Attrition_Flag', data=newdf_cleaned)
plt.title('Relationship between Gender and Churn Rate',fontdict={'size': 17})
plt.xlabel('Customer Gender (Male = 0 , Female = 1)', fontdict={'size': 12})
plt.ylabel('Customer Type', fontdict={'size': 12})
plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left')
plt.show()
151/142: # Exploring the distribution of education level
151/143:
sns.countplot(x='Education_Level_High School', data=newdf_cleaned)
plt.title('Distribution of Education Level',fontdict={'size': 17})
plt.xlabel('Education Level High School (0', fontdict={'size': 12})
plt.show()
151/144: # Exploring the relationship between education level and churn rates
151/145:
sns.countplot(x='Education_Level_High School', hue='Attrition_Flag', data=newdf_cleaned)
plt.title('Relationship between Education Level and Churn Rate')
plt.show()
151/146: # Exploring the distribution of marital status
151/147:
sns.countplot(x='Marital_Status_Married', data=newdf_cleaned)
plt.title('Distribution of Marital Status')
plt.show()
151/148: # Exploring the relationship between marital status and churn rates
151/149:
sns.countplot(x='Marital_Status_Married', hue='Attrition_Flag', data=newdf_cleaned)
plt.title('Relationship between Marital Status and Churn Rate')
plt.show()
151/150: # Exploring the distribution of income category
151/151:
sns.countplot(x='Income_Category_Less than $40K', data=df)
plt.title('Distribution of Income Category')
plt.show()
151/152: # Exploring the relationship between income category and churn rates
151/153:
sns.countplot(x='Income_Category_Less than $40K', hue='Attrition_Flag', data=df)
plt.title('Relationship between Income Category and Churn Rate')
plt.show()
151/154: # Exploring the distribution of card category
151/155:
sns.countplot(x='Card_Category_Silver', data=df)
plt.title('Distribution of Card Category')
plt.show()
151/156: # Exploring the relationship between card category and churn rates
151/157:
sns.countplot(x='Card_Category_Silver', hue='Attrition_Flag', data=df)
plt.title('Relationship between Card Category and Churn Rate')
151/158: print(newdf_cleaned)
151/159:
print(newdf_cleaned.dtypes)
# Checking the data types of each column
151/160:
sns.countplot(x='Education_Level_High School', data=newdf_cleaned)
plt.title('Distribution of Education Level',fontdict={'size': 17})
plt.xlabel('Education Level High School (0 = Yes , 1 = No)', fontdict={'size': 12})
plt.show()
151/161:
sns.countplot(x='Education_Level_High School', hue='Attrition_Flag', data=newdf_cleaned)
plt.title('Relationship between Education Level and Churn Rate')
plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left')
plt.show()
151/162:
sns.countplot(x='Education_Level_High School', hue='Attrition_Flag', data=newdf_cleaned)
plt.title('Relationship between High School Education Level and Churn Rate' , fontdict={'size': 17})
plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left')
plt.show()
151/163:
sns.countplot(x='Education_Level_High School', hue='Attrition_Flag', data=newdf_cleaned)
plt.title('Relationship between High School Education Level and Churn Rate' , fontdict={'size': 15})
plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left')
plt.show()
151/164:
sns.countplot(x='Education_Level_High School', hue='Attrition_Flag', data=newdf_cleaned)
plt.title('Relationship between High School Education Level and Churn Rate' , fontdict={'size': 15})
plt.xlabel('Education Level High School (0 = Yes , 1 = No)', fontdict={'size': 12})
plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left')
plt.show()
151/165:
sns.countplot(x='Education_Level_High School', hue='Attrition_Flag', data=newdf_cleaned)
plt.title('Relationship between High School Education Level and Churn Rate' , fontdict={'size': 15})
plt.xlabel('Education Level High School (0 = Yes , 1 = No)', fontdict={'size': 12})
plt.ylabel('Customer Type', fontdict={'size': 12})

plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left')
plt.show()
151/166:
sns.countplot(x='Education_Level_High School', hue='Attrition_Flag', data=newdf_cleaned)
plt.title('Relationship between High School Education Level and Churn Rate' , fontdict={'size': 15})
plt.xlabel('Education Level High School (0 = Yes , 1 = No)', fontdict={'size': 12})
plt.ylabel('Customer Type', fontdict={'size': 12})
plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left')
plt.show()
151/167:
sns.countplot(x='Education_Level_High School', data=newdf_cleaned)
plt.title('Distribution of High School Education Level',fontdict={'size': 17})
plt.xlabel('Education Level High School (0 = Yes , 1 = No)', fontdict={'size': 12})
plt.show()
151/168:
sns.countplot(x='Education_Level_High School', data=newdf_cleaned)
plt.title('Distribution of High School Education Level',fontdict={'size': 17})
plt.xlabel('High School Education Level(0 = Yes , 1 = No)', fontdict={'size': 12})
plt.show()
151/169:
sns.countplot(x='Education_Level_High School', data=newdf_cleaned)
plt.title('Distribution of High School Education Level',fontdict={'size': 17})
plt.xlabel('High School Education Level (0 = Yes , 1 = No)', fontdict={'size': 12})
plt.show()
151/170:
sns.countplot(x='Marital_Status_Married', data=newdf_cleaned)
plt.title('Distribution of Married Marital Status' ,fontdict={'size': 17})
plt.show()
151/171:
sns.countplot(x='Marital_Status_Married', data=newdf_cleaned)
plt.title('Distribution of Married Marital Status' ,fontdict={'size': 17})
plt.xlabel('Customer Marital Status  (0 = Married , 1 = Non-Married/Unknown)', fontdict={'size': 12})

plt.show()
151/172:
sns.countplot(x='Marital_Status_Married', hue='Attrition_Flag', data=newdf_cleaned)
plt.title('Relationship between Marital Status and Churn Rate',fontdict={'size': 15})
plt.show()
151/173:
sns.countplot(x='Marital_Status_Married', hue='Attrition_Flag', data=newdf_cleaned)
plt.title('Relationship between Married Marital Status and Churn Rate',fontdict={'size': 15})
plt.show()
151/174:
sns.countplot(x='Marital_Status_Married', hue='Attrition_Flag', data=newdf_cleaned)
plt.title('Relationship between Married Marital Status and Churn Rate',fontdict={'size': 15})
plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left')
plt.show()
151/175:
sns.countplot(x='Marital_Status_Married', hue='Attrition_Flag', data=newdf_cleaned)
plt.title('Relationship between Married Marital Status and Churn Rate',fontdict={'size': 15})
plt.xlabel('Customer Marital Status  (0 = Married , 1 = Non-Married/Unknown)', fontdict={'size': 12})
plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left')
plt.show()
151/176:
sns.countplot(x='Marital_Status_Married', hue='Attrition_Flag', data=newdf_cleaned)
plt.title('Relationship between Married Marital Status and Churn Rate',fontdict={'size': 15})
plt.xlabel('Customer Marital Status  (0 = Married , 1 = Non-Married/Unknown)', fontdict={'size': 12})
plt.ylabel('Customer Type', fontdict={'size': 12})
plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left')
plt.show()
151/177:
sns.countplot(x='Income_Category_Less than $40K', data=df)
plt.title('Distribution of Income Category',fontdict={'size': 12})
plt.show()
151/178:
sns.countplot(x='Income_Category_Less than $40K', data=df)
plt.title('Distribution of Income Category',fontdict={'size': 17})
plt.xlabel('Customer Income CategoryLess than $40K  (0 = Yes , 1 = No)', fontdict={'size': 12})
plt.show()
151/179:
sns.countplot(x='Income_Category_Less than $40K', data=df)
plt.title('Distribution of Income Category Less than $40K',fontdict={'size': 17})
plt.xlabel('Customer Income CategoryLess than $40K  (0 = Yes , 1 = No)', fontdict={'size': 12})
plt.show()
151/180:
sns.countplot(x='Income_Category_Less than $40K', data=df)
plt.title('Distribution of Income Category',fontdict={'size': 17})
plt.xlabel('Customer Income CategoryLess than $40K  (0 = Yes , 1 = No)', fontdict={'size': 12})
plt.show()
151/181:
sns.countplot(x='Marital_Status_Married', hue='Attrition_Flag', data=newdf_cleaned)
plt.title('Relationship between Marital Status and Churn Rate',fontdict={'size': 15})
plt.xlabel('Customer Marital Status  (0 = Married , 1 = Non-Married/Unknown)', fontdict={'size': 12})
plt.ylabel('Customer Type', fontdict={'size': 12})
plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left')
plt.show()
151/182:
sns.countplot(x='Marital_Status_Married', data=newdf_cleaned)
plt.title('Distribution of Marital Status' ,fontdict={'size': 17})
plt.xlabel('Customer Marital Status  (0 = Married , 1 = Non-Married/Unknown)', fontdict={'size': 12})
plt.show()
151/183:
sns.countplot(x='Income_Category_Less than $40K', hue='Attrition_Flag', data=df)
plt.title('Relationship between Income Category and Churn Rate',fontdict={'size': 15})
plt.show()
151/184:
sns.countplot(x='Income_Category_Less than $40K', hue='Attrition_Flag', data=df)
plt.title('Relationship between Income Category and Churn Rate',fontdict={'size': 15})
plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left')

plt.show()
151/185:
sns.countplot(x='Income_Category_Less than $40K', hue='Attrition_Flag', data=df)
plt.title('Relationship between Income Category and Churn Rate',fontdict={'size': 15})
plt.xlabel('Customer Income CategoryLess than $40K  (0 = Yes , 1 = No)', fontdict={'size': 12})
plt.ylabel('Customer Type', fontdict={'size': 12})

plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left')

plt.show()
151/186:
sns.countplot(x='Income_Category_Less than $40K', hue='Attrition_Flag', data=df)
plt.title('Relationship between Income Category and Churn Rate',fontdict={'size': 15})
plt.xlabel('Customer Income CategoryLess than $40K  (0 = Yes , 1 = No)', fontdict={'size': 12})
plt.ylabel('Customer Type', fontdict={'size': 12})
plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left')
plt.show()
151/187:
sns.countplot(x='Card_Category_Silver', data=df)
plt.title('Distribution of Card Category',fontdict={'size': 15})
plt.show()
151/188:
sns.countplot(x='Card_Category_Silver', data=df)
plt.title('Distribution of Card Category',fontdict={'size': 15})
plt.xlabel('Customer Silver Card Category  (0 = No , 1 = Yes)', fontdict={'size': 12})
plt.show()
151/189:
sns.countplot(x='Card_Category_Silver', data=df)
plt.title('Distribution of Card Category',fontdict={'size': 15})
plt.xlabel('Customers in Silver Card Category  (0 = No , 1 = Yes)', fontdict={'size': 12})
plt.show()
151/190:
sns.countplot(x='Card_Category_Silver', hue='Attrition_Flag', data=df)
plt.title('Relationship between Card Category and Churn Rate',fontdict={'size': 15})
151/191:
sns.countplot(x='Card_Category_Silver', hue='Attrition_Flag', data=df)
plt.title('Relationship between Card Category and Churn Rate',fontdict={'size': 15})
plt.xlabel('Customers in Silver Card Category  (0 = No , 1 = Yes)', fontdict={'size': 12})
151/192:
sns.countplot(x='Card_Category_Silver', hue='Attrition_Flag', data=df)
plt.title('Relationship between Card Category and Churn Rate',fontdict={'size': 15})
plt.xlabel('Customers in Silver Card Category  (0 = No , 1 = Yes)', fontdict={'size': 12})
plt.ylabel('Customer Type', fontdict={'size': 12})
plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left')
152/1:
import pandas as pd
df = pd.read_csv('data/grades1a.csv')
df2 = pd.read_csv('data/grades1b.csv')
df3 = pd.read_csv('data/grades1c.csv')
df
152/2: df2
152/3: df3
152/4:
merged_dataset = pd.merge(grades1a, grades1b, on='student_id', how='inner')
merged_dataset = pd.merge(merged_dataset, grades1c, on='student_id', how='inner')
print(merged_dataset)
152/5:
merged_dataset = pd.merge(df, df2, on='student_id', how='inner')
merged_dataset = pd.merge(merged_dataset, df3, on='student_id', how='inner')
print(merged_dataset)
152/6:
merged_dataset = pd.merge(df, df2, on='Student ID', how='inner')
merged_dataset = pd.merge(merged_dataset, df3, on='Student ID', how='inner')
print(merged_dataset)
152/7:
merged_dataset = pd.merge(df, df2, on='Student ID', how='inner')
merged_dataset = pd.merge(merged_dataset, df3, on='Student ID', how='inner')
print(merged_dataset)
152/8:
merged_dataset = pd.merge(df, df2,df3 on='Student ID', how='inner')

print(merged_dataset)
152/9:
merged_dataset = pd.merge(df, df2,df3 , on='Student ID', how='inner')

print(merged_dataset)
152/10:
merged_dataset = pd.merge(df, df2 ,df3 , on='Student ID', how='inner')

print(merged_dataset)
152/11:
merged_dataset = pd.merge(df, df2, on='Student ID')
merged_dataset = pd.merge(merged_dataset, df3, on='Student ID')
print(merged_dataset)
152/12:
merged_dataset = pd.merge(df, df2, on='Student ID')
result = pd.merge(merged_dataset, df3, on='Student ID')
print(result)
152/13:
merged_dataset = pd.merge(df, df2, on='Student ID')
result = pd.merge(merged_dataset, df3, on='Student ID')
result
152/14:
merged_dataset = pd.merge(df, df2, on='Student ID')
result = pd.merge(merged_dataset, df3, on='Student ID')
result.head(9)
152/15:
merged_dataset = pd.merge(df, df2, on='Student ID')
result = pd.merge(merged_dataset, df3, on='Student ID')
result
152/16:
df1 = pd.read_csv('grades2a.csv')
df2 = pd.read_csv('grades2b.csv')
152/17:
df1 = pd.read_csv('data/grades2a.csv')
df2 = pd.read_csv('data/grades2b.csv')
152/18:
df1 = pd.read_csv('data/grades2a.csv')
df1
152/19:
df2 = pd.read_csv('data/grades2b.csv')
df2
152/20: df = pd.merge(df1, df2, left_on='Student ID', right_on='SID')
152/21:
df = pd.merge(df1, df2, left_on='Student ID', right_on='SID')
df
152/22:
result2 = pd.merge(df1, df2, left_on='Student ID', right_on='SID')
result2
153/1:
| Merge Type | Explanation |
| ---------- | ----------- |
| Left join  | # Your sentence here |
| Right join | # Your sentence here |
| Outer join | # Your sentence here |
| Inner join | # Your sentence here |
| Cross join | # Your sentence here |
153/2:
| Merge Type | Explanation |
| ---------- | ----------- |
| Left join  | # Your sentence here |
| Right join | # Your sentence here |
| Outer join | # Your sentence here |
| Inner join | # Your sentence here |
| Cross join | # Your sentence here |
153/3:
| Merge Type | Explanation |
| ---------- | ----------- |
| Left join  | # Your sentence here |
| Right join | # Your sentence here |
| Outer join | # Your sentence here |
| Inner join | # Your sentence here |
| Cross join | # Your sentence here |
153/4:
data = [["Left join  ", 99], 
        ["Suns", 91], 
        ["Spurs", 94], 
        ["Nets", 88]]
153/5:
data = [["Left join  ", 99], 
        ["Suns", 91], 
        ["Spurs", 94], 
        ["Nets", 88]]
col_names = ["Team", "Points"]
153/6:
data = [["Left join  ", 99], 
        ["Suns", 91], 
        ["Spurs", 94], 
        ["Nets", 88]]
col_names = ["Team", "Points"]
  print(tabulate(data, headers=col_names))
153/7:
data = [["Left join  ", 99], 
        ["Suns", 91], 
        ["Spurs", 94], 
        ["Nets", 88]]
col_names = ["Team", "Points"]
print(tabulate(data, headers=col_names))
153/8:
import pandas as pd
from tabulate import tabulate
153/9:
pip install tabulate
import pandas as pd
from tabulate import tabulate
153/10: pip install tabulate
153/11:

import pandas as pd
from tabulate import tabulate
153/12:

import pandas as pd
from tabulate import tabulate
153/13:
data = [["Left join  ", 99], 
        ["Suns", 91], 
        ["Spurs", 94], 
        ["Nets", 88]]
col_names = ["Team", "Points"]
print(tabulate(data, headers=col_names))
153/14:
data = [["Left join  ", 99], 
        ["Suns", 91], 
        ["Spurs", 94], 
        ["Nets", 88]]
col_names = ["Team", "Points"]
print(tabulate(data, headers=col_names, tablefmt="fancy_grid", showindex="always"))
153/15:
data = [["Left join  ", 99], 
        ["Right join", 91], 
        ["Outer join", 94], 
        ["Inner join", 88],
       ["Cross join", 88]]
col_names = ["Team", "Points"]
print(tabulate(data, headers=col_names, tablefmt="fancy_grid", showindex="always"))
153/16:
data = [["Left join  ", "Left join returns all rows from the left table and the matched rows from the right table"], 
        ["Right join", 91], 
        ["Outer join", 94], 
        ["Inner join", 88],
       ["Cross join", 88]]
col_names = ["Team", "Points"]
print(tabulate(data, headers=col_names, tablefmt="fancy_grid", showindex="always"))
153/17:
data = [["Left join  ", "Left join returns all rows from the left table and the matched rows from the right table"], 
        ["Right join", "Right join returns all rows from the right table and the matched rows from the left table"], 
        ["Outer join", 94], 
        ["Inner join", 88],
       ["Cross join", 88]]
col_names = ["Team", "Points"]
print(tabulate(data, headers=col_names, tablefmt="fancy_grid", showindex="always"))
153/18:
data = [["Left join  ", "Left join returns all rows from the left table and the matched rows from the right table"], 
        ["Right join", "Right join returns all rows from the right table and the matched rows from the left table"], 
        ["Outer join", "Outer join returns all rows from both tables, combining the matched and non-matched rows from each"], 
        ["Inner join", 88],
       ["Cross join", 88]]
col_names = ["Team", "Points"]
print(tabulate(data, headers=col_names, tablefmt="fancy_grid", showindex="always"))
153/19:
data = [["Left join  ", "Left join returns all rows from the left table and the matched rows from the right table"], 
        ["Right join", "Right join returns all rows from the right table and the matched rows from the left table"], 
        ["Outer join", "Outer join returns all rows from both tables, combining the matched and non-matched rows from each"], 
        ["Inner join", "Inner join returns only the matched rows from both tables"],
       ["Cross join", 88]]
col_names = ["Team", "Points"]
print(tabulate(data, headers=col_names, tablefmt="fancy_grid", showindex="always"))
153/20:
data = [["Left join  ", "Left join returns all rows from the left table and the matched rows from the right table"], 
        ["Right join", "Right join returns all rows from the right table and the matched rows from the left table"], 
        ["Outer join", "Outer join returns all rows from both tables, combining the matched and non-matched rows from each"], 
        ["Inner join", "Inner join returns only the matched rows from both tables"],
       ["Cross join", "Cross join creates a Cartesian product by combining all rows from both tables"]]
col_names = ["Team", "Points"]
print(tabulate(data, headers=col_names, tablefmt="fancy_grid", showindex="always"))
153/21:
data = [["Left join  ", "Left join returns all rows from the left table and the matched rows from the right table"], 
        ["Right join", "Right join returns all rows from the right table and the matched rows from the left table"], 
        ["Outer join", "Outer join returns all rows from both tables, combining the matched and non-matched rows from each"], 
        ["Inner join", "Inner join returns only the matched rows from both tables"],
       ["Cross join", "Cross join creates a Cartesian product by combining all rows from both tables"]]
col_names = [" Merge Type", "Explanation"]
print(tabulate(data, headers=col_names, tablefmt="fancy_grid", showindex="always"))
153/22:
data = [["Left join  ", "Left join returns all rows from the left table and the matched rows from the right table"], 
        ["Right join", "Right join returns all rows from the right table and the matched rows from the left table"], 
        ["Outer join", "Outer join returns all rows from both tables, combining the matched and non-matched rows from each"], 
        ["Inner join", "Inner join returns only the matched rows from both tables"],
       ["Cross join", "Cross join creates a Cartesian product by combining all rows from both tables"]]
col_names = [" Merge Type", "Explanation"]
print(tabulate(data, headers=col_names, tablefmt="fancy_grid", showindex="always"))
154/1:
pokemon = (pokemon
           .drop(['Generation', 'Sp. Atk', 'Sp. Def', 'Total', '#'], axis=1)  # drop unnecessary columns
           .dropna(subset=['HP', 'Attack', 'Defense', 'Speed'])  # drop rows with missing values
           .reset_index(drop=True)  # reset the index without missing values
           .drop('index', axis=1)  # drop the index column
           .assign(Weighted_Score=lambda x: 0.2*x['HP'] + 0.4*x['Attack'] + 0.3*x['Defense'] + 0.1*x['Speed'])  # calculate weighted score
          )
154/2: pokemon = pd.read_csv('https://github.com/firasm/bits/raw/master/pokemon.csv')
154/3:
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
154/4: pokemon = pd.read_csv('https://github.com/firasm/bits/raw/master/pokemon.csv')
154/5:
pokemon = (pokemon
           .drop(['Generation', 'Sp. Atk', 'Sp. Def', 'Total', '#'], axis=1)  # drop unnecessary columns
           .dropna(subset=['HP', 'Attack', 'Defense', 'Speed'])  # drop rows with missing values
           .reset_index(drop=True)  # reset the index without missing values
           .drop('index', axis=1)  # drop the index column
           .assign(Weighted_Score=lambda x: 0.2*x['HP'] + 0.4*x['Attack'] + 0.3*x['Defense'] + 0.1*x['Speed'])  # calculate weighted score
          )
154/6: pokemon = (pokemon .drop(['Generation', 'Sp. Atk', 'Sp. Def', 'Total', '#'], axis=1)
154/7: pokemon = pokemon .drop(['Generation', 'Sp. Atk', 'Sp. Def', 'Total', '#'], axis=1)
154/8:
pokemon = (pokemon
           .drop(['Generation', 'Sp. Atk', 'Sp. Def', 'Total', '#'], axis=1)  # drop unnecessary columns
           .dropna(subset=['HP', 'Attack', 'Defense', 'Speed'])  # drop rows with missing values
           .reset_index(drop=True)  # reset the index without missing values
           .drop('index', axis=1)  # drop the index column
           .assign(Weighted_Score=lambda x: 0.2*x['HP'] + 0.4*x['Attack'] + 0.3*x['Defense'] + 0.1*x['Speed'])  # calculate weighted score
          )
154/9:
pokemon = pd.read_csv('https://github.com/firasm/bits/raw/master/pokemon.csv')
pokemon
154/10:
pokemon = (pokemon
           .drop(['Generation', 'Sp.Atk', 'Sp.Def', 'Total', '#'], axis=1)  # drop unnecessary columns
           .dropna(subset=['HP', 'Attack', 'Defense', 'Speed'])  # drop rows with missing values
           .reset_index(drop=True)  # reset the index without missing values
           .drop('index', axis=1)  # drop the index column
           .assign(Weighted_Score=lambda x: 0.2*x['HP'] + 0.4*x['Attack'] + 0.3*x['Defense'] + 0.1*x['Speed'])  # calculate weighted score
          )
154/11:
pokemon = (pokemon
           .drop(['Generation', 'Sp. Atk', 'Sp. Def', 'Total', '#'], axis=1)  # drop unnecessary columns
           .dropna(subset=['HP', 'Attack', 'Defense', 'Speed'])  # drop rows with missing values
           .reset_index(drop=True)  # reset the index without missing values
           .drop('index', axis=1)  # drop the index column
           .assign(Weighted_Score=lambda x: 0.2*x['HP'] + 0.4*x['Attack'] + 0.3*x['Defense'] + 0.1*x['Speed'])  # calculate weighted score
          )
154/12:
pokemon = (pokemon
           .drop(['Generation', 'Sp. Atk', 'Sp. Def', 'Total', '#'], axis=1)  # drop unnecessary columns
           .dropna(subset=['HP', 'Attack', 'Defense', 'Speed'])  # drop rows with missing values
           .reset_index(drop=True)  # reset the index without missing values
           .assign(Weighted_Score=lambda x: 0.2*x['HP'] + 0.4*x['Attack'] + 0.3*x['Defense'] + 0.1*x['Speed'])  # calculate weighted score
          )
154/13:
pokemon = (pokemon
           .drop(['Generation', 'Sp. Atk', 'Sp. Def', 'Total', '#'], axis=1)  # drop unnecessary columns
           .dropna(subset=['HP', 'Attack', 'Defense', 'Speed'])  # drop rows with missing values
           .reset_index(drop=True)  # reset the index without missing values
           .assign(Weighted_Score=lambda x: 0.2*x['HP'] + 0.4*x['Attack'] + 0.3*x['Defense'] + 0.1*x['Speed'])  # calculate weighted score
          )
pokemon
154/14:
pokemon = (pokemon
           .drop(['Generation', 'Sp. Atk', 'Sp. Def', 'Total', '#'], axis=1)  # drop unnecessary columns
           .dropna(subset=['HP', 'Attack', 'Defense', 'Speed'])  # drop rows with missing values
           .reset_index(drop=True)  # reset the index without missing values
           .assign(Weighted_Score=lambda x: 0.2*x['HP'] + 0.4*x['Attack'] + 0.3*x['Defense'] + 0.1*x['Speed'])  # calculate weighted score
          )
154/15:
pokemon = (pokemon
           .drop(['Generation', 'Sp. Atk', 'Sp. Def', 'Total', '#'], axis=1)  # drop unnecessary columns
           .dropna(subset=['HP', 'Attack', 'Defense', 'Speed'])  # drop rows with missing values
           .reset_index(drop=True)  # reset the index without missing values
           .assign(Weighted_Score=lambda x: 0.2*x['HP'] + 0.4*x['Attack'] + 0.3*x['Defense'] + 0.1*x['Speed'])  # calculate weighted score
          )
154/16: pokemon = (pokemon.drop(['Generation', 'Sp. Atk', 'Sp. Def', 'Total', '#'], axis=1).dropna(subset=['HP', 'Attack', 'Defense', 'Speed']).reset_index(drop=True).assign(Weighted_Score=lambda x: 0.2*x['HP'] + 0.4*x['Attack'] + 0.3*x['Defense'] + 0.1*x['Speed'])  # calculate weighted score )
154/17: pokemon = (pokemon.drop(['Generation', 'Sp. Atk', 'Sp. Def', 'Total', '#'], axis=1).dropna(subset=['HP', 'Attack', 'Defense', 'Speed']).reset_index(drop=True).assign(Weighted_Score=lambda x: 0.2*x['HP'] + 0.4*x['Attack'] + 0.3*x['Defense'] + 0.1*x['Speed']) )
154/18: pokemon = (pokemon.drop(['Generation', 'Sp. Atk', 'Sp. Def', 'Total', '#'], axis=1).dropna(subset=['HP', 'Attack', 'Defense', 'Speed']).reset_index(drop=True).assign(Weighted_Score=lambda x: 0.2*x['HP'] + 0.4*x['Attack'] + 0.3*x['Defense'] + 0.1*x['Speed']))
154/19:
pokemon = pd.read_csv('https://github.com/firasm/bits/raw/master/pokemon.csv')
pokemon
154/20:
pokemon = (pokemon.drop(['Generation', 'Sp. Atk', 'Sp. Def', 'Total', '#'], axis=1).dropna(subset=['HP', 'Attack', 'Defense', 'Speed']).reset_index(drop=True)
           .assign(Weighted_Score=lambda x: 0.2*x['HP'] + 0.4*x['Attack'] + 0.3*x['Defense'] + 0.1*x['Speed']))
154/21:
newpokemon = (pokemon.drop(['Generation', 'Sp. Atk', 'Sp. Def', 'Total', '#'], axis=1).dropna(subset=['HP', 'Attack', 'Defense', 'Speed']).reset_index(drop=True)
           .assign(Weighted_Score=lambda x: 0.2*x['HP'] + 0.4*x['Attack'] + 0.3*x['Defense'] + 0.1*x['Speed']))
154/22:
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
154/23:
pokemon = pd.read_csv('https://github.com/firasm/bits/raw/master/pokemon.csv')
pokemon
154/24:
newpokemon = (pokemon.drop(['Generation', 'Sp. Atk', 'Sp. Def', 'Total', '#'], axis=1).dropna(subset=['HP', 'Attack', 'Defense', 'Speed']).reset_index(drop=True)
           .assign(Weighted_Score=lambda x: 0.2*x['HP'] + 0.4*x['Attack'] + 0.3*x['Defense'] + 0.1*x['Speed']))
154/25: newpokemon
154/26:
newpokemon2 = (pokemon
           .query('Generation < 6')  # remove all Pokemon 6th generation and above
           .drop('Legendary', axis=1)  # remove Legendary column
           .query('Name.str.contains("Forme") == False')  # remove rows containing "Forme"
           .query('Name.str.contains("Mega") == False')  # remove rows containing "Mega"
          )
154/27: newpokemon2
154/28: newpokemon2 = (pokemon.query('Generation < 6').drop('Legendary', axis=1).query('Name.str.contains("Forme") == False').query('Name.str.contains("Mega") == False'))
154/29: newpokemon2
154/30: newpokemon = (pokemon.drop(['Generation', 'Sp. Atk', 'Sp. Def', 'Total', '#'], axis=1).dropna(subset=['HP', 'Attack', 'Defense', 'Speed']).reset_index(drop=True).assign(Weighted_Score=lambda x: 0.2*x['HP'] + 0.4*x['Attack'] + 0.3*x['Defense'] + 0.1*x['Speed']))
154/31: newpokemon
155/1:
df = pd.read_csv('https://github.com/firasm/bits/raw/master/pokemon.csv')
df
155/2:
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
155/3:
df = pd.read_csv('https://github.com/firasm/bits/raw/master/pokemon.csv')
df
155/4: df['HP'] = df['HP'].apply(lambda x: x**(1/3))
155/5:
df['HP'] = df['HP'].apply(lambda x: x**(1/3))
df
155/6:
df['HP'] = df['HP'].apply(lambda x: x**(1/3))
print(df.head())
155/7:
df['HP'] = df['HP'].apply(lambda x: x**(1/3))
print(df.head(5))
155/8:
df['HP'] = df['HP'].apply(lambda x: x**(1/3))
df.head(5)
155/9:
df['HP'] = df['HP'].apply(lambda x: x**(1/3))
df.head(5)
155/10:
df['HP'] = df['HP'].apply(lambda x: x**(1/3))
df.head(5)
155/11:
df['HP'] = df['HP'].apply(lambda x: x**(1/3))
df.head(5)
155/12:
df['HP'] = df['HP'].apply(lambda x: x**(1/3))
df.head(5)
155/13:
df['HP'] = df['HP'].apply(lambda x: x**(1/3))
df.head(5)
155/14:
df['HP'] = df['HP'].apply(lambda x: x**(1/3))
df.head(5)
155/15:
df['HP'] = df['HP'].apply(lambda x: x**(1/3))
df.head(5)
155/16:
df['HP'] = df['HP'].apply(lambda x: x**(1/3))
df.head(5)
155/17:
df['HP'] = df['HP'].apply(lambda x: x**(1/3))
df.head(5)
155/18:
df['HP'] = df['HP'].apply(lambda x: x**(1/3))
df.head(5)
155/19:
df['HP'] = df['HP'].apply(lambda x: x**(1/3))
df.head(5)
155/20: df.head(5)
155/21:
df = pd.read_csv('https://github.com/firasm/bits/raw/master/pokemon.csv')
df
155/22: df.head(5)
155/23:
df['HP'] = df['HP'].apply(lambda x: x**(1/3))
df.head(5)
155/24:
df['Temporary Health'] = df['HP'].apply(lambda x: x**3)
df['Temporary Health'] = df['HP'].apply(lambda x: x**3)
df.head(5)
155/25:
df['Temporary Health'] = df['HP'].apply(lambda x: x**3)
df['Temporary Attack'] = df['Attack'].apply(lambda x: x*2)
df.head(5)
155/26:
df['Temporary Health'] = df['HP'].apply(lambda x: x**3)
df['Temporary Attack'] = df['Attack'].apply(lambda x: x*2)
df.head(5)
155/27: df = pd.read_csv('https://github.com/firasm/bits/raw/master/pokemon.csv')
155/28:
df['Special_Power'] = df['Sp. Atk'] * df['Sp. Def']
df.head(5)
155/29:
df['Type_Combined'] = df['Type 1'] + ' ' + df['Type 2'].fillna('')
df.head(5)
155/30:
df['Type_Combined'] = df['Type 1'] + ' ' + df['Type 2'].fillna('')
df.head(7)
155/31:
df['Type_Combined'] = df['Type 1'] + ' ' + df['Type 2'].fillna('')
df.head(6)
152/23: result = pd.concat([df1a, df1b, df1c])
152/24: result = pd.concat([df, df12, df3])
152/25: result = pd.concat([df, df2, df3])
152/26:
import pandas as pd
df = pd.read_csv('data/grades1a.csv')
df2 = pd.read_csv('data/grades1b.csv')
df3 = pd.read_csv('data/grades1c.csv')
df
152/27: df2
152/28: df3
152/29: result = pd.concat([df, df2, df3])
152/30:
result = pd.concat([df, df2, df3])
result
152/31:
merged_df = pd.merge(df1, df2, on="Student ID")
merged_df = pd.merge(merged_df, df3, on="Student ID")
152/32:
merged_df = pd.merge(df1, df2, on="Student ID")
merged_df = pd.merge(merged_df, df3, on="Student ID")
merged_df
153/23:
data = [["Left join  ", "Left join returns all rows from the left table and the matched rows from the right table"], 
        ["Right join", "Right join returns all rows from the right table and the matched rows from the left table"], 
        ["Outer join", "Outer join returns all rows from both tables, combining the matched and non-matched rows from each"], 
        ["Inner join", "Inner join returns only the matched rows from both tables"],
       ["Cross join", "Cross join creates a Cartesian product by combining all rows from both tables"]]
col_names = [" Merge Type", "Explanation"]
print(tabulate(data, headers=col_names, tablefmt="fancy_grid", showindex="always"))
153/24:
left_df = pd.DataFrame({'key': ['A', 'B', 'C', 'D'], 'value': [1, 2, 3, 4]})
right_df = pd.DataFrame({'key': ['B', 'D', 'E', 'F'], 'value': [5, 6, 7, 8]})
153/25:
df1 = pd.DataFrame({'key': ['A', 'B', 'C', 'D'], 'value': [1, 2, 3, 4]})
df2 = pd.DataFrame({'key': ['B', 'D', 'E', 'F'], 'value': [5, 6, 7, 8]})
153/26: df1
153/27: df2
153/28:
#Performing left join
df_left_join = pd.merge(df1, df2, on='ID', how='left')
153/29:
#Performing left join
df_left_join = pd.merge(df1, df2, on='Key', how='left')
153/30:
#Performing left join
df_left_join = pd.merge(df1, df2, on='key', how='left')
153/31:
#Performing left join
df_left_join = pd.merge(df1, df2, on='key', how='left')
df_left_join
153/32:
df1 = pd.DataFrame({'Letter': ['A', 'B', 'C', 'D'], 'value': [1, 2, 3, 4]})
df2 = pd.DataFrame({'Letter': ['E', 'F', 'G', 'H'], 'value': [5, 6, 7, 8]})
153/33: df1
153/34: df2
153/35:
#Performing left join
df_left_join = pd.merge(df1, df2, on='key', how='left')
df_left_join
153/36:
#Performing left join
df_left_join = pd.merge(df1, df2, on='Letter', how='left')
df_left_join
153/37:
df1 = pd.DataFrame({'Letter': ['A', 'B', 'C', 'D'], 'value': [1, 2, 3, 4]})
df2 = pd.DataFrame({'Letter': ['A', 'C', 'G', 'H'], 'value': [5, 6, 7, 8]})
153/38: df1
153/39: df2
153/40:
#Performing left join
df_left_join = pd.merge(df1, df2, on='Letter', how='left')
df_left_join
153/41:
df1 = pd.DataFrame({'Letter': ['A', 'B', 'C', 'D'], 'value': [1, 2, 3, 4]})
df2 = pd.DataFrame({'Letter': ['F', 'C', 'A', 'H'], 'value': [5, 6, 7, 8]})
153/42: df1
153/43: df2
153/44:
#Performing left join
df_left_join = pd.merge(df1, df2, on='Letter', how='left')
df_left_join
153/45:
df1 = pd.DataFrame({'Letter': ['A', 'B', 'C', 'D'], 'value': [1, 2, 3, 4]})
df2 = pd.DataFrame({'Letter': ['A', 'C', 'A', 'H'], 'value': [5, 6, 7, 8]})
153/46: df1
153/47: df2
153/48:
#Performing left join
df_left_join = pd.merge(df1, df2, on='Letter', how='left')
df_left_join
153/49: df_right_join = pd.merge(df1, df2, on='Letter', how='right')
153/50:
df_right_join = pd.merge(df1, df2, on='Letter', how='right')
df_right_join
153/51:
df1 = pd.DataFrame({'Letter': ['A', 'B', 'C', 'D'], 'value': [1, 2, 3, 4]})
df2 = pd.DataFrame({'Letter': ['A', 'C', 'E', 'H'], 'value': [5, 6, 7, 8]})
153/52: df1
153/53: df2
153/54:
#Performing left join
df_left_join = pd.merge(df1, df2, on='Letter', how='left')
df_left_join
153/55: **Right Join**
153/56:
df_right_join = pd.merge(df1, df2, on='Letter', how='right')
df_right_join
153/57: **Right Join**
153/58: **Right Join**
153/59: **RightJoin**
153/60: df_right_join = pd.merge(df1, df2, on='Letter', how='outer')
153/61: df_outer_join = pd.merge(df1, df2, on='Letter', how='outer')
153/62:
df_outer_join = pd.merge(df1, df2, on='Letter', how='outer')
df_outer_join
153/63:
df_inner_join = pd.merge(df1, df2, on='Letter', how='outer')
df_inner_join
153/64: df_cross_join = pd.merge(df1, df2, on='Letter', how='cross')
153/65: df_cross_join = pd.merge(df1.assign(Letter=1), df2.assign(Letter=1), on='Letter').drop('Letter', axis=1)
153/66:
df_cross_join = pd.merge(df1.assign(Letter=1), df2.assign(Letter=1), on='Letter').drop('Letter', axis=1)
df_cross_join
153/67: #Therefore ,as we can see from above after performing left join , our new df will return all rows from df1 with all the matching rows from df2.
153/68: #Therefore ,as we can see from above after performing left join , our new df will return all rows from df2 with all the matching rows from df1.
153/69: #Therefore ,as we can see from above after performing inner join , our new df will return all rows from df1 and df2 with null values for both columns.
153/70:
df_inner_join = pd.merge(df1, df2, on='Letter', how='inner')
df_inner_join
153/71:
df3 = pd.DataFrame({'Letter': ['A', 'B', 'C', 'D'], 'value3': [1, 2, 3, 4]})
df4 = pd.DataFrame({'Letter': ['A', 'C', 'E', 'H'], 'value4': [5, 6, 7, 8]})
153/72: df_cross_join = pd.merge(df1.assign(Letter=1), df2.assign(Letter=1), on='Letter').drop('Letter', axis=1)
153/73:
df_cross_join = pd.merge(df1.assign(Letter=1), df2.assign(Letter=1), on='Letter').drop('Letter', axis=1)
df_cross_join
152/33:
merged_df = pd.merge(df1, df2, on="Student ID")
newdf = pd.merge(merged_df, df3, on="Student ID")
newdf
152/34:
import pandas as pd
df = pd.read_csv('data/grades1a.csv')
df2 = pd.read_csv('data/grades1b.csv')
df3 = pd.read_csv('data/grades1c.csv')
df
152/35: df2
152/36: df3
152/37:
merged_df = pd.merge(df1, df2, on="Student ID")
newdf = pd.merge(merged_df, df3, on="Student ID")
newdf
152/38:
merged_df = pd.merge(df1, df2, on="Student ID" ,how='inner')
newdf = pd.merge(merged_df, df3, on="Student ID",,how='inner')
newdf
152/39:
merged_df = pd.merge(df1, df2, on="Student ID" ,how='inner')
newdf = pd.merge(merged_df, df3, on="Student ID",how='inner')
newdf
152/40:
import pandas as pd
df1 = pd.read_csv('data/grades1a.csv')
df2 = pd.read_csv('data/grades1b.csv')
df3 = pd.read_csv('data/grades1c.csv')
df
152/41:
import pandas as pd
df1 = pd.read_csv('data/grades1a.csv')
df2 = pd.read_csv('data/grades1b.csv')
df3 = pd.read_csv('data/grades1c.csv')
df1
152/42: df2
152/43: df3
152/44: frames = [df1, df2, df3]
152/45:
frames = [df1, df2, df3]
result = pd.concat(frames)
152/46:
frames = [df1, df2, df3]
result = pd.concat(frames)
result
152/47: concat_df = pd.concat([df1, df2, df3], axis=0, join='inner')
152/48:
concat_df = pd.concat([df1, df2, df3], axis=0, join='inner')
concat_df
152/49:
concat_df = pd.concat([df1, df2, df3], axis=0, join='outer')
concat_df
152/50:
merged_df = pd.concat([df1, df2, df3], axis=0, join='outer')
merged_df
152/51:
merged_df = pd.concat([df1, df2, df3], axis=0, join='outer')
merged_df = merged_df.reset_index(drop=True)

merged_df
152/52:
merged_df = pd.concat([df1, df2, df3], axis=0, join='outer')
merged_df = merged_df.reset_index(drop=True)
152/53:
merged_df = pd.concat([df1, df2, df3], axis=0, join='outer')
merged_df = merged_df.reset_index(drop=True)
152/54:
merged_df = pd.concat([df1, df2, df3], axis=0, join='outer')
merged_df = merged_df.reset_index(drop=True)
merged_df
152/55:
merged_df = pd.concat([df1, df2, df3], axis=0)
merged_df = merged_df.reset_index(drop=True)
merged_df
152/56:
merged_df = pd.concat([df1, df2, df3], axis=0)
merged_df = merged_df.reset_index(drop=True)
merged_df
152/57:
merged_df = pd.concat([df1, df2, df3], axis=0)
merged_df = merged_df.reset_index(drop=True)
152/58:
merged_df = pd.concat([df1, df2, df3], axis=0)
merged_df = merged_df.reset_index(drop=True)
merged_df
152/59:
merged_df = pd.concat([df1, df2, df3], axis=1)
merged_df = merged_df.reset_index(drop=True)
merged_df
152/60:
df1 = df1.rename(columns={'Chemistry_1': 'Chemistry'})

merged_df = pd.concat([df1, df2, df3], axis=1)
merged_df = merged_df.reset_index(drop=True)
merged_df
152/61:
df1 = df1.rename(columns={'Chemistry_1': 'Chemistry'})
merged_df = pd.concat([df1, df2, df3], axis=1)
merged_df = merged_df.reset_index(drop=True)
merged_df
152/62:
df1 = df1.rename(columns={'Chemistry_1': 'Chemistry'})
merged_df = pd.concat([df1, df2, df3], axis=0)
merged_df = merged_df.reset_index(drop=True)
merged_df
152/63:
merged_df = pd.concat([df1, df2, df3], axis=1)
merged_df = merged_df.reset_index(drop=True)
merged_df
152/64:
result2 = pd.merge(df1, df2, left_on='Student ID', right_on='SID')
result2
152/65:
df1 = pd.read_csv('data/grades2a.csv')
df1
152/66:
df2 = pd.read_csv('data/grades2b.csv')
df2
152/67:
result2 = pd.merge(df1, df2, left_on='Student ID', right_on='SID')
result2
152/68:
result = pd.concat([df1, df2, df3], axis=1)
result = merged_df.reset_index(drop=True)
152/69:
result = pd.concat([df1, df2, df3], axis=1)
result = merged_df.reset_index(drop=True)
result
152/70:
result3 = pd.merge(df1, df2, left_on='Student ID', right_on='SID')
result3
155/32:
df['Type_Combined'] = df['Type 1'] + ' ' + df['Type 2'].fillna('')
df.head(6)
155/33:
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
155/34:
df = pd.read_csv('https://github.com/firasm/bits/raw/master/pokemon.csv')
df
155/35:
df['HP'] = df['HP'].apply(lambda x: x**(1/3))
df.head(5)
155/36:
df['Temporary Health'] = df['HP'].apply(lambda x: x**3)
df['Temporary Attack'] = df['Attack'].apply(lambda x: x*2)
df.head(5)
155/37: df = pd.read_csv('https://github.com/firasm/bits/raw/master/pokemon.csv')
158/1:
df['Type_Combined'] = df['Type 1'] + ' ' + df['Type 2'].fillna('')
df.head(6)
158/2:
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
158/3:
df = pd.read_csv('https://github.com/firasm/bits/raw/master/pokemon.csv')
df
158/4:
df['HP'] = df['HP'].apply(lambda x: x**(1/3))
df.head(5)
158/5:
df['Temporary Health'] = df['HP'].apply(lambda x: x**3)
df['Temporary Attack'] = df['Attack'].apply(lambda x: x*2)
df.head(5)
158/6: df = pd.read_csv('https://github.com/firasm/bits/raw/master/pokemon.csv')
158/7:
df['Special_Power'] = df['Sp. Atk'] * df['Sp. Def']
df.head(5)
158/8:
df['Type_Combined'] = df['Type 1'] + ' ' + df['Type 2'].fillna('')
df.head(6)
158/9:
df['Type_Combined'] = df['Type 1']  + df['Type 2'].fillna('')
df.head(6)
158/10:
df['Type_Combined'] = df['Type 1']+ df['Type 2'].fillna('')
df.head(6)
158/11:
df['Type_Combined'] = df['Type 1'] + df['Type 2'].fillna('')
df.head(6)
162/1:
import pandas as pd
df1 = pd.read_csv('data/grades1a.csv')
df2 = pd.read_csv('data/grades1b.csv')
df3 = pd.read_csv('data/grades1c.csv')
df1
162/2: df2
162/3: df3
162/4:
result = pd.concat([df1, df2, df3], axis=1)
result = merged_df.reset_index(drop=True)
result
162/5:
df2 = pd.read_csv('data/grades2b.csv')
df2
162/6:
result2 = pd.merge(df1, df2, left_on='Student ID', right_on='SID')
result2
162/7:
result3 = pd.merge(df1, df2, left_on='Student ID', right_on='SID')
result3
162/8:
result = pd.concat([df1, df2, df3], axis=1)
result = result.reset_index(drop=True)
result
162/9:
result = pd.concat([df1, df2, df3], axis=0)
result = result.reset_index(drop=True)
result
162/10:
result = pd.concat([df1, df2, df3], axis=0)
result
162/11:
import pandas as pd
df1 = pd.read_csv('data/grades1a.csv')
df2 = pd.read_csv('data/grades1b.csv')
df3 = pd.read_csv('data/grades1c.csv')
df1
162/12: df2
162/13: df3
162/14:
import pandas as pd
df1 = pd.read_csv('data/grades1a.csv')
df2 = pd.read_csv('data/grades1b.csv')
df3 = pd.read_csv('data/grades1c.csv')
df1
162/15: df2
162/16: df3
162/17:
result = pd.merge([df1, df2, df3], axis=0)
result
162/18:
result = pd.merge([df1, df2, df3])
result
162/19:
result = pd.merge([df1, df2, df3] ,how = 'inner')
result
162/20:
result = pd.merge(left = df1,right = df2 ,how = 'inner' , on = ' Student ID')

result
162/21:
result = pd.merge(left = df1,right = df2 ,how = 'inner' , on = 'Student ID')

result
162/22:
result = pd.merge(left = df1,right = df2 ,how = 'inner' , on = 'Student ID')
result2 = pd.merge(left = result,right = df3 ,how = 'inner' , on = 'Student ID')
result2
162/23:
result = pd.merge(left = df1,right = df2 ,how = 'left' , on = 'Student ID')
result2 = pd.merge(left = result,right = df3 ,how = 'left' , on = 'Student ID')
result2
162/24:
result = pd.merge(left = df1,right = df2 ,how = 'left' , on = 'Student ID')
result
162/25:
result = pd.merge(left = df1,right = df3 ,how = 'left' , on = 'Student ID')
result
162/26:
result = pd.merge(left = df1,right = df2 ,how = 'inner' , on = 'Student ID')
result2 = pd.merge(left = result,right = df3 ,how = 'inner' , on = 'Student ID')
result3 = pd.concat([result,result2] , axis = 0)

result3
162/27:
result = pd.merge(left = df1,right = df2 ,how = 'inner' , on = 'Student ID')
result2 = pd.merge(left = df1,right = df3 ,how = 'inner' , on = 'Student ID')
result3 = pd.concat([result,result2] , axis = 0)
result3
162/28:
result = pd.merge(left = df1,right = df2 ,how = 'inner' , on = 'Student ID')
result2 = pd.merge(left = df1,right = df3 ,how = 'inner' , on = 'Student ID')
result3 = pd.concat([result,result2] , axis = 0)
result3.drop_duplicates()
162/29:
result = pd.merge(left = df1,right = df2 ,how = 'inner' , on = 'Student ID')
result2 = pd.merge(left = df1,right = df3 ,how = 'inner' , on = 'Student ID')
result3 = pd.concat([result,result2] , axis = 0)
result3.drop_duplicates().sort_values()
162/30:
result = pd.merge(left = df1,right = df2 ,how = 'inner' , on = 'Student ID')
result2 = pd.merge(left = df1,right = df3 ,how = 'inner' , on = 'Student ID')
result3 = pd.concat([result,result2] , axis = 0)
result3.drop_duplicates().sort_values(by = 'Student ID')
162/31:
result = pd.merge(left = df1,right = df2 ,how = 'inner' , on = 'Student ID')
result2 = pd.merge(left = df1,right = df3 ,how = 'inner' , on = 'Student ID')
result3 = pd.concat([result,result2] , axis = 0).reset_index()
result3.drop_duplicates().sort_values(by = 'Student ID')
162/32:
result = pd.merge(left = df1,right = df2 ,how = 'inner' , on = 'Student ID')
result2 = pd.merge(left = df1,right = df3 ,how = 'inner' , on = 'Student ID')
result3 = pd.concat([result,result2] , axis = 0)
result3.drop_duplicates().sort_values(by = 'Student ID').reset_index()
162/33:
result = pd.merge(left = df1,right = df2 ,how = 'inner' , on = 'Student ID')
result2 = pd.merge(left = df1,right = df3 ,how = 'inner' , on = 'Student ID')
result3 = pd.concat([result,result2] , axis = 0)
result3.drop_duplicates().sort_values(by = 'Student ID').reset_index(drop = True)
162/34:
result = pd.merge(left = df1,right = df2 ,how = 'inner' , on = 'Student ID')
result2 = pd.merge(left = df1,right = df3 ,how = 'inner' , on = 'Student ID')
result3 = pd.concat([result,result2] , axis = 0)
result3.drop_duplicates().sort_values(by = 'Student ID').reset_index(drop = True).loc[:,['Name' , 'Student ID' , 'Chemistry' , "Physics" , 'Math']
162/35:
result = pd.merge(left = df1,right = df2 ,how = 'inner' , on = 'Student ID')
result2 = pd.merge(left = df1,right = df3 ,how = 'inner' , on = 'Student ID')
result3 = pd.concat([result,result2] , axis = 0)
result3.drop_duplicates().sort_values(by = 'Student ID').reset_index(drop = True).loc[:,['Name' , 'Student ID' , 'Chemistry' , "Physics" , 'Math']]
162/36:
df1 = pd.read_csv('data/grades2a.csv')
df1
162/37:
df2 = pd.read_csv('data/grades2b.csv')
df2
162/38:
result2 = pd.merge(df1, df2, left_on='Student ID', right_on='SID' , how= 'inner' , copy = False)
result2
162/39:
result2 = pd.concat([df1, df2], how= 'inner' , copy = False)
result2
162/40:
result2 = pd.concat([df1, df2] , copy = False)
result2
162/41:
result2 = pd.concat([df1, df2] , axis = 0)
result2
162/42:
result2 = pd.concat([df1, df2.rename(columns = {'SID':'Student ID'})] , axis = 0)
result2
162/43:
result2 = pd.concat([df1, df2.rename(columns = {'SID':'Student ID'})] , axis = 0)
result2.drop_duplicates().sort_values(by = 'Student ID').reset_index(drop = True).loc[:,['Name' , 'Student ID' , 'Chemistry' , "Physics" , 'Math']]
162/44: result3 = pd.merge(df1, df2, left_on='Student ID', right_on='SID' , how = 'inner')
162/45:
result3 = pd.merge(df1, df2, left_on='Student ID', right_on='SID' , how = 'inner')
result3
167/1:
def avglist(lst, low=0, high=100):
    count = 0
    total = 0
    for num in lst:
        if low < num < high:
            count += 1
            total += num
    return total / count if count > 0 else 0
167/2:
lst1 = list(range(1, 11))
result1 = avglist(lst1)
print("Average of {} is: {}".format(lst1, result1))
167/3:
list1 = list(range(1, 11))
result1 = avglist(list1)
print("Average of list 1 is".format(lst1, result1))
167/4:
list1 = list(range(1, 11))
result1 = avglist(list1)
print("Average of list 1 is".format(list1, result1))
167/5:
list1 = list(range(1, 11))
result1 = avglist(list1)
print("Average of list 1 is".format(list1, result1))
167/6:
list1 = list(range(1, 11))
result1 = avglist(list1)
print("Average of list 1 is".format(list1, result1))
167/7:
def avglist(lst, low=0, high=100):
    count = 0
    total = 0
    for num in lst:
        if low < num < high:
            count += 1
            total += num
    return total / count if count > 0 else 0
167/8:
list1 = list(range(1, 11))
result1 = avglist(list1)
print("Average of list 1 is".format(list1, result1))
167/9:
list1 = list(range(1, 11))
result1 = avglist(list1)
print("Average of list 1 is".format(list1, result1))
167/10:
list1 = list(range(1, 11))
result1 = avglist(lst1)
print("Average of {} is: {}".format(lst1, result1))
167/11:
list1 = list(range(1, 11))
result1 = avglist(list1)
print("Average of {} is: {}".format(lst1, result1))
167/12:
list1 = list(range(1, 11))
result1 = avglist(list1)
print("Average of {} is: {}".format(list1, result1))
167/13:
list1 = list(range(1, 11))
result1 = avglist(list1)
print("Average of list1 is".format(list1, result1))
167/14:
list1 = list(range(1, 11))
result1 = avglist(list1)
print("Average of ".format(list1, result1))
167/15:
list1 = list(range(1, 11))
result1 = avglist(list1)
print("Average of {} is: {}".format(list1, result1))
167/16:
list1 = list(range(1, 11))
result1 = avglist(list1)
print("Average of list 1 is".format(result1))
167/17:
list1 = list(range(1, 11))
result1 = avglist(list1)
print("Average of list 1 is".(result1))
167/18:
list1 = list(range(1, 11))
result1 = avglist(list1)
print("Average of list 1 is".format(result1))
167/19:
list1 = list(range(1, 11))
result1 = avglist(list1)
print("Average of {} is: {}".format(list1, result1))
167/20:
list1 = list(range(1, 11))
result1 = avglist(list1)
print("Average of list 1 is: {}".format(list1, result1))
167/21:
list1 = list(range(1, 11))
result1 = avglist(list1)
print("Average of list 1 is: {}".format(result1))
167/22:
list2 = list(range(1, 101))
result2 = avglist(list2, 20, 80)
print("Average of {} in the range ({}, {}) is: {}".format(lst2, 20, 80, result2))
167/23:
list2 = list(range(1, 101))
result2 = avglist(list2, 20, 80)
print("Average of {} in the range ({}, {}) is: {}".format(list2, 20, 80, result2))
167/24:
list2 = list(range(1, 101))
result2 = avglist(list2, 20, 80)
print("Average of list2 in the range ({}, {}) is: {}".format(list2, 20, 80, result2))
167/25:
list2 = list(range(1, 101))
result2 = avglist(list2, 20, 80)
print("Average of list2 in the range ({}, {}) is: {}".format(20, 80, result2))
167/26:
list2 = list(range(1, 101))
result2 = avglist(list2, 20, 80)
print("Average of list2 with range ({}, {}) is: {}".format(20, 80, result2))
167/27:
lst3 = [random.randint(1, 100) for i in range(100)]
result3 = avglist(lst3, 30, 100)
print("Average of {} in the range ({}, {}) is: {}".format(lst3, 30, 100, result3))
167/28:
import random
list3 = [random.randint(1, 100) for i in range(100)]
result3 = avglist(list3, 30, 100)
print("Average of {} in the range ({}, {}) is: {}".format(list3, 30, 100, result3))
167/29:
import random
list3 = [random.randint(1, 100) for i in range(100)]
result3 = avglist(list3, 30, 100)
print("Average of list3 with range({}, {}) is: {}".format(list3, 30, 100, result3))
167/30:
import random
list3 = [random.randint(1, 100) for i in range(100)]
result3 = avglist(list3, 30, 100)
print("Average of list3 with range({}, {}) is: {}".format(30, 100, result3))
166/1:
def calc_tax(item_name, pre_tax_price):
    provincial_tax = round(pre_tax_price * 0.05, 2)
    federal_tax = round(pre_tax_price * 0.07, 2)
    total_price = round(pre_tax_price + provincial_tax + federal_tax, 2)

    print("Item: {}".format(item_name))
    print("Pre-tax price: ${:.2f}".format(pre_tax_price))
    print("Provincial tax (5%): ${:.2f}".format(provincial_tax))
    print("Federal tax (7%): ${:.2f}".format(federal_tax))
    print("Total price: ${:.2f}".format(total_price))

assert calc_tax("Book", 10.00) == None
assert calc_tax("Jacket", 50.00) == None
166/2:
def calc_tax(item_name, pre_tax_price):
    provincial_tax = round(pre_tax_price * 0.05, 2)
    federal_tax = round(pre_tax_price * 0.07, 2)
    total_price = round(pre_tax_price + provincial_tax + federal_tax, 2)

    print("Item: {}".format(item_name))
    print("Pre-tax price: ${:.2f}".format(pre_tax_price))
    print("Provincial tax (5%): ${:.2f}".format(provincial_tax))
    print("Federal tax (7%): ${:.2f}".format(federal_tax))
    print("Total price: ${:.2f}".format(total_price))

assert calc_tax("Book", 20.00) == None
assert calc_tax("Jacket", 50.00) == None
166/3:
def calc_tax(item_name, pre_tax_price):
    provincial_tax = round(pre_tax_price * 0.05, 2)
    federal_tax = round(pre_tax_price * 0.07, 2)
    total_price = round(pre_tax_price + provincial_tax + federal_tax, 2)

    print("Item: {}".format(item_name))
    print("Pre-tax price: ${:.2f}".format(pre_tax_price))
    print("Provincial tax (5%): ${:.2f}".format(provincial_tax))
    print("Federal tax (7%): ${:.2f}".format(federal_tax))
    print("Total price: ${:.2f}".format(total_price))

assert calc_tax("Book", 20.00) == None
166/4:
def calc_tax(item_name, pre_tax_price):
    provincial_tax = round(pre_tax_price * 0.05, 2)
    federal_tax = round(pre_tax_price * 0.07, 2)
    total_price = round(pre_tax_price + provincial_tax + federal_tax, 2)

    print("Item: {}".format(item_name))
    print("Pre-tax price: ${:.2f}".format(pre_tax_price))
    print("Provincial tax (5%): ${:.2f}".format(provincial_tax))
    print("Federal tax (7%): ${:.2f}".format(federal_tax))
    print("Total price: ${:.2f}".format(total_price))

assert calc_tax("Jordans", 180.00) == None
166/5:
def calc_tax(item_name, pre_tax_price):
    provincial_tax = round(pre_tax_price * 0.05, 2)
    federal_tax = round(pre_tax_price * 0.07, 2)
    total_price = round(pre_tax_price + provincial_tax + federal_tax, 2)

    print("Item: {}".format(item_name))
    print("Pre-tax price: ${:.2f}".format(pre_tax_price))
    print("Provincial tax (5%): ${:.2f}".format(provincial_tax))
    print("Federal tax (7%): ${:.2f}".format(federal_tax))
    print("Total price: ${:.2f}".format(total_price))

assert calc_tax("Jordans", 180.00) == None
assert calc_tax("Hoodie", 380.00) == None
166/6:
assert calc_tax("Jordans", 180.00) == None
assert calc_tax("Hoodie", 380.00) == None
166/7:
def calc_tax(item_name, pre_tax_price):
    provincial_tax = round(pre_tax_price * 0.05, 2)
    federal_tax = round(pre_tax_price * 0.07, 2)
    total_price = round(pre_tax_price + provincial_tax + federal_tax, 2)

    print("Item: {}".format(item_name))
    print("Pre-tax price: ${:.2f}".format(pre_tax_price))
    print("Provincial tax (5%): ${:.2f}".format(provincial_tax))
    print("Federal tax (7%): ${:.2f}".format(federal_tax))
    print("Total price: ${:.2f}".format(total_price))
166/8:
assert calc_tax("Jordans", 180.00) == None
assert calc_tax("Hoodie", 380.00) == None
166/9:
def calc_tax(item_name, pre_tax_price):
    provincial_tax = round(pre_tax_price * 0.05, 2)
    federal_tax = round(pre_tax_price * 0.07, 2)
    total_price = round(pre_tax_price + provincial_tax + federal_tax, 2)

    print((item_name))
    print("Pre-tax price: ${:.2f}".format(pre_tax_price))
    print("Provincial tax (5%): ${:.2f}".format(provincial_tax))
    print("Federal tax (7%): ${:.2f}".format(federal_tax))
    print("Total price: ${:.2f}".format(total_price))
166/10:
def calc_tax(item_name, pre_tax_price):
    provincial_tax = round(pre_tax_price * 0.05, 2)
    federal_tax = round(pre_tax_price * 0.07, 2)
    total_price = round(pre_tax_price + provincial_tax + federal_tax, 2)

    print((item_name))
    print("Pre-tax price: ${:.2f}".format(pre_tax_price))
    print("Provincial tax (5%): ${:.2f}".format(provincial_tax))
    print("Federal tax (7%): ${:.2f}".format(federal_tax))
    print("Total price: ${:.2f}".format(total_price))
166/11:
assert calc_tax("Jordans", 180.00) == None
assert calc_tax("Hoodie", 380.00) == None
166/12:
def calc_tax(item_name, pre_tax_price):
    provincial_tax = round(pre_tax_price * 0.05, 2)
    federal_tax = round(pre_tax_price * 0.07, 2)
    total_price = round(pre_tax_price + provincial_tax + federal_tax, 2)

    print((item_name))
    print("Pre-tax price of: ${:.2f}".format(pre_tax_price))
    print("Provincial tax : ${:.2f}".format(provincial_tax))
    print("Federal tax (7%): ${:.2f}".format(federal_tax))
    print("Total price: ${:.2f}".format(total_price))
166/13:
assert calc_tax("Jordans", 180.00) == None
assert calc_tax("Hoodie", 380.00) == None
166/14:
def calc_tax(item_name, pre_tax_price):
    provincial_tax = round(pre_tax_price * 0.05, 2)
    federal_tax = round(pre_tax_price * 0.07, 2)
    total_price = round(pre_tax_price + provincial_tax + federal_tax, 2)

    print((item_name))
    print("Pre-tax price of: ${:.2f}".format(pre_tax_price))
    print("Provincial tax : ${:.2f}".format(provincial_tax))
    print("Federal tax : ${:.2f}".format(federal_tax))
    print("Total price: ${:.2f}".format(total_price))
166/15:
def calc_tax(item_name, pre_tax_price):
    provincial_tax = round(pre_tax_price * 0.05, 2)
    federal_tax = round(pre_tax_price * 0.07, 2)
    total_price = round(pre_tax_price + provincial_tax + federal_tax, 2)

    print((item_name))
    print("Pre-tax price of: ${:.2f}".format(pre_tax_price))
    print("Provincial tax : ${:.2f}".format(provincial_tax))
    print("Federal tax : ${:.2f}".format(federal_tax))
    print("Total price of: ${:.2f}".format(total_price))
166/16:
assert calc_tax("Jordans", 180.00) == None
assert calc_tax("Hoodie", 380.00) == None
166/17:
assert calc_tax("Jordans", 180.00) == None

assert calc_tax("Hoodie", 380.00) == None
166/18:
assert calc_tax("Jordans", 180.00) == None
#
assert calc_tax("Hoodie", 380.00) == None
166/19:
assert calc_tax("Jordans", 180.00) == None
---
assert calc_tax("Hoodie", 380.00) == None
166/20:
assert calc_tax("Jordans", 180.00) == None
assert calc_tax("Hoodie", 380.00) == None
166/21:
assert calc_tax("Jordans", 180.00) == None
print("--------')
assert calc_tax("Hoodie", 380.00) == None
166/22:
assert calc_tax("Jordans", 180.00) == None
print("--------")
assert calc_tax("Hoodie", 380.00) == None
166/23:
assert calc_tax("Jordans", 180.00) == None
print("------------------")
assert calc_tax("Hoodie", 380.00) == None
166/24:
assert calc_tax("Jordans", 180.00) == None
print("-----------------------")
assert calc_tax("Hoodie", 380.00) == None
166/25:
assert calc_tax("Jordans", 180.00) == None
print("-----------------------")
assert calc_tax("Hoodie", 380.00) == None
print("-----------------------")
assert calc_tax("PS5", 500.00) == None
164/1: import math
164/2:
def solution(a, b, c):
    discriminant = b**2 - 4*a*c

    # Check if discriminant is negative (i.e. complex roots)
    if discriminant < 0:
        print("No real solutions")
    else:
        # Calculate and print real roots
        root1 = (-b + math.sqrt(discriminant)) / (2*a)
        root2 = (-b - math.sqrt(discriminant)) / (2*a)
        print("Real roots:")
        print("x = {:.2f}".format(root1))
        print("x = {:.2f}".format(root2))
164/3: solution(1,1,1)
164/4: solution(1,0,-4)
164/5: solution(1,2,1)
164/6:
def solution(a, b, c):
    discriminant = b**2 - 4*a*c
    if discriminant < 0:
        print("The equation does not have any real solution")
    else:
        # Calculate and print real roots
        root1 = (-b + math.sqrt(discriminant)) / (2*a)
        root2 = (-b - math.sqrt(discriminant)) / (2*a)
        print("Real roots:")
        print("x = {:.2f}".format(root1))
        print("x = {:.2f}".format(root2))
164/7: solution(1,1,1)
164/8: solution(1,0,-4)
164/9:
def solution(a, b, c):
    discriminant = b**2 - 4*a*c
    if discriminant < 0:
        print("The equation does not have any real solution")
    else:
        # Calculate and print real roots
        root1 = (-b + math.sqrt(discriminant)) / (2*a)
        root2 = (-b - math.sqrt(discriminant)) / (2*a)
       print("For a={}, b={}, and c={}: x1 = {} and x2 = {}".format(a, b, c, x1, x2))
164/11:
def solution(a, b, c):
    discriminant = b**2 - 4*a*c
    if discriminant < 0:
        print("The equation does not have any real solution")
    else:
        # Calculate and print real roots
        root1 = (-b + math.sqrt(discriminant)) / (2*a)
        root2 = (-b - math.sqrt(discriminant)) / (2*a)
        print("For a={}, b={}, and c={}: x1 = {} and x2 = {}".format(a, b, c, x1, x2))
164/12: solution(1,1,1)
164/13: solution(1,0,-4)
164/14:
def solution(a, b, c):
    discriminant = b**2 - 4*a*c
    if discriminant < 0:
        print("The equation does not have any real solution")
    else:
        # Calculate and print real roots
        root1 = (-b + math.sqrt(discriminant)) / (2*a)
        root2 = (-b - math.sqrt(discriminant)) / (2*a)
        print("For a={}, b={}, and c={}: x1 = {} and x2 = {}".format(a, b, c))
164/15: solution(1,1,1)
164/16: solution(1,0,-4)
164/17:
def solution(a, b, c):
    discriminant = b**2 - 4*a*c
    if discriminant < 0:
        print("The equation does not have any real solution")
    else:
        # Calculate and print real roots
        root1 = (-b + math.sqrt(discriminant)) / (2*a)
        root2 = (-b - math.sqrt(discriminant)) / (2*a)
        print("For a={}, b={}, and c={}: root1 = {} and root2 = {}".format(a, b, c ,root1 ,root2))
164/18: solution(1,1,1)
164/19: solution(1,0,-4)
164/20: solution(1,2,1)
164/21:
def solution(a, b, c):
    discriminant = b**2 - 4*a*c
    if discriminant < 0:
        print("The equation does not have any real solution")
    else:
        # Calculate and print real roots
        root1 = (-b + math.sqrt(discriminant)) / (2*a)
        root2 = (-b - math.sqrt(discriminant)) / (2*a)
        print("For a={}, b={}, and c={}: x1 = {} and x2 = {}".format(a, b, c ,x1 ,x2))
164/22: solution(1,1,1)
164/23: solution(1,0,-4)
164/24: solution(1,2,1)
164/25:
def solution(a, b, c):
    discriminant = b**2 - 4*a*c
    if discriminant < 0:
        print("The equation does not have any real solution")
    else:
        # Calculate and print real roots
        x1 = (-b + math.sqrt(discriminant)) / (2*a)
        x2 = (-b - math.sqrt(discriminant)) / (2*a)
        print("For a={}, b={}, and c={}: x1 = {} and x2 = {}".format(a, b, c ,x1 ,x2))
164/26: solution(1,1,1)
164/27: solution(1,0,-4)
164/28: solution(1,2,1)
165/1:
text = """Elephants are mammals of the family Elephantidae and the largest existing land animals. Three species are currently recognised: the African bush elephant, the African forest elephant, and the Asian elephant. Elephantidae is the only surviving family of the order Proboscidea; extinct members include the mastodons. The family Elephantidae also contains several now-extinct groups, including the mammoths and straight-tusked elephants. African elephants have larger ears and concave backs, whereas Asian elephants have smaller ears, and convex or level backs. Distinctive features of all elephants include a long trunk, tusks, large ear flaps, massive legs, and tough but sensitive skin. The trunk, also called a proboscis, is used for breathing, bringing food and water to the mouth, and grasping objects. Tusks, which are derived from the incisor teeth, serve both as weapons and as tools for moving objects and digging. The large ear flaps assist in maintaining a constant body temperature as well as in communication. The pillar-like legs carry their great weight. Elephants are scattered throughout sub-Saharan Africa, South Asia, and Southeast Asia and are found in different habitats, including savannahs, forests, deserts, and marshes. They are herbivorous, and they stay near water when it is accessible. They are considered to be keystone species, due to their impact on their environments.[1] Other animals tend to keep their distance from elephants; the exception is their predators such as lions, tigers, hyenas, and wild dogs, which usually target only young elephants (calves). Elephants have a fission–fusion society, in which multiple family groups come together to socialise. Females (cows) tend to live in family groups, which can consist of one female with her calves or several related females with offspring. The groups, which do not include bulls, are led by the (usually) oldest cow, known as the matriarch."""

def character_frequency(text):
    import collections
    unique_chars = set(text)
    counter_chars = collections.Counter(text)
    result = []
    total_characters = len(text)
    
    # loop through each character and compute its frequency in terms of count and percentage
    for char in unique_chars:
        count = counter_chars[char]
        percentage = round(count/total_characters * 100, 1)
        result.append((char, count, percentage))
        
    return result
165/2:
text = """Elephants are mammals of the family Elephantidae and the largest existing land animals. Three species are currently recognised: the African bush elephant, the African forest elephant, and the Asian elephant. Elephantidae is the only surviving family of the order Proboscidea; extinct members include the mastodons. The family Elephantidae also contains several now-extinct groups, including the mammoths and straight-tusked elephants. African elephants have larger ears and concave backs, whereas Asian elephants have smaller ears, and convex or level backs. Distinctive features of all elephants include a long trunk, tusks, large ear flaps, massive legs, and tough but sensitive skin. The trunk, also called a proboscis, is used for breathing, bringing food and water to the mouth, and grasping objects. Tusks, which are derived from the incisor teeth, serve both as weapons and as tools for moving objects and digging. The large ear flaps assist in maintaining a constant body temperature as well as in communication. The pillar-like legs carry their great weight. Elephants are scattered throughout sub-Saharan Africa, South Asia, and Southeast Asia and are found in different habitats, including savannahs, forests, deserts, and marshes. They are herbivorous, and they stay near water when it is accessible. They are considered to be keystone species, due to their impact on their environments.[1] Other animals tend to keep their distance from elephants; the exception is their predators such as lions, tigers, hyenas, and wild dogs, which usually target only young elephants (calves). Elephants have a fission–fusion society, in which multiple family groups come together to socialise. Females (cows) tend to live in family groups, which can consist of one female with her calves or several related females with offspring. The groups, which do not include bulls, are led by the (usually) oldest cow, known as the matriarch."""

def character_frequency(text):
    import collections
    unique_chars = set(text)
    counter_chars = collections.Counter(text)
    result = []
    total_characters = len(text)
    
    for char in unique_chars:
        count = counter_chars[char]
        percentage = round(count/total_characters * 100, 1)
        result.append((char, count, percentage))
        
    return result
165/3:
text = """Elephants are mammals of the family Elephantidae and the largest existing land animals. Three species are currently recognised: the African bush elephant, the African forest elephant, and the Asian elephant. Elephantidae is the only surviving family of the order Proboscidea; extinct members include the mastodons. The family Elephantidae also contains several now-extinct groups, including the mammoths and straight-tusked elephants. African elephants have larger ears and concave backs, whereas Asian elephants have smaller ears, and convex or level backs. Distinctive features of all elephants include a long trunk, tusks, large ear flaps, massive legs, and tough but sensitive skin. The trunk, also called a proboscis, is used for breathing, bringing food and water to the mouth, and grasping objects. Tusks, which are derived from the incisor teeth, serve both as weapons and as tools for moving objects and digging. The large ear flaps assist in maintaining a constant body temperature as well as in communication. The pillar-like legs carry their great weight. Elephants are scattered throughout sub-Saharan Africa, South Asia, and Southeast Asia and are found in different habitats, including savannahs, forests, deserts, and marshes. They are herbivorous, and they stay near water when it is accessible. They are considered to be keystone species, due to their impact on their environments.[1] Other animals tend to keep their distance from elephants; the exception is their predators such as lions, tigers, hyenas, and wild dogs, which usually target only young elephants (calves). Elephants have a fission–fusion society, in which multiple family groups come together to socialise. Females (cows) tend to live in family groups, which can consist of one female with her calves or several related females with offspring. The groups, which do not include bulls, are led by the (usually) oldest cow, known as the matriarch."""

def character_frequency(text):
    import collections
    unique_chars = set(text)
    counter_chars = collections.Counter(text)
    result = []
    total_characters = len(text)
    
    for char in unique_chars:
        count = counter_chars[char]
        percentage = round(count/total_characters * 100, 1)
        result.append((char, count, percentage))
        
    return result
168/1: import os
168/2: ListFiles("/Users/poojalal/Desktop/DATA301/lab08-DARTH-LAL")
168/3:
def ListFiles(/Users/poojalal/Desktop/DATA301/lab08-DARTH-LAL):
for filename in os.listdir(directory_path):
        filepath = os.path.join(directory_path, filename)
        if os.path.isfile(filepath):
            print(filepath)
168/4: import os
168/5:
def ListFiles(Users/poojalal/Desktop/DATA301/lab08-DARTH-LAL):
for filename in os.listdir(directory_path):
        filepath = os.path.join(directory_path, filename)
        if os.path.isfile(filepath):
            print(filepath)
168/6:
def ListFiles(/directory_listL):
for filename in os.listdir(directory_path):
        filepath = os.path.join(directory_path, filename)
        if os.path.isfile(filepath):
            print(filepath)
168/7:
def ListFiles("/directory_listL"):
for filename in os.listdir(directory_path):
        filepath = os.path.join(directory_path, filename)
        if os.path.isfile(filepath):
            print(filepath)
168/8:
def ListFiles("/directory_listL"):
for filename in os.listdir(directory_path):
        filepath = os.path.join(directory_path, filename)
        if os.path.isfile(filepath):
            print(filepath)
168/9: def ListFiles(address):
165/4:
text = """Elephants are mammals of the family Elephantidae and the largest existing land animals. Three species are currently recognised: the African bush elephant, the African forest elephant, and the Asian elephant. Elephantidae is the only surviving family of the order Proboscidea; extinct members include the mastodons. The family Elephantidae also contains several now-extinct groups, including the mammoths and straight-tusked elephants. African elephants have larger ears and concave backs, whereas Asian elephants have smaller ears, and convex or level backs. Distinctive features of all elephants include a long trunk, tusks, large ear flaps, massive legs, and tough but sensitive skin. The trunk, also called a proboscis, is used for breathing, bringing food and water to the mouth, and grasping objects. Tusks, which are derived from the incisor teeth, serve both as weapons and as tools for moving objects and digging. The large ear flaps assist in maintaining a constant body temperature as well as in communication. The pillar-like legs carry their great weight. Elephants are scattered throughout sub-Saharan Africa, South Asia, and Southeast Asia and are found in different habitats, including savannahs, forests, deserts, and marshes. They are herbivorous, and they stay near water when it is accessible. They are considered to be keystone species, due to their impact on their environments.[1] Other animals tend to keep their distance from elephants; the exception is their predators such as lions, tigers, hyenas, and wild dogs, which usually target only young elephants (calves). Elephants have a fission–fusion society, in which multiple family groups come together to socialise. Females (cows) tend to live in family groups, which can consist of one female with her calves or several related females with offspring. The groups, which do not include bulls, are led by the (usually) oldest cow, known as the matriarch."""

def character_frequency(text):
 char_count = Counter(text)

    # Getting the total number of characters in the text
    total_chars = sum(char_count.values())

    # Looping through each unique character and printing out its count and percentage
    for char in set(text):
        count = char_count[char]
        percentage = (count / total_chars) * 100
        print(f"'{char}': Count of {count} and Percentage of {percentage:.1f}%")
        
calculate_char_frequency(text)
165/5:
text = """Elephants are mammals of the family Elephantidae and the largest existing land animals. Three species are currently recognised: the African bush elephant, the African forest elephant, and the Asian elephant. Elephantidae is the only surviving family of the order Proboscidea; extinct members include the mastodons. The family Elephantidae also contains several now-extinct groups, including the mammoths and straight-tusked elephants. African elephants have larger ears and concave backs, whereas Asian elephants have smaller ears, and convex or level backs. Distinctive features of all elephants include a long trunk, tusks, large ear flaps, massive legs, and tough but sensitive skin. The trunk, also called a proboscis, is used for breathing, bringing food and water to the mouth, and grasping objects. Tusks, which are derived from the incisor teeth, serve both as weapons and as tools for moving objects and digging. The large ear flaps assist in maintaining a constant body temperature as well as in communication. The pillar-like legs carry their great weight. Elephants are scattered throughout sub-Saharan Africa, South Asia, and Southeast Asia and are found in different habitats, including savannahs, forests, deserts, and marshes. They are herbivorous, and they stay near water when it is accessible. They are considered to be keystone species, due to their impact on their environments.[1] Other animals tend to keep their distance from elephants; the exception is their predators such as lions, tigers, hyenas, and wild dogs, which usually target only young elephants (calves). Elephants have a fission–fusion society, in which multiple family groups come together to socialise. Females (cows) tend to live in family groups, which can consist of one female with her calves or several related females with offspring. The groups, which do not include bulls, are led by the (usually) oldest cow, known as the matriarch."""

def character_frequency(text):
 char_count = Counter(text)
    total_chars = sum(char_count.values())

    # Looping through each unique character and printing out its count and percentage
    for char in set(text):
        count = char_count[char]
        percentage = (count / total_chars) * 100
        print(f"'{char}': Count of {count} and Percentage of {percentage:.1f}%")
        
calculate_char_frequency(text)
165/6:
text = """Elephants are mammals of the family Elephantidae and the largest existing land animals. Three species are currently recognised: the African bush elephant, the African forest elephant, and the Asian elephant. Elephantidae is the only surviving family of the order Proboscidea; extinct members include the mastodons. The family Elephantidae also contains several now-extinct groups, including the mammoths and straight-tusked elephants. African elephants have larger ears and concave backs, whereas Asian elephants have smaller ears, and convex or level backs. Distinctive features of all elephants include a long trunk, tusks, large ear flaps, massive legs, and tough but sensitive skin. The trunk, also called a proboscis, is used for breathing, bringing food and water to the mouth, and grasping objects. Tusks, which are derived from the incisor teeth, serve both as weapons and as tools for moving objects and digging. The large ear flaps assist in maintaining a constant body temperature as well as in communication. The pillar-like legs carry their great weight. Elephants are scattered throughout sub-Saharan Africa, South Asia, and Southeast Asia and are found in different habitats, including savannahs, forests, deserts, and marshes. They are herbivorous, and they stay near water when it is accessible. They are considered to be keystone species, due to their impact on their environments.[1] Other animals tend to keep their distance from elephants; the exception is their predators such as lions, tigers, hyenas, and wild dogs, which usually target only young elephants (calves). Elephants have a fission–fusion society, in which multiple family groups come together to socialise. Females (cows) tend to live in family groups, which can consist of one female with her calves or several related females with offspring. The groups, which do not include bulls, are led by the (usually) oldest cow, known as the matriarch."""

def character_frequency(text):
char_count = Counter(text)
 total_chars = sum(char_count.values())

    # Looping through each unique character and printing out its count and percentage
    for char in set(text):
        count = char_count[char]
        percentage = (count / total_chars) * 100
        print(f"'{char}': Count of {count} and Percentage of {percentage:.1f}%")
        
calculate_char_frequency(text)
165/7:
text = """Elephants are mammals of the family Elephantidae and the largest existing land animals. Three species are currently recognised: the African bush elephant, the African forest elephant, and the Asian elephant. Elephantidae is the only surviving family of the order Proboscidea; extinct members include the mastodons. The family Elephantidae also contains several now-extinct groups, including the mammoths and straight-tusked elephants. African elephants have larger ears and concave backs, whereas Asian elephants have smaller ears, and convex or level backs. Distinctive features of all elephants include a long trunk, tusks, large ear flaps, massive legs, and tough but sensitive skin. The trunk, also called a proboscis, is used for breathing, bringing food and water to the mouth, and grasping objects. Tusks, which are derived from the incisor teeth, serve both as weapons and as tools for moving objects and digging. The large ear flaps assist in maintaining a constant body temperature as well as in communication. The pillar-like legs carry their great weight. Elephants are scattered throughout sub-Saharan Africa, South Asia, and Southeast Asia and are found in different habitats, including savannahs, forests, deserts, and marshes. They are herbivorous, and they stay near water when it is accessible. They are considered to be keystone species, due to their impact on their environments.[1] Other animals tend to keep their distance from elephants; the exception is their predators such as lions, tigers, hyenas, and wild dogs, which usually target only young elephants (calves). Elephants have a fission–fusion society, in which multiple family groups come together to socialise. Females (cows) tend to live in family groups, which can consist of one female with her calves or several related females with offspring. The groups, which do not include bulls, are led by the (usually) oldest cow, known as the matriarch."""

def character_frequency(text):
char_count = Counter(text)
total_chars = sum(char_count.values())

    # Looping through each unique character and printing out its count and percentage
    for char in set(text):
        count = char_count[char]
        percentage = (count / total_chars) * 100
        print(f"'{char}': Count of {count} and Percentage of {percentage:.1f}%")
        
calculate_char_frequency(text)
165/8:
text = """Elephants are mammals of the family Elephantidae and the largest existing land animals. Three species are currently recognised: the African bush elephant, the African forest elephant, and the Asian elephant. Elephantidae is the only surviving family of the order Proboscidea; extinct members include the mastodons. The family Elephantidae also contains several now-extinct groups, including the mammoths and straight-tusked elephants. African elephants have larger ears and concave backs, whereas Asian elephants have smaller ears, and convex or level backs. Distinctive features of all elephants include a long trunk, tusks, large ear flaps, massive legs, and tough but sensitive skin. The trunk, also called a proboscis, is used for breathing, bringing food and water to the mouth, and grasping objects. Tusks, which are derived from the incisor teeth, serve both as weapons and as tools for moving objects and digging. The large ear flaps assist in maintaining a constant body temperature as well as in communication. The pillar-like legs carry their great weight. Elephants are scattered throughout sub-Saharan Africa, South Asia, and Southeast Asia and are found in different habitats, including savannahs, forests, deserts, and marshes. They are herbivorous, and they stay near water when it is accessible. They are considered to be keystone species, due to their impact on their environments.[1] Other animals tend to keep their distance from elephants; the exception is their predators such as lions, tigers, hyenas, and wild dogs, which usually target only young elephants (calves). Elephants have a fission–fusion society, in which multiple family groups come together to socialise. Females (cows) tend to live in family groups, which can consist of one female with her calves or several related females with offspring. The groups, which do not include bulls, are led by the (usually) oldest cow, known as the matriarch."""

def character_frequency(text): 
    char_count = Counter(text)
total_chars = sum(char_count.values())

    # Looping through each unique character and printing out its count and percentage
    for char in set(text):
        count = char_count[char]
        percentage = (count / total_chars) * 100
        print(f"'{char}': Count of {count} and Percentage of {percentage:.1f}%")
        
calculate_char_frequency(text)
165/9:
text = """Elephants are mammals of the family Elephantidae and the largest existing land animals. Three species are currently recognised: the African bush elephant, the African forest elephant, and the Asian elephant. Elephantidae is the only surviving family of the order Proboscidea; extinct members include the mastodons. The family Elephantidae also contains several now-extinct groups, including the mammoths and straight-tusked elephants. African elephants have larger ears and concave backs, whereas Asian elephants have smaller ears, and convex or level backs. Distinctive features of all elephants include a long trunk, tusks, large ear flaps, massive legs, and tough but sensitive skin. The trunk, also called a proboscis, is used for breathing, bringing food and water to the mouth, and grasping objects. Tusks, which are derived from the incisor teeth, serve both as weapons and as tools for moving objects and digging. The large ear flaps assist in maintaining a constant body temperature as well as in communication. The pillar-like legs carry their great weight. Elephants are scattered throughout sub-Saharan Africa, South Asia, and Southeast Asia and are found in different habitats, including savannahs, forests, deserts, and marshes. They are herbivorous, and they stay near water when it is accessible. They are considered to be keystone species, due to their impact on their environments.[1] Other animals tend to keep their distance from elephants; the exception is their predators such as lions, tigers, hyenas, and wild dogs, which usually target only young elephants (calves). Elephants have a fission–fusion society, in which multiple family groups come together to socialise. Females (cows) tend to live in family groups, which can consist of one female with her calves or several related females with offspring. The groups, which do not include bulls, are led by the (usually) oldest cow, known as the matriarch."""

def character_frequency(text): 
    char_count = Counter(text)
total_chars = sum(char_count.values())

    for char in set(text):
        count = char_count[char]
        percentage = (count / total_chars) * 100
        print(f"'{char}': Count of {count} and Percentage of {percentage:.1f}%")
        
calculate_char_frequency(text)
165/10:
text = """Elephants are mammals of the family Elephantidae and the largest existing land animals. Three species are currently recognised: the African bush elephant, the African forest elephant, and the Asian elephant. Elephantidae is the only surviving family of the order Proboscidea; extinct members include the mastodons. The family Elephantidae also contains several now-extinct groups, including the mammoths and straight-tusked elephants. African elephants have larger ears and concave backs, whereas Asian elephants have smaller ears, and convex or level backs. Distinctive features of all elephants include a long trunk, tusks, large ear flaps, massive legs, and tough but sensitive skin. The trunk, also called a proboscis, is used for breathing, bringing food and water to the mouth, and grasping objects. Tusks, which are derived from the incisor teeth, serve both as weapons and as tools for moving objects and digging. The large ear flaps assist in maintaining a constant body temperature as well as in communication. The pillar-like legs carry their great weight. Elephants are scattered throughout sub-Saharan Africa, South Asia, and Southeast Asia and are found in different habitats, including savannahs, forests, deserts, and marshes. They are herbivorous, and they stay near water when it is accessible. They are considered to be keystone species, due to their impact on their environments.[1] Other animals tend to keep their distance from elephants; the exception is their predators such as lions, tigers, hyenas, and wild dogs, which usually target only young elephants (calves). Elephants have a fission–fusion society, in which multiple family groups come together to socialise. Females (cows) tend to live in family groups, which can consist of one female with her calves or several related females with offspring. The groups, which do not include bulls, are led by the (usually) oldest cow, known as the matriarch."""

def character_frequency(text): 
    char_count = Counter(text)
total_chars = sum(char_count.values())
    for char in set(text):
        count = char_count[char]
        percentage = (count / total_chars) * 100
        print(f"'{char}': Count of {count} and Percentage of {percentage:.1f}%")
        
calculate_char_frequency(text)
165/11:
text = """Elephants are mammals of the family Elephantidae and the largest existing land animals. Three species are currently recognised: the African bush elephant, the African forest elephant, and the Asian elephant. Elephantidae is the only surviving family of the order Proboscidea; extinct members include the mastodons. The family Elephantidae also contains several now-extinct groups, including the mammoths and straight-tusked elephants. African elephants have larger ears and concave backs, whereas Asian elephants have smaller ears, and convex or level backs. Distinctive features of all elephants include a long trunk, tusks, large ear flaps, massive legs, and tough but sensitive skin. The trunk, also called a proboscis, is used for breathing, bringing food and water to the mouth, and grasping objects. Tusks, which are derived from the incisor teeth, serve both as weapons and as tools for moving objects and digging. The large ear flaps assist in maintaining a constant body temperature as well as in communication. The pillar-like legs carry their great weight. Elephants are scattered throughout sub-Saharan Africa, South Asia, and Southeast Asia and are found in different habitats, including savannahs, forests, deserts, and marshes. They are herbivorous, and they stay near water when it is accessible. They are considered to be keystone species, due to their impact on their environments.[1] Other animals tend to keep their distance from elephants; the exception is their predators such as lions, tigers, hyenas, and wild dogs, which usually target only young elephants (calves). Elephants have a fission–fusion society, in which multiple family groups come together to socialise. Females (cows) tend to live in family groups, which can consist of one female with her calves or several related females with offspring. The groups, which do not include bulls, are led by the (usually) oldest cow, known as the matriarch."""

def character_frequency(text): 
    char_count = Counter(text)
total_chars = sum(char_count.values())
for char in set(text):
        count = char_count[char]
        percentage = (count / total_chars) * 100
        print(f"'{char}': Count of {count} and Percentage of {percentage:.1f}%")
        
calculate_char_frequency(text)
165/12:
text = """Elephants are mammals of the family Elephantidae and the largest existing land animals. Three species are currently recognised: the African bush elephant, the African forest elephant, and the Asian elephant. Elephantidae is the only surviving family of the order Proboscidea; extinct members include the mastodons. The family Elephantidae also contains several now-extinct groups, including the mammoths and straight-tusked elephants. African elephants have larger ears and concave backs, whereas Asian elephants have smaller ears, and convex or level backs. Distinctive features of all elephants include a long trunk, tusks, large ear flaps, massive legs, and tough but sensitive skin. The trunk, also called a proboscis, is used for breathing, bringing food and water to the mouth, and grasping objects. Tusks, which are derived from the incisor teeth, serve both as weapons and as tools for moving objects and digging. The large ear flaps assist in maintaining a constant body temperature as well as in communication. The pillar-like legs carry their great weight. Elephants are scattered throughout sub-Saharan Africa, South Asia, and Southeast Asia and are found in different habitats, including savannahs, forests, deserts, and marshes. They are herbivorous, and they stay near water when it is accessible. They are considered to be keystone species, due to their impact on their environments.[1] Other animals tend to keep their distance from elephants; the exception is their predators such as lions, tigers, hyenas, and wild dogs, which usually target only young elephants (calves). Elephants have a fission–fusion society, in which multiple family groups come together to socialise. Females (cows) tend to live in family groups, which can consist of one female with her calves or several related females with offspring. The groups, which do not include bulls, are led by the (usually) oldest cow, known as the matriarch."""

def character_frequency(text): 
    char_count = Counter(text)
    total_chars = sum(char_count.values())
    for char in set(text):
        count = char_count[char]
        percentage = (count / total_chars) * 100
        print(f"'{char}': Count of {count} and Percentage of {percentage:.1f}%")
        
calculate_char_frequency(text)
165/13:
text = """Elephants are mammals of the family Elephantidae and the largest existing land animals. Three species are currently recognised: the African bush elephant, the African forest elephant, and the Asian elephant. Elephantidae is the only surviving family of the order Proboscidea; extinct members include the mastodons. The family Elephantidae also contains several now-extinct groups, including the mammoths and straight-tusked elephants. African elephants have larger ears and concave backs, whereas Asian elephants have smaller ears, and convex or level backs. Distinctive features of all elephants include a long trunk, tusks, large ear flaps, massive legs, and tough but sensitive skin. The trunk, also called a proboscis, is used for breathing, bringing food and water to the mouth, and grasping objects. Tusks, which are derived from the incisor teeth, serve both as weapons and as tools for moving objects and digging. The large ear flaps assist in maintaining a constant body temperature as well as in communication. The pillar-like legs carry their great weight. Elephants are scattered throughout sub-Saharan Africa, South Asia, and Southeast Asia and are found in different habitats, including savannahs, forests, deserts, and marshes. They are herbivorous, and they stay near water when it is accessible. They are considered to be keystone species, due to their impact on their environments.[1] Other animals tend to keep their distance from elephants; the exception is their predators such as lions, tigers, hyenas, and wild dogs, which usually target only young elephants (calves). Elephants have a fission–fusion society, in which multiple family groups come together to socialise. Females (cows) tend to live in family groups, which can consist of one female with her calves or several related females with offspring. The groups, which do not include bulls, are led by the (usually) oldest cow, known as the matriarch."""

def character_frequency(text): 
    char_count = Counter(text)
    total_chars = sum(char_count.values())
    for char in set(text):
        count = char_count[char]
        percentage = (count / total_chars) * 100
        print(f"'{char}': Count of {count} and Percentage of {percentage:.1f}%")
        
calculate_char_frequency(text)
165/14:
from collections import Counter

text = """Elephants are mammals of the family Elephantidae and the largest existing land animals. Three species are currently recognised: the African bush elephant, the African forest elephant, and the Asian elephant. Elephantidae is the only surviving family of the order Proboscidea; extinct members include the mastodons. The family Elephantidae also contains several now-extinct groups, including the mammoths and straight-tusked elephants. African elephants have larger ears and concave backs, whereas Asian elephants have smaller ears, and convex or level backs. Distinctive features of all elephants include a long trunk, tusks, large ear flaps, massive legs, and tough but sensitive skin. The trunk, also called a proboscis, is used for breathing, bringing food and water to the mouth, and grasping objects. Tusks, which are derived from the incisor teeth, serve both as weapons and as tools for moving objects and digging. The large ear flaps assist in maintaining a constant body temperature as well as in communication. The pillar-like legs carry their great weight. Elephants are scattered throughout sub-Saharan Africa, South Asia, and Southeast Asia and are found in different habitats, including savannahs, forests, deserts, and marshes. They are herbivorous, and they stay near water when it is accessible. They are considered to be keystone species, due to their impact on their environments.[1] Other animals tend to keep their distance from elephants; the exception is their predators such as lions, tigers, hyenas, and wild dogs, which usually target only young elephants (calves). Elephants have a fission–fusion society, in which multiple family groups come together to socialise. Females (cows) tend to live in family groups, which can consist of one female with her calves or several related females with offspring. The groups, which do not include bulls, are led by the (usually) oldest cow, known as the matriarch."""

def character_frequency(text): 
    char_count = Counter(text)
    total_chars = sum(char_count.values())
    for char in set(text):
        count = char_count[char]
        percentage = (count / total_chars) * 100
        print(f"'{char}': Count of {count} and Percentage of {percentage:.1f}%")
        
calculate_char_frequency(text)
165/15:
from collections import Counter

text = """Elephants are mammals of the family Elephantidae and the largest existing land animals. Three species are currently recognised: the African bush elephant, the African forest elephant, and the Asian elephant. Elephantidae is the only surviving family of the order Proboscidea; extinct members include the mastodons. The family Elephantidae also contains several now-extinct groups, including the mammoths and straight-tusked elephants. African elephants have larger ears and concave backs, whereas Asian elephants have smaller ears, and convex or level backs. Distinctive features of all elephants include a long trunk, tusks, large ear flaps, massive legs, and tough but sensitive skin. The trunk, also called a proboscis, is used for breathing, bringing food and water to the mouth, and grasping objects. Tusks, which are derived from the incisor teeth, serve both as weapons and as tools for moving objects and digging. The large ear flaps assist in maintaining a constant body temperature as well as in communication. The pillar-like legs carry their great weight. Elephants are scattered throughout sub-Saharan Africa, South Asia, and Southeast Asia and are found in different habitats, including savannahs, forests, deserts, and marshes. They are herbivorous, and they stay near water when it is accessible. They are considered to be keystone species, due to their impact on their environments.[1] Other animals tend to keep their distance from elephants; the exception is their predators such as lions, tigers, hyenas, and wild dogs, which usually target only young elephants (calves). Elephants have a fission–fusion society, in which multiple family groups come together to socialise. Females (cows) tend to live in family groups, which can consist of one female with her calves or several related females with offspring. The groups, which do not include bulls, are led by the (usually) oldest cow, known as the matriarch."""

def character_frequency(text): 
    char_count = Counter(text)
    total_chars = sum(char_count.values())
    for char in set(text):
        count = char_count[char]
        percentage = (count / total_chars) * 100
        print(f"'{char}': Count of {count} and Percentage of {percentage:.1f}%")
        
calculate_char_frequency(text)
165/16:
from collections import Counter

text = """Elephants are mammals of the family Elephantidae and the largest existing land animals. Three species are currently recognised: the African bush elephant, the African forest elephant, and the Asian elephant. Elephantidae is the only surviving family of the order Proboscidea; extinct members include the mastodons. The family Elephantidae also contains several now-extinct groups, including the mammoths and straight-tusked elephants. African elephants have larger ears and concave backs, whereas Asian elephants have smaller ears, and convex or level backs. Distinctive features of all elephants include a long trunk, tusks, large ear flaps, massive legs, and tough but sensitive skin. The trunk, also called a proboscis, is used for breathing, bringing food and water to the mouth, and grasping objects. Tusks, which are derived from the incisor teeth, serve both as weapons and as tools for moving objects and digging. The large ear flaps assist in maintaining a constant body temperature as well as in communication. The pillar-like legs carry their great weight. Elephants are scattered throughout sub-Saharan Africa, South Asia, and Southeast Asia and are found in different habitats, including savannahs, forests, deserts, and marshes. They are herbivorous, and they stay near water when it is accessible. They are considered to be keystone species, due to their impact on their environments.[1] Other animals tend to keep their distance from elephants; the exception is their predators such as lions, tigers, hyenas, and wild dogs, which usually target only young elephants (calves). Elephants have a fission–fusion society, in which multiple family groups come together to socialise. Females (cows) tend to live in family groups, which can consist of one female with her calves or several related females with offspring. The groups, which do not include bulls, are led by the (usually) oldest cow, known as the matriarch."""

def character_frequency(text): 
    char_count = Counter(text)
    total_chars = sum(char_count.values())
    for char in set(text):
        count = char_count[char]
        percentage = (count / total_chars) * 100
        print(f"'{char}': Count of {count} and Percentage of {percentage:.1f}%")
        
character_frequency(text)
165/17:
 import collections 

text = """Elephants are mammals of the family Elephantidae and the largest existing land animals. Three species are currently recognised: the African bush elephant, the African forest elephant, and the Asian elephant. Elephantidae is the only surviving family of the order Proboscidea; extinct members include the mastodons. The family Elephantidae also contains several now-extinct groups, including the mammoths and straight-tusked elephants. African elephants have larger ears and concave backs, whereas Asian elephants have smaller ears, and convex or level backs. Distinctive features of all elephants include a long trunk, tusks, large ear flaps, massive legs, and tough but sensitive skin. The trunk, also called a proboscis, is used for breathing, bringing food and water to the mouth, and grasping objects. Tusks, which are derived from the incisor teeth, serve both as weapons and as tools for moving objects and digging. The large ear flaps assist in maintaining a constant body temperature as well as in communication. The pillar-like legs carry their great weight. Elephants are scattered throughout sub-Saharan Africa, South Asia, and Southeast Asia and are found in different habitats, including savannahs, forests, deserts, and marshes. They are herbivorous, and they stay near water when it is accessible. They are considered to be keystone species, due to their impact on their environments.[1] Other animals tend to keep their distance from elephants; the exception is their predators such as lions, tigers, hyenas, and wild dogs, which usually target only young elephants (calves). Elephants have a fission–fusion society, in which multiple family groups come together to socialise. Females (cows) tend to live in family groups, which can consist of one female with her calves or several related females with offspring. The groups, which do not include bulls, are led by the (usually) oldest cow, known as the matriarch."""

def character_frequency(text): 
    char_count = Counter(text)
    total_chars = sum(char_count.values())
    for char in set(text):
        count = char_count[char]
        percentage = (count / total_chars) * 100
        print(f"'{char}': Count of {count} and Percentage of {percentage:.1f}%")
        
character_frequency(text)
165/18:
 import collections 

text = """Elephants are mammals of the family Elephantidae and the largest existing land animals. Three species are currently recognised: the African bush elephant, the African forest elephant, and the Asian elephant. Elephantidae is the only surviving family of the order Proboscidea; extinct members include the mastodons. The family Elephantidae also contains several now-extinct groups, including the mammoths and straight-tusked elephants. African elephants have larger ears and concave backs, whereas Asian elephants have smaller ears, and convex or level backs. Distinctive features of all elephants include a long trunk, tusks, large ear flaps, massive legs, and tough but sensitive skin. The trunk, also called a proboscis, is used for breathing, bringing food and water to the mouth, and grasping objects. Tusks, which are derived from the incisor teeth, serve both as weapons and as tools for moving objects and digging. The large ear flaps assist in maintaining a constant body temperature as well as in communication. The pillar-like legs carry their great weight. Elephants are scattered throughout sub-Saharan Africa, South Asia, and Southeast Asia and are found in different habitats, including savannahs, forests, deserts, and marshes. They are herbivorous, and they stay near water when it is accessible. They are considered to be keystone species, due to their impact on their environments.[1] Other animals tend to keep their distance from elephants; the exception is their predators such as lions, tigers, hyenas, and wild dogs, which usually target only young elephants (calves). Elephants have a fission–fusion society, in which multiple family groups come together to socialise. Females (cows) tend to live in family groups, which can consist of one female with her calves or several related females with offspring. The groups, which do not include bulls, are led by the (usually) oldest cow, known as the matriarch."""

def character_frequency(text): 
    char_count = Counter(text)
    for char, count in sorted(counter.items()):
        percentage = (count / total_count) * 100
        print(f"'{char}': Count of {count} and Percentage of {percentage:.1f}%")


        
character_frequency(text)
165/19:
 import collections 

text = """Elephants are mammals of the family Elephantidae and the largest existing land animals. Three species are currently recognised: the African bush elephant, the African forest elephant, and the Asian elephant. Elephantidae is the only surviving family of the order Proboscidea; extinct members include the mastodons. The family Elephantidae also contains several now-extinct groups, including the mammoths and straight-tusked elephants. African elephants have larger ears and concave backs, whereas Asian elephants have smaller ears, and convex or level backs. Distinctive features of all elephants include a long trunk, tusks, large ear flaps, massive legs, and tough but sensitive skin. The trunk, also called a proboscis, is used for breathing, bringing food and water to the mouth, and grasping objects. Tusks, which are derived from the incisor teeth, serve both as weapons and as tools for moving objects and digging. The large ear flaps assist in maintaining a constant body temperature as well as in communication. The pillar-like legs carry their great weight. Elephants are scattered throughout sub-Saharan Africa, South Asia, and Southeast Asia and are found in different habitats, including savannahs, forests, deserts, and marshes. They are herbivorous, and they stay near water when it is accessible. They are considered to be keystone species, due to their impact on their environments.[1] Other animals tend to keep their distance from elephants; the exception is their predators such as lions, tigers, hyenas, and wild dogs, which usually target only young elephants (calves). Elephants have a fission–fusion society, in which multiple family groups come together to socialise. Females (cows) tend to live in family groups, which can consist of one female with her calves or several related females with offspring. The groups, which do not include bulls, are led by the (usually) oldest cow, known as the matriarch."""

def character_frequency(text): 
     counter = collections.Counter(text)

    total_count = sum(counter.values())

    for char, count in sorted(counter.items()):
        percentage = (count / total_count) * 100
        print(f"'{char}': Count of {count} and Percentage of {percentage:.1f}%")


        
character_frequency(text)
165/21:
 import collections 

text = """Elephants are mammals of the family Elephantidae and the largest existing land animals. Three species are currently recognised: the African bush elephant, the African forest elephant, and the Asian elephant. Elephantidae is the only surviving family of the order Proboscidea; extinct members include the mastodons. The family Elephantidae also contains several now-extinct groups, including the mammoths and straight-tusked elephants. African elephants have larger ears and concave backs, whereas Asian elephants have smaller ears, and convex or level backs. Distinctive features of all elephants include a long trunk, tusks, large ear flaps, massive legs, and tough but sensitive skin. The trunk, also called a proboscis, is used for breathing, bringing food and water to the mouth, and grasping objects. Tusks, which are derived from the incisor teeth, serve both as weapons and as tools for moving objects and digging. The large ear flaps assist in maintaining a constant body temperature as well as in communication. The pillar-like legs carry their great weight. Elephants are scattered throughout sub-Saharan Africa, South Asia, and Southeast Asia and are found in different habitats, including savannahs, forests, deserts, and marshes. They are herbivorous, and they stay near water when it is accessible. They are considered to be keystone species, due to their impact on their environments.[1] Other animals tend to keep their distance from elephants; the exception is their predators such as lions, tigers, hyenas, and wild dogs, which usually target only young elephants (calves). Elephants have a fission–fusion society, in which multiple family groups come together to socialise. Females (cows) tend to live in family groups, which can consist of one female with her calves or several related females with offspring. The groups, which do not include bulls, are led by the (usually) oldest cow, known as the matriarch."""

def character_frequency(text): 
     counter = collections.Counter(text)
    total_count = sum(counter.values())

    for char, count in sorted(counter.items()):
        percentage = (count / total_count) * 100
        print(f"'{char}': Count of {count} and Percentage of {percentage:.1f}%")


        
character_frequency(text)
165/23:
 import collections 

text = """Elephants are mammals of the family Elephantidae and the largest existing land animals. Three species are currently recognised: the African bush elephant, the African forest elephant, and the Asian elephant. Elephantidae is the only surviving family of the order Proboscidea; extinct members include the mastodons. The family Elephantidae also contains several now-extinct groups, including the mammoths and straight-tusked elephants. African elephants have larger ears and concave backs, whereas Asian elephants have smaller ears, and convex or level backs. Distinctive features of all elephants include a long trunk, tusks, large ear flaps, massive legs, and tough but sensitive skin. The trunk, also called a proboscis, is used for breathing, bringing food and water to the mouth, and grasping objects. Tusks, which are derived from the incisor teeth, serve both as weapons and as tools for moving objects and digging. The large ear flaps assist in maintaining a constant body temperature as well as in communication. The pillar-like legs carry their great weight. Elephants are scattered throughout sub-Saharan Africa, South Asia, and Southeast Asia and are found in different habitats, including savannahs, forests, deserts, and marshes. They are herbivorous, and they stay near water when it is accessible. They are considered to be keystone species, due to their impact on their environments.[1] Other animals tend to keep their distance from elephants; the exception is their predators such as lions, tigers, hyenas, and wild dogs, which usually target only young elephants (calves). Elephants have a fission–fusion society, in which multiple family groups come together to socialise. Females (cows) tend to live in family groups, which can consist of one female with her calves or several related females with offspring. The groups, which do not include bulls, are led by the (usually) oldest cow, known as the matriarch."""

def character_frequency(text): 
    counter = collections.Counter(text)
    total_count = sum(counter.values())

    for char, count in sorted(counter.items()):
        percentage = (count / total_count) * 100
        print(f"'{char}': Count of {count} and Percentage of {percentage:.1f}%")


        
character_frequency(text)
165/24:
 import collections 

text = """Elephants are mammals of the family Elephantidae and the largest existing land animals. Three species are currently recognised: the African bush elephant, the African forest elephant, and the Asian elephant. Elephantidae is the only surviving family of the order Proboscidea; extinct members include the mastodons. The family Elephantidae also contains several now-extinct groups, including the mammoths and straight-tusked elephants. African elephants have larger ears and concave backs, whereas Asian elephants have smaller ears, and convex or level backs. Distinctive features of all elephants include a long trunk, tusks, large ear flaps, massive legs, and tough but sensitive skin. The trunk, also called a proboscis, is used for breathing, bringing food and water to the mouth, and grasping objects. Tusks, which are derived from the incisor teeth, serve both as weapons and as tools for moving objects and digging. The large ear flaps assist in maintaining a constant body temperature as well as in communication. The pillar-like legs carry their great weight. Elephants are scattered throughout sub-Saharan Africa, South Asia, and Southeast Asia and are found in different habitats, including savannahs, forests, deserts, and marshes. They are herbivorous, and they stay near water when it is accessible. They are considered to be keystone species, due to their impact on their environments.[1] Other animals tend to keep their distance from elephants; the exception is their predators such as lions, tigers, hyenas, and wild dogs, which usually target only young elephants (calves). Elephants have a fission–fusion society, in which multiple family groups come together to socialise. Females (cows) tend to live in family groups, which can consist of one female with her calves or several related females with offspring. The groups, which do not include bulls, are led by the (usually) oldest cow, known as the matriarch."""

def character_frequency(text): 
    counter = collections.Counter(text)
    total_count = sum(counter.values())
    for char, count in sorted(counter.items()):
        percentage = (count / total_count) * 100
        print(f"'{char}': Count of {count} and Percentage of {percentage:.1f}%")    
character_frequency(text)
165/25:
 import collections 

text = """Elephants are mammals of the family Elephantidae and the largest existing land animals. Three species are currently recognised: the African bush elephant, the African forest elephant, and the Asian elephant. Elephantidae is the only surviving family of the order Proboscidea; extinct members include the mastodons. The family Elephantidae also contains several now-extinct groups, including the mammoths and straight-tusked elephants. African elephants have larger ears and concave backs, whereas Asian elephants have smaller ears, and convex or level backs. Distinctive features of all elephants include a long trunk, tusks, large ear flaps, massive legs, and tough but sensitive skin. The trunk, also called a proboscis, is used for breathing, bringing food and water to the mouth, and grasping objects. Tusks, which are derived from the incisor teeth, serve both as weapons and as tools for moving objects and digging. The large ear flaps assist in maintaining a constant body temperature as well as in communication. The pillar-like legs carry their great weight. Elephants are scattered throughout sub-Saharan Africa, South Asia, and Southeast Asia and are found in different habitats, including savannahs, forests, deserts, and marshes. They are herbivorous, and they stay near water when it is accessible. They are considered to be keystone species, due to their impact on their environments.[1] Other animals tend to keep their distance from elephants; the exception is their predators such as lions, tigers, hyenas, and wild dogs, which usually target only young elephants (calves). Elephants have a fission–fusion society, in which multiple family groups come together to socialise. Females (cows) tend to live in family groups, which can consist of one female with her calves or several related females with offspring. The groups, which do not include bulls, are led by the (usually) oldest cow, known as the matriarch."""

def character_frequency(text): 
    counter = collections.Counter(text)
    total_count = sum(counter.values())
    for char, count in sorted(counter.items()):
        percentage = (count / total_count) * 100
        print(f"'{char}': Count of {count} and Percentage of {percentage:.1f}%")
165/26:
 import collections 

text = """Elephants are mammals of the family Elephantidae and the largest existing land animals. Three species are currently recognised: the African bush elephant, the African forest elephant, and the Asian elephant. Elephantidae is the only surviving family of the order Proboscidea; extinct members include the mastodons. The family Elephantidae also contains several now-extinct groups, including the mammoths and straight-tusked elephants. African elephants have larger ears and concave backs, whereas Asian elephants have smaller ears, and convex or level backs. Distinctive features of all elephants include a long trunk, tusks, large ear flaps, massive legs, and tough but sensitive skin. The trunk, also called a proboscis, is used for breathing, bringing food and water to the mouth, and grasping objects. Tusks, which are derived from the incisor teeth, serve both as weapons and as tools for moving objects and digging. The large ear flaps assist in maintaining a constant body temperature as well as in communication. The pillar-like legs carry their great weight. Elephants are scattered throughout sub-Saharan Africa, South Asia, and Southeast Asia and are found in different habitats, including savannahs, forests, deserts, and marshes. They are herbivorous, and they stay near water when it is accessible. They are considered to be keystone species, due to their impact on their environments.[1] Other animals tend to keep their distance from elephants; the exception is their predators such as lions, tigers, hyenas, and wild dogs, which usually target only young elephants (calves). Elephants have a fission–fusion society, in which multiple family groups come together to socialise. Females (cows) tend to live in family groups, which can consist of one female with her calves or several related females with offspring. The groups, which do not include bulls, are led by the (usually) oldest cow, known as the matriarch."""

def character_frequency(text): 
    counter = collections.Counter(text)
    total_count = sum(counter.values())
    for char, count in sorted(counter.items()):
        percentage = (count / total_count) * 100
        print(f"'{char}': Count of {count} and Percentage of {percentage:.1f}%")    
character_frequency(text)
165/27:
 import collections 

text = """Elephants are mammals of the family Elephantidae and the largest existing land animals. Three species are currently recognised: the African bush elephant, the African forest elephant, and the Asian elephant. Elephantidae is the only surviving family of the order Proboscidea; extinct members include the mastodons. The family Elephantidae also contains several now-extinct groups, including the mammoths and straight-tusked elephants. African elephants have larger ears and concave backs, whereas Asian elephants have smaller ears, and convex or level backs. Distinctive features of all elephants include a long trunk, tusks, large ear flaps, massive legs, and tough but sensitive skin. The trunk, also called a proboscis, is used for breathing, bringing food and water to the mouth, and grasping objects. Tusks, which are derived from the incisor teeth, serve both as weapons and as tools for moving objects and digging. The large ear flaps assist in maintaining a constant body temperature as well as in communication. The pillar-like legs carry their great weight. Elephants are scattered throughout sub-Saharan Africa, South Asia, and Southeast Asia and are found in different habitats, including savannahs, forests, deserts, and marshes. They are herbivorous, and they stay near water when it is accessible. They are considered to be keystone species, due to their impact on their environments.[1] Other animals tend to keep their distance from elephants; the exception is their predators such as lions, tigers, hyenas, and wild dogs, which usually target only young elephants (calves). Elephants have a fission–fusion society, in which multiple family groups come together to socialise. Females (cows) tend to live in family groups, which can consist of one female with her calves or several related females with offspring. The groups, which do not include bulls, are led by the (usually) oldest cow, known as the matriarch."""

def character_frequency(text): 
    counter = collections.Counter(text)
    total_count = sum(counter.values())
    for char 
    count in sorted(counter.items()):
        percentage = (count / total_count) * 100
        print(f"'{char}': Count of {count} and Percentage of {percentage:.1f}%")    
character_frequency(text)
165/28:
 import collections 

text = """Elephants are mammals of the family Elephantidae and the largest existing land animals. Three species are currently recognised: the African bush elephant, the African forest elephant, and the Asian elephant. Elephantidae is the only surviving family of the order Proboscidea; extinct members include the mastodons. The family Elephantidae also contains several now-extinct groups, including the mammoths and straight-tusked elephants. African elephants have larger ears and concave backs, whereas Asian elephants have smaller ears, and convex or level backs. Distinctive features of all elephants include a long trunk, tusks, large ear flaps, massive legs, and tough but sensitive skin. The trunk, also called a proboscis, is used for breathing, bringing food and water to the mouth, and grasping objects. Tusks, which are derived from the incisor teeth, serve both as weapons and as tools for moving objects and digging. The large ear flaps assist in maintaining a constant body temperature as well as in communication. The pillar-like legs carry their great weight. Elephants are scattered throughout sub-Saharan Africa, South Asia, and Southeast Asia and are found in different habitats, including savannahs, forests, deserts, and marshes. They are herbivorous, and they stay near water when it is accessible. They are considered to be keystone species, due to their impact on their environments.[1] Other animals tend to keep their distance from elephants; the exception is their predators such as lions, tigers, hyenas, and wild dogs, which usually target only young elephants (calves). Elephants have a fission–fusion society, in which multiple family groups come together to socialise. Females (cows) tend to live in family groups, which can consist of one female with her calves or several related females with offspring. The groups, which do not include bulls, are led by the (usually) oldest cow, known as the matriarch."""

def character_frequency(text): 
    counter = collections.Counter(text)
    total_count = sum(counter.values())
    for char, count in sorted(counter.items()):
        percentage = (count / total_count) * 100
        print(f"'{char}': Count of {count} and Percentage of {percentage:.1f}%")    
character_frequency(text)
168/10:
def ListFiles(directory):
    for filename in os.listdir(directory):
        filepath = os.path.join(directory, filename)
        if os.path.isfile(filepath):
            print(filepat
168/11:
def ListFiles(directory):
    for filename in os.listdir(directory):
        filepath = os.path.join(directory, filename)
        if os.path.isfile(filepath):
            print(filepat0
168/12:
def ListFiles(directory):
    for filename in os.listdir(directory):
        filepath = os.path.join(directory, filename)
        if os.path.isfile(filepath):
            print(filepat)
168/13:
def ListFiles(directory):
    for filename in os.listdir(directory):
        filepath = os.path.join(directory, filename)
        if os.path.isfile(filepath):
            print(filepath)
168/14: ListFiles('directory_list')
168/15: ListFiles('directory_list')
168/16:
def ListFiles(/Users/poojalal/Desktop/DATA301/lab08-DARTH-LAL/directory_list):
    for filename in os.listdir(directory):
        filepath = os.path.join(directory, filename)
        if os.path.isfile(filepath):
            print(filepath)
168/17: ListFiles('/Users/poojalal/Desktop/DATA301/lab08-DARTH-LAL/directory_list')
168/18:
def ListFiles(directory):
    for filename in os.listdir(directory):
        filepath = os.path.join(directory, filename)
        if os.path.isfile(filepath):
            print(filepath)
168/19: ListFiles('/Users/poojalal/Desktop/DATA301/lab08-DARTH-LAL/directory_list')
168/20:
def ListFiles(directory):
    for filename in os.listdir(directory):
        filepath = os.path.join(directory, filename)
        if os.path.isfile(filepath):
            print(filepath)
168/21: ListFiles('directory_list')
168/22: def ListFiles(directory):
168/23:
def ListDirectories(address):
    for item in os.listdir(path):
        fullpath = os.path.join(path, item)
        if os.path.isdir(fullpath):
            print(fullpath)
            ListDirectories(fullpath)
168/24: ListDirectories("directory_list")
168/25:
import os
def ListDirectories(address):
    for item in os.listdir(path):
        fullpath = os.path.join(path, item)
        if os.path.isdir(fullpath):
            print(fullpath)
            ListDirectories(fullpath)
168/26: ListDirectories("directory_list")
168/27: ListDirectories("/Users/poojalal/Desktop/DATA301/lab08-DARTH-LAL/directory_list")
168/28:
import os
def ListDirectories(address):
    for item in os.listdir(path):
        fullpath = os.path.join(path, item)
        if os.path.isdir(fullpath):
            print(fullpath)
            ListDirectories(fullpath)
168/29: ListDirectories("/Users/poojalal/Desktop/DATA301/lab08-DARTH-LAL/directory_list")
168/30:
import os
def ListDirectories(address):
    for item in os.listdir(address):
        fullpath = os.path.join(address, item)
        if os.path.isdir(fullpath):
            print(fullpath)
            ListDirectories(fullpath)
168/31: ListDirectories("/Users/poojalal/Desktop/DATA301/lab08-DARTH-LAL/directory_list")
168/32: ListDirectories("")
168/33: ListDirectories("directory_list")
168/34: ListDirectories("directory_list")
168/35:
import os
def tree(path):
    # Your Solution here
168/36:
import os
def tree(path):
    or root, dirs, files in os.walk(path):
        for file in files:
            print(os.path.join(root, file))
        for dir in dirs:
            print(os.path.join(root, dir) + '/')
168/37:
import os
def tree(path):
    or root, dirs, files in os.walk(path):
        for file in files:
            print(os.path.join(root, file))
        for dir in dirs:
            print(os.path.join(root, dir) + '/')
168/38:
import os
def tree(path):
    for root, dirs, files in os.walk(path):
        for file in files:
            print(os.path.join(root, file))
        for dir in dirs:
            print(os.path.join(root, dir) + '/')
168/39:
# Test your function
tree("directory_list")
168/40:
# Test your function
tree('/Users/poojalal/Desktop/DATA301/lab08-DARTH-LAL/directory_list')
168/41: ListDirectories("/Users/poojalal/Desktop/DATA301/lab08-DARTH-LAL/directory_list")
168/42: ListFiles('directory_list')
168/43: ListFiles('directory_list')
168/44: def ListFiles(directory):
168/45: ListFiles('directory_list')
168/46:
import os
def tree(path):
    for root, dirs, files in os.walk(path):
        for file in files:
            print(os.path.join(root, file))
        for dir in dirs:
            print(os.path.join(root, dir))
168/47:
# Test your function
tree('/Users/poojalal/Desktop/DATA301/lab08-DARTH-LAL/directory_list')
168/48:
import os
def tree(path):
    for root, dirs, files in os.walk(path):
        for file in files:
            print(os.path.join(root, file))
        for dir in dirs:
            print(os.path.join(root, dir) + '/')
168/49:
# Test your function
tree('/Users/poojalal/Desktop/DATA301/lab08-DARTH-LAL/directory_list')
168/50:
import os
def tree(path):
    for root, dirs, files in os.walk(path):
        for file in files:
            print(os.path.join(root, file))
        for dir in dirs:
            print(os.path.join(root, dir))
167/31:
def avglist(lst, low=0, high=100):
    count = 0
    total = 0
    for num in lst:
        if low < num < high:
            count += 1
            total += num
    return total / count if count > 0 else 0
167/32:
list1 = list(range(1, 11))
result1 = avglist(list1)
print("Average of list 1 is: {}".format(result1))
167/33:
list2 = list(range(1, 101))
result2 = avglist(list2, 20, 80)
print("Average of list2 with range ({}, {}) is: {}".format(20, 80, result2))
167/34:
import random
list3 = [random.randint(1, 100) for i in range(100)]
result3 = avglist(list3, 30, 100)
print("Average of list3 with range({}, {}) is: {}".format(30, 100, result3))
167/35:
def avglist(lst, low=0, high=100):
    count = 0
    total = 0
    for num in lst:
        if low < num < high:
            count += 1
            total += num
    return total / count if count > 0 else 0
167/36:
list1 = list(range(1, 11))
result1 = avglist(list1)
print("Average of list 1 is: {}".format(result1))
167/37:
list2 = list(range(1, 101))
result2 = avglist(list2, 20, 80)
print("Average of list2 with range ({}, {}) is: {}".format(20, 80, result2))
167/38:
import random
list3 = [random.randint(1, 100) for i in range(100)]
result3 = avglist(list3, 30, 100)
print("Average of list3 with range({}, {}) is: {}".format(30, 100, result3))
166/26:
def calc_tax(item_name, pre_tax_price):
    provincial_tax = round(pre_tax_price * 0.05, 2)
    federal_tax = round(pre_tax_price * 0.07, 2)
    total_price = round(pre_tax_price + provincial_tax + federal_tax, 2)

    print((item_name))
    print("Pre-tax price of: ${:.2f}".format(pre_tax_price))
    print("Provincial tax : ${:.2f}".format(provincial_tax))
    print("Federal tax : ${:.2f}".format(federal_tax))
    print("Total price of: ${:.2f}".format(total_price))
166/27:
assert calc_tax("Jordans", 180.00) == None
print("-----------------------")
assert calc_tax("Hoodie", 380.00) == None
print("-----------------------")
assert calc_tax("PS5", 500.00) == None
164/29: import math
164/30:
def solution(a, b, c):
    discriminant = b**2 - 4*a*c
    if discriminant < 0:
        print("The equation does not have any real solution")
    else:
        # Calculate and print real roots
        x1 = (-b + math.sqrt(discriminant)) / (2*a)
        x2 = (-b - math.sqrt(discriminant)) / (2*a)
        print("For a={}, b={}, and c={}: x1 = {} and x2 = {}".format(a, b, c ,x1 ,x2))
164/31: solution(1,1,1)
164/32: solution(1,0,-4)
164/33: solution(1,2,1)
165/29:
import collections 

text = """Elephants are mammals of the family Elephantidae and the largest existing land animals. Three species are currently recognised: the African bush elephant, the African forest elephant, and the Asian elephant. Elephantidae is the only surviving family of the order Proboscidea; extinct members include the mastodons. The family Elephantidae also contains several now-extinct groups, including the mammoths and straight-tusked elephants. African elephants have larger ears and concave backs, whereas Asian elephants have smaller ears, and convex or level backs. Distinctive features of all elephants include a long trunk, tusks, large ear flaps, massive legs, and tough but sensitive skin. The trunk, also called a proboscis, is used for breathing, bringing food and water to the mouth, and grasping objects. Tusks, which are derived from the incisor teeth, serve both as weapons and as tools for moving objects and digging. The large ear flaps assist in maintaining a constant body temperature as well as in communication. The pillar-like legs carry their great weight. Elephants are scattered throughout sub-Saharan Africa, South Asia, and Southeast Asia and are found in different habitats, including savannahs, forests, deserts, and marshes. They are herbivorous, and they stay near water when it is accessible. They are considered to be keystone species, due to their impact on their environments.[1] Other animals tend to keep their distance from elephants; the exception is their predators such as lions, tigers, hyenas, and wild dogs, which usually target only young elephants (calves). Elephants have a fission–fusion society, in which multiple family groups come together to socialise. Females (cows) tend to live in family groups, which can consist of one female with her calves or several related females with offspring. The groups, which do not include bulls, are led by the (usually) oldest cow, known as the matriarch."""

def character_frequency(text): 
    counter = collections.Counter(text)
    total_count = sum(counter.values())
    for char, count in sorted(counter.items()):
        percentage = (count / total_count) * 100
        print(f"'{char}': Count of {count} and Percentage of {percentage:.1f}%")    
character_frequency(text)
165/30: import collections
165/31: import collections
165/32:
text = """Elephants are mammals of the family Elephantidae and the largest existing land animals. Three species are currently recognised: the African bush elephant, the African forest elephant, and the Asian elephant. Elephantidae is the only surviving family of the order Proboscidea; extinct members include the mastodons. The family Elephantidae also contains several now-extinct groups, including the mammoths and straight-tusked elephants. African elephants have larger ears and concave backs, whereas Asian elephants have smaller ears, and convex or level backs. Distinctive features of all elephants include a long trunk, tusks, large ear flaps, massive legs, and tough but sensitive skin. The trunk, also called a proboscis, is used for breathing, bringing food and water to the mouth, and grasping objects. Tusks, which are derived from the incisor teeth, serve both as weapons and as tools for moving objects and digging. The large ear flaps assist in maintaining a constant body temperature as well as in communication. The pillar-like legs carry their great weight. Elephants are scattered throughout sub-Saharan Africa, South Asia, and Southeast Asia and are found in different habitats, including savannahs, forests, deserts, and marshes. They are herbivorous, and they stay near water when it is accessible. They are considered to be keystone species, due to their impact on their environments.[1] Other animals tend to keep their distance from elephants; the exception is their predators such as lions, tigers, hyenas, and wild dogs, which usually target only young elephants (calves). Elephants have a fission–fusion society, in which multiple family groups come together to socialise. Females (cows) tend to live in family groups, which can consist of one female with her calves or several related females with offspring. The groups, which do not include bulls, are led by the (usually) oldest cow, known as the matriarch."""

def character_frequency(text): 
    counter = collections.Counter(text)
    total_count = sum(counter.values())
    for char, count in sorted(counter.items()):
        percentage = (count / total_count) * 100
        print(f"'{char}': Count of {count} and Percentage of {percentage:.1f}%")    
character_frequency(text)
168/51: import os
168/52: def ListFiles(directory):
168/53: ListFiles('directory_list')
168/54:
import os
def ListDirectories(address):
    for item in os.listdir(address):
        fullpath = os.path.join(address, item)
        if os.path.isdir(fullpath):
            print(fullpath)
            ListDirectories(fullpath)
168/55: ListDirectories("/Users/poojalal/Desktop/DATA301/lab08-DARTH-LAL/directory_list")
168/56:
import os
def tree(path):
    for root, dirs, files in os.walk(path):
        for file in files:
            print(os.path.join(root, file))
        for dir in dirs:
            print(os.path.join(root, dir))
168/57:
# Test your function
tree('/Users/poojalal/Desktop/DATA301/lab08-DARTH-LAL/directory_list')
169/1:
text = "Elephants are mammals of the family Elephantidae and the largest existing land animals. Three species are currently recognised: the African bush elephant, the African forest elephant, and the Asian elephant. Elephantidae is the only surviving family of the order Proboscidea; extinct members include the mastodons. The family Elephantidae also contains several now-extinct groups, including the mammoths and straight-tusked elephants. African elephants have larger ears and concave backs, whereas Asian elephants have smaller ears, and convex or level backs. Distinctive features of all elephants include a long trunk, tusks, large ear flaps, massive legs, and tough but sensitive skin. The trunk, also called a proboscis, is used for breathing, bringing food and water to the mouth, and grasping objects. Tusks, which are derived from the incisor teeth, serve both as weapons and as tools for moving objects and digging. The large ear flaps assist in maintaining a constant body temperature as well as in communication. The pillar-like legs carry their great weight. Elephants are scattered throughout sub-Saharan Africa, South Asia, and Southeast Asia and are found in different habitats, including savannahs, forests, deserts, and marshes. They are herbivorous, and they stay near water when it is accessible. They are considered to be keystone species, due to their impact on their environments.[1] Other animals tend to keep their distance from elephants; the exception is their predators such as lions, tigers, hyenas, and wild dogs, which usually target only young elephants (calves). Elephants have a fission–fusion society, in which multiple family groups come together to socialise. Females (cows) tend to live in family groups, which can consist of one female with her calves or several related females with offspring. The groups, which do not include bulls, are led by the (usually) oldest cow, known as the matriarch."

def character_frequency(text): 
    counter = collections.Counter(text)
    total_count = sum(counter.values())
    for char, count in sorted(counter.items()):
        percentage = (count / total_count) * 100
        print(f"'{char}': Count of {count} and Percentage of {percentage:.1f}%")    
character_frequency(text)
169/2: import collections
169/3:
text = "Elephants are mammals of the family Elephantidae and the largest existing land animals. Three species are currently recognised: the African bush elephant, the African forest elephant, and the Asian elephant. Elephantidae is the only surviving family of the order Proboscidea; extinct members include the mastodons. The family Elephantidae also contains several now-extinct groups, including the mammoths and straight-tusked elephants. African elephants have larger ears and concave backs, whereas Asian elephants have smaller ears, and convex or level backs. Distinctive features of all elephants include a long trunk, tusks, large ear flaps, massive legs, and tough but sensitive skin. The trunk, also called a proboscis, is used for breathing, bringing food and water to the mouth, and grasping objects. Tusks, which are derived from the incisor teeth, serve both as weapons and as tools for moving objects and digging. The large ear flaps assist in maintaining a constant body temperature as well as in communication. The pillar-like legs carry their great weight. Elephants are scattered throughout sub-Saharan Africa, South Asia, and Southeast Asia and are found in different habitats, including savannahs, forests, deserts, and marshes. They are herbivorous, and they stay near water when it is accessible. They are considered to be keystone species, due to their impact on their environments.[1] Other animals tend to keep their distance from elephants; the exception is their predators such as lions, tigers, hyenas, and wild dogs, which usually target only young elephants (calves). Elephants have a fission–fusion society, in which multiple family groups come together to socialise. Females (cows) tend to live in family groups, which can consist of one female with her calves or several related females with offspring. The groups, which do not include bulls, are led by the (usually) oldest cow, known as the matriarch."

def character_frequency(text): 
    counter = collections.Counter(text)
    total_count = sum(counter.values())
    for char, count in sorted(counter.items()):
        percentage = (count / total_count) * 100
        print(f"'{char}': Count of {count} and Percentage of {percentage:.1f}%")    
character_frequency(text)
171/1: df= pd.read_csv('https://github.com/firasm/bits/raw/master/pokemon.csv')
171/2:
import pandas as pd
df= pd.read_csv('https://github.com/firasm/bits/raw/master/pokemon.csv')
171/3:
import pandas as pd

df = pd.read_csv('https://github.com/firasm/bits/raw/master/pokemon.csv')
171/4:
import pandas as pd

df = pd.read_csv('https://github.com/firasm/bits/raw/master/pokemon.csv')
171/5:
import pandas as pd

df= pd.read_csv('https://github.com/firasm/bits/raw/master/pokemon.csv')
172/1:
# This data was provided by Rounak Banik who is a Data Science Fellow at Mckinsey & Company. 
#The dataset conatins information on all 802 pokemon from all seven generations of pokemon , the information inlcudes name , type , total , HP , Attcak , Defence etc.
#The date when this data was collected is not given.
#The purpose of this dataset was for fun and learning by anazlsing and exploring the popular pokemon game.
#The data about all 802 pokemon was taken from the website http://serebii.net/.
172/2:
import pandas as pd

df= pd.read_csv('https://github.com/firasm/bits/raw/master/pokemon.csv')
print(df)
173/1:
import pandas as pd
import numpy as np
import matplotlib.pyplot as pl
import seaborn as sns
173/2:
newdf = pd.read_csv('data/lab05_task2.csv')
newdf
173/3: grass_hp_gt_20 = df[(df['Type 1'] == 'Grass') & (df['HP'] > 20)]
173/4: grass_hp_gt_20 = newdf[(df['Type 1'] == 'Grass') & (df['HP'] > 20)]
173/5: grass_hp_gt_20 = newdf[(newdf['Type 1'] == 'Grass') & (newdf['HP'] > 20)]
173/6:
grass_hp_gt_20 = newdf[(newdf['Type 1'] == 'Grass') & (newdf['HP'] > 20)]
grass_hp_gt_20
171/6:
import pandas as pd

df = sns.load_dataset("penguins")
171/7:
import pandas as pd
import seaborn as sns

df = sns.load_dataset("penguins")
171/8:
import pandas as pd
import seaborn as sns

df = sns.load_dataset("penguins")
df
171/9:
import pandas as pd
import seaborn as sns

df = sns.load_dataset("penguins")
grouped_mean = df.groupby(['island', 'species']).mean()
171/10:
import pandas as pd
import seaborn as sns

df = sns.load_dataset("penguins")
grouped_mean = df.groupby(['island', 'species']).mean()
171/11:
import pandas as pd
import seaborn as sns

df = sns.load_dataset("penguins")

grouped_mean = df.groupby(['island', 'species']).mean()
171/12:
import pandas as pd
import seaborn as sns

df = sns.load_dataset("penguins")
171/13:
import pandas as pd
import seaborn as sns

df = sns.load_dataset("penguins")

df
171/14: grouped_mean = df.groupby(['island', 'species']).mean()
171/15: df.groupby(['island', 'species']).mean()
171/16: df.groupby(['island', 'species']).mean().reset_index()
173/7: df[0:10]['HP'].mean(skipna=False)
173/8:
import pandas as pd
import numpy as np
import matplotlib.pyplot as pl
import seaborn as sns
173/9:
newdf = pd.read_csv('data/lab05_task2.csv')
newdf
173/10: df[0:10]['HP'].mean(skipna=False)
173/11:
newdf = pd.read_csv('data/lab05_task2.csv')
newdf
173/12: df[0:10]['HP'].mean(skipna=False)
173/13: newdf[0:10]['HP'].mean(skipna=False)
171/17: df.drop(['flipper_length_mm','bill_depth_mm','island'])
171/18: df.drop(['flipper_length','bill_depth_mm','island'])
171/19: df.drop(['flipper_length_mm ','bill_depth_mm','island'])
171/20: df.drop(['flipper_length_mm','bill_depth_mm','island'])
171/21:
import pandas as pd
import seaborn as sns

df = sns.load_dataset("penguins")

df.columns()
171/22:
import pandas as pd
import seaborn as sns

df = sns.load_dataset("penguins")

df
171/23:
import pandas as pd
import seaborn as sns

df = sns.load_dataset("penguins")

df.columns
171/24: df.drop(['flipper_length_mm','bill_depth_mm','island'])
176/1:
# From the graph above , it can be observed that the major percentage of customers are between the age range of appoximately 40 to 60 years old , with a few number of customers in the below 40 and above 60 years old age range. 
# The distribution of the histogram is roughly symmetric with a big peak between the 40 and 50 years old age range.
176/2: # From the graph above , it can be observed that the median age of customers who have churned is a little higher than the median age of customers who have not churned. We can aslo see that the
176/3: # Exploring the distribution of income
176/4:
import pandas as pd
import numpy as np
import matplotlib.pylab as plt
import seaborn as sns
df = pd.read_csv('BankChurners.csv')
df
176/5: df.shape
176/6: #The dataset has 10127 rows and 23 columns.
176/7: df.columns
176/8:
#We can see all the names of the columns in the dataset , there are a lot of columns some of which are not needed in my research.
#Therefore , I will be  remooving them in further steps.
176/9:
df.nunique(axis=0)
#To see the number of unique values in my dataset for each variable.
176/10:
print(df.dtypes)
#Checking the datat types of each column
176/11:
df.describe()
#A numerical summary of the variables in the dataset.
176/12: #The first step in cleaning my dataset is remvoing redundant variables.
176/13: newdf = df.drop(columns=['Avg_Open_To_Buy','Naive_Bayes_Classifier_Attrition_Flag_Card_Category_Contacts_Count_12_mon_Dependent_count_Education_Level_Months_Inactive_12_mon_1','Naive_Bayes_Classifier_Attrition_Flag_Card_Category_Contacts_Count_12_mon_Dependent_count_Education_Level_Months_Inactive_12_mon_2','CLIENTNUM' ,'Total_Relationship_Count','Contacts_Count_12_mon','Total_Trans_Ct','Total_Ct_Chng_Q4_Q1'])
176/14: newdf
176/15:
#The second step in cleaning my dataset is remvoing null values
newdf_cleaned = newdf.dropna(axis=0)
176/16: newdf.shape
176/17: newdf_cleaned.shape
176/18: #The dataset does not contain any null values .Therefore , the shape of the dataset has not been changed.
176/19:
newdf_cleaned = pd.get_dummies(newdf_cleaned, columns=['Gender', 'Education_Level', 'Marital_Status', 'Income_Category', 'Card_Category'], drop_first=True)
# Converting categorical variables into numerical values
176/20:
print(newdf_cleaned.dtypes)
# Checking the data types of each column
176/21: print(newdf_cleaned)
176/22:
sns.countplot(x='Attrition_Flag', data=newdf_cleaned)
plt.title('Churn Rates',fontdict={'size': 17})
plt.xlabel('Customer Type', fontdict={'size': 12})
plt.show()
176/23: # From the graph above , it can be observed that the attrition flag value is significantly  higher for existing customers than attrited customers.Thus , this clearly shows that the dataset is imbalanced as the dataset has a much larger value for existing customers than churned customers.
176/24:
sns.histplot(x='Customer_Age', data=newdf_cleaned, bins=20)
plt.title('Distribution of Age',fontdict={'size': 17})
plt.xlabel('Customer Age', fontdict={'size': 12})
plt.show()
176/25:
# From the graph above , it can be observed that the major percentage of customers are between the age range of appoximately 40 to 60 years old , with a few number of customers in the below 40 and above 60 years old age range. 
# The distribution of the histogram is roughly symmetric with a big peak between the 40 and 50 years old age range.
176/26:
sns.boxplot(x='Attrition_Flag', y='Customer_Age', data=newdf_cleaned)
plt.title('Relationship between Age and Churn Rate',fontdict={'size': 17})
plt.xlabel('Customer Type', fontdict={'size': 12})
plt.ylabel('Customer Age', fontdict={'size': 12})
plt.show()
176/27: # From the graph above , it can be observed that the median age of customers who have churned is a little higher than the median age of customers who have not churned. We can aslo see that the
176/28: # Exploring the distribution of income
176/29:
sns.histplot(x='Credit_Limit', data=newdf_cleaned, bins=20)
plt.title('Distribution of Credit Limit',fontdict={'size': 17})
plt.xlabel('Customer Credit Limit', fontdict={'size': 12})
plt.show()
176/30: # Exploring the relationship between income and churn rates
176/31:
sns.boxplot(x='Attrition_Flag', y='Credit_Limit', data=newdf_cleaned)
plt.title('Relationship between Credit Limit and Churn Rate',fontdict={'size': 17})
plt.xlabel('Customer Type', fontdict={'size': 12})
plt.ylabel('Customer Credit Limit', fontdict={'size': 12})
plt.show()
176/32: #Exploring the distribution of gender
176/33:
sns.countplot(x='Gender_M', data=newdf_cleaned)
plt.title('Distribution of Gender',fontdict={'size': 17})
plt.xlabel('Customer Gender (Male = 0 , Female = 1)', fontdict={'size': 12})
plt.show()
176/34: # Exploring the relationship between gender and churn rates
176/35:
sns.countplot(x='Gender_M', hue='Attrition_Flag', data=newdf_cleaned)
plt.title('Relationship between Gender and Churn Rate',fontdict={'size': 17})
plt.xlabel('Customer Gender (Male = 0 , Female = 1)', fontdict={'size': 12})
plt.ylabel('Customer Type', fontdict={'size': 12})
plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left')
plt.show()
176/36: # Exploring the distribution of education level
176/37:
sns.countplot(x='Education_Level_High School', data=newdf_cleaned)
plt.title('Distribution of High School Education Level',fontdict={'size': 17})
plt.xlabel('High School Education Level (0 = Yes , 1 = No)', fontdict={'size': 12})
plt.show()
176/38: # Exploring the relationship between education level and churn rates
176/39:
sns.countplot(x='Education_Level_High School', hue='Attrition_Flag', data=newdf_cleaned)
plt.title('Relationship between High School Education Level and Churn Rate' , fontdict={'size': 15})
plt.xlabel('Education Level High School (0 = Yes , 1 = No)', fontdict={'size': 12})
plt.ylabel('Customer Type', fontdict={'size': 12})
plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left')
plt.show()
176/40: # Exploring the distribution of marital status
176/41:
sns.countplot(x='Marital_Status_Married', data=newdf_cleaned)
plt.title('Distribution of Marital Status' ,fontdict={'size': 17})
plt.xlabel('Customer Marital Status  (0 = Married , 1 = Non-Married/Unknown)', fontdict={'size': 12})
plt.show()
176/42: # Exploring the relationship between marital status and churn rates
176/43:
sns.countplot(x='Marital_Status_Married', hue='Attrition_Flag', data=newdf_cleaned)
plt.title('Relationship between Marital Status and Churn Rate',fontdict={'size': 15})
plt.xlabel('Customer Marital Status  (0 = Married , 1 = Non-Married/Unknown)', fontdict={'size': 12})
plt.ylabel('Customer Type', fontdict={'size': 12})
plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left')
plt.show()
176/44: # Exploring the distribution of income category
176/45:
sns.countplot(x='Income_Category_Less than $40K', data=df)
plt.title('Distribution of Income Category',fontdict={'size': 17})
plt.xlabel('Customer Income CategoryLess than $40K  (0 = Yes , 1 = No)', fontdict={'size': 12})
plt.show()
176/46: # Exploring the distribution of income category
176/47:
sns.countplot(x='Income_Category_Less than $40K', data=df)
plt.title('Distribution of Income Category',fontdict={'size': 17})
plt.xlabel('Customer Income CategoryLess than $40K  (0 = Yes , 1 = No)', fontdict={'size': 12})
plt.show()
176/48: # From the graph above , it can be observed that the majority of customers have high school education.
176/49:
sns.countplot(x='Education_Level_Post-Graduate', data=newdf_cleaned)
plt.title('Distribution of High School Education Level',fontdict={'size': 17})
plt.xlabel('High School Education Level (0 = Yes , 1 = No)', fontdict={'size': 12})
plt.show()
176/50:
sns.countplot(x='Education_Level_Post-Graduate', data=newdf_cleaned)
plt.title('Distribution of Post-Graduate Education Level',fontdict={'size': 17})
plt.xlabel('High School Education Level (0 = Yes , 1 = No)', fontdict={'size': 12})
plt.show()
176/51:
sns.countplot(x='Education_Level_Post-Graduate', data=newdf_cleaned)
plt.title('Distribution of Post-Graduate Education Level',fontdict={'size': 17})
plt.xlabel('Post-Graduate Education Level (0 = Yes , 1 = No)', fontdict={'size': 12})
plt.show()
176/52:
sns.countplot(x='Education_Level_Post-Graduate', hue='Attrition_Flag', data=newdf_cleaned)
plt.title('Relationship between Post-Graduate Education Level and Churn Rate' , fontdict={'size': 15})
plt.xlabel('Education Level Post-Graduate (0 = Yes , 1 = No)', fontdict={'size': 12})
plt.ylabel('Customer Type', fontdict={'size': 12})
plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left')
plt.show()
176/53:
# From the graph above , it can be observed that the number of churned customers is higher for customers with a post-graduate education than customers without a post-graduate education.However , the number of customers with a post-graduate education is also significantly higher than customers without a post-graduate education.
#Thus , further analysis is required for a concrte conclusion.
176/54:
sns.countplot(x='Education_Level_Graduate', data=newdf_cleaned)
plt.title('Distribution of Graduate Education Level',fontdict={'size': 17})
plt.xlabel('Graduate Education Level (0 = Yes , 1 = No)', fontdict={'size': 12})
plt.show()
176/55: #### Exploring the relationship between graduate education level and churn rates
176/56:
sns.countplot(x='Education_Level_Graduate', hue='Attrition_Flag', data=newdf_cleaned)
plt.title('Relationship between Graduate Education Level and Churn Rate' , fontdict={'size': 15})
plt.xlabel('Education Level Graduate (0 = Yes , 1 = No)', fontdict={'size': 12})
plt.ylabel('Customer Type', fontdict={'size': 12})
plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left')
plt.show()
176/57:
sns.countplot(x='Education_Level_Graduate', data=newdf_cleaned)
plt.title('Distribution of Graduate Education Level',fontdict={'size': 17})
plt.xlabel('Graduate Education Level (0 = Yes , 1 = No)', fontdict={'size': 12})
plt.show()
176/58:
sns.countplot(x='Education_Level_Doctorate', data=newdf_cleaned)
plt.title('Distribution of Doctorate Education Level',fontdict={'size': 17})
plt.xlabel('Doctorate Education Level (0 = Yes , 1 = No)', fontdict={'size': 12})
plt.show()
176/59: # From the graph above , it can be observed that the majority of customers have a doctorate education.
176/60:
sns.countplot(x='Education_Level_Doctorate', hue='Attrition_Flag', data=newdf_cleaned)
plt.title('Relationship between Doctorate Education Level and Churn Rate' , fontdict={'size': 15})
plt.xlabel('Education Level Doctorate (0 = Yes , 1 = No)', fontdict={'size': 12})
plt.ylabel('Customer Type', fontdict={'size': 12})
plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left')
plt.show()
176/61:
# From the graph above , it can be observed that the number of churned customers is higher for customers with a doctorate education than customers without a doctorate education.However , the number of customers with a doctorate education is also significantly higher than customers without a doctorate education.
#Thus , further analysis is required for a concrte conclusion.
176/62:
sns.countplot(x='Education_Level_Uneducated', data=newdf_cleaned)
plt.title('Distribution of Uneducated Education Level',fontdict={'size': 17})
plt.xlabel('Doctorate Uneducated Level (0 = Yes , 1 = No)', fontdict={'size': 12})
plt.show()
176/63:
sns.countplot(x='Education_Level', data=newdf_cleaned)
plt.title('Distribution of Education Level',fontdict={'size': 17})
plt.xlabel('Education Level', fontdict={'size': 12})
plt.show()
176/64:
sns.countplot(x='Education_Level', data=df)
plt.title('Distribution of Education Level',fontdict={'size': 17})
plt.xlabel('Education Level', fontdict={'size': 12})
plt.show()
176/65:
sns.countplot(x='Education_Level', data=newdf)
plt.title('Distribution of Education Level',fontdict={'size': 17})
plt.xlabel('Education Level', fontdict={'size': 12})
plt.show()
176/66:
sns.countplot(x='Education_Level', hue='Attrition_Flag', data=newdf_cleaned, order=['Uneducated', 'High School', 'College', 'Graduate', 'Post-Graduate', 'Doctorate'])
plt.title('Relationship between Education Level and Churn Rate' , fontdict={'size': 15})
plt.xlabel('Education Level', fontdict={'size': 12})
plt.ylabel('Count', fontdict={'size': 12})
plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left')
plt.show()
176/67:
sns.countplot(x='Education_Level', hue='Attrition_Flag', data=newdf, order=['Uneducated', 'High School', 'College', 'Graduate', 'Post-Graduate', 'Doctorate'])
plt.title('Relationship between Education Level and Churn Rate' , fontdict={'size': 15})
plt.xlabel('Education Level', fontdict={'size': 12})
plt.ylabel('Count', fontdict={'size': 12})
plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left')
plt.show()
176/68:
sns.countplot(x='Education_Level', data=newdf)
plt.title('Distribution of Education Level',fontdict={'size': 17})
plt.xlabel('Education Level', fontdict={'size': 12})
plt.xticks(rotation=45)
plt.show()
176/69: # From the graph above , it can be observed that number of customers have a Graduate education level and with a high school education level being the second highest.Also , we can see that the doctorate education level has the least number of customers.
176/70:
sns.countplot(x='Education_Level', hue='Attrition_Flag', data=newdf, order=['Uneducated', 'High School', 'College', 'Graduate', 'Post-Graduate', 'Doctorate'])
plt.title('Relationship between Education Level and Churn Rate' , fontdict={'size': 15})
plt.xlabel('Education Level', fontdict={'size': 12})
plt.ylabel('Count', fontdict={'size': 12})
plt.xticks(rotation=45)

plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left')
plt.show()
176/71:
sns.countplot(x='Education_Level', hue='Attrition_Flag', data=newdf, order=['Uneducated', 'High School', 'College', 'Graduate', 'Post-Graduate', 'Doctorate'])
plt.title('Relationship between Education Level and Churn Rate' , fontdict={'size': 15})
plt.xlabel('Education Level', fontdict={'size': 12})
plt.ylabel('Count', fontdict={'size': 12})
plt.xticks(rotation=45)
plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left')
plt.show()
176/72: From the graph above , it can be observed that the attrition flag value is significantly  higher for existing customers than attrited customers.Thus , this clearly shows that the dataset is imbalanced as the dataset has a much larger value for existing customers than churned customers.
176/73: # From the graph above , it can be observed that the attrition flag value is significantly  higher for existing customers than attrited customers.Thus , this clearly shows that the dataset is imbalanced as the dataset has a much larger value for existing customers than churned customers.
176/74:
sns.countplot(x='Marital_Status', data=newdf)
plt.title('Distribution of Marital Status' ,fontdict={'size': 17})
plt.xlabel('Customer Marital Status  (0 = Married , 1 = Non-Married/Unknown)', fontdict={'size': 12})
plt.show()
176/75:
sns.countplot(x='Marital_Status', data=newdf)
plt.title('Distribution of Marital Status', fontdict={'size': 17})
plt.xlabel('Marital Status', fontdict={'size': 12})
plt.show()
176/76:
sns.countplot(x='Marital_Status', data=newdf)
plt.title('Distribution of Marital Status', fontdict={'size': 17})
plt.xlabel('Marital Status', fontdict={'size': 12})
plt.xticks(rotation=45)

plt.show()
176/77:
sns.countplot(x='Marital_Status', data=newdf)
plt.title('Distribution of Marital Status', fontdict={'size': 17})
plt.xlabel('Marital Status', fontdict={'size': 12})
plt.xticks(rotation=45)
plt.show()
176/78:
sns.countplot(x='Marital_Status', hue='Attrition_Flag', data=newdf_cleaned)
plt.title('Relationship between Marital Status and Churn Rate', fontdict={'size': 15})
plt.xlabel('Marital Status', fontdict={'size': 12})
plt.ylabel('Customer Type', fontdict={'size': 12})
plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left')
plt.show()
176/79:
sns.countplot(x='Marital_Status', hue='Attrition_Flag', data=newdf)
plt.title('Relationship between Marital Status and Churn Rate', fontdict={'size': 15})
plt.xlabel('Marital Status', fontdict={'size': 12})
plt.ylabel('Customer Type', fontdict={'size': 12})
plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left')
plt.show()
176/80:
# From the graph above , it can be observed that the churn rate for married and single customers is the highest but it also important to consider that the number of married and single customers is also significantly higher.
# Therefore , further analysis is required for a concrete conclusion.
176/81:
sns.countplot(x='Income_Category', data=newdf)
plt.title('Distribution of Income Category',fontdict={'size': 17})
plt.xlabel('Income Category', fontdict={'size': 12})
plt.xticks(rotation=45)
plt.show()
176/82:
sns.countplot(x='Income_Category', hue='Attrition_Flag', data=newdf, order=['Unknown', 'Less than $40K', '$40K - $60K', '$60K - $80K', '$80K - $120K', '$120K +'])
plt.title('Relationship between Income Category and Churn Rate',fontdict={'size': 17})
plt.xlabel('Customer Income Category', fontdict={'size': 12})
plt.ylabel('Number of Customers', fontdict={'size': 12})
plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left')
plt.show()
176/83:
sns.countplot(x='Income_Category', hue='Attrition_Flag', data=newdf, order=['Unknown', 'Less than $40K', '$40K - $60K', '$60K - $80K', '$80K - $120K', '$120K +'])
plt.title('Relationship between Income Category and Churn Rate',fontdict={'size': 17})
plt.xlabel('Customer Income Category', fontdict={'size': 12})
plt.ylabel('Number of Customers', fontdict={'size': 12})
plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left')
plt.xticks(rotation=45)

plt.show()
176/84:
sns.countplot(x='Income_Category', hue='Attrition_Flag', data=newdf, order=['Unknown', 'Less than $40K', '$40K - $60K', '$60K - $80K', '$80K - $120K', '$120K +'])
plt.title('Relationship between Income Category and Churn Rate',fontdict={'size': 17})
plt.xlabel('Customer Income Category', fontdict={'size': 12})
plt.ylabel('Number of Customers', fontdict={'size': 12})
plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left')
plt.xticks(rotation=45)
plt.show()
176/85:
sns.countplot(x='Card_Category', data=newdf)
plt.title('Distribution of Card Category',fontdict={'size': 17})
plt.xlabel('Card Category', fontdict={'size': 12})
plt.show()
176/86: # From the graph above , it can be observed that the majority of customers are in the blue card category , therefore making the graph skewed to the left.
176/87:
sns.countplot(x='Card_Category', hue='Attrition_Flag', data=newdf)
plt.title('Relationship between Card Category and Churn Rate', fontdict={'size': 15})
plt.xlabel('Card Category', fontdict={'size': 12})
plt.ylabel('Customer Type', fontdict={'size': 12})
plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left')
plt.show()
176/88: agedf = df[['Age', 'Attrition_Flag']]
176/89: agedf = newdf[['Age', 'Attrition_Flag']]
176/90: agedf = newdf[['Customer_Age', 'Attrition_Flag']]
176/91:
agedf = newdf[['Customer_Age', 'Attrition_Flag']]
df['Attrition_Flag'] = df['Attrition_Flag'].map({'Existing Customer': 0, 'Attrited Customer': 1})
176/92:
df1 = newdf[['Customer_Age', 'Attrition_Flag']]
df2['Attrition_Flag'] = df['Attrition_Flag'].map({'Existing Customer': 0, 'Attrited Customer': 1})
176/93:
df1 = newdf[['Customer_Age', 'Attrition_Flag']]
df2['Attrition_Flag'] = df2['Attrition_Flag'].map({'Existing Customer': 0, 'Attrited Customer': 1})
176/94:
df1 = newdf[['Customer_Age', 'Attrition_Flag']]
df2['Attrition_Flag'] = df2['Attrition_Flag'].map({'Existing Customer': 0, 'Attrited Customer': 1})
176/95:
df1 = newdf[['Customer_Age', 'Attrition_Flag']]
df2['Attrition_Flag'] = df1['Attrition_Flag'].map({'Existing Customer': 0, 'Attrited Customer': 1})
176/96:
df1 = newdf[['Customer_Age', 'Attrition_Flag']]
df2['Attrition_Flag'] = df1['Attrition_Flag'].map({'Existing Customer': 0, 'Attrited Customer': 1})
176/97:
df1 = newdf[['Customer_Age', 'Attrition_Flag']]
df1['Attrition_Flag'] = df1['Attrition_Flag'].map({'Existing Customer': 0, 'Attrited Customer': 1})
176/98:
df1 = newdf[['Customer_Age', 'Attrition_Flag']]
df1['Attrition_Flag'] = df1['Attrition_Flag'].map({'Existing Customer': 0, 'Attrited Customer': 1})
176/99:
df1 = newdf[['Customer_Age', 'Attrition_Flag']]
df1['Attrition_Flag'] = df1['Attrition_Flag'].map({'Existing Customer': 0, 'Attrited Customer': 1})
corr = df['Age'].corr(df['Attrition_Flag'])
print("Correlation coefficient between Age and Churn Rate: ", corr)
176/100:
df1 = newdf[['Customer_Age', 'Attrition_Flag']]
df1['Attrition_Flag'] = df1['Attrition_Flag'].map({'Existing Customer': 0, 'Attrited Customer': 1})
corr = df1['Customer_Age'].corr(df1['Attrition_Flag'])
print("Correlation coefficient between Age and Churn Rate: ", corr)
176/101:
df1 = newdf[['Customer_Age', 'Attrition_Flag']]
df['Attrition_Flag'] = df['Attrition_Flag'].map({'Existing Customer': 0, 'Attrited Customer': 1})
corr = df1['Customer_Age'].corr(df1['Attrition_Flag'])
print("Correlation coefficient between Age and Churn Rate: ", corr)
176/102:
df1 = newdf[['Customer_Age', 'Attrition_Flag']]
df['Attrition_Flag'] = df['Attrition_Flag'].map({'Existing Customer': 0, 'Attrited Customer': 1})
corr = df['Customer_Age'].corr(df['Attrition_Flag'])
print("Correlation coefficient between Age and Churn Rate: ", corr)
176/103:
df = newdf[['Customer_Age', 'Attrition_Flag']]
df['Attrition_Flag'] = df['Attrition_Flag'].map({'Existing Customer': 0, 'Attrited Customer': 1})
corr = df['Customer_Age'].corr(df['Attrition_Flag'])
print("Correlation coefficient between Age and Churn Rate: ", corr)
176/104:
df = newdf[['Customer_Age', 'Attrition_Flag']]
df['Attrition_Flag'] = df['Attrition_Flag'].map({'Existing Customer': 0, 'Attrited Customer': 1})
corr = df['Customer_Age'].corr(df['Attrition_Flag'])
print("Correlation coefficient between Age and Churn Rate: ", corr)
176/105:
df['Attrition_Flag'] = df['Attrition_Flag'].map({'Existing Customer': 0, 'Attrited Customer': 1})
corr = df['Customer_Age'].corr(df['Attrition_Flag'])
print("Correlation coefficient between Age and Churn Rate: ", corr)
176/106:
df['Attrition_Flag'] = df['Attrition_Flag'].map({'Existing Customer': 0, 'Attrited Customer': 1})
corr = df['Age'].corr(df['Attrition_Flag'])
print("Correlation coefficient between Age and Attrition_Flag:", corr)
176/107:
df['Attrition_Flag'] = df['Attrition_Flag'].map({'Existing Customer': 0, 'Attrited Customer': 1})
corr = newdf['Customer_Age'].corr(df['Attrition_Flag'])
print("Correlation coefficient between Age and Attrition_Flag:", corr)
176/108:
newdf.loc[newdf['Attrition_Flag'] == 'Existing Customer', 'Attrition_Flag'] = 0
newdf.loc[newdf['Attrition_Flag'] == 'Attrited Customer', 'Attrition_Flag'] = 1
176/109:
newdf.loc[newdf['Attrition_Flag'] == 'Existing Customer', 'Attrition_Flag'] = 0
newdf.loc[newdf['Attrition_Flag'] == 'Attrited Customer', 'Attrition_Flag'] = 1
corr = newdf[['Age', 'Attrition_Flag']].dropna().corr().iloc[0,1]
print("Correlation coefficient between Age and Attrition_Flag:", corr)
176/110:
newdf.loc[newdf['Attrition_Flag'] == 'Existing Customer', 'Attrition_Flag'] = 0
newdf.loc[newdf['Attrition_Flag'] == 'Attrited Customer', 'Attrition_Flag'] = 1
corr = newdf[['Customer_Age', 'Attrition_Flag']].dropna().corr().iloc[0,1]
print("Correlation coefficient between Age and Attrition_Flag:", corr)
176/111:
newdf.loc[newdf['Attrition_Flag'] == 'Existing Customer', 'Attrition_Flag'] = 0
newdf.loc[newdf['Attrition_Flag'] == 'Attrited Customer', 'Attrition_Flag'] = 1
176/112:
corr = newdf[['Age', 'Attrition_Flag']].dropna().corr().iloc[0,1]
print("Correlation coefficient between Age and Attrition_Flag:", corr)
176/113: print(df['Age'].isnull().sum())
176/114: print(df['Customer_Age'].isnull().sum())
176/115: print(df['Customer_Age'].isnull().sum())
176/116:
corr = newdf[['Customer_Age', 'Attrition_Flag']].dropna().corr().iloc[0,1]
print("Correlation coefficient between Age and Attrition_Flag:", corr)
176/117:
age_churn = df.groupby(['Customer_Age', 'Attrition_Flag']).size().unstack()
age_churn.plot(kind='bar', stacked=True)
plt.title('Churn Rates by Age Group')
plt.xlabel('Age Group')
plt.ylabel('Count')
plt.show()
176/118:
age_churn = newdf.groupby(['Customer_Age', 'Attrition_Flag']).size().unstack()
age_churn.plot(kind='bar', stacked=True)
plt.title('Churn Rates by Age Group')
plt.xlabel('Age Group')
plt.ylabel('Count')
plt.show()
176/119:
age_churn = newdf.groupby(['Customer_Age', 'Attrition_Flag']).size().unstack()
age_churn.plot(kind='bar', stacked=True)
plt.title('Churn Rates by Age Group')
plt.xlabel('Age Group')
plt.ylabel('Count')
plt.xticks(rotation=45)

plt.show()
176/120:
age_churn = newdf.groupby(['Customer_Age', 'Attrition_Flag']).size().unstack()
age_churn.plot(kind='bar', stacked=True)
plt.title('Churn Rates by Age Group')
plt.xlabel('Age Group')
plt.ylabel('Count')
plt.xticks(rotation=45)
plt.show()
176/121:
age_churn = newdf.groupby(['Customer_Age', 'Attrition_Flag']).size().unstack()
age_churn.plot(kind='bar', stacked=True)
plt.title('Churn Rates by Age Group')
plt.xlabel('Age Group')
plt.ylabel('Count')
plt.xticks(rotation=180)
plt.show()
176/122:
age_churn = newdf.groupby(['Customer_Age', 'Attrition_Flag']).size().unstack()
age_churn.plot(kind='bar', stacked=True)
plt.title('Churn Rates by Age Group')
plt.xlabel('Age Group')
plt.ylabel('Count')
plt.xticks(rotation=100)
plt.show()
176/123: age_churn_rate = df.groupby('Customer_Age')['Attrition_Flag'].mean()
176/124:
age_churn_rate = df.groupby('Customer_Age')['Attrition_Flag'].mean()
plt.plot(age_churn_rate.index, age_churn_rate.values)
plt.title('Churn Rates by Age Group')
plt.xlabel('Age')
plt.ylabel('Churn Rate')
plt.show()
176/125:
age_churn_rate = df.groupby('Customer_Age')['Attrition_Flag'].mean()

plt.plot(age_churn_rate.index, age_churn_rate.values)
plt.title('Churn Rates by Age Group')
plt.xlabel('Age')
plt.ylabel('Churn Rate')
plt.show()
176/126:
plt.plot(age_churn_rate.index, age_churn_rate.values)
plt.title('Churn Rates by Age Group')
plt.xlabel('Age')
plt.ylabel('Churn Rate')
plt.show()
176/127: age_churn_rate = df.groupby('Customer_Age')['Attrition_Flag'].mean()
176/128:
plt.plot(age_churn_rate.index, age_churn_rate.values)
plt.title('Churn Rates by Age Group')
plt.xlabel('Age')
plt.ylabel('Churn Rate')
plt.show()
176/129:
age_churn_rate = df.groupby('Customer_Age')['Attrition_Flag'].mean()
age_churn_rate.dropna(inplace=True)
176/130:
plt.plot(age_churn_rate.index, age_churn_rate.values)
plt.title('Churn Rates by Age Group')
plt.xlabel('Age')
plt.ylabel('Churn Rate')
plt.show()
176/131: age_churn_rate = newdf.groupby('Customer_Age')['Attrition_Flag'].mean()
176/132:
plt.plot(age_churn_rate.index, age_churn_rate.values)
plt.title('Churn Rates by Age Group')
plt.xlabel('Age')
plt.ylabel('Churn Rate')
plt.show()
176/133:
plt.plot(age_churn.index, age_churn.values)
plt.title('Churn Rates by Age Group')
plt.xlabel('Age')
plt.ylabel('Churn Rate')
plt.show()
176/134:
# I will firstly be analysisng the affect of customer age on churn rates.Below , i have firstly written code to calculate the churn rates for each customer age.
age_churn= newdf.groupby('Customer_Age')['Attrition_Flag'].mean()
176/135:
plt.plot(age_churn.index, age_churn.values)
plt.title('Churn Rates by Age Group')
plt.xlabel('Age')
plt.ylabel('Churn Rate')
plt.show()
176/136:
# I will firstly be analysisng the affect of customer age on churn rates.Below , i have firstly written code to calculate the churn rates for each customer age.
age_churn= newdf.groupby('Customer_Age')['Attrition_Flag'].mean()
176/137:
plt.plot(age_churn.index, age_churn.values)
plt.title('Churn Rates by Age Group')
plt.xlabel('Age')
plt.ylabel('Churn Rate')
plt.show()
176/138:
plt.plot(age_churn.index, age_churn.values)
plt.title('Churn Rates for each Customer Age')
plt.xlabel('Customer Age')
plt.ylabel('Churn Rate')
plt.show()
176/139:
plt.plot(age_churn.index, age_churn.values)
plt.title('Churn Rates for each Customer Age', fontdict={'size': 12})
plt.xlabel('Customer Age')
plt.ylabel('Churn Rate')
plt.show()
176/140:
plt.plot(age_churn.index, age_churn.values)
plt.title('Churn Rates for each Customer Age', fontdict={'size': 12})
plt.xlabel('Customer Age', fontdict={'size': 12})
plt.ylabel('Churn Rate')
plt.show()
176/141:
plt.plot(age_churn.index, age_churn.values)
plt.title('Churn Rates for each Customer Age', fontdict={'size': 12})
plt.xlabel('Customer Age', fontdict={'size': 12})
plt.ylabel('Churn Rate', fontdict={'size': 12})
plt.show()
176/142:
plt.plot(age_churn.index, age_churn.values)
plt.title('Churn Rates for each Customer Age', fontdict={'size': 17})
plt.xlabel('Customer Age', fontdict={'size': 12})
plt.ylabel('Churn Rate', fontdict={'size': 12})
plt.show()
176/143:
plt.plot(age_churn.index, age_churn.values)
plt.title('Churn Rates for each Customer Age', fontdict={'size': 15})
plt.xlabel('Customer Age', fontdict={'size': 12})
plt.ylabel('Churn Rate', fontdict={'size': 12})
plt.show()
176/144:

plt.plot(age_churn.index, age_churn.values)
plt.title('Churn Rates for each Customer Age', fontdict={'size': 15})
plt.xlabel('Customer Age', fontdict={'size': 12})
plt.ylabel('Churn Rate', fontdict={'size': 12})
plt.grid()

plt.show()
176/145:

plt.plot(age_churn.index, age_churn.values)
plt.plot(age_churn_rate.index, age_churn_rate.values, linestyle='--', marker='o', color='red')

plt.title('Churn Rates for each Customer Age', fontdict={'size': 15})
plt.xlabel('Customer Age', fontdict={'size': 12})
plt.ylabel('Churn Rate', fontdict={'size': 12})
plt.grid()

plt.show()
176/146:

plt.plot(age_churn.index, age_churn.values)
plt.plot(age_churn_rate.index, age_churn_rate.values, linestyle='--', marker='o', color='red')
plt.title('Churn Rates for each Customer Age', fontdict={'size': 15})
plt.xlabel('Customer Age', fontdict={'size': 12})
plt.ylabel('Churn Rate', fontdict={'size': 12})
plt.grid()

plt.show()
176/147:

plt.plot(age_churn.index, age_churn.values)
plt.plot(age_churn_rate.index, age_churn_rate.values, linestyle='-', marker='o', color='red')
plt.title('Churn Rates for each Customer Age', fontdict={'size': 15})
plt.xlabel('Customer Age', fontdict={'size': 12})
plt.ylabel('Churn Rate', fontdict={'size': 12})
plt.grid()

plt.show()
176/148:

plt.plot(age_churn.index, age_churn.values)
plt.plot(age_churn_rate.index, age_churn_rate.values, linestyle='---', marker='o', color='red')
plt.title('Churn Rates for each Customer Age', fontdict={'size': 15})
plt.xlabel('Customer Age', fontdict={'size': 12})
plt.ylabel('Churn Rate', fontdict={'size': 12})
plt.grid()

plt.show()
176/149:

plt.plot(age_churn.index, age_churn.values)
plt.plot(age_churn_rate.index, age_churn_rate.values, linestyle='-', marker='o', color='red')
plt.title('Churn Rates for each Customer Age', fontdict={'size': 15})
plt.xlabel('Customer Age', fontdict={'size': 12})
plt.ylabel('Churn Rate', fontdict={'size': 12})
plt.grid()

plt.show()
176/150:

plt.plot(age_churn.index, age_churn.values)
plt.plot(age_churn_rate.index, age_churn_rate.values, linestyle='-', marker='x', color='red')
plt.title('Churn Rates for each Customer Age', fontdict={'size': 15})
plt.xlabel('Customer Age', fontdict={'size': 12})
plt.ylabel('Churn Rate', fontdict={'size': 12})
plt.grid()

plt.show()
176/151:

plt.plot(age_churn.index, age_churn.values)
plt.plot(age_churn_rate.index, age_churn_rate.values, linestyle='-', marker='0', color='red')
plt.title('Churn Rates for each Customer Age', fontdict={'size': 15})
plt.xlabel('Customer Age', fontdict={'size': 12})
plt.ylabel('Churn Rate', fontdict={'size': 12})
plt.grid()

plt.show()
176/152:

plt.plot(age_churn.index, age_churn.values)
plt.plot(age_churn_rate.index, age_churn_rate.values, linestyle='-', marker='o', color='red')
plt.title('Churn Rates for each Customer Age', fontdict={'size': 15})
plt.xlabel('Customer Age', fontdict={'size': 12})
plt.ylabel('Churn Rate', fontdict={'size': 12})
plt.grid()

plt.show()
176/153:

plt.plot(age_churn.index, age_churn.values)
plt.plot(age_churn_rate.index, age_churn_rate.values,', marker='o', color='red')
plt.title('Churn Rates for each Customer Age', fontdict={'size': 15})
plt.xlabel('Customer Age', fontdict={'size': 12})
plt.ylabel('Churn Rate', fontdict={'size': 12})
plt.grid()

plt.show()
176/154:

plt.plot(age_churn.index, age_churn.values)
plt.plot(age_churn_rate.index, age_churn_rate.values', marker='o', color='red')
plt.title('Churn Rates for each Customer Age', fontdict={'size': 15})
plt.xlabel('Customer Age', fontdict={'size': 12})
plt.ylabel('Churn Rate', fontdict={'size': 12})
plt.grid()

plt.show()
176/155:

plt.plot(age_churn.index, age_churn.values)
plt.plot(age_churnindex, age_churn.values, marker='o', color='red')
plt.title('Churn Rates for each Customer Age', fontdict={'size': 15})
plt.xlabel('Customer Age', fontdict={'size': 12})
plt.ylabel('Churn Rate', fontdict={'size': 12})
plt.grid()

plt.show()
176/156:

plt.plot(age_churn.index, age_churn.values)
plt.plot(age_churn.index, age_churn.values, marker='o', color='red')
plt.title('Churn Rates for each Customer Age', fontdict={'size': 15})
plt.xlabel('Customer Age', fontdict={'size': 12})
plt.ylabel('Churn Rate', fontdict={'size': 12})
plt.grid()

plt.show()
176/157:
#Graph of churn rates for the calculated churn rates for each customer age.
plt.plot(age_churn.index, age_churn.values)
plt.plot(age_churn.index, age_churn.values, marker='o', color='')
plt.title('Churn Rates for each Customer Age', fontdict={'size': 15})
plt.xlabel('Customer Age', fontdict={'size': 12})
plt.ylabel('Churn Rate', fontdict={'size': 12})
plt.grid()

plt.show()
176/158:
#Graph of churn rates for the calculated churn rates for each customer age.
plt.plot(age_churn.index, age_churn.values)
plt.plot(age_churn.index, age_churn.values, marker='o', color='')
plt.title('Churn Rates for each Customer Age', fontdict={'size': 15})
plt.xlabel('Customer Age', fontdict={'size': 12})
plt.ylabel('Churn Rate', fontdict={'size': 12})
plt.grid()

plt.show()
176/159:
#Graph of churn rates for the calculated churn rates for each customer age.
plt.plot(age_churn.index, age_churn.values)
plt.plot(age_churn.index, age_churn.values, marker='o', color='red')
plt.title('Churn Rates for each Customer Age', fontdict={'size': 15})
plt.xlabel('Customer Age', fontdict={'size': 12})
plt.ylabel('Churn Rate', fontdict={'size': 12})
plt.grid()

plt.show()
176/160:
#Graph of churn rates for the calculated churn rates for each customer age.
plt.plot(age_churn.index, age_churn.values)
plt.plot(age_churn_rate.index, age_churn_rate.values, linestyle='--', color='green', marker='o', markerfacecolor='red')
plt.title('Churn Rates for each Customer Age', fontdict={'size': 15})
plt.xlabel('Customer Age', fontdict={'size': 12})
plt.ylabel('Churn Rate', fontdict={'size': 12})
plt.grid()

plt.show()
176/161:
#Graph of churn rates for the calculated churn rates for each customer age.
plt.plot(age_churn.index, age_churn.values)
plt.plot(age_churn_rate.index, age_churn_rate.values, color='green', marker='o', markerfacecolor='red')
plt.title('Churn Rates for each Customer Age', fontdict={'size': 15})
plt.xlabel('Customer Age', fontdict={'size': 12})
plt.ylabel('Churn Rate', fontdict={'size': 12})
plt.grid()

plt.show()
176/162:
#Graph of churn rates for the calculated churn rates for each customer age.
plt.plot(age_churn.index, age_churn.values)
plt.plot(age_churn_rate.index, age_churn.values, color='green', marker='o', markerfacecolor='red')
plt.title('Churn Rates for each Customer Age', fontdict={'size': 15})
plt.xlabel('Customer Age', fontdict={'size': 12})
plt.ylabel('Churn Rate', fontdict={'size': 12})
plt.grid()

plt.show()
176/163:
#Graph of churn rates for the calculated churn rates for each customer age.
plt.plot(age_churn.index, age_churn.values)
plt.plot(age_churn.index, age_churn.values, color='green', marker='o', markerfacecolor='red')
plt.title('Churn Rates for each Customer Age', fontdict={'size': 15})
plt.xlabel('Customer Age', fontdict={'size': 12})
plt.ylabel('Churn Rate', fontdict={'size': 12})
plt.grid()

plt.show()
176/164:
#Graph of churn rates for the calculated churn rates for each customer age.
plt.plot(age_churn.index, age_churn.values)
plt.plot(age_churn.index, age_churn.values, color='purple', marker='o', markerfacecolor='red')
plt.title('Churn Rates for each Customer Age', fontdict={'size': 15})
plt.xlabel('Customer Age', fontdict={'size': 12})
plt.ylabel('Churn Rate', fontdict={'size': 12})
plt.grid()

plt.show()
176/165:
#Graph of churn rates for the calculated churn rates for each customer age.
plt.plot(age_churn.index, age_churn.values)
plt.plot(age_churn.index, age_churn.values, color='black', marker='o', markerfacecolor='red')
plt.title('Churn Rates for each Customer Age', fontdict={'size': 15})
plt.xlabel('Customer Age', fontdict={'size': 12})
plt.ylabel('Churn Rate', fontdict={'size': 12})
plt.grid()

plt.show()
176/166:
#Graph of churn rates for the calculated churn rates for each customer age.
plt.plot(age_churn.index, age_churn.values)
plt.plot(age_churn.index, age_churn.values, color='black', marker='o', markerfacecolor='organge')
plt.title('Churn Rates for each Customer Age', fontdict={'size': 15})
plt.xlabel('Customer Age', fontdict={'size': 12})
plt.ylabel('Churn Rate', fontdict={'size': 12})
plt.grid()

plt.show()
176/167:
#Graph of churn rates for the calculated churn rates for each customer age.
plt.plot(age_churn.index, age_churn.values)
plt.plot(age_churn.index, age_churn.values, color='black', marker='o', markerfacecolor='organge')
plt.title('Churn Rates for each Customer Age', fontdict={'size': 15})
plt.xlabel('Customer Age', fontdict={'size': 12})
plt.ylabel('Churn Rate', fontdict={'size': 12})
plt.grid()

plt.show()
176/168:
#Graph of churn rates for the calculated churn rates for each customer age.
plt.plot(age_churn.index, age_churn.values)
plt.plot(age_churn.index, age_churn.values, color='black', marker='o', markerfacecolor='orange')
plt.title('Churn Rates for each Customer Age', fontdict={'size': 15})
plt.xlabel('Customer Age', fontdict={'size': 12})
plt.ylabel('Churn Rate', fontdict={'size': 12})
plt.grid()

plt.show()
176/169:
#Graph of churn rates for the calculated churn rates for each customer age.
plt.plot(age_churn.index, age_churn.values)
plt.plot(age_churn.index, age_churn.values, color='black', marker='o', markerfacecolor='orange')
plt.title('Churn Rates for each Customer Age', fontdict={'size': 15})
plt.xlabel('Customer Age', fontdict={'size': 12})
plt.ylabel('Churn Rate', fontdict={'size': 12})
plt.figure(figsize=(10, 6))

plt.grid()
plt.show()
176/170:
#Graph of churn rates for the calculated churn rates for each customer age.
plt.plot(age_churn.index, age_churn.values)
plt.plot(age_churn.index, age_churn.values, color='black', marker='o', markerfacecolor='orange')
plt.title('Churn Rates for each Customer Age', fontdict={'size': 15})
plt.xlabel('Customer Age', fontdict={'size': 12})
plt.ylabel('Churn Rate', fontdict={'size': 12})
plt.figure(figsize=(10, 6))
plt.grid()
plt.show()
176/171:
#Graph of churn rates for the calculated churn rates for each customer age.
plt.figure(figsize=(10, 6))

plt.plot(age_churn.index, age_churn.values)
plt.plot(age_churn.index, age_churn.values, color='black', marker='o', markerfacecolor='orange')
plt.title('Churn Rates for each Customer Age', fontdict={'size': 15})
plt.xlabel('Customer Age', fontdict={'size': 12})
plt.ylabel('Churn Rate', fontdict={'size': 12})
plt.grid()
plt.show()
176/172:
#Graph of churn rates for the calculated churn rates for each customer age.
plt.figure(figsize=(10, 6))
plt.plot(age_churn.index, age_churn.values)
plt.plot(age_churn.index, age_churn.values, color='black', marker='o', markerfacecolor='orange')
plt.title('Churn Rates for each Customer Age', fontdict={'size': 15})
plt.xlabel('Customer Age', fontdict={'size': 12})
plt.ylabel('Churn Rate', fontdict={'size': 12})
plt.grid()
plt.show()
176/173:
#Graph of churn rates for the calculated churn rates for each customer age.
plt.figure(figsize=(10, 10))
plt.plot(age_churn.index, age_churn.values)
plt.plot(age_churn.index, age_churn.values, color='black', marker='o', markerfacecolor='orange')
plt.title('Churn Rates for each Customer Age', fontdict={'size': 15})
plt.xlabel('Customer Age', fontdict={'size': 12})
plt.ylabel('Churn Rate', fontdict={'size': 12})
plt.grid()
plt.show()
176/174:
#Graph of churn rates for the calculated churn rates for each customer age.
plt.figure(figsize=(12, 8))
plt.plot(age_churn.index, age_churn.values)
plt.plot(age_churn.index, age_churn.values, color='black', marker='o', markerfacecolor='orange')
plt.title('Churn Rates for each Customer Age', fontdict={'size': 15})
plt.xlabel('Customer Age', fontdict={'size': 12})
plt.ylabel('Churn Rate', fontdict={'size': 12})
plt.grid()
plt.show()
176/175:
#Graph of churn rates for the calculated churn rates for each customer age.
plt.figure(figsize=(12, 8))
plt.xticks(range(20, 71, 5))
plt.plot(age_churn.index, age_churn.values)
plt.plot(age_churn.index, age_churn.values, color='black', marker='o', markerfacecolor='orange')
plt.title('Churn Rates for each Customer Age', fontdict={'size': 15})
plt.xlabel('Customer Age', fontdict={'size': 12})
plt.ylabel('Churn Rate', fontdict={'size': 12})
plt.grid()
plt.show()
176/176:
#Graph of churn rates for the calculated churn rates for each customer age.
plt.figure(figsize=(12, 8))
plt.xticks(range(20, 5))
plt.plot(age_churn.index, age_churn.values)
plt.plot(age_churn.index, age_churn.values, color='black', marker='o', markerfacecolor='orange')
plt.title('Churn Rates for each Customer Age', fontdict={'size': 15})
plt.xlabel('Customer Age', fontdict={'size': 12})
plt.ylabel('Churn Rate', fontdict={'size': 12})
plt.grid()
plt.show()
176/177:
#Graph of churn rates for the calculated churn rates for each customer age.
plt.figure(figsize=(12, 8))
plt.xticks(range(20, 71))
plt.plot(age_churn.index, age_churn.values)
plt.plot(age_churn.index, age_churn.values, color='black', marker='o', markerfacecolor='orange')
plt.title('Churn Rates for each Customer Age', fontdict={'size': 15})
plt.xlabel('Customer Age', fontdict={'size': 12})
plt.ylabel('Churn Rate', fontdict={'size': 12})
plt.grid()
plt.show()
176/178:
#Graph of churn rates for the calculated churn rates for each customer age.
plt.figure(figsize=(12, 8))
plt.xticks(range(20, 71 ,5))
plt.plot(age_churn.index, age_churn.values)
plt.plot(age_churn.index, age_churn.values, color='black', marker='o', markerfacecolor='orange')
plt.title('Churn Rates for each Customer Age', fontdict={'size': 15})
plt.xlabel('Customer Age', fontdict={'size': 12})
plt.ylabel('Churn Rate', fontdict={'size': 12})
plt.grid()
plt.show()
176/179:
#Graph of churn rates for the calculated churn rates for each customer age.
plt.figure(figsize=(12, 8))
plt.xticks(range(20, 75 ,5))
plt.plot(age_churn.index, age_churn.values)
plt.plot(age_churn.index, age_churn.values, color='black', marker='o', markerfacecolor='orange')
plt.title('Churn Rates for each Customer Age', fontdict={'size': 15})
plt.xlabel('Customer Age', fontdict={'size': 12})
plt.ylabel('Churn Rate', fontdict={'size': 12})
plt.grid()
plt.show()
176/180:
#Graph of churn rates for the calculated churn rates for each customer age.
plt.figure(figsize=(12, 8))
plt.xticks(range(20, 80 ,5))
plt.plot(age_churn.index, age_churn.values)
plt.plot(age_churn.index, age_churn.values, color='black', marker='o', markerfacecolor='orange')
plt.title('Churn Rates for each Customer Age', fontdict={'size': 15})
plt.xlabel('Customer Age', fontdict={'size': 12})
plt.ylabel('Churn Rate', fontdict={'size': 12})
plt.grid()
plt.show()
176/181:
#Graph of churn rates for the calculated churn rates for each customer age.
plt.figure(figsize=(12, 8))
plt.xticks(range(0, 80 ,5))
plt.plot(age_churn.index, age_churn.values)
plt.plot(age_churn.index, age_churn.values, color='black', marker='o', markerfacecolor='orange')
plt.title('Churn Rates for each Customer Age', fontdict={'size': 15})
plt.xlabel('Customer Age', fontdict={'size': 12})
plt.ylabel('Churn Rate', fontdict={'size': 12})
plt.grid()
plt.show()
176/182:
#Graph of churn rates for the calculated churn rates for each customer age.
plt.figure(figsize=(12, 8))
plt.xticks(range(1, 80 ,5))
plt.plot(age_churn.index, age_churn.values)
plt.plot(age_churn.index, age_churn.values, color='black', marker='o', markerfacecolor='orange')
plt.title('Churn Rates for each Customer Age', fontdict={'size': 15})
plt.xlabel('Customer Age', fontdict={'size': 12})
plt.ylabel('Churn Rate', fontdict={'size': 12})
plt.grid()
plt.show()
176/183:
#Graph of churn rates for the calculated churn rates for each customer age.
plt.figure(figsize=(12, 8))
plt.xticks(range(8, 80 ,5))
plt.plot(age_churn.index, age_churn.values)
plt.plot(age_churn.index, age_churn.values, color='black', marker='o', markerfacecolor='orange')
plt.title('Churn Rates for each Customer Age', fontdict={'size': 15})
plt.xlabel('Customer Age', fontdict={'size': 12})
plt.ylabel('Churn Rate', fontdict={'size': 12})
plt.grid()
plt.show()
176/184:
#Graph of churn rates for the calculated churn rates for each customer age.
plt.figure(figsize=(12, 8))
plt.xticks(range(20, 80 ,5))
plt.plot(age_churn.index, age_churn.values)
plt.plot(age_churn.index, age_churn.values, color='black', marker='o', markerfacecolor='orange')
plt.title('Churn Rates for each Customer Age', fontdict={'size': 15})
plt.xlabel('Customer Age', fontdict={'size': 12})
plt.ylabel('Churn Rate', fontdict={'size': 12})
plt.grid()
plt.show()
176/185:
#Graph of churn rates for the calculated churn rates for each customer age.
plt.figure(figsize=(12, 8))
plt.xticks(range(10, 80 ,5))
plt.plot(age_churn.index, age_churn.values)
plt.plot(age_churn.index, age_churn.values, color='black', marker='o', markerfacecolor='orange')
plt.title('Churn Rates for each Customer Age', fontdict={'size': 15})
plt.xlabel('Customer Age', fontdict={'size': 12})
plt.ylabel('Churn Rate', fontdict={'size': 12})
plt.grid()
plt.show()
176/186:
# Graph of churn rates for the calculated churn rates for each customer age.
plt.figure(figsize=(12, 8))
plt.xticks(range(10, 80 ,5))
plt.plot(age_churn.index, age_churn.values)
plt.plot(age_churn.index, age_churn.values, color='black', marker='o', markerfacecolor='orange')
plt.title('Churn Rates for each Customer Age', fontdict={'size': 15})
plt.xlabel('Customer Age', fontdict={'size': 12})
plt.ylabel('Churn Rate', fontdict={'size': 12})
plt.grid()
plt.show()
176/187: # Performing regression analysis to model the relationship between demographic variables and churn rates
176/188:
# Performing regression analysis to model the relationship between demographic variables and churn rates
model = sm.formula.ols('Attrition_Flag ~ Customer_Age', data=df).fit()
176/189:
import pandas as pd
import numpy as np
import matplotlib.pylab as plt
import seaborn as sns
import statsmodels.api as sm

df = pd.read_csv('BankChurners.csv')
df
176/190:
# Performing regression analysis to model the relationship between demographic variables and churn rates
model = sm.formula.ols('Attrition_Flag ~ Customer_Age', data=df).fit()
176/191:
# Performing regression analysis to model the relationship between demographic variables and churn rates
X = df['Age']
y = df['churn']

# add constant to independent variable
X = sm.add_constant(X)

# fit linear regression model
model = sm.OLS(y, X).fit()
176/192:
# Performing regression analysis to model the relationship between demographic variables and churn rates
X = df['Customer_Age']
y = df['churn']

# add constant to independent variable
X = sm.add_constant(X)

# fit linear regression model
model = sm.OLS(y, X).fit()
176/193:
# Performing regression analysis to model the relationship between demographic variables and churn rates
X = df['Customer_Age']
y = df['Attrition_Flag']

# add constant to independent variable
X = sm.add_constant(X)

# fit linear regression model
model = sm.OLS(y, X).fit()
176/194:
# Performing regression analysis to model the relationship between demographic variables and churn rates
X = df['Customer_Age']
y = df['age_churn']

# add constant to independent variable
X = sm.add_constant(X)

# fit linear regression model
model = sm.OLS(y, X).fit()
176/195:
# Performing regression analysis to model the relationship between demographic variables and churn rates
X = newdf['Customer_Age']
y = newdf['age_churn']

# add constant to independent variable
X = sm.add_constant(X)

# fit linear regression model
model = sm.OLS(y, X).fit()
176/196:
# Performing regression analysis to model the relationship between demographic variables and churn rates
age_churn= newdf.groupby('Customer_Age')['Attrition_Flag'].mean()
X = newdf['Customer_Age']
y = newdf['age_churn']

# add constant to independent variable
X = sm.add_constant(X)

# fit linear regression model
model = sm.OLS(y, X).fit()
176/197:
# Performing regression analysis to model the relationship between demographic variables and churn rates
age_churn= newdf.groupby('Customer_Age')['Attrition_Flag'].mean()
X = newdf['Customer_Age']
y = 'age_churn'

# add constant to independent variable
X = sm.add_constant(X)

# fit linear regression model
model = sm.OLS(y, X).fit()
176/198:
# Performing regression analysis to model the relationship between demographic variables and churn rates
age_churn= newdf.groupby('Customer_Age')['Attrition_Flag'].mean()
X = newdf['Customer_Age']
y = df['churn']

# add constant to independent variable
X = sm.add_constant(X)

# fit linear regression model
model = sm.OLS(y, X).fit()

# print model summary
print(model.summary())
176/199:
# Performing regression analysis to model the relationship between demographic variables and churn rates
age_churn= newdf.groupby('Customer_Age')['Attrition_Flag'].mean()
X = newdf['Customer_Age']
y = newdf['churn']

# add constant to independent variable
X = sm.add_constant(X)

# fit linear regression model
model = sm.OLS(y, X).fit()

# print model summary
print(model.summary())
176/200:
#Adding churn column to my dataset
newdf['churn'] = newdf.apply(lambda x: 1 if x['Months_Inactive_12_mon'] >= 6 else 0, axis=1)
176/201:
# Performing regression analysis to model the relationship between demographic variables and churn rates
age_churn= newdf.groupby('Customer_Age')['Attrition_Flag'].mean()
X = newdf['Customer_Age']
y = newdf['churn']

# add constant to independent variable
X = sm.add_constant(X)

# fit linear regression model
model = sm.OLS(y, X).fit()

# print model summary
print(model.summary())
176/202:
# Performing regression analysis to model the relationship between demographic variables and churn rates
age_churn= newdf.groupby('Customer_Age')['Attrition_Flag'].mean()
X = newdf['Customer_Age']
y = newdf['churn']

# fit linear regression model
model = sm.OLS(y, X).fit()

# print model summary
print(model.summary())
176/203:
# Performing regression analysis to model the relationship between demographic variables and churn rates
age_churn= newdf.groupby('Customer_Age')['Attrition_Flag'].mean()
X = newdf['Customer_Age']
y = newdf['churn']

# add constant to independent variable
X = sm.add_constant(X)

# fit linear regression model
model = sm.OLS(y, X).fit()

# print model summary
print(model.summary())
176/204:
# Performing regression analysis to model the relationship between demographic variables and churn rates
age_churn= newdf.groupby('Customer_Age')['Attrition_Flag'].mean()
X = newdf['Customer_Age']
y = newdf['churn']

# fit linear regression model
model = sm.OLS(y, X).fit()

# print model summary
print(model.summary())
176/205:
# Performing regression analysis to model the relationship between demographic variables and churn rates
age_churn= newdf.groupby('Customer_Age')['Attrition_Flag'].mean()
X = newdf['Customer_Age']
y = newdf['churn']

# add constant to independent variable
X = sm.add_constant(X)

# fit linear regression model
model = sm.OLS(y, X).fit()

# print model summary
print(model.summary())
176/206:
# Performing regression analysis to model the relationship between demographic variables and churn rates
age_churn= newdf.groupby('Customer_Age')['Attrition_Flag'].mean()
X = newdf['Customer_Age']
y = newdf['churn']
X = sm.add_constant(X)
age_model = sm.OLS(y, X).fit()
print(model.summary())
176/207:
# Performing regression analysis to model the relationship between demographic variables and churn rates
data = newdf[['Age', 'Attrition_Flag']]

# add constant column to input variables
data = sm.add_constant(data)

# fit logistic regression model
model = sm.Logit(data['Attrition_Flag'], data[['const', 'Age']]).fit()

# print summary of model results
print(model.summary())
176/208:
# Performing regression analysis to model the relationship between demographic variables and churn rates
data = newdf[['Customer_Age', 'Attrition_Flag']]

# add constant column to input variables
data = sm.add_constant(data)

# fit logistic regression model
model = sm.Logit(data['Attrition_Flag'], data[['const', 'Age']]).fit()

# print summary of model results
print(model.summary())
176/209:
# Performing regression analysis to model the relationship between demographic variables and churn rates
data = newdf[['Customer_Age', 'Attrition_Flag']]

# add constant column to input variables
data = sm.add_constant(data)

# fit logistic regression model
model = sm.Logit(data['Attrition_Flag'], data[['const', 'Customer_Age']]).fit()

# print summary of model results
print(model.summary())
176/210:
# Performing regression analysis to model the relationship between demographic variables and churn rates
age_churn= newdf.groupby('Customer_Age')['Attrition_Flag'].mean()
X = newdf['Customer_Age']
y = newdf['churn']
X = sm.add_constant(X)
age_model = sm.Logit(y, X).fit()
print(model.summary())
176/211:
# Performing regression analysis to model the relationship between demographic variables and churn rates
age_churn= newdf.groupby('Customer_Age')['Attrition_Flag'].mean()
model = sm.formula.ols('Attrition_Flag ~ Customer_Age', data=newdf).fit()
print(model.summary())
176/212:
# Performing regression analysis to model the relationship between demographic variables and churn rates
age_churn= newdf.groupby('Customer_Age')['Attrition_Flag'].mean()
model = sm.formula.ols('Customer_Age ~ Churn', data=newdf).fit()
print(model.summary())
176/213:
# Performing regression analysis to model the relationship between demographic variables and churn rates
age_churn= newdf.groupby('Customer_Age')['Attrition_Flag'].mean()
model = sm.formula.ols('Customer_Age ~ churn', data=newdf).fit()
print(model.summary())
176/214:
# Performing regression analysis to model the relationship between demographic variables and churn rates
churn= newdf.groupby('Customer_Age')['Attrition_Flag'].mean()
model = sm.formula.ols('Customer_Age ~ churn', data=newdf).fit()
print(model.summary())
176/215:
# Performing regression analysis to model the relationship between demographic variables and churn rates
churn = newdf.groupby('Customer_Age')['Attrition_Flag'].mean()
model = sm.formula.ols('Customer_Age ~ churn', data=newdf).fit()
print(model.summary())
176/216:
# Performing regression analysis to model the relationship between demographic variables and churn rates
churn = newdf.groupby('Customer_Age')['Attrition_Flag'].mean()
model = sm.formula.Logit('Customer_Age ~ churn', data=newdf).fit()
print(model.summary())
176/217:
# Performing regression analysis to model the relationship between demographic variables and churn rates
churn = newdf.groupby('Customer_Age')['Attrition_Flag'].mean()
model = sm.formula.ols('Customer_Age ~ churn', data=newdf).fit()
print(model.summary())
176/218:
# Performing regression analysis to model the relationship between demographic variables and churn rates
churn = newdf.groupby('Customer_Age')['Attrition_Flag'].mean()
X = sm.add_constant(df['Customer_Age'])
y = df['churn']
model = sm.Logit(y, X).fit()print(model.summary())
176/219:
# Performing regression analysis to model the relationship between demographic variables and churn rates
churn = newdf.groupby('Customer_Age')['Attrition_Flag'].mean()
X = sm.add_constant(df['Customer_Age'])
y = df['churn']
model = sm.Logit(y, X).fit()
print(model.summary())
176/220:
# Performing regression analysis to model the relationship between demographic variables and churn rates
churn = newdf.groupby('Customer_Age')['Attrition_Flag'].mean()
X = sm.add_constant(newdf['Customer_Age'])
y = newdf['churn']
model = sm.Logit(y, X).fit()
print(model.summary())
176/221:
# Performing regression analysis to model the relationship between demographic variables and churn rates
X = sm.add_constant(newdf['Customer_Age'])
y = newdf['churn']
model = sm.Logit(y, X).fit()
print(model.summary())
176/222:
# Graph of churn rates for the calculated churn rates for each customer age.
plt.figure(figsize=(12, 8))
plt.xticks(range(10, 80 ,5))
plt.plot(age_churn.index, age_churn.values)
plt.plot(age_churn.index, age_churn.values, color='black', marker='o', markerfacecolor='orange')
plt.title('Churn Rates for each Customer Age', fontdict={'size': 15})
plt.xlabel('Customer Age', fontdict={'size': 12})
plt.ylabel('Churn Rate', fontdict={'size': 12})
plt.grid()
plt.show()
176/223:
plt.figure(figsize=(12, 8))
plt.xticks(range(10, 80 ,5))
plt.plot(age_churn.index, age_churn.values)
plt.plot(age_churn.index, age_churn.values, color='black', marker='o', markerfacecolor='orange')
plt.title('Churn Rates for each Customer Age', fontdict={'size': 15})
plt.xlabel('Customer Age', fontdict={'size': 12})
plt.ylabel('Churn Rate', fontdict={'size': 12})
plt.grid()
plt.show()
176/224:
plt.figure(figsize=(12, 8))
sns.barplot(x='Credit_Limit', y='Attrition_Flag', data=df)
176/225:
sns.histplot(x='Credit_Limit', data=newdf, bins=20)
plt.title('Distribution of Credit Limit',fontdict={'size': 17})
plt.xlabel('Customer Credit Limit', fontdict={'size': 12})
plt.show()
176/226:
sns.histplot(x='Credit_Limit', data=newdf_cleaned, bins=20)
plt.title('Distribution of Credit Limit',fontdict={'size': 17})
plt.xlabel('Customer Credit Limit', fontdict={'size': 12})
plt.show()
176/227:
plt.figure(figsize=(12, 8))
churn_rates = df.groupby('Credit_Limit')['Attrition_Flag'].mean().reset_index(name='Churn_Rate')
176/228: churn_rates = df.groupby('Credit_Limit')['Attrition_Flag'].mean().reset_index(name='Churn_Rate')
176/229: churn_rates = newdf.groupby('Credit_Limit')['Attrition_Flag'].mean().reset_index(name='Churn_Rate')
176/230:
credit_limits = df['Credit_Limit'].unique()
churn_rates = []
for limit in credit_limits:
    churn_rate = df[df['Credit_Limit']==limit]['Churn'].mean()
    churn_rates.append(churn_rate)

# create scatter plot
plt.scatter(credit_limits, churn_rates)
plt.xlabel('Credit Limit')
plt.ylabel('Churn Rate')
plt.show()
176/231:
credit_limits = df['Credit_Limit'].unique()
churn_rates = []
for limit in credit_limits:
    churn_rate = newdf[newdf['Credit_Limit']==limit]['Churn'].mean()
    churn_rates.append(churn_rate)

# create scatter plot
plt.scatter(credit_limits, churn_rates)
plt.xlabel('Credit Limit')
plt.ylabel('Churn Rate')
plt.show()
176/232:
credit_limits = df['Credit_Limit'].unique()
churn_rates = []
for limit in credit_limits:
    churn_rate = newdf[newdf['Credit_Limit']==limit]['churn'].mean()
    churn_rates.append(churn_rate)

# create scatter plot
plt.scatter(credit_limits, churn_rates)
plt.xlabel('Credit Limit')
plt.ylabel('Churn Rate')
plt.show()
176/233:
credit_limits = df['Credit_Limit'].unique()
churn_rates = []
for limit in credit_limits:
    churn_rate = newdf[newdf['Credit_Limit']==limit]['churn'].mean()
    churn_rates.append(churn_rate)

# create scatter plot
plt.scatter(credit_limits, churn_rates)
plt.xlabel('Credit Limit')
plt.ylabel('Churn Rate')
plt.show()
176/234:
plt.figure(figsize=(12, 8))
plt.bar(churn_rates['Credit_Limit'], churn_rates['Churn_Rate'])
plt.xlabel('Credit Limit')
plt.ylabel('Churn Rate')
plt.title('Churn Rates vs Credit Limit')
plt.show()
176/235:
plt.figure(figsize=(12, 8))
plt.bar(churn_rates['Credit_Limit'], churn_rates['Churn_Rate'])
plt.xlabel('Credit Limit')
plt.ylabel('Churn Rate')
plt.title('Churn Rates vs Credit Limit')
plt.show()
176/236: churn_rate = newdf.groupby('Credit_Limit')['Attrition_Flag'].mean().reset_index(name='Churn_Rate')
176/237: newdf['churn_rate_credit']=newdf.groupby('Credit_Limit')['Attrition_Flag'].mean().reset_index(name='Churn_Rate')
176/238: newdf['churn_rate_credit']=newdf.groupby('Credit_Limit')['Attrition_Flag'].mean().reset_index()
176/239:
churn_rates = newdf.groupby('Credit_Limit')['Attrition_Flag'].mean().reset_index(name='Churn_Rate')
newdf = newdf.merge(churn_rates, on='Credit_Limit')
176/240:
plt.figure(figsize=(12, 8))
plt.bar(churn_rates['Credit_Limit'], churn_rates['Churn_Rate'])
plt.xlabel('Credit Limit')
plt.ylabel('Churn Rate')
plt.title('Churn Rates vs Credit Limit')
plt.show()
176/241:
churn_rate_credit = newdf.groupby('Credit_Limit')['Attrition_Flag'].mean().reset_index(name='Churn_Rate')
newdf = newdf.merge(churn_rates, on='Credit_Limit')
176/242:
churn_rate_credit = newdf.groupby('Credit_Limit')['Attrition_Flag'].mean().reset_index(name='Churn_Rate')
newdf = newdf.merge(churn_rate_credit, on='Credit_Limit')
176/243:
churn_rate_credit = newdf.groupby('Credit_Limit')['Attrition_Flag'].mean().reset_index(name='Churn_Rate')
newdf = newdf.merge(churn_rate_credit, on='Credit_Limit')
newdf.head()
176/244:
plt.figure(figsize=(12, 8))
plt.bar(newdf['Credit_Limit'], newdf['Churn_Rate'])
plt.xlabel('Credit Limit')
plt.ylabel('Churn Rate')
plt.title('Churn Rates vs Credit Limit')
plt.show()
176/245:
plt.figure(figsize=(12, 8))
plt.bar(newdf['Credit_Limit'], newdf['churn_rate_credit'])
plt.xlabel('Credit Limit')
plt.ylabel('Churn Rate')
plt.title('Churn Rates vs Credit Limit')
plt.show()
176/246: newdf.head()
176/247: newdf.head
176/248: newdf
176/249: newdf
176/250: newdf
176/251: newdf
176/252:
newdf
newdf = df.drop(columns=['churn','Churn_Rate_x','Churn_Rate_y','Churn_Rate_x' ,'Churn_Rate_x'])
176/253: newdf
176/254: newdf = df.drop(columns=['churn','Churn_Rate_x','Churn_Rate_y','Churn_Rate_x' ,'Churn_Rate_x'])
176/255: newdf = newdf.drop(columns=['churn','Churn_Rate_x','Churn_Rate_y','Churn_Rate_x' ,'Churn_Rate_x'])
176/256: newdf
176/257:
# I will firstly be analysisng the affect of customer age on churn rates.Below , i have firstly written code to calculate the churn rates for each customer age.
age_churn= newdf.groupby('Customer_Age')['Attrition_Flag'].mean()
176/258:
# Graph of churn rates for the calculated churn rates for each customer age.
plt.figure(figsize=(12, 8))
plt.xticks(range(10, 80 ,5))
plt.plot(age_churn.index, age_churn.values)
plt.plot(age_churn.index, age_churn.values, color='black', marker='o', markerfacecolor='orange')
plt.title('Churn Rates for each Customer Age', fontdict={'size': 15})
plt.xlabel('Customer Age', fontdict={'size': 12})
plt.ylabel('Churn Rate', fontdict={'size': 12})
plt.grid()
plt.show()
176/259: # From the graph above , it can be observed that the customers with age between 65 to 70 have the highest churn rates. It can be seen that younger age customers haver lower churn rates.
176/260:
#Adding churn column to my dataset
newdf['churn'] = newdf.apply(lambda x: 1 if x['Months_Inactive_12_mon'] >= 6 else 0, axis=1)
176/261:
# Performing regression analysis to model the relationship between demographic variables and churn rates
X = sm.add_constant(newdf['Customer_Age'])
y = newdf['churn']
model = sm.Logit(y, X).fit()
print(model.summary())
176/262:
#From the table above , it can be observed thatthere is a statistically significant relationship between customer age and churn rates as the p-value is less than 0.05. From the coefficient of age indicates that an one year increase in age , decreases the odds of churn rates by 0.0344.However , from the graph above
#we know this is not true between the age range 65-70.Overall , there is a significant realptionship between customer age and churn rates but there are other important factors too as the r-squared value is only of 0.0068.
176/263: # Secondly , I will be analysisng the affect of credit limit on churn rates.
176/264: newdf
176/265: newdf = newdf.drop(columns=['churn','Churn_Rate_x','Churn_Rate_y','Churn_Rate_x' ,'Churn_Rate_x'])
176/266: newdf
176/267: # Secondly , I will be analysisng the affect of credit limit on churn rates.
176/268: newdf
176/269: newdf = newdf.drop(columns=['churn','Churn_Rate_x','Churn_Rate_y','Churn_Rate_x' ,'Churn_Rate_x'])
176/270: newdf
176/271:
import pandas as pd
import numpy as np
import matplotlib.pylab as plt
import seaborn as sns
import statsmodels.api as sm

df = pd.read_csv('BankChurners.csv')
df
176/272: df.shape
176/273: #The dataset has 10127 rows and 23 columns.
176/274: df.columns
176/275:
#We can see all the names of the columns in the dataset , there are a lot of columns some of which are not needed in my research.
#Therefore , I will be  remooving them in further steps.
176/276:
df.nunique(axis=0)
#To see the number of unique values in my dataset for each variable.
176/277:
print(df.dtypes)
#Checking the datat types of each column
176/278:
df.describe()
#A numerical summary of the variables in the dataset.
176/279: #The first step in cleaning my dataset is remvoing redundant variables.
176/280: newdf = df.drop(columns=['Avg_Open_To_Buy','Naive_Bayes_Classifier_Attrition_Flag_Card_Category_Contacts_Count_12_mon_Dependent_count_Education_Level_Months_Inactive_12_mon_1','Naive_Bayes_Classifier_Attrition_Flag_Card_Category_Contacts_Count_12_mon_Dependent_count_Education_Level_Months_Inactive_12_mon_2','CLIENTNUM' ,'Total_Relationship_Count','Contacts_Count_12_mon','Total_Trans_Ct','Total_Ct_Chng_Q4_Q1'])
176/281: newdf
176/282:
#The second step in cleaning my dataset is remvoing null values
newdf_cleaned = newdf.dropna(axis=0)
176/283: newdf.shape
176/284: newdf_cleaned.shape
176/285: #The dataset does not contain any null values .Therefore , the shape of the dataset has not been changed.
176/286:
newdf_cleaned = pd.get_dummies(newdf_cleaned, columns=['Gender', 'Education_Level', 'Marital_Status', 'Income_Category', 'Card_Category'], drop_first=True)
# Converting categorical variables into numerical values
176/287:
print(newdf_cleaned.dtypes)
# Checking the data types of each column
176/288: print(newdf_cleaned)
176/289:
sns.countplot(x='Attrition_Flag', data=newdf_cleaned)
plt.title('Churn Rates',fontdict={'size': 17})
plt.xlabel('Customer Type', fontdict={'size': 12})
plt.show()
176/290: # From the graph above , it can be observed that the attrition flag value is significantly  higher for existing customers than attrited customers.Thus , this clearly shows that the dataset is imbalanced as the dataset has a much larger value for existing customers than churned customers.
176/291:
sns.histplot(x='Customer_Age', data=newdf_cleaned, bins=20)
plt.title('Distribution of Age',fontdict={'size': 17})
plt.xlabel('Customer Age', fontdict={'size': 12})
plt.show()
176/292:
# From the graph above , it can be observed that the major percentage of customers are between the age range of appoximately 40 to 60 years old , with a few number of customers in the below 40 and above 60 years old age range. 
# The distribution of the histogram is roughly symmetric with a big peak between the 40 and 50 years old age range.
176/293:
sns.boxplot(x='Attrition_Flag', y='Customer_Age', data=newdf_cleaned)
plt.title('Relationship between Age and Churn Rate',fontdict={'size': 17})
plt.xlabel('Customer Type', fontdict={'size': 12})
plt.ylabel('Customer Age', fontdict={'size': 12})
plt.show()
176/294: # From the graph above , it can be observed that the median age of customers who have churned is a little higher than the median age of customers who have not churned. We can aslo see that the existing customers group have more outliers than the attrited customer group.
176/295:
sns.histplot(x='Credit_Limit', data=newdf_cleaned, bins=20)
plt.title('Distribution of Credit Limit',fontdict={'size': 17})
plt.xlabel('Customer Credit Limit', fontdict={'size': 12})
plt.show()
176/296:
# From the graph above , it can be observed that the majority of customers have a credit limit range of 0-20,000 with a big peak between the 0-5000 credit limit range.Along , with a few customers having a credit limit greater than 3000.
#The distribution of the graph is skewed to the right , which showcases that there are a less number of customers with a credit limit greater than 20,000 or with very high credit limits.
176/297:
sns.boxplot(x='Attrition_Flag', y='Credit_Limit', data=newdf_cleaned)
plt.title('Relationship between Credit Limit and Churn Rate',fontdict={'size': 17})
plt.xlabel('Customer Type', fontdict={'size': 12})
plt.ylabel('Customer Credit Limit', fontdict={'size': 12})
plt.show()
176/298:
# From the graph above , it can be observed that the median credit limit is a little higher for existing customers than customers who have churned.The distribution of the credit limit is wider for existing customers than attrited customers.The attried customers also havea higher number of outlier values than existing customers.
#The graph hints that higher credit limit may be related to lower churn rates but further analysis is required for a concrete conclusion.
176/299:
sns.countplot(x='Gender_M', data=newdf_cleaned)
plt.title('Distribution of Gender',fontdict={'size': 17})
plt.xlabel('Customer Gender (Male = 0 , Female = 1)', fontdict={'size': 12})
plt.show()
176/300: # From the graph above , it can be observed that the dataset contains slightly higher number of male customers than female customers.
176/301:
sns.countplot(x='Gender_M', hue='Attrition_Flag', data=newdf_cleaned)
plt.title('Relationship between Gender and Churn Rate',fontdict={'size': 17})
plt.xlabel('Customer Gender (Male = 0 , Female = 1)', fontdict={'size': 12})
plt.ylabel('Customer Type', fontdict={'size': 12})
plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left')
plt.show()
176/302: # From the graph above , it can be observed that the number of both attrited and exisiting customers is higher for male customers , however the datatset also contains higher number of male customers.Thus , further analysis is required for a concrete conclusion.
176/303:
sns.countplot(x='Education_Level', data=newdf)
plt.title('Distribution of Education Level',fontdict={'size': 17})
plt.xlabel('Education Level', fontdict={'size': 12})
plt.xticks(rotation=45)
plt.show()
176/304: # From the graph above , it can be observed that majority number of customers have a Graduate education level and with a high school education level being the second highest.Also , we can see that the doctorate education level has the least number of customers.
176/305:
sns.countplot(x='Education_Level', hue='Attrition_Flag', data=newdf, order=['Uneducated', 'High School', 'College', 'Graduate', 'Post-Graduate', 'Doctorate'])
plt.title('Relationship between Education Level and Churn Rate' , fontdict={'size': 15})
plt.xlabel('Education Level', fontdict={'size': 12})
plt.ylabel('Count', fontdict={'size': 12})
plt.xticks(rotation=45)
plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left')
plt.show()
176/306:
# From the graph above , it can be observed that the churn rates for graduate education level customers is the highest but it alsooo imporatant to remember that the number of graduate customers is also significantly higher.
# It can also be observed that the higher education levels have a lower churn rates but further analysis is required for a concrete conclusion.
176/307:
sns.countplot(x='Marital_Status', data=newdf)
plt.title('Distribution of Marital Status', fontdict={'size': 17})
plt.xlabel('Marital Status', fontdict={'size': 12})
plt.xticks(rotation=45)
plt.show()
176/308: # From the graph above , it can be observed that the majority of customers are married or single with number of married customers being slightly higher than single customers.
176/309:
sns.countplot(x='Marital_Status', hue='Attrition_Flag', data=newdf)
plt.title('Relationship between Marital Status and Churn Rate', fontdict={'size': 15})
plt.xlabel('Marital Status', fontdict={'size': 12})
plt.ylabel('Customer Type', fontdict={'size': 12})
plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left')
plt.show()
176/310:
# From the graph above , it can be observed that the churn rate for married and single customers is the highest but it also important to consider that the number of married and single customers is also significantly higher.
# Therefore , further analysis is required for a concrete conclusion.
176/311:
sns.countplot(x='Income_Category', data=newdf)
plt.title('Distribution of Income Category',fontdict={'size': 17})
plt.xlabel('Income Category', fontdict={'size': 12})
plt.xticks(rotation=45)
plt.show()
176/312: # From the graph above , it can be observed that the majority of customers are in the income category less than $40k , therefore making the graph skewed to the left.
176/313:
sns.countplot(x='Income_Category', hue='Attrition_Flag', data=newdf, order=['Unknown', 'Less than $40K', '$40K - $60K', '$60K - $80K', '$80K - $120K', '$120K +'])
plt.title('Relationship between Income Category and Churn Rate',fontdict={'size': 17})
plt.xlabel('Customer Income Category', fontdict={'size': 12})
plt.ylabel('Number of Customers', fontdict={'size': 12})
plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left')
plt.xticks(rotation=45)
plt.show()
176/314:
# From the graph above , it can be observed that the churn rates are the highest for customers in the less than $40k income category , but it also important to consider that the number of customers in the less than $40k income category is also significantly higher.
# Therefore , further analysis is required for a concrete conclusion.
176/315:
sns.countplot(x='Card_Category', data=newdf)
plt.title('Distribution of Card Category',fontdict={'size': 17})
plt.xlabel('Card Category', fontdict={'size': 12})
plt.show()
176/316: # From the graph above , it can be observed that the majority of customers are in the blue card category , therefore making the graph skewed to the left.
176/317:
sns.countplot(x='Card_Category', hue='Attrition_Flag', data=newdf)
plt.title('Relationship between Card Category and Churn Rate', fontdict={'size': 15})
plt.xlabel('Card Category', fontdict={'size': 12})
plt.ylabel('Customer Type', fontdict={'size': 12})
plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left')
plt.show()
176/318:
# From the graph above , it can be observed that the churn rates are the highest for customers in the blue card category , but it also important to consider that the number of customers in the blue card category is also significantly higher.
# Therefore , further analysis is required for a concrete conclusion.
176/319:
# I will firstly be analysisng the affect of customer age on churn rates.Below , i have firstly written code to calculate the churn rates for each customer age.
age_churn= newdf.groupby('Customer_Age')['Attrition_Flag'].mean()
176/320: # From the graph above , it can be observed that the customers with age between 65 to 70 have the highest churn rates. It can be seen that younger age customers haver lower churn rates.
176/321:
#Adding churn column to my dataset
newdf['churn'] = newdf.apply(lambda x: 1 if x['Months_Inactive_12_mon'] >= 6 else 0, axis=1)
176/322:
# Performing regression analysis to model the relationship between demographic variables and churn rates
X = sm.add_constant(newdf['Customer_Age'])
y = newdf['churn']
model = sm.Logit(y, X).fit()
print(model.summary())
176/323:
#From the table above , it can be observed thatthere is a statistically significant relationship between customer age and churn rates as the p-value is less than 0.05. From the coefficient of age indicates that an one year increase in age , decreases the odds of churn rates by 0.0344.However , from the graph above
#we know this is not true between the age range 65-70.Overall , there is a significant realptionship between customer age and churn rates but there are other important factors too as the r-squared value is only of 0.0068.
176/324: # Secondly , I will be analysisng the affect of credit limit on churn rates.
176/325: newdf
176/326: newdf = newdf.drop(columns=['churn','Churn_Rate_x','Churn_Rate_y','Churn_Rate_x' ,'Churn_Rate_x'])
176/327: newdf
176/328: newdf
176/329: newdf = newdf.drop(columns=['churn'])
176/330: newdf
176/331:
churn_rates = newdf.groupby('Credit_Limit')['Attrition_Flag'].mean().reset_index(name='Churn_Rate')
newdf = newdf.merge(churn_rates, on='Credit_Limit')
176/332: newdf
176/333: newdf
176/334: newdf
176/335:
# I will firstly be analysisng the affect of customer age on churn rates.Below , i have firstly written code to calculate the churn rates for each customer age.
age_churn= newdf.groupby('Customer_Age')['Attrition_Flag'].mean()
176/336:
import pandas as pd
import numpy as np
import matplotlib.pylab as plt
import seaborn as sns
import statsmodels.api as sm

df = pd.read_csv('BankChurners.csv')
df
176/337: df.shape
176/338: #The dataset has 10127 rows and 23 columns.
176/339: df.columns
176/340:
#We can see all the names of the columns in the dataset , there are a lot of columns some of which are not needed in my research.
#Therefore , I will be  remooving them in further steps.
176/341:
df.nunique(axis=0)
#To see the number of unique values in my dataset for each variable.
176/342:
print(df.dtypes)
#Checking the datat types of each column
176/343:
df.describe()
#A numerical summary of the variables in the dataset.
176/344: #The first step in cleaning my dataset is remvoing redundant variables.
176/345: newdf = df.drop(columns=['Avg_Open_To_Buy','Naive_Bayes_Classifier_Attrition_Flag_Card_Category_Contacts_Count_12_mon_Dependent_count_Education_Level_Months_Inactive_12_mon_1','Naive_Bayes_Classifier_Attrition_Flag_Card_Category_Contacts_Count_12_mon_Dependent_count_Education_Level_Months_Inactive_12_mon_2','CLIENTNUM' ,'Total_Relationship_Count','Contacts_Count_12_mon','Total_Trans_Ct','Total_Ct_Chng_Q4_Q1'])
176/346: newdf
176/347:
#The second step in cleaning my dataset is remvoing null values
newdf_cleaned = newdf.dropna(axis=0)
176/348: newdf.shape
176/349: newdf_cleaned.shape
176/350: #The dataset does not contain any null values .Therefore , the shape of the dataset has not been changed.
176/351:
newdf_cleaned = pd.get_dummies(newdf_cleaned, columns=['Gender', 'Education_Level', 'Marital_Status', 'Income_Category', 'Card_Category'], drop_first=True)
# Converting categorical variables into numerical values
176/352:
print(newdf_cleaned.dtypes)
# Checking the data types of each column
176/353: print(newdf_cleaned)
176/354:
sns.countplot(x='Attrition_Flag', data=newdf_cleaned)
plt.title('Churn Rates',fontdict={'size': 17})
plt.xlabel('Customer Type', fontdict={'size': 12})
plt.show()
176/355: # From the graph above , it can be observed that the attrition flag value is significantly  higher for existing customers than attrited customers.Thus , this clearly shows that the dataset is imbalanced as the dataset has a much larger value for existing customers than churned customers.
176/356:
sns.histplot(x='Customer_Age', data=newdf_cleaned, bins=20)
plt.title('Distribution of Age',fontdict={'size': 17})
plt.xlabel('Customer Age', fontdict={'size': 12})
plt.show()
176/357:
# From the graph above , it can be observed that the major percentage of customers are between the age range of appoximately 40 to 60 years old , with a few number of customers in the below 40 and above 60 years old age range. 
# The distribution of the histogram is roughly symmetric with a big peak between the 40 and 50 years old age range.
176/358:
sns.boxplot(x='Attrition_Flag', y='Customer_Age', data=newdf_cleaned)
plt.title('Relationship between Age and Churn Rate',fontdict={'size': 17})
plt.xlabel('Customer Type', fontdict={'size': 12})
plt.ylabel('Customer Age', fontdict={'size': 12})
plt.show()
176/359: # From the graph above , it can be observed that the median age of customers who have churned is a little higher than the median age of customers who have not churned. We can aslo see that the existing customers group have more outliers than the attrited customer group.
176/360:
sns.histplot(x='Credit_Limit', data=newdf_cleaned, bins=20)
plt.title('Distribution of Credit Limit',fontdict={'size': 17})
plt.xlabel('Customer Credit Limit', fontdict={'size': 12})
plt.show()
176/361:
# From the graph above , it can be observed that the majority of customers have a credit limit range of 0-20,000 with a big peak between the 0-5000 credit limit range.Along , with a few customers having a credit limit greater than 3000.
#The distribution of the graph is skewed to the right , which showcases that there are a less number of customers with a credit limit greater than 20,000 or with very high credit limits.
176/362:
sns.boxplot(x='Attrition_Flag', y='Credit_Limit', data=newdf_cleaned)
plt.title('Relationship between Credit Limit and Churn Rate',fontdict={'size': 17})
plt.xlabel('Customer Type', fontdict={'size': 12})
plt.ylabel('Customer Credit Limit', fontdict={'size': 12})
plt.show()
176/363:
# From the graph above , it can be observed that the median credit limit is a little higher for existing customers than customers who have churned.The distribution of the credit limit is wider for existing customers than attrited customers.The attried customers also havea higher number of outlier values than existing customers.
#The graph hints that higher credit limit may be related to lower churn rates but further analysis is required for a concrete conclusion.
176/364:
sns.countplot(x='Gender_M', data=newdf_cleaned)
plt.title('Distribution of Gender',fontdict={'size': 17})
plt.xlabel('Customer Gender (Male = 0 , Female = 1)', fontdict={'size': 12})
plt.show()
176/365: # From the graph above , it can be observed that the dataset contains slightly higher number of male customers than female customers.
176/366:
sns.countplot(x='Gender_M', hue='Attrition_Flag', data=newdf_cleaned)
plt.title('Relationship between Gender and Churn Rate',fontdict={'size': 17})
plt.xlabel('Customer Gender (Male = 0 , Female = 1)', fontdict={'size': 12})
plt.ylabel('Customer Type', fontdict={'size': 12})
plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left')
plt.show()
176/367: # From the graph above , it can be observed that the number of both attrited and exisiting customers is higher for male customers , however the datatset also contains higher number of male customers.Thus , further analysis is required for a concrete conclusion.
176/368:
sns.countplot(x='Education_Level', data=newdf)
plt.title('Distribution of Education Level',fontdict={'size': 17})
plt.xlabel('Education Level', fontdict={'size': 12})
plt.xticks(rotation=45)
plt.show()
176/369: # From the graph above , it can be observed that majority number of customers have a Graduate education level and with a high school education level being the second highest.Also , we can see that the doctorate education level has the least number of customers.
176/370:
sns.countplot(x='Education_Level', hue='Attrition_Flag', data=newdf, order=['Uneducated', 'High School', 'College', 'Graduate', 'Post-Graduate', 'Doctorate'])
plt.title('Relationship between Education Level and Churn Rate' , fontdict={'size': 15})
plt.xlabel('Education Level', fontdict={'size': 12})
plt.ylabel('Count', fontdict={'size': 12})
plt.xticks(rotation=45)
plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left')
plt.show()
176/371:
# From the graph above , it can be observed that the churn rates for graduate education level customers is the highest but it alsooo imporatant to remember that the number of graduate customers is also significantly higher.
# It can also be observed that the higher education levels have a lower churn rates but further analysis is required for a concrete conclusion.
176/372:
sns.countplot(x='Marital_Status', data=newdf)
plt.title('Distribution of Marital Status', fontdict={'size': 17})
plt.xlabel('Marital Status', fontdict={'size': 12})
plt.xticks(rotation=45)
plt.show()
176/373: # From the graph above , it can be observed that the majority of customers are married or single with number of married customers being slightly higher than single customers.
176/374:
sns.countplot(x='Marital_Status', hue='Attrition_Flag', data=newdf)
plt.title('Relationship between Marital Status and Churn Rate', fontdict={'size': 15})
plt.xlabel('Marital Status', fontdict={'size': 12})
plt.ylabel('Customer Type', fontdict={'size': 12})
plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left')
plt.show()
176/375:
# From the graph above , it can be observed that the churn rate for married and single customers is the highest but it also important to consider that the number of married and single customers is also significantly higher.
# Therefore , further analysis is required for a concrete conclusion.
176/376:
sns.countplot(x='Income_Category', data=newdf)
plt.title('Distribution of Income Category',fontdict={'size': 17})
plt.xlabel('Income Category', fontdict={'size': 12})
plt.xticks(rotation=45)
plt.show()
176/377: # From the graph above , it can be observed that the majority of customers are in the income category less than $40k , therefore making the graph skewed to the left.
176/378:
sns.countplot(x='Income_Category', hue='Attrition_Flag', data=newdf, order=['Unknown', 'Less than $40K', '$40K - $60K', '$60K - $80K', '$80K - $120K', '$120K +'])
plt.title('Relationship between Income Category and Churn Rate',fontdict={'size': 17})
plt.xlabel('Customer Income Category', fontdict={'size': 12})
plt.ylabel('Number of Customers', fontdict={'size': 12})
plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left')
plt.xticks(rotation=45)
plt.show()
176/379:
# From the graph above , it can be observed that the churn rates are the highest for customers in the less than $40k income category , but it also important to consider that the number of customers in the less than $40k income category is also significantly higher.
# Therefore , further analysis is required for a concrete conclusion.
176/380:
sns.countplot(x='Card_Category', data=newdf)
plt.title('Distribution of Card Category',fontdict={'size': 17})
plt.xlabel('Card Category', fontdict={'size': 12})
plt.show()
176/381: # From the graph above , it can be observed that the majority of customers are in the blue card category , therefore making the graph skewed to the left.
176/382:
sns.countplot(x='Card_Category', hue='Attrition_Flag', data=newdf)
plt.title('Relationship between Card Category and Churn Rate', fontdict={'size': 15})
plt.xlabel('Card Category', fontdict={'size': 12})
plt.ylabel('Customer Type', fontdict={'size': 12})
plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left')
plt.show()
176/383:
# From the graph above , it can be observed that the churn rates are the highest for customers in the blue card category , but it also important to consider that the number of customers in the blue card category is also significantly higher.
# Therefore , further analysis is required for a concrete conclusion.
176/384:
# I will firstly be analysisng the affect of customer age on churn rates.Below , i have firstly written code to calculate the churn rates for each customer age.
age_churn= newdf.groupby('Customer_Age')['Attrition_Flag'].mean()
176/385:
# I will firstly be analysisng the affect of customer age on churn rates.Below , i have firstly written code to calculate the churn rates for each customer age.
age_churn = newdf.groupby('Customer_Age')['Attrition_Flag'].mean()
176/386:
# Graph of churn rates for the calculated churn rates for each customer age.
plt.figure(figsize=(12, 8))
plt.xticks(range(10, 80 ,5))
plt.plot(age_churn.index, age_churn.values)
plt.plot(age_churn.index, age_churn.values, color='black', marker='o', markerfacecolor='orange')
plt.title('Churn Rates for each Customer Age', fontdict={'size': 15})
plt.xlabel('Customer Age', fontdict={'size': 12})
plt.ylabel('Churn Rate', fontdict={'size': 12})
plt.grid()
plt.show()
176/387: # From the graph above , it can be observed that the customers with age between 65 to 70 have the highest churn rates. It can be seen that younger age customers haver lower churn rates.
176/388:
#Adding churn column to my dataset
newdf['churn'] = newdf.apply(lambda x: 1 if x['Months_Inactive_12_mon'] >= 6 else 0, axis=1)
176/389:
# Performing regression analysis to model the relationship between demographic variables and churn rates
X = sm.add_constant(newdf['Customer_Age'])
y = newdf['churn']
model = sm.Logit(y, X).fit()
print(model.summary())
176/390:
#From the table above , it can be observed thatthere is a statistically significant relationship between customer age and churn rates as the p-value is less than 0.05. From the coefficient of age indicates that an one year increase in age , decreases the odds of churn rates by 0.0344.However , from the graph above
#we know this is not true between the age range 65-70.Overall , there is a significant realptionship between customer age and churn rates but there are other important factors too as the r-squared value is only of 0.0068.
176/391: # Secondly , I will be analysisng the affect of credit limit on churn rates.
176/392: newdf
176/393: newdf = newdf.drop(columns=['churn'])
176/394: newdf
176/395:
churn_rates = newdf.groupby('Credit_Limit')['Attrition_Flag'].mean()

# Create a bar plot of churn rates for each credit limit
plt.figure(figsize=(12, 8))
churn_rates.plot(kind='bar')
plt.xlabel('Credit Limit')
plt.ylabel('Churn Rate')
plt.title('Churn Rates vs Credit Limit')
plt.show()
176/396:
# I will firstly be analysisng the affect of customer age on churn rates.Below , i have firstly written code to calculate the churn rates for each customer age.
age_churn = newdf.groupby('Customer_Age')['Attrition_Flag'].mean()
176/397:
# Graph of churn rates for the calculated churn rates for each customer age.
plt.figure(figsize=(12, 8))
plt.xticks(range(10, 80 ,5))
plt.plot(age_churn.index, age_churn.values)
plt.plot(age_churn.index, age_churn.values, color='black', marker='o', markerfacecolor='orange')
plt.title('Churn Rates for each Customer Age', fontdict={'size': 15})
plt.xlabel('Customer Age', fontdict={'size': 12})
plt.ylabel('Churn Rate', fontdict={'size': 12})
plt.grid()
plt.show()
176/398: # From the graph above , it can be observed that the customers with age between 65 to 70 have the highest churn rates. It can be seen that younger age customers haver lower churn rates.
176/399:
#Adding churn column to my dataset
newdf['churn'] = newdf.apply(lambda x: 1 if x['Months_Inactive_12_mon'] >= 6 else 0, axis=1)
176/400:
# Performing regression analysis to model the relationship between demographic variables and churn rates
X = sm.add_constant(newdf['Customer_Age'])
y = newdf['churn']
model = sm.Logit(y, X).fit()
print(model.summary())
176/401:
#From the table above , it can be observed thatthere is a statistically significant relationship between customer age and churn rates as the p-value is less than 0.05. From the coefficient of age indicates that an one year increase in age , decreases the odds of churn rates by 0.0344.However , from the graph above
#we know this is not true between the age range 65-70.Overall , there is a significant realptionship between customer age and churn rates but there are other important factors too as the r-squared value is only of 0.0068.
176/402: # Secondly , I will be analysisng the affect of credit limit on churn rates.
176/403: newdf
176/404: newdf = newdf.drop(columns=['churn'])
176/405: newdf
176/406: newdf
176/407: newdf
176/408:
import pandas as pd
import numpy as np
import matplotlib.pylab as plt
import seaborn as sns
import statsmodels.api as sm

df = pd.read_csv('BankChurners.csv')
df
176/409: df.shape
176/410: #The dataset has 10127 rows and 23 columns.
176/411: df.columns
176/412:
#We can see all the names of the columns in the dataset , there are a lot of columns some of which are not needed in my research.
#Therefore , I will be  remooving them in further steps.
176/413:
df.nunique(axis=0)
#To see the number of unique values in my dataset for each variable.
176/414:
print(df.dtypes)
#Checking the datat types of each column
176/415:
df.describe()
#A numerical summary of the variables in the dataset.
176/416: #The first step in cleaning my dataset is remvoing redundant variables.
176/417: newdf = df.drop(columns=['Avg_Open_To_Buy','Naive_Bayes_Classifier_Attrition_Flag_Card_Category_Contacts_Count_12_mon_Dependent_count_Education_Level_Months_Inactive_12_mon_1','Naive_Bayes_Classifier_Attrition_Flag_Card_Category_Contacts_Count_12_mon_Dependent_count_Education_Level_Months_Inactive_12_mon_2','CLIENTNUM' ,'Total_Relationship_Count','Contacts_Count_12_mon','Total_Trans_Ct','Total_Ct_Chng_Q4_Q1'])
176/418: newdf
176/419:
#The second step in cleaning my dataset is remvoing null values
newdf_cleaned = newdf.dropna(axis=0)
176/420: newdf.shape
176/421: newdf_cleaned.shape
176/422: #The dataset does not contain any null values .Therefore , the shape of the dataset has not been changed.
176/423:
newdf_cleaned = pd.get_dummies(newdf_cleaned, columns=['Gender', 'Education_Level', 'Marital_Status', 'Income_Category', 'Card_Category'], drop_first=True)
# Converting categorical variables into numerical values
176/424:
print(newdf_cleaned.dtypes)
# Checking the data types of each column
176/425: print(newdf_cleaned)
176/426:
sns.countplot(x='Attrition_Flag', data=newdf_cleaned)
plt.title('Churn Rates',fontdict={'size': 17})
plt.xlabel('Customer Type', fontdict={'size': 12})
plt.show()
176/427: # From the graph above , it can be observed that the attrition flag value is significantly  higher for existing customers than attrited customers.Thus , this clearly shows that the dataset is imbalanced as the dataset has a much larger value for existing customers than churned customers.
176/428:
sns.histplot(x='Customer_Age', data=newdf_cleaned, bins=20)
plt.title('Distribution of Age',fontdict={'size': 17})
plt.xlabel('Customer Age', fontdict={'size': 12})
plt.show()
176/429:
# From the graph above , it can be observed that the major percentage of customers are between the age range of appoximately 40 to 60 years old , with a few number of customers in the below 40 and above 60 years old age range. 
# The distribution of the histogram is roughly symmetric with a big peak between the 40 and 50 years old age range.
176/430:
sns.boxplot(x='Attrition_Flag', y='Customer_Age', data=newdf_cleaned)
plt.title('Relationship between Age and Churn Rate',fontdict={'size': 17})
plt.xlabel('Customer Type', fontdict={'size': 12})
plt.ylabel('Customer Age', fontdict={'size': 12})
plt.show()
176/431: # From the graph above , it can be observed that the median age of customers who have churned is a little higher than the median age of customers who have not churned. We can aslo see that the existing customers group have more outliers than the attrited customer group.
176/432:
sns.histplot(x='Credit_Limit', data=newdf_cleaned, bins=20)
plt.title('Distribution of Credit Limit',fontdict={'size': 17})
plt.xlabel('Customer Credit Limit', fontdict={'size': 12})
plt.show()
176/433:
# From the graph above , it can be observed that the majority of customers have a credit limit range of 0-20,000 with a big peak between the 0-5000 credit limit range.Along , with a few customers having a credit limit greater than 3000.
#The distribution of the graph is skewed to the right , which showcases that there are a less number of customers with a credit limit greater than 20,000 or with very high credit limits.
176/434:
sns.boxplot(x='Attrition_Flag', y='Credit_Limit', data=newdf_cleaned)
plt.title('Relationship between Credit Limit and Churn Rate',fontdict={'size': 17})
plt.xlabel('Customer Type', fontdict={'size': 12})
plt.ylabel('Customer Credit Limit', fontdict={'size': 12})
plt.show()
176/435:
# From the graph above , it can be observed that the median credit limit is a little higher for existing customers than customers who have churned.The distribution of the credit limit is wider for existing customers than attrited customers.The attried customers also havea higher number of outlier values than existing customers.
#The graph hints that higher credit limit may be related to lower churn rates but further analysis is required for a concrete conclusion.
176/436:
sns.countplot(x='Gender_M', data=newdf_cleaned)
plt.title('Distribution of Gender',fontdict={'size': 17})
plt.xlabel('Customer Gender (Male = 0 , Female = 1)', fontdict={'size': 12})
plt.show()
176/437: # From the graph above , it can be observed that the dataset contains slightly higher number of male customers than female customers.
176/438:
sns.countplot(x='Gender_M', hue='Attrition_Flag', data=newdf_cleaned)
plt.title('Relationship between Gender and Churn Rate',fontdict={'size': 17})
plt.xlabel('Customer Gender (Male = 0 , Female = 1)', fontdict={'size': 12})
plt.ylabel('Customer Type', fontdict={'size': 12})
plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left')
plt.show()
176/439: # From the graph above , it can be observed that the number of both attrited and exisiting customers is higher for male customers , however the datatset also contains higher number of male customers.Thus , further analysis is required for a concrete conclusion.
176/440:
sns.countplot(x='Education_Level', data=newdf)
plt.title('Distribution of Education Level',fontdict={'size': 17})
plt.xlabel('Education Level', fontdict={'size': 12})
plt.xticks(rotation=45)
plt.show()
176/441: # From the graph above , it can be observed that majority number of customers have a Graduate education level and with a high school education level being the second highest.Also , we can see that the doctorate education level has the least number of customers.
176/442:
sns.countplot(x='Education_Level', hue='Attrition_Flag', data=newdf, order=['Uneducated', 'High School', 'College', 'Graduate', 'Post-Graduate', 'Doctorate'])
plt.title('Relationship between Education Level and Churn Rate' , fontdict={'size': 15})
plt.xlabel('Education Level', fontdict={'size': 12})
plt.ylabel('Count', fontdict={'size': 12})
plt.xticks(rotation=45)
plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left')
plt.show()
176/443:
# From the graph above , it can be observed that the churn rates for graduate education level customers is the highest but it alsooo imporatant to remember that the number of graduate customers is also significantly higher.
# It can also be observed that the higher education levels have a lower churn rates but further analysis is required for a concrete conclusion.
176/444:
sns.countplot(x='Marital_Status', data=newdf)
plt.title('Distribution of Marital Status', fontdict={'size': 17})
plt.xlabel('Marital Status', fontdict={'size': 12})
plt.xticks(rotation=45)
plt.show()
176/445: # From the graph above , it can be observed that the majority of customers are married or single with number of married customers being slightly higher than single customers.
176/446:
sns.countplot(x='Marital_Status', hue='Attrition_Flag', data=newdf)
plt.title('Relationship between Marital Status and Churn Rate', fontdict={'size': 15})
plt.xlabel('Marital Status', fontdict={'size': 12})
plt.ylabel('Customer Type', fontdict={'size': 12})
plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left')
plt.show()
176/447:
# From the graph above , it can be observed that the churn rate for married and single customers is the highest but it also important to consider that the number of married and single customers is also significantly higher.
# Therefore , further analysis is required for a concrete conclusion.
176/448:
sns.countplot(x='Income_Category', data=newdf)
plt.title('Distribution of Income Category',fontdict={'size': 17})
plt.xlabel('Income Category', fontdict={'size': 12})
plt.xticks(rotation=45)
plt.show()
176/449: # From the graph above , it can be observed that the majority of customers are in the income category less than $40k , therefore making the graph skewed to the left.
176/450:
sns.countplot(x='Income_Category', hue='Attrition_Flag', data=newdf, order=['Unknown', 'Less than $40K', '$40K - $60K', '$60K - $80K', '$80K - $120K', '$120K +'])
plt.title('Relationship between Income Category and Churn Rate',fontdict={'size': 17})
plt.xlabel('Customer Income Category', fontdict={'size': 12})
plt.ylabel('Number of Customers', fontdict={'size': 12})
plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left')
plt.xticks(rotation=45)
plt.show()
176/451:
# From the graph above , it can be observed that the churn rates are the highest for customers in the less than $40k income category , but it also important to consider that the number of customers in the less than $40k income category is also significantly higher.
# Therefore , further analysis is required for a concrete conclusion.
176/452:
sns.countplot(x='Card_Category', data=newdf)
plt.title('Distribution of Card Category',fontdict={'size': 17})
plt.xlabel('Card Category', fontdict={'size': 12})
plt.show()
176/453: # From the graph above , it can be observed that the majority of customers are in the blue card category , therefore making the graph skewed to the left.
176/454:
sns.countplot(x='Card_Category', hue='Attrition_Flag', data=newdf)
plt.title('Relationship between Card Category and Churn Rate', fontdict={'size': 15})
plt.xlabel('Card Category', fontdict={'size': 12})
plt.ylabel('Customer Type', fontdict={'size': 12})
plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left')
plt.show()
176/455:
# From the graph above , it can be observed that the churn rates are the highest for customers in the blue card category , but it also important to consider that the number of customers in the blue card category is also significantly higher.
# Therefore , further analysis is required for a concrete conclusion.
176/456:
# I will firstly be analysisng the affect of customer age on churn rates.Below , i have firstly written code to calculate the churn rates for each customer age.
age_churn = newdf.groupby('Customer_Age')['Attrition_Flag'].mean()
176/457:
#Adding churn column to my dataset
newdf['churn'] = newdf.apply(lambda x: 1 if x['Months_Inactive_12_mon'] >= 6 else 0, axis=1)
176/458:
# Performing regression analysis to model the relationship between demographic variables and churn rates
X = sm.add_constant(newdf['Customer_Age'])
y = newdf['churn']
model = sm.Logit(y, X).fit()
print(model.summary())
176/459:
#From the table above , it can be observed thatthere is a statistically significant relationship between customer age and churn rates as the p-value is less than 0.05. From the coefficient of age indicates that an one year increase in age , decreases the odds of churn rates by 0.0344.However , from the graph above
#we know this is not true between the age range 65-70.Overall , there is a significant realptionship between customer age and churn rates but there are other important factors too as the r-squared value is only of 0.0068.
176/460: # Secondly , I will be analysisng the affect of credit limit on churn rates.
176/461: newdf
176/462: newdf = newdf.drop(columns=['churn'])
176/463: newdf
176/464: newdf
176/465: newdf
176/466: newdf = newdf.drop(columns=['churn'])
176/467: newdf
176/468:
newdf2 = newdf.drop(columns=['CLIENTNUM', 'Attrition_Flag', 'Customer_Age', 'Dependent_count', 'Months_on_book',
                      'Total_Relationship_Count', 'Months_Inactive_12_mon', 'Contacts_Count_12_mon', 'Credit_Limit',
                      'Total_Revolving_Bal', 'Avg_Open_To_Buy', 'Total_Amt_Chng_Q4_Q1', 'Total_Trans_Amt',
                      'Total_Trans_Ct', 'Total_Ct_Chng_Q4_Q1', 'Avg_Utilization_Ratio'])
176/469:
newdf2 = df.drop(columns=['CLIENTNUM', 'Attrition_Flag', 'Customer_Age', 'Dependent_count', 'Months_on_book',
                      'Total_Relationship_Count', 'Months_Inactive_12_mon', 'Contacts_Count_12_mon', 'Credit_Limit',
                      'Total_Revolving_Bal', 'Avg_Open_To_Buy', 'Total_Amt_Chng_Q4_Q1', 'Total_Trans_Amt',
                      'Total_Trans_Ct', 'Total_Ct_Chng_Q4_Q1', 'Avg_Utilization_Ratio'])
176/470: newdf
176/471: newdf2
176/472: df = df.dropna()
176/473:
df['Gender'] = df['Gender'].replace({'M': 0, 'F': 1})
df['Education_Level'] = df['Education_Level'].replace({'Unknown': 0, 'Uneducated': 1, 'High School': 2,
                                                       'College': 3, 'Graduate': 4, 'Post-Graduate': 5, 'Doctorate': 6})
df['Marital_Status'] = df['Marital_Status'].replace({'Unknown': 0, 'Single': 1, 'Married': 2, 'Divorced': 3})
df['Income_Category'] = df['Income_Category'].replace({'Unknown': 0, 'Less than $40K': 1, '$40K - $60K': 2,
                                                       '$60K - $80K': 3, '$80K - $120K': 4, '$120K +': 5})
176/474:
newdf2['Gender'] = newdf2['Gender'].replace({'M': 0, 'F': 1})
newdf2['Education_Level'] = newdf2['Education_Level'].replace({'Unknown': 0, 'Uneducated': 1, 'High School': 2,
                                                       'College': 3, 'Graduate': 4, 'Post-Graduate': 5, 'Doctorate': 6})
newdf2['Marital_Status'] = newdf2['Marital_Status'].replace({'Unknown': 0, 'Single': 1, 'Married': 2, 'Divorced': 3})
df['Income_Category'] = newdf2['Income_Category'].replace({'Unknown': 0, 'Less than $40K': 1, '$40K - $60K': 2,
                                                       '$60K - $80K': 3, '$80K - $120K': 4, '$120K +': 5})
176/475: newdf2
176/476: gender_churn_rates = df.groupby('Gender')['Attrition_Flag_Churned'].mean().reset_index(name='Churn_Rate')
176/477: churn_rates = newdf.groupby('Gender')['Attrition_Flag'].mean()
176/478: churn_rates = newdf2.groupby('Gender')['Attrition_Flag'].mean()
176/479: newdf
176/480:
newdf2 = df.drop(columns=['CLIENTNUM', 'Naive_Bayes_Classifier_Attrition_Flag_Card_Category_Contacts_Count_12_mon_Dependent_count_Education_Level_Months_Inactive_12_mon_1', 'Customer_Age', 'Dependent_count', 'Months_on_book','Total_Relationship_Count', 'Months_Inactive_12_mon', 'Contacts_Count_12_mon', 'Credit_Limit','Total_Revolving_Bal', 'Avg_Open_To_Buy', 'Total_Amt_Chng_Q4_Q1', 'Total_Trans_Amt',
                          'Total_Trans_Ct', 'Total_Ct_Chng_Q4_Q1', 'Avg_Utilization_Ratio' ,'Naive_Bayes_Classifier_Attrition_Flag_Card_Category_Contacts_Count_12_mon_Dependent_count_Education_Level_Months_Inactive_12_mon_2',])
176/481: newdf2
176/482:
newdf2['Gender'] = newdf2['Gender'].replace({'M': 0, 'F': 1})
newdf2['Education_Level'] = newdf2['Education_Level'].replace({'Unknown': 0, 'Uneducated': 1, 'High School': 2,'College': 3, 'Graduate': 4, 'Post-Graduate': 5, 'Doctorate': 6})

newdf2['Marital_Status'] = newdf2['Marital_Status'].replace({'Unknown': 0, 'Single': 1, 'Married': 2, 'Divorced': 3})
df['Income_Category'] = newdf2['Income_Category'].replace({'Unknown': 0, 'Less than $40K': 1, '$40K - $60K': 2,'$60K - $80K': 3, '$80K - $120K': 4, '$120K +': 5})
176/483: newdf2
176/484: churn_rates = newdf2.groupby('Gender')['Attrition_Flag'].mean()
176/485: newdf2 = newdf2.dropna()
176/486:
newdf2['Gender'] = newdf2['Gender'].replace({'M': 0, 'F': 1})
newdf2['Education_Level'] = newdf2['Education_Level'].replace({'Unknown': 0, 'Uneducated': 1, 'High School': 2,'College': 3, 'Graduate': 4, 'Post-Graduate': 5, 'Doctorate': 6})

newdf2['Marital_Status'] = newdf2['Marital_Status'].replace({'Unknown': 0, 'Single': 1, 'Married': 2, 'Divorced': 3})
df['Income_Category'] = newdf2['Income_Category'].replace({'Unknown': 0, 'Less than $40K': 1, '$40K - $60K': 2,'$60K - $80K': 3, '$80K - $120K': 4, '$120K +': 5})
176/487: newdf2
176/488: churn_rates = newdf2.groupby('Gender')['Attrition_Flag'].mean()
176/489: churn_rates = newdf2.groupby('Gender')['Attrition_Flag'].mean()
176/490:
newdf2 = newdf2.drop(columns=['CLIENTNUM', 'Naive_Bayes_Classifier_Attrition_Flag_Card_Category_Contacts_Count_12_mon_Dependent_count_Education_Level_Months_Inactive_12_mon_1', 'Customer_Age', 'Dependent_count', 'Months_on_book','Total_Relationship_Count', 'Months_Inactive_12_mon', 'Contacts_Count_12_mon', 'Credit_Limit','Total_Revolving_Bal', 'Avg_Open_To_Buy', 'Total_Amt_Chng_Q4_Q1', 'Total_Trans_Amt',
                          'Total_Trans_Ct', 'Total_Ct_Chng_Q4_Q1', 'Avg_Utilization_Ratio' ,'Naive_Bayes_Classifier_Attrition_Flag_Card_Category_Contacts_Count_12_mon_Dependent_count_Education_Level_Months_Inactive_12_mon_2',])
176/491:
newdf2 = df.drop(columns=['CLIENTNUM', 'Naive_Bayes_Classifier_Attrition_Flag_Card_Category_Contacts_Count_12_mon_Dependent_count_Education_Level_Months_Inactive_12_mon_1', 'Customer_Age', 'Dependent_count', 'Months_on_book','Total_Relationship_Count', 'Months_Inactive_12_mon', 'Contacts_Count_12_mon', 'Credit_Limit','Total_Revolving_Bal', 'Avg_Open_To_Buy', 'Total_Amt_Chng_Q4_Q1', 'Total_Trans_Amt',
                          'Total_Trans_Ct', 'Total_Ct_Chng_Q4_Q1', 'Avg_Utilization_Ratio' ,'Naive_Bayes_Classifier_Attrition_Flag_Card_Category_Contacts_Count_12_mon_Dependent_count_Education_Level_Months_Inactive_12_mon_2',])
176/492: newdf2
176/493: newdf2 = newdf2.dropna()
176/494:
newdf2['Gender'] = newdf2['Gender'].replace({'M': 0, 'F': 1})
newdf2['Education_Level'] = newdf2['Education_Level'].replace({'Unknown': 0, 'Uneducated': 1, 'High School': 2,'College': 3, 'Graduate': 4, 'Post-Graduate': 5, 'Doctorate': 6})

newdf2['Marital_Status'] = newdf2['Marital_Status'].replace({'Unknown': 0, 'Single': 1, 'Married': 2, 'Divorced': 3})
df['Income_Category'] = newdf2['Income_Category'].replace({'Unknown': 0, 'Less than $40K': 1, '$40K - $60K': 2,'$60K - $80K': 3, '$80K - $120K': 4, '$120K +': 5})
176/495:
newdf2 = df.drop(columns=['CLIENTNUM', 'Naive_Bayes_Classifier_Attrition_Flag_Card_Category_Contacts_Count_12_mon_Dependent_count_Education_Level_Months_Inactive_12_mon_1', 'Customer_Age', 'Dependent_count', 'Months_on_book','Total_Relationship_Count', 'Months_Inactive_12_mon', 'Contacts_Count_12_mon', 'Credit_Limit','Total_Revolving_Bal', 'Avg_Open_To_Buy', 'Total_Amt_Chng_Q4_Q1', 'Total_Trans_Amt',
                          'Total_Trans_Ct', 'Total_Ct_Chng_Q4_Q1', 'Avg_Utilization_Ratio' ,'Naive_Bayes_Classifier_Attrition_Flag_Card_Category_Contacts_Count_12_mon_Dependent_count_Education_Level_Months_Inactive_12_mon_2','Card_Category'])
176/496: newdf2
176/497: newdf2 = newdf2.dropna()
176/498:
newdf2['Gender'] = newdf2['Gender'].replace({'M': 0, 'F': 1})
newdf2['Education_Level'] = newdf2['Education_Level'].replace({'Unknown': 0, 'Uneducated': 1, 'High School': 2,'College': 3, 'Graduate': 4, 'Post-Graduate': 5, 'Doctorate': 6})

newdf2['Marital_Status'] = newdf2['Marital_Status'].replace({'Unknown': 0, 'Single': 1, 'Married': 2, 'Divorced': 3})
df['Income_Category'] = newdf2['Income_Category'].replace({'Unknown': 0, 'Less than $40K': 1, '$40K - $60K': 2,'$60K - $80K': 3, '$80K - $120K': 4, '$120K +': 5})
176/499: newdf2
176/500: churn_rates = newdf2.groupby('Gender')['Attrition_Flag'].mean()
176/501:
import pandas as pd
import numpy as np
import matplotlib.pylab as plt
import seaborn as sns
import statsmodels.api as sm

df = pd.read_csv('BankChurners.csv')
df
176/502: df.shape
176/503: #The dataset has 10127 rows and 23 columns.
176/504: df.columns
176/505:
#We can see all the names of the columns in the dataset , there are a lot of columns some of which are not needed in my research.
#Therefore , I will be  remooving them in further steps.
176/506:
df.nunique(axis=0)
#To see the number of unique values in my dataset for each variable.
176/507:
print(df.dtypes)
#Checking the datat types of each column
176/508:
df.describe()
#A numerical summary of the variables in the dataset.
176/509: #The first step in cleaning my dataset is remvoing redundant variables.
176/510: newdf = df.drop(columns=['Avg_Open_To_Buy','Naive_Bayes_Classifier_Attrition_Flag_Card_Category_Contacts_Count_12_mon_Dependent_count_Education_Level_Months_Inactive_12_mon_1','Naive_Bayes_Classifier_Attrition_Flag_Card_Category_Contacts_Count_12_mon_Dependent_count_Education_Level_Months_Inactive_12_mon_2','CLIENTNUM' ,'Total_Relationship_Count','Contacts_Count_12_mon','Total_Trans_Ct','Total_Ct_Chng_Q4_Q1'])
176/511: newdf
176/512:
#The second step in cleaning my dataset is remvoing null values
newdf_cleaned = newdf.dropna(axis=0)
176/513: newdf.shape
176/514: newdf_cleaned.shape
176/515: #The dataset does not contain any null values .Therefore , the shape of the dataset has not been changed.
176/516:
newdf_cleaned = pd.get_dummies(newdf_cleaned, columns=['Gender', 'Education_Level', 'Marital_Status', 'Income_Category', 'Card_Category'], drop_first=True)
# Converting categorical variables into numerical values
176/517:
print(newdf_cleaned.dtypes)
# Checking the data types of each column
176/518: print(newdf_cleaned)
176/519:
sns.countplot(x='Attrition_Flag', data=newdf_cleaned)
plt.title('Churn Rates',fontdict={'size': 17})
plt.xlabel('Customer Type', fontdict={'size': 12})
plt.show()
176/520: # From the graph above , it can be observed that the attrition flag value is significantly  higher for existing customers than attrited customers.Thus , this clearly shows that the dataset is imbalanced as the dataset has a much larger value for existing customers than churned customers.
176/521:
sns.histplot(x='Customer_Age', data=newdf_cleaned, bins=20)
plt.title('Distribution of Age',fontdict={'size': 17})
plt.xlabel('Customer Age', fontdict={'size': 12})
plt.show()
176/522:
# From the graph above , it can be observed that the major percentage of customers are between the age range of appoximately 40 to 60 years old , with a few number of customers in the below 40 and above 60 years old age range. 
# The distribution of the histogram is roughly symmetric with a big peak between the 40 and 50 years old age range.
176/523:
sns.boxplot(x='Attrition_Flag', y='Customer_Age', data=newdf_cleaned)
plt.title('Relationship between Age and Churn Rate',fontdict={'size': 17})
plt.xlabel('Customer Type', fontdict={'size': 12})
plt.ylabel('Customer Age', fontdict={'size': 12})
plt.show()
176/524: # From the graph above , it can be observed that the median age of customers who have churned is a little higher than the median age of customers who have not churned. We can aslo see that the existing customers group have more outliers than the attrited customer group.
176/525:
sns.histplot(x='Credit_Limit', data=newdf_cleaned, bins=20)
plt.title('Distribution of Credit Limit',fontdict={'size': 17})
plt.xlabel('Customer Credit Limit', fontdict={'size': 12})
plt.show()
176/526:
# From the graph above , it can be observed that the majority of customers have a credit limit range of 0-20,000 with a big peak between the 0-5000 credit limit range.Along , with a few customers having a credit limit greater than 3000.
#The distribution of the graph is skewed to the right , which showcases that there are a less number of customers with a credit limit greater than 20,000 or with very high credit limits.
176/527:
sns.boxplot(x='Attrition_Flag', y='Credit_Limit', data=newdf_cleaned)
plt.title('Relationship between Credit Limit and Churn Rate',fontdict={'size': 17})
plt.xlabel('Customer Type', fontdict={'size': 12})
plt.ylabel('Customer Credit Limit', fontdict={'size': 12})
plt.show()
176/528:
# From the graph above , it can be observed that the median credit limit is a little higher for existing customers than customers who have churned.The distribution of the credit limit is wider for existing customers than attrited customers.The attried customers also havea higher number of outlier values than existing customers.
#The graph hints that higher credit limit may be related to lower churn rates but further analysis is required for a concrete conclusion.
176/529:
sns.countplot(x='Gender_M', data=newdf_cleaned)
plt.title('Distribution of Gender',fontdict={'size': 17})
plt.xlabel('Customer Gender (Male = 0 , Female = 1)', fontdict={'size': 12})
plt.show()
176/530: # From the graph above , it can be observed that the dataset contains slightly higher number of male customers than female customers.
176/531:
sns.countplot(x='Gender_M', hue='Attrition_Flag', data=newdf_cleaned)
plt.title('Relationship between Gender and Churn Rate',fontdict={'size': 17})
plt.xlabel('Customer Gender (Male = 0 , Female = 1)', fontdict={'size': 12})
plt.ylabel('Customer Type', fontdict={'size': 12})
plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left')
plt.show()
176/532: # From the graph above , it can be observed that the number of both attrited and exisiting customers is higher for male customers , however the datatset also contains higher number of male customers.Thus , further analysis is required for a concrete conclusion.
176/533:
sns.countplot(x='Education_Level', data=newdf)
plt.title('Distribution of Education Level',fontdict={'size': 17})
plt.xlabel('Education Level', fontdict={'size': 12})
plt.xticks(rotation=45)
plt.show()
176/534: # From the graph above , it can be observed that majority number of customers have a Graduate education level and with a high school education level being the second highest.Also , we can see that the doctorate education level has the least number of customers.
176/535:
sns.countplot(x='Education_Level', hue='Attrition_Flag', data=newdf, order=['Uneducated', 'High School', 'College', 'Graduate', 'Post-Graduate', 'Doctorate'])
plt.title('Relationship between Education Level and Churn Rate' , fontdict={'size': 15})
plt.xlabel('Education Level', fontdict={'size': 12})
plt.ylabel('Count', fontdict={'size': 12})
plt.xticks(rotation=45)
plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left')
plt.show()
176/536:
# From the graph above , it can be observed that the churn rates for graduate education level customers is the highest but it alsooo imporatant to remember that the number of graduate customers is also significantly higher.
# It can also be observed that the higher education levels have a lower churn rates but further analysis is required for a concrete conclusion.
176/537:
sns.countplot(x='Marital_Status', data=newdf)
plt.title('Distribution of Marital Status', fontdict={'size': 17})
plt.xlabel('Marital Status', fontdict={'size': 12})
plt.xticks(rotation=45)
plt.show()
176/538: # From the graph above , it can be observed that the majority of customers are married or single with number of married customers being slightly higher than single customers.
176/539:
sns.countplot(x='Marital_Status', hue='Attrition_Flag', data=newdf)
plt.title('Relationship between Marital Status and Churn Rate', fontdict={'size': 15})
plt.xlabel('Marital Status', fontdict={'size': 12})
plt.ylabel('Customer Type', fontdict={'size': 12})
plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left')
plt.show()
176/540:
# From the graph above , it can be observed that the churn rate for married and single customers is the highest but it also important to consider that the number of married and single customers is also significantly higher.
# Therefore , further analysis is required for a concrete conclusion.
176/541:
sns.countplot(x='Income_Category', data=newdf)
plt.title('Distribution of Income Category',fontdict={'size': 17})
plt.xlabel('Income Category', fontdict={'size': 12})
plt.xticks(rotation=45)
plt.show()
176/542: # From the graph above , it can be observed that the majority of customers are in the income category less than $40k , therefore making the graph skewed to the left.
176/543:
sns.countplot(x='Income_Category', hue='Attrition_Flag', data=newdf, order=['Unknown', 'Less than $40K', '$40K - $60K', '$60K - $80K', '$80K - $120K', '$120K +'])
plt.title('Relationship between Income Category and Churn Rate',fontdict={'size': 17})
plt.xlabel('Customer Income Category', fontdict={'size': 12})
plt.ylabel('Number of Customers', fontdict={'size': 12})
plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left')
plt.xticks(rotation=45)
plt.show()
176/544:
# From the graph above , it can be observed that the churn rates are the highest for customers in the less than $40k income category , but it also important to consider that the number of customers in the less than $40k income category is also significantly higher.
# Therefore , further analysis is required for a concrete conclusion.
176/545:
sns.countplot(x='Card_Category', data=newdf)
plt.title('Distribution of Card Category',fontdict={'size': 17})
plt.xlabel('Card Category', fontdict={'size': 12})
plt.show()
176/546: # From the graph above , it can be observed that the majority of customers are in the blue card category , therefore making the graph skewed to the left.
176/547:
sns.countplot(x='Card_Category', hue='Attrition_Flag', data=newdf)
plt.title('Relationship between Card Category and Churn Rate', fontdict={'size': 15})
plt.xlabel('Card Category', fontdict={'size': 12})
plt.ylabel('Customer Type', fontdict={'size': 12})
plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left')
plt.show()
176/548:
# From the graph above , it can be observed that the churn rates are the highest for customers in the blue card category , but it also important to consider that the number of customers in the blue card category is also significantly higher.
# Therefore , further analysis is required for a concrete conclusion.
176/549:
# I will firstly be analysisng the affect of customer age on churn rates.Below , i have firstly written code to calculate the churn rates for each customer age.
age_churn = newdf.groupby('Customer_Age')['Attrition_Flag'].mean()
176/550:
newdf2['Gender'] = newdf2['Gender'].replace({'M': 0, 'F': 1})
newdf2['Education_Level'] = newdf2['Education_Level'].replace({'Unknown': 0, 'Uneducated': 1, 'High School': 2,'College': 3, 'Graduate': 4, 'Post-Graduate': 5, 'Doctorate': 6})

newdf2['Marital_Status'] = newdf2['Marital_Status'].replace({'Unknown': 0, 'Single': 1, 'Married': 2, 'Divorced': 3})
df['Income_Category'] = newdf2['Income_Category'].replace({'Unknown': 0, 'Less than $40K': 1, '$40K - $60K': 2,'$60K - $80K': 3, '$80K - $120K': 4, '$120K +': 5})
176/551: newdf2
176/552: churn_rates = newdf2.groupby('Gender')['Attrition_Flag'].mean()
176/553: df['Gender'] = pd.get_dummies(df['Gender'])['F']
176/554: newdf2['Gender'] = pd.get_dummies(newdf2['Gender'])['F']
176/555: newdf
176/556:
newdf2 = df.drop(columns=['CLIENTNUM', 'Naive_Bayes_Classifier_Attrition_Flag_Card_Category_Contacts_Count_12_mon_Dependent_count_Education_Level_Months_Inactive_12_mon_1', 'Customer_Age', 'Dependent_count', 'Months_on_book','Total_Relationship_Count', 'Months_Inactive_12_mon', 'Contacts_Count_12_mon', 'Credit_Limit','Total_Revolving_Bal', 'Avg_Open_To_Buy', 'Total_Amt_Chng_Q4_Q1', 'Total_Trans_Amt',
                          'Total_Trans_Ct', 'Total_Ct_Chng_Q4_Q1', 'Avg_Utilization_Ratio' ,'Naive_Bayes_Classifier_Attrition_Flag_Card_Category_Contacts_Count_12_mon_Dependent_count_Education_Level_Months_Inactive_12_mon_2','Card_Category'])
176/557: newdf2
176/558: newdf2 = newdf2.dropna()
176/559: newdf2
176/560: newdf
176/561:
newdf2 = df.drop(columns=['CLIENTNUM', 'Naive_Bayes_Classifier_Attrition_Flag_Card_Category_Contacts_Count_12_mon_Dependent_count_Education_Level_Months_Inactive_12_mon_1', 'Customer_Age', 'Dependent_count', 'Months_on_book','Total_Relationship_Count', 'Months_Inactive_12_mon', 'Contacts_Count_12_mon', 'Credit_Limit','Total_Revolving_Bal', 'Avg_Open_To_Buy', 'Total_Amt_Chng_Q4_Q1', 'Total_Trans_Amt',
                          'Total_Trans_Ct', 'Total_Ct_Chng_Q4_Q1', 'Avg_Utilization_Ratio' ,'Naive_Bayes_Classifier_Attrition_Flag_Card_Category_Contacts_Count_12_mon_Dependent_count_Education_Level_Months_Inactive_12_mon_2','Card_Category'])
176/562: newdf2
176/563: newdf2 = pd.get_dummies(newdf2, columns=['Gender', 'Education_Level', 'Marital_Status', 'Income_Category'], drop_first=True)
176/564: newdf2
176/565: churn_rates = df.groupby('Gender')['Attrition_Flag_Churned'].mean()
176/566: churn_rates = df.groupby('Gender')['Attrition_Flag'].mean()
176/567: print(newdf2.dtypes)
176/568: newdf2
176/569:
newdf2 = df.drop(columns=['CLIENTNUM', 'Naive_Bayes_Classifier_Attrition_Flag_Card_Category_Contacts_Count_12_mon_Dependent_count_Education_Level_Months_Inactive_12_mon_1', 'Customer_Age', 'Dependent_count', 'Months_on_book','Total_Relationship_Count', 'Months_Inactive_12_mon', 'Contacts_Count_12_mon', 'Credit_Limit','Total_Revolving_Bal', 'Avg_Open_To_Buy', 'Total_Amt_Chng_Q4_Q1', 'Total_Trans_Amt',
                          'Total_Trans_Ct', 'Total_Ct_Chng_Q4_Q1', 'Avg_Utilization_Ratio' ,'Naive_Bayes_Classifier_Attrition_Flag_Card_Category_Contacts_Count_12_mon_Dependent_count_Education_Level_Months_Inactive_12_mon_2','Card_Category'])
176/570: newdf2
176/571: newdf2 = newdf2.dropna()
176/572: newdf2
176/573:
# I will firstly be analysisng the affect of customer age on churn rates.Below , i have firstly written code to calculate the churn rates for each customer age.
age_churn = newdf.groupby('Customer_Age')['Attrition_Flag'].mean()
176/574: newdf['Attrition_Flag_Churned'] = newdf['Attrition_Flag'].apply(lambda x: 1 if x == 'Attrited Customer' else 0)
176/575: churn_rates = newdf.groupby('Education_Level')['Attrition_Flag_Churned'].mean().reset_index(name='Churn_Rate')
176/576:
plt.figure(figsize=(12, 8))
plt.bar(churn_rates['Education_Level'], churn_rates['Churn_Rate'])
plt.xlabel('Education Level')
plt.ylabel('Churn Rate')
plt.title('Churn Rates vs Education Level')
plt.show()
176/577:
plt.figure(figsize=(10, 6))
plt.plot(edu_churn['Education_Level'], edu_churn['Churn_Rate'], marker='o')
plt.xlabel('Education Level')
plt.ylabel('Churn Rate')
plt.title('Churn Rates vs Education Level')
plt.show()
176/578:
plt.figure(figsize=(10, 6))
plt.plot(churn_rates['Education_Level'], edu_churn['Churn_Rate'], marker='o')
plt.xlabel('Education Level')
plt.ylabel('Churn Rate')
plt.title('Churn Rates vs Education Level')
plt.show()
176/579:
fig, ax = plt.subplots(figsize=(10, 6))
bars = ax.bar(churn_rates['Education_Level'], churn_rates['Churn_Rate'], color='#4C72B0')
176/580:
fig, ax = plt.subplots(figsize=(10, 6))
bars = ax.bar(churn_rates['Education_Level'], churn_rates['Churn_Rate'], color='#4C72B0')
ax.grid(axis='y', linestyle='--', alpha=0.7)
176/581:
fig, ax = plt.subplots(figsize=(10, 6))
bars = ax.bar(churn_rates['Education_Level'], churn_rates['Churn_Rate'], color='#4C72B0')
ax.grid(axis='y', linestyle='--', alpha=0.7)
for bar in bars:
    height = bar.get_height()
    ax.annotate('{:.2f}%'.format(height*100), 
                xy=(bar.get_x() + bar.get_width() / 2, height),
                xytext=(0, 3),  # 3 points vertical offset
                textcoords="offset points",
                ha='center', va='bottom', fontsize=10)

# format the plot
ax.set_xlabel('Education Level', fontsize=12)
ax.set_ylabel('Churn Rate', fontsize=12)
ax.set_title('Churn Rates by Education Level', fontsize=14)
ax.spines['top'].set_visible(False)
ax.spines['right'].set_visible(False)
ax.tick_params(axis='both', labelsize=10)

plt.show()
176/582:
fig, ax = plt.subplots(figsize=(10, 6))
bars = ax.bar(churn_rates['Education_Level'], churn_rates['Churn_Rate'], color='#4C72B0')
ax.grid(axis='y', linestyle='--', alpha=0.7)
for bar in bars:
    height = bar.get_height()
    ax.annotate('{:.2f}%'.format(height*100), 
                xy=(bar.get_x() + bar.get_width() / 2, height),
                xytext=(0, 3),  # 3 points vertical offset
                textcoords="offset points",
                ha='center', va='bottom', fontsize=10)
ax.set_xlabel('Education Level', fontsize=12)
ax.set_ylabel('Churn Rate', fontsize=12)
ax.set_title('Churn Rates by Education Level', fontsize=14)

ax.tick_params(axis='both', labelsize=10)

plt.show()
176/583:
fig, ax = plt.subplots(figsize=(10, 6))
bars = ax.bar(churn_rates['Education_Level'], churn_rates['Churn_Rate'], color='#4C72B0')
ax.grid(axis='y', linestyle='--', alpha=0.7)
for bar in bars:
    height = bar.get_height()
    ax.annotate('{:.2f}%'.format(height*100), 
                xy=(bar.get_x() + bar.get_width() / 2, height),
                xytext=(0, 3),  # 3 points vertical offset
                textcoords="offset points",
                ha='center', va='bottom', fontsize=10)
ax.set_xlabel('Education Level', fontsize=12)
ax.set_ylabel('Churn Rate', fontsize=12)
ax.set_title('Churn Rates by Education Level', fontsize=14)
ax.spines['top'].set_visible(False)
ax.spines['right'].set_visible(False)
ax.tick_params(axis='both', labelsize=10)

plt.show()
176/584:
fig, ax = plt.subplots(figsize=(10, 6))
bars = ax.bar(churn_rates['Education_Level'], churn_rates['Churn_Rate'], color='#4C72B0')
ax.grid(axis='y', linestyle='--', alpha=0.7)
for bar in bars:
    height = bar.get_height()
    ax.annotate('{:.2f}%'.format(height*100), 
                xy=(bar.get_x() + bar.get_width() / 2, height),
                xytext=(0, 3),  # 3 points vertical offset
                textcoords="offset points",
                ha='center', va='bottom', fontsize=10)
ax.set_xlabel('Education Level', fontsize=12)
ax.set_ylabel('Churn Rate', fontsize=12)
ax.set_title('Churn Rates by Education Level', fontsize=14)

plt.show()
176/585:
fig, ax = plt.subplots(figsize=(10, 6))
bars = ax.bar(churn_rates['Education_Level'], churn_rates['Churn_Rate'], color='#4C72B0')
ax.grid(axis='y', linestyle='--', alpha=0.7)
for bar in bars:
    height = bar.get_height()
    ax.annotate('{:.2f}%'.format(height*100), xy=(bar.get_x() + bar.get_width() / 2, height), xytext=(0, 3),textcoords="offset points",, fontsize=10)
ax.set_xlabel('Education Level', fontsize=12)
ax.set_ylabel('Churn Rate', fontsize=12)
ax.set_title('Churn Rates by Education Level', fontsize=14)
plt.show()
176/586:
fig, ax = plt.subplots(figsize=(10, 6))
bars = ax.bar(churn_rates['Education_Level'], churn_rates['Churn_Rate'], color='#4C72B0')
ax.grid(axis='y', linestyle='--', alpha=0.7)
for bar in bars:
    height = bar.get_height()
    ax.annotate('{:.2f}%'.format(height*100), xy=(bar.get_x() + bar.get_width() / 2, height), xytext=(0, 3),textcoords="offset points", fontsize=10)
ax.set_xlabel('Education Level', fontsize=12)
ax.set_ylabel('Churn Rate', fontsize=12)
ax.set_title('Churn Rates by Education Level', fontsize=14)
plt.show()
176/587:
fig, ax = plt.subplots(figsize=(10, 6))
bars = ax.bar(churn_rates['Education_Level'], churn_rates['Churn_Rate'], color='#4C72B0')
ax.grid(axis='y', linestyle='-', alpha=0.7)
for bar in bars:
    height = bar.get_height()
    ax.annotate('{:.2f}%'.format(height*100), xy=(bar.get_x() + bar.get_width() / 2, height), xytext=(0, 3),textcoords="offset points", fontsize=10)
ax.set_xlabel('Education Level', fontsize=12)
ax.set_ylabel('Churn Rate', fontsize=12)
ax.set_title('Churn Rates by Education Level', fontsize=14)
plt.show()
176/588:
fig, ax = plt.subplots(figsize=(10, 6))
bars = ax.bar(churn_rates['Education_Level'], churn_rates['Churn_Rate'], color='#4C72B0')
ax.grid(axis='y', linestyle='-', alpha=1)
for bar in bars:
    height = bar.get_height()
    ax.annotate('{:.2f}%'.format(height*100), xy=(bar.get_x() + bar.get_width() / 2, height), xytext=(0, 3),textcoords="offset points", fontsize=10)
ax.set_xlabel('Education Level', fontsize=12)
ax.set_ylabel('Churn Rate', fontsize=12)
ax.set_title('Churn Rates by Education Level', fontsize=14)
plt.show()
176/589:
fig, ax = plt.subplots(figsize=(10, 6))
bars = ax.bar(churn_rates['Education_Level'], churn_rates['Churn_Rate'], color='#4C72B0')
ax.grid(axis='y', linestyle='-')
for bar in bars:
    height = bar.get_height()
    ax.annotate('{:.2f}%'.format(height*100), xy=(bar.get_x() + bar.get_width() / 2, height), xytext=(0, 3),textcoords="offset points", fontsize=10)
ax.set_xlabel('Education Level', fontsize=12)
ax.set_ylabel('Churn Rate', fontsize=12)
ax.set_title('Churn Rates by Education Level', fontsize=14)
plt.show()
176/590:
fig, ax = plt.subplots(figsize=(10, 6))
bars = ax.bar(churn_rates['Education_Level'], churn_rates['Churn_Rate'], color='#4C72B0')
ax.grid(axis='y', linestyle='-', alpha=1)
for bar in bars:
    height = bar.get_height()
    ax.annotate('{:.2f}%'.format(height*100), xy=(bar.get_x() + bar.get_width() / 2, height), xytext=(0, 3),textcoords="offset points", fontsize=10)
ax.set_xlabel('Education Level', fontsize=12)
ax.set_ylabel('Churn Rate', fontsize=12)
ax.set_title('Churn Rates by Education Level', fontsize=14)
plt.show()
176/591:
fig, ax = plt.subplots(figsize=(10, 6))
bars = ax.bar(churn_rates['Education_Level'], churn_rates['Churn_Rate'], color='#4C72B0')
ax.grid(axis='y', linestyle='-', alpha=0.7)
for bar in bars:
    height = bar.get_height()
    ax.annotate('{:.2f}%'.format(height*100), xy=(bar.get_x() + bar.get_width() / 2, height), xytext=(0, 3),textcoords="offset points", fontsize=10)
ax.set_xlabel('Education Level', fontsize=12)
ax.set_ylabel('Churn Rate', fontsize=12)
ax.set_title('Churn Rates by Education Level', fontsize=14)
plt.show()
176/592:
fig, ax = plt.subplots(figsize=(10, 6))
bars = ax.bar(churn_rates['Education_Level'], churn_rates['Churn_Rate'], color='#4C72B0')
ax.grid(axis='y', linestyle='-')
for bar in bars:
    height = bar.get_height()
    ax.annotate('{:.2f}%'.format(height*100), xy=(bar.get_x() + bar.get_width() / 2, height), xytext=(0, 3),textcoords="offset points", fontsize=10)
ax.set_xlabel('Education Level', fontsize=12)
ax.set_ylabel('Churn Rate', fontsize=12)
ax.set_title('Churn Rates by Education Level', fontsize=14)
plt.show()
176/593:
fig, ax = plt.subplots(figsize=(10, 6))
bars = ax.bar(churn_rates['Education_Level'], churn_rates['Churn_Rate'], color='#4C72B0')
ax.grid(axis='y', linestyle='-')

for bar in bars:
    height = bar.get_height()
    ax.annotate('{:.2f}%'.format(height*100), xy=(bar.get_x() + bar.get_width() / 2, height), xytext=(0, 3),textcoords="offset points", fontsize=10)
ax.set_xlabel('Education Level', fontsize=12)
ax.set_ylabel('Churn Rate', fontsize=12)
ax.set_title('Churn Rates by Education Level', fontsize=14)
plt.show()
176/594:
fig, ax = plt.subplots(figsize=(10, 6))
bars = ax.bar(churn_rates['Education_Level'], churn_rates['Churn_Rate'], color='#4C72B0')
ax.grid(axis='y', linestyle='-')

for bar in bars:
    height = bar.get_height()
ax.set_xlabel('Education Level', fontsize=12)
ax.set_ylabel('Churn Rate', fontsize=12)
ax.set_title('Churn Rates by Education Level', fontsize=14)
plt.show()
176/595:
fig, ax = plt.subplots(figsize=(10, 6))
bars = ax.bar(churn_rates['Education_Level'], churn_rates['Churn_Rate'], color='#4C72B0')
ax.grid(axis='y', linestyle='-')

for bar in bars:
    height = bar.get_height()
    ax.annotate('{:.2f}%'.format(height*100), xy=(bar.get_x() + bar.get_width() / 2, height), xytext=(0, 3),textcoords="offset points", fontsize=10)
ax.set_xlabel('Education Level', fontsize=12)
ax.set_ylabel('Churn Rate', fontsize=12)
ax.set_title('Churn Rates by Education Level', fontsize=14)
plt.show()
176/596:
fig, ax = plt.subplots(figsize=(10, 6))
bars = ax.bar(churn_rates['Education_Level'], churn_rates['Churn_Rate'], color='#4C72B0')
ax.grid(axis='y', linestyle='-')

for bar in bars:
    height = bar.get_height()
    ax.annotate('{:.2f}%'.format(height*100), xy=(bar.get_x() + bar.get_width() / 2, height), xytext=(0, 3), fontsize=10)
ax.set_xlabel('Education Level', fontsize=12)
ax.set_ylabel('Churn Rate', fontsize=12)
ax.set_title('Churn Rates by Education Level', fontsize=14)
plt.show()
176/597:
fig, ax = plt.subplots(figsize=(10, 6))
bars = ax.bar(churn_rates['Education_Level'], churn_rates['Churn_Rate'], color='#4C72B0')
ax.grid(axis='y', linestyle='-')

for bar in bars:
    height = bar.get_height()
    ax.annotate('{:.2f}%'.format(height*100), xy=(bar.get_x() + bar.get_width() / 2, height), xytext=(0, 3),textcoords="offset points", fontsize=10)
ax.set_xlabel('Education Level', fontsize=12)
ax.set_ylabel('Churn Rate', fontsize=12)
ax.set_title('Churn Rates by Education Level', fontsize=14)
plt.show()
176/598:
fig, ax = plt.subplots(figsize=(10, 6))
bars = ax.bar(churn_rates['Education_Level'], churn_rates['Churn_Rate'], color='#4C72B0')
ax.grid(axis='y', linestyle='-')

for bar in bars:
    height = bar.get_height()
    ax.annotate('{:.2f}%'.format(height*100), xy=(bar.get_x() + bar.get_width() / 2, height), xytext=(0, 3),textcoords="offset points", fontsize=10)
    
ax.set_title('Churn Rates by Education Level', fontsize=15)    
ax.set_xlabel('Education Level', fontsize=12)
ax.set_ylabel('Churn Rate', fontsize=12)
plt.xticks(rotation=45)
plt.show()
176/599:
fig, ax = plt.subplots(figsize=(12, 8))
colors = ['#FFC0CB', '#FFA07A', '#FFD700', '#B0E0E6', '#00BFFF', '#8B008B', '#9370DB']

bars = ax.bar(churn_rates['Education_Level'], churn_rates['Churn_Rate'], color='#4C72B0')
ax.grid(axis='y', linestyle='-')

for bar in bars:
    height = bar.get_height()
    ax.annotate('{:.2f}%'.format(height*100), xy=(bar.get_x() + bar.get_width() / 2, height), xytext=(0, 3),textcoords="offset points", fontsize=10)
    
ax.set_title('Churn Rates by Education Level', fontsize=15)    
ax.set_xlabel('Education Level', fontsize=12)
ax.set_ylabel('Churn Rate', fontsize=12)
plt.xticks(rotation=45)
plt.show()
176/600:
fig, ax = plt.subplots(figsize=(12, 8))
colors = ['#FFC0CB', '#FFA07A', '#FFD700', '#B0E0E6', '#00BFFF', '#8B008B', '#9370DB']

bars = ax.bar(churn_rates['Education_Level'], churn_rates['Churn_Rate'],color=colors)
ax.grid(axis='y', linestyle='-')

for bar in bars:
    height = bar.get_height()
    ax.annotate('{:.2f}%'.format(height*100), xy=(bar.get_x() + bar.get_width() / 2, height), xytext=(0, 3),textcoords="offset points", fontsize=10)
    
ax.set_title('Churn Rates by Education Level', fontsize=15)    
ax.set_xlabel('Education Level', fontsize=12)
ax.set_ylabel('Churn Rate', fontsize=12)
plt.xticks(rotation=45)
plt.show()
176/601:
fig, ax = plt.subplots(figsize=(12, 8))
colors = ['lightblue', 'orange', 'yellow', 'green', 'red', 'purple', 'pink', 'gray']

bars = ax.bar(churn_rates['Education_Level'], churn_rates['Churn_Rate'],color=colors)
ax.grid(axis='y', linestyle='-')

for bar in bars:
    height = bar.get_height()
    ax.annotate('{:.2f}%'.format(height*100), xy=(bar.get_x() + bar.get_width() / 2, height), xytext=(0, 3),textcoords="offset points", fontsize=10)
    
ax.set_title('Churn Rates by Education Level', fontsize=15)    
ax.set_xlabel('Education Level', fontsize=12)
ax.set_ylabel('Churn Rate', fontsize=12)
plt.xticks(rotation=45)
plt.show()
176/602:
fig, ax = plt.subplots(figsize=(12, 8))
colors = ['blue', 'orange', 'yellow', 'green', 'red', 'purple', 'pink', 'gray']

bars = ax.bar(churn_rates['Education_Level'], churn_rates['Churn_Rate'],color=colors)
ax.grid(axis='y', linestyle='-')

for bar in bars:
    height = bar.get_height()
    ax.annotate('{:.2f}%'.format(height*100), xy=(bar.get_x() + bar.get_width() / 2, height), xytext=(0, 3),textcoords="offset points", fontsize=10)
    
ax.set_title('Churn Rates by Education Level', fontsize=15)    
ax.set_xlabel('Education Level', fontsize=12)
ax.set_ylabel('Churn Rate', fontsize=12)
plt.xticks(rotation=45)
plt.show()
176/603:
fig, ax = plt.subplots(figsize=(12, 8))
colors = ['blue', 'orange', 'yellow', 'green', 'red', 'purple', 'pink',]

bars = ax.bar(churn_rates['Education_Level'], churn_rates['Churn_Rate'],color=colors)
ax.grid(axis='y', linestyle='-')

for bar in bars:
    height = bar.get_height()
    ax.annotate('{:.2f}%'.format(height*100), xy=(bar.get_x() + bar.get_width() / 2, height), xytext=(0, 3),textcoords="offset points", fontsize=10)
    
ax.set_title('Churn Rates by Education Level', fontsize=15)    
ax.set_xlabel('Education Level', fontsize=12)
ax.set_ylabel('Churn Rate', fontsize=12)
plt.xticks(rotation=45)
plt.show()
176/604:
fig, ax = plt.subplots(figsize=(12, 8))
colors = ['blue', 'orange', 'yellow', 'green', 'red', 'purple', 'pink']

bars = ax.bar(churn_rates['Education_Level'], churn_rates['Churn_Rate'],color=colors)
ax.grid(axis='y', linestyle='-')

for bar in bars:
    height = bar.get_height()
    ax.annotate('{:.2f}%'.format(height*100), xy=(bar.get_x() + bar.get_width() / 2, height), xytext=(0, 3),textcoords="offset points", fontsize=10)
    
ax.set_title('Churn Rates by Education Level', fontsize=15)    
ax.set_xlabel('Education Level', fontsize=12)
ax.set_ylabel('Churn Rate', fontsize=12)
plt.xticks(rotation=45)
plt.show()
176/605:
fig, ax = plt.subplots(figsize=(12, 8))
colors = ['blue', 'orange', 'brown', 'green', 'red', 'purple', 'pink']

bars = ax.bar(churn_rates['Education_Level'], churn_rates['Churn_Rate'],color=colors)
ax.grid(axis='y', linestyle='-')

for bar in bars:
    height = bar.get_height()
    ax.annotate('{:.2f}%'.format(height*100), xy=(bar.get_x() + bar.get_width() / 2, height), xytext=(0, 3),textcoords="offset points", fontsize=10)
    
ax.set_title('Churn Rates by Education Level', fontsize=15)    
ax.set_xlabel('Education Level', fontsize=12)
ax.set_ylabel('Churn Rate', fontsize=12)
plt.xticks(rotation=45)
plt.show()
176/606:
fig, ax = plt.subplots(figsize=(12, 8))
colors = ['blue', 'orange', 'brown', 'green', 'red', 'purple', 'lightgrean']

bars = ax.bar(churn_rates['Education_Level'], churn_rates['Churn_Rate'],color=colors)
ax.grid(axis='y', linestyle='-')

for bar in bars:
    height = bar.get_height()
    ax.annotate('{:.2f}%'.format(height*100), xy=(bar.get_x() + bar.get_width() / 2, height), xytext=(0, 3),textcoords="offset points", fontsize=10)
    
ax.set_title('Churn Rates by Education Level', fontsize=15)    
ax.set_xlabel('Education Level', fontsize=12)
ax.set_ylabel('Churn Rate', fontsize=12)
plt.xticks(rotation=45)
plt.show()
176/607:
fig, ax = plt.subplots(figsize=(12, 8))
colors = ['blue', 'orange', 'brown', 'green', 'red', 'purple', 'lightgreen']

bars = ax.bar(churn_rates['Education_Level'], churn_rates['Churn_Rate'],color=colors)
ax.grid(axis='y', linestyle='-')

for bar in bars:
    height = bar.get_height()
    ax.annotate('{:.2f}%'.format(height*100), xy=(bar.get_x() + bar.get_width() / 2, height), xytext=(0, 3),textcoords="offset points", fontsize=10)
    
ax.set_title('Churn Rates by Education Level', fontsize=15)    
ax.set_xlabel('Education Level', fontsize=12)
ax.set_ylabel('Churn Rate', fontsize=12)
plt.xticks(rotation=45)
plt.show()
176/608: churn_rates['Ratio'] = churn_rates['count'] / churn_rates['count'].sum()
176/609: churn_rates['Churn_Rate_Ratio'] = churn_rates['Churn_Rate'] / customer_counts[churn_rates['Education_Level']].values
176/610:
customer_counts = newdf['Education_Level'].value_counts()
churn_rates['Churn_Rate_Ratio'] = churn_rates['Churn_Rate'] / customer_counts[churn_rates['Education_Level']].values
176/611:
plt.figure(figsize=(12, 8))
plt.bar(churn_rates['Education_Level'], churn_rates['Churn_Rate_Ratio'])
plt.xlabel('Education Level')
plt.ylabel('Churn Rate Ratio')
plt.title('Churn Rates Ratio vs Education Level')
plt.show()
176/612: newdf
176/613:
plt.figure(figsize=(12, 8))
plt.bar(edu_df['Education_Level'], edu_df['Churn_Rate'], color=[colors[x] for x in edu_df['Education_Level']])
plt.xlabel('Education Level')
plt.ylabel('Churn Rate')
plt.title('Churn Rates vs Education Level')
plt.show()
176/614:
fig, ax = plt.subplots(figsize=(12, 8))
colors = ['blue', 'orange', 'brown', 'green', 'red', 'purple', 'lightgreen']

bars = ax.bar(churn_rates['Education_Level'], churn_rates['Churn_Rate'],color=colors)
ax.grid(axis='y', linestyle='-')

for bar in bars:
    height = bar.get_height()
    ax.annotate('{:.2f}%'.format(height*100), xy=(bar.get_x() + bar.get_width() / 2, height), xytext=(0, 3),textcoords="offset points", fontsize=10)
    
ax.set_title('Churn Rates by Education Level', fontsize=15)    
ax.set_xlabel('Education Level', fontsize=12)
ax.set_ylabel('Churn Rate', fontsize=12)
plt.xticks(rotation=45)
plt.show()
176/615:
fig, ax = plt.subplots(figsize=(12, 8))
colors = ['blue', 'orange', 'brown', 'green', 'red', 'purple', 'lightgreen']

bars = ax.bar(churn_rates['Education_Level'], churn_rates['Churn_Rate_Ratio'],color=colors)
ax.grid(axis='y', linestyle='-')

for bar in bars:
    height = bar.get_height()
    ax.annotate('{:.2f}%'.format(height*100), xy=(bar.get_x() + bar.get_width() / 2, height), xytext=(0, 3),textcoords="offset points", fontsize=10)
    
ax.set_title('Churn Rates by Education Level', fontsize=15)    
ax.set_xlabel('Education Level', fontsize=12)
ax.set_ylabel('Churn Rate', fontsize=12)
plt.xticks(rotation=45)
plt.show()
176/616: churn_rates = df.groupby('Marital_Status')['churn_rates'].mean().reset_index(name='Churn_Rate')
176/617: churn_rates = newdf.groupby('Marital_Status')['churn_rates'].mean().reset_index(name='Churn_Rate')
176/618: churn_rates = newdf.groupby('Marital_Status')['Attrition_Flag_Churned'].mean().reset_index(name='Churn_Rate')
176/619: churn_rate_ed = newdf.groupby('Education_Level')['Attrition_Flag_Churned'].mean().reset_index(name='Churn_Rate')
176/620:
fig, ax = plt.subplots(figsize=(12, 8))
colors = ['blue', 'orange', 'brown', 'green', 'red', 'purple', 'lightgreen']

bars = ax.bar(churn_rates['Education_Level'], churn_rates['Churn_Rate'],color=colors)
ax.grid(axis='y', linestyle='-')

for bar in bars:
    height = bar.get_height()
    ax.annotate('{:.2f}%'.format(height*100), xy=(bar.get_x() + bar.get_width() / 2, height), xytext=(0, 3),textcoords="offset points", fontsize=10)
    
ax.set_title('Churn Rates by Education Level', fontsize=15)    
ax.set_xlabel('Education Level', fontsize=12)
ax.set_ylabel('Churn Rate', fontsize=12)
plt.xticks(rotation=45)
plt.show()
176/621:
fig, ax = plt.subplots(figsize=(12, 8))
colors = ['blue', 'orange', 'brown', 'green', 'red', 'purple', 'lightgreen']

bars = ax.bar(churn_rates['Education_Level'], churn_rates['Churn_Rate_Ratio'],color=colors)
ax.grid(axis='y', linestyle='-')

for bar in bars:
    height = bar.get_height()
    ax.annotate('{:.2f}%'.format(height*100), xy=(bar.get_x() + bar.get_width() / 2, height), xytext=(0, 3),textcoords="offset points", fontsize=10)
    
ax.set_title('Churn Rates by Education Level', fontsize=15)    
ax.set_xlabel('Education Level', fontsize=12)
ax.set_ylabel('Churn Rate', fontsize=12)
plt.xticks(rotation=45)
plt.show()
176/622:
fig, ax = plt.subplots(figsize=(12, 8))
colors = ['blue', 'orange', 'brown', 'green', 'red', 'purple', 'lightgreen']

bars = ax.bar(churn_rate_ed['Education_Level'], churn_rates['Churn_Rate'],color=colors)
ax.grid(axis='y', linestyle='-')

for bar in bars:
    height = bar.get_height()
    ax.annotate('{:.2f}%'.format(height*100), xy=(bar.get_x() + bar.get_width() / 2, height), xytext=(0, 3),textcoords="offset points", fontsize=10)
    
ax.set_title('Churn Rates by Education Level', fontsize=15)    
ax.set_xlabel('Education Level', fontsize=12)
ax.set_ylabel('Churn Rate', fontsize=12)
plt.xticks(rotation=45)
plt.show()
176/623:
customer_counts = newdf['Education_Level'].value_counts()
churn_rates['Churn_Rate_Ratio'] = churn_rates['Churn_Rate'] / customer_counts[churn_rates['Education_Level']].values
176/624: newdf['Attrition_Flag_Churned'] = newdf['Attrition_Flag'].apply(lambda x: 1 if x == 'Attrited Customer' else 0)
176/625: newdf
176/626: churn_rates = newdf.groupby('Education_Level')['Attrition_Flag_Churned'].mean().reset_index(name='Churn_Rate')
176/627:
fig, ax = plt.subplots(figsize=(12, 8))
colors = ['blue', 'orange', 'brown', 'green', 'red', 'purple', 'lightgreen']

bars = ax.bar(churn_rates['Education_Level'], churn_rates['Churn_Rate'],color=colors)
ax.grid(axis='y', linestyle='-')

for bar in bars:
    height = bar.get_height()
    ax.annotate('{:.2f}%'.format(height*100), xy=(bar.get_x() + bar.get_width() / 2, height), xytext=(0, 3),textcoords="offset points", fontsize=10)
    
ax.set_title('Churn Rates by Education Level', fontsize=15)    
ax.set_xlabel('Education Level', fontsize=12)
ax.set_ylabel('Churn Rate', fontsize=12)
plt.xticks(rotation=45)
plt.show()
176/628:
customer_counts = newdf['Education_Level'].value_counts()
churn_rates['Churn_Rate_Ratio'] = churn_rates['Churn_Rate'] / customer_counts[churn_rates['Education_Level']].values
176/629:
fig, ax = plt.subplots(figsize=(12, 8))
colors = ['blue', 'orange', 'brown', 'green', 'red', 'purple', 'lightgreen']

bars = ax.bar(churn_rates['Education_Level'], churn_rates['Churn_Rate_Ratio'],color=colors)
ax.grid(axis='y', linestyle='-')

for bar in bars:
    height = bar.get_height()
    ax.annotate('{:.2f}%'.format(height*100), xy=(bar.get_x() + bar.get_width() / 2, height), xytext=(0, 3),textcoords="offset points", fontsize=10)
    
ax.set_title('Churn Rates by Education Level', fontsize=15)    
ax.set_xlabel('Education Level', fontsize=12)
ax.set_ylabel('Churn Rate', fontsize=12)
plt.xticks(rotation=45)
plt.show()
176/630: churn_rates = newdf.groupby('Marital_Status')['Attrition_Flag_Churned'].mean().reset_index(name='Churn_Rate')
176/631:
plt.figure(figsize=(12, 8))
plt.bar(churn_rates['Marital_Status'], churn_rates['Churn_Rate'], color=['blue', 'red', 'green', 'purple', 'orange', 'brown'])
plt.xlabel('Marital Status')
plt.ylabel('Churn Rate')
plt.title('Churn Rates vs Marital Status')
plt.show()
176/632:
fig, ax = plt.subplots(figsize=(12, 8))
colors = ['blue', 'orange', 'brown', 'green']

bars = ax.bar(churn_rates['Marital_Status'], churn_rates['Attrition_Flag_Churned'],color=colors)
ax.grid(axis='y', linestyle='-')

for bar in bars:
    height = bar.get_height()
    ax.annotate('{:.2f}%'.format(height*100), xy=(bar.get_x() + bar.get_width() / 2, height), xytext=(0, 3),textcoords="offset points", fontsize=10)
    
ax.set_title('Churn Rates by Education Level', fontsize=15)    
ax.set_xlabel('Education Level', fontsize=12)
ax.set_ylabel('Churn Rate', fontsize=12)
plt.xticks(rotation=45)
plt.show()
176/633:
plt.figure(figsize=(12, 8))
plt.bar(churn_rates['Marital_Status'], churn_rates['Churn_Rate'], color=['blue', 'red', 'green', 'purple', 'orange', 'brown'])
plt.xlabel('Marital Status')
plt.ylabel('Churn Rate')
plt.title('Churn Rates vs Marital Status')
plt.show()
176/634:
plt.figure(figsize=(10,6))
plt.bar(churn_rates['Marital_Status'], churn_rates['Churn_Rate'], color=colors)
plt.xlabel('Marital Status')
plt.ylabel('Churn Rate')
plt.title('Churn Rates by Marital Status')
plt.show()
176/635:
plt.figure(figsize=(12,8))
plt.bar(churn_rates['Marital_Status'], churn_rates['Churn_Rate'], color=colors)
plt.xlabel('Marital Status')
plt.ylabel('Churn Rate')
plt.title('Churn Rates by Marital Status')
plt.show()
176/636:
plt.figure(figsize=(12,8))

colors = ['blue', 'orange', 'brown', 'green', 'red', 'purple', 'lightgreen']
plt.bar(churn_rates['Marital_Status'], churn_rates['Churn_Rate'], color=colors)
plt.xlabel('Marital Status')
plt.ylabel('Churn Rate')
plt.title('Churn Rates by Marital Status')
plt.show()
176/637:
plt.figure(figsize=(12,8))

colors = ['blue', 'orange', 'brown', 'green', 'red', 'purple', 'lightgreen']

plt.bar(churn_rates['Marital_Status'], churn_rates['Churn_Rate'], color=colors)
plt.xlabel('Marital Status')
plt.ylabel('Churn Rate')
plt.title('Churn Rates by Marital Status')
plt.show()
176/638:
plt.figure(figsize=(12,8))

colors = ['blue', 'orange', 'brown', 'green',]

plt.bar(churn_rates['Marital_Status'], churn_rates['Churn_Rate'], color=colors)
plt.xlabel('Marital Status')
plt.ylabel('Churn Rate')
plt.title('Churn Rates by Marital Status')
plt.show()
176/639:
plt.figure(figsize=(12,8))

colors = ['blue', 'orange', 'brown', 'green',]

bars = ax.bar(churn_rates['Marital_Status'], churn_rates['Churn_Rate'],color=colors)
ax.grid(axis='y', linestyle='-')

for bar in bars:
    height = bar.get_height()
    ax.annotate('{:.2f}%'.format(height*100), xy=(bar.get_x() + bar.get_width() / 2, height), xytext=(0, 3),textcoords="offset points", fontsize=10)
    
plt.xlabel('Marital Status')
plt.ylabel('Churn Rate')
plt.title('Churn Rates by Marital Status')
plt.show()
176/640: churn_rates2 = newdf.groupby('Marital_Status')['Attrition_Flag_Churned'].mean().reset_index(name='Churn_Rate')
176/641:
plt.figure(figsize=(12,8))

colors = ['blue', 'orange', 'brown', 'green',]

bars = ax.bar(churn_rates['Marital_Status'], churn_rates2['Churn_Rate'],color=colors)
ax.grid(axis='y', linestyle='-')

for bar in bars:
    height = bar.get_height()
    ax.annotate('{:.2f}%'.format(height*100), xy=(bar.get_x() + bar.get_width() / 2, height), xytext=(0, 3),textcoords="offset points", fontsize=10)
    
plt.xlabel('Marital Status')
plt.ylabel('Churn Rate')
plt.title('Churn Rates by Marital Status')
plt.show()
176/642: churn_rates2 = newdf.groupby('Marital_Status')['Attrition_Flag_Churned'].mean().reset_index(name='Churn_Rate')
176/643: churn_rates2
176/644: churn_rates
176/645: Churn_Rate_Ratio
176/646: churn_rates['Churn_Rate_Ratio']
176/647: churn_rates
176/648: newdf
176/649: newdf['Attrition_Flag_Churned'] = newdf['Attrition_Flag'].apply(lambda x: 1 if x == 'Attrited Customer' else 0)
176/650: newdf
176/651: churn_rates = newdf.groupby('Education_Level')['Attrition_Flag_Churned'].mean().reset_index(name='Churn_Rate')
176/652: churn_rates
176/653:
fig, ax = plt.subplots(figsize=(12, 8))
colors = ['blue', 'orange', 'brown', 'green', 'red', 'purple', 'lightgreen']

bars = ax.bar(churn_rates['Education_Level'], churn_rates['Churn_Rate'],color=colors)
ax.grid(axis='y', linestyle='-')

for bar in bars:
    height = bar.get_height()
    ax.annotate('{:.2f}%'.format(height*100), xy=(bar.get_x() + bar.get_width() / 2, height), xytext=(0, 3),textcoords="offset points", fontsize=10)
    
ax.set_title('Churn Rates by Education Level', fontsize=15)    
ax.set_xlabel('Education Level', fontsize=12)
ax.set_ylabel('Churn Rate', fontsize=12)
plt.xticks(rotation=45)
plt.show()
176/654:
customer_counts = newdf['Education_Level'].value_counts()
churn_rates['Churn_Rate_Ratio'] = churn_rates['Churn_Rate'] / customer_counts[churn_rates['Education_Level']].values
176/655:
fig, ax = plt.subplots(figsize=(12, 8))
colors = ['blue', 'orange', 'brown', 'green', 'red', 'purple', 'lightgreen']

bars = ax.bar(churn_rates['Education_Level'], churn_rates['Churn_Rate_Ratio'],color=colors)
ax.grid(axis='y', linestyle='-')

for bar in bars:
    height = bar.get_height()
    ax.annotate('{:.2f}%'.format(height*100), xy=(bar.get_x() + bar.get_width() / 2, height), xytext=(0, 3),textcoords="offset points", fontsize=10)
    
ax.set_title('Churn Rates by Education Level', fontsize=15)    
ax.set_xlabel('Education Level', fontsize=12)
ax.set_ylabel('Churn Rate', fontsize=12)
plt.xticks(rotation=45)
plt.show()
176/656: churn_rates2 = newdf.groupby('Marital_Status')['Attrition_Flag_Churned'].mean().reset_index(name='Churn_Rate')
176/657: churn_rates2
176/658:
plt.figure(figsize=(12,8))

colors = ['blue', 'orange', 'brown', 'green',]

bars = ax.bar(churn_rates['Marital_Status'], churn_rates2['Churn_Rate'],color=colors)
ax.grid(axis='y', linestyle='-')

for bar in bars:
    height = bar.get_height()
    ax.annotate('{:.2f}%'.format(height*100), xy=(bar.get_x() + bar.get_width() / 2, height), xytext=(0, 3),textcoords="offset points", fontsize=10)
    
plt.xlabel('Marital Status')
plt.ylabel('Churn Rate')
plt.title('Churn Rates by Marital Status')
plt.show()
176/659:
plt.figure(figsize=(12,8))

colors = ['blue', 'orange', 'brown', 'green',]

bars = ax.bar(churn_rates2['Marital_Status'], churn_rates2['Churn_Rate'],color=colors)
ax.grid(axis='y', linestyle='-')

for bar in bars:
    height = bar.get_height()
    ax.annotate('{:.2f}%'.format(height*100), xy=(bar.get_x() + bar.get_width() / 2, height), xytext=(0, 3),textcoords="offset points", fontsize=10)
    
plt.xlabel('Marital Status')
plt.ylabel('Churn Rate')
plt.title('Churn Rates by Marital Status')
plt.show()
176/660:
import pandas as pd
import numpy as np
import matplotlib.pylab as plt
import seaborn as sns
import statsmodels.api as sm

df = pd.read_csv('BankChurners.csv')
df
176/661: df.shape
176/662: #The dataset has 10127 rows and 23 columns.
176/663: df.columns
176/664:
#We can see all the names of the columns in the dataset , there are a lot of columns some of which are not needed in my research.
#Therefore , I will be  remooving them in further steps.
176/665:
df.nunique(axis=0)
#To see the number of unique values in my dataset for each variable.
176/666:
print(df.dtypes)
#Checking the datat types of each column
176/667:
df.describe()
#A numerical summary of the variables in the dataset.
176/668: #The first step in cleaning my dataset is remvoing redundant variables.
176/669: newdf = df.drop(columns=['Avg_Open_To_Buy','Naive_Bayes_Classifier_Attrition_Flag_Card_Category_Contacts_Count_12_mon_Dependent_count_Education_Level_Months_Inactive_12_mon_1','Naive_Bayes_Classifier_Attrition_Flag_Card_Category_Contacts_Count_12_mon_Dependent_count_Education_Level_Months_Inactive_12_mon_2','CLIENTNUM' ,'Total_Relationship_Count','Contacts_Count_12_mon','Total_Trans_Ct','Total_Ct_Chng_Q4_Q1'])
176/670: newdf
176/671:
#The second step in cleaning my dataset is remvoing null values
newdf_cleaned = newdf.dropna(axis=0)
176/672: newdf.shape
176/673: newdf_cleaned.shape
176/674: #The dataset does not contain any null values .Therefore , the shape of the dataset has not been changed.
176/675:
newdf_cleaned = pd.get_dummies(newdf_cleaned, columns=['Gender', 'Education_Level', 'Marital_Status', 'Income_Category', 'Card_Category'], drop_first=True)
# Converting categorical variables into numerical values
176/676:
print(newdf_cleaned.dtypes)
# Checking the data types of each column
176/677: print(newdf_cleaned)
176/678:
sns.countplot(x='Attrition_Flag', data=newdf_cleaned)
plt.title('Churn Rates',fontdict={'size': 17})
plt.xlabel('Customer Type', fontdict={'size': 12})
plt.show()
176/679: # From the graph above , it can be observed that the attrition flag value is significantly  higher for existing customers than attrited customers.Thus , this clearly shows that the dataset is imbalanced as the dataset has a much larger value for existing customers than churned customers.
176/680:
sns.histplot(x='Customer_Age', data=newdf_cleaned, bins=20)
plt.title('Distribution of Age',fontdict={'size': 17})
plt.xlabel('Customer Age', fontdict={'size': 12})
plt.show()
176/681:
# From the graph above , it can be observed that the major percentage of customers are between the age range of appoximately 40 to 60 years old , with a few number of customers in the below 40 and above 60 years old age range. 
# The distribution of the histogram is roughly symmetric with a big peak between the 40 and 50 years old age range.
176/682:
sns.boxplot(x='Attrition_Flag', y='Customer_Age', data=newdf_cleaned)
plt.title('Relationship between Age and Churn Rate',fontdict={'size': 17})
plt.xlabel('Customer Type', fontdict={'size': 12})
plt.ylabel('Customer Age', fontdict={'size': 12})
plt.show()
176/683: # From the graph above , it can be observed that the median age of customers who have churned is a little higher than the median age of customers who have not churned. We can aslo see that the existing customers group have more outliers than the attrited customer group.
176/684:
sns.histplot(x='Credit_Limit', data=newdf_cleaned, bins=20)
plt.title('Distribution of Credit Limit',fontdict={'size': 17})
plt.xlabel('Customer Credit Limit', fontdict={'size': 12})
plt.show()
176/685:
# From the graph above , it can be observed that the majority of customers have a credit limit range of 0-20,000 with a big peak between the 0-5000 credit limit range.Along , with a few customers having a credit limit greater than 3000.
#The distribution of the graph is skewed to the right , which showcases that there are a less number of customers with a credit limit greater than 20,000 or with very high credit limits.
176/686:
sns.boxplot(x='Attrition_Flag', y='Credit_Limit', data=newdf_cleaned)
plt.title('Relationship between Credit Limit and Churn Rate',fontdict={'size': 17})
plt.xlabel('Customer Type', fontdict={'size': 12})
plt.ylabel('Customer Credit Limit', fontdict={'size': 12})
plt.show()
176/687:
# From the graph above , it can be observed that the median credit limit is a little higher for existing customers than customers who have churned.The distribution of the credit limit is wider for existing customers than attrited customers.The attried customers also havea higher number of outlier values than existing customers.
#The graph hints that higher credit limit may be related to lower churn rates but further analysis is required for a concrete conclusion.
176/688:
sns.countplot(x='Gender_M', data=newdf_cleaned)
plt.title('Distribution of Gender',fontdict={'size': 17})
plt.xlabel('Customer Gender (Male = 0 , Female = 1)', fontdict={'size': 12})
plt.show()
176/689: # From the graph above , it can be observed that the dataset contains slightly higher number of male customers than female customers.
176/690:
sns.countplot(x='Gender_M', hue='Attrition_Flag', data=newdf_cleaned)
plt.title('Relationship between Gender and Churn Rate',fontdict={'size': 17})
plt.xlabel('Customer Gender (Male = 0 , Female = 1)', fontdict={'size': 12})
plt.ylabel('Customer Type', fontdict={'size': 12})
plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left')
plt.show()
176/691: # From the graph above , it can be observed that the number of both attrited and exisiting customers is higher for male customers , however the datatset also contains higher number of male customers.Thus , further analysis is required for a concrete conclusion.
176/692:
sns.countplot(x='Education_Level', data=newdf)
plt.title('Distribution of Education Level',fontdict={'size': 17})
plt.xlabel('Education Level', fontdict={'size': 12})
plt.xticks(rotation=45)
plt.show()
176/693: # From the graph above , it can be observed that majority number of customers have a Graduate education level and with a high school education level being the second highest.Also , we can see that the doctorate education level has the least number of customers.
176/694:
sns.countplot(x='Education_Level', hue='Attrition_Flag', data=newdf, order=['Uneducated', 'High School', 'College', 'Graduate', 'Post-Graduate', 'Doctorate'])
plt.title('Relationship between Education Level and Churn Rate' , fontdict={'size': 15})
plt.xlabel('Education Level', fontdict={'size': 12})
plt.ylabel('Count', fontdict={'size': 12})
plt.xticks(rotation=45)
plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left')
plt.show()
176/695:
# From the graph above , it can be observed that the churn rates for graduate education level customers is the highest but it alsooo imporatant to remember that the number of graduate customers is also significantly higher.
# It can also be observed that the higher education levels have a lower churn rates but further analysis is required for a concrete conclusion.
176/696:
sns.countplot(x='Marital_Status', data=newdf)
plt.title('Distribution of Marital Status', fontdict={'size': 17})
plt.xlabel('Marital Status', fontdict={'size': 12})
plt.xticks(rotation=45)
plt.show()
176/697: # From the graph above , it can be observed that the majority of customers are married or single with number of married customers being slightly higher than single customers.
176/698:
sns.countplot(x='Marital_Status', hue='Attrition_Flag', data=newdf)
plt.title('Relationship between Marital Status and Churn Rate', fontdict={'size': 15})
plt.xlabel('Marital Status', fontdict={'size': 12})
plt.ylabel('Customer Type', fontdict={'size': 12})
plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left')
plt.show()
176/699:
# From the graph above , it can be observed that the churn rate for married and single customers is the highest but it also important to consider that the number of married and single customers is also significantly higher.
# Therefore , further analysis is required for a concrete conclusion.
176/700:
sns.countplot(x='Income_Category', data=newdf)
plt.title('Distribution of Income Category',fontdict={'size': 17})
plt.xlabel('Income Category', fontdict={'size': 12})
plt.xticks(rotation=45)
plt.show()
176/701: # From the graph above , it can be observed that the majority of customers are in the income category less than $40k , therefore making the graph skewed to the left.
176/702:
sns.countplot(x='Income_Category', hue='Attrition_Flag', data=newdf, order=['Unknown', 'Less than $40K', '$40K - $60K', '$60K - $80K', '$80K - $120K', '$120K +'])
plt.title('Relationship between Income Category and Churn Rate',fontdict={'size': 17})
plt.xlabel('Customer Income Category', fontdict={'size': 12})
plt.ylabel('Number of Customers', fontdict={'size': 12})
plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left')
plt.xticks(rotation=45)
plt.show()
176/703:
# From the graph above , it can be observed that the churn rates are the highest for customers in the less than $40k income category , but it also important to consider that the number of customers in the less than $40k income category is also significantly higher.
# Therefore , further analysis is required for a concrete conclusion.
176/704:
sns.countplot(x='Card_Category', data=newdf)
plt.title('Distribution of Card Category',fontdict={'size': 17})
plt.xlabel('Card Category', fontdict={'size': 12})
plt.show()
176/705: # From the graph above , it can be observed that the majority of customers are in the blue card category , therefore making the graph skewed to the left.
176/706:
sns.countplot(x='Card_Category', hue='Attrition_Flag', data=newdf)
plt.title('Relationship between Card Category and Churn Rate', fontdict={'size': 15})
plt.xlabel('Card Category', fontdict={'size': 12})
plt.ylabel('Customer Type', fontdict={'size': 12})
plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left')
plt.show()
176/707:
# From the graph above , it can be observed that the churn rates are the highest for customers in the blue card category , but it also important to consider that the number of customers in the blue card category is also significantly higher.
# Therefore , further analysis is required for a concrete conclusion.
176/708:
# I will firstly be analysisng the affect of customer age on churn rates.Below , i have firstly written code to calculate the churn rates for each customer age.
age_churn = newdf.groupby('Customer_Age')['Attrition_Flag'].mean()
176/709:
#Adding churn column to my dataset
newdf['churn'] = newdf.apply(lambda x: 1 if x['Months_Inactive_12_mon'] >= 6 else 0, axis=1)
176/710:
# Performing regression analysis to model the relationship between demographic variables and churn rates
X = sm.add_constant(newdf['Customer_Age'])
y = newdf['churn']
model = sm.Logit(y, X).fit()
print(model.summary())
176/711:
#From the table above , it can be observed thatthere is a statistically significant relationship between customer age and churn rates as the p-value is less than 0.05. From the coefficient of age indicates that an one year increase in age , decreases the odds of churn rates by 0.0344.However , from the graph above
#we know this is not true between the age range 65-70.Overall , there is a significant realptionship between customer age and churn rates but there are other important factors too as the r-squared value is only of 0.0068.
176/712: newdf
176/713:
newdf2 = df.drop(columns=['CLIENTNUM', 'Naive_Bayes_Classifier_Attrition_Flag_Card_Category_Contacts_Count_12_mon_Dependent_count_Education_Level_Months_Inactive_12_mon_1', 'Customer_Age', 'Dependent_count', 'Months_on_book','Total_Relationship_Count', 'Months_Inactive_12_mon', 'Contacts_Count_12_mon', 'Credit_Limit','Total_Revolving_Bal', 'Avg_Open_To_Buy', 'Total_Amt_Chng_Q4_Q1', 'Total_Trans_Amt',
                          'Total_Trans_Ct', 'Total_Ct_Chng_Q4_Q1', 'Avg_Utilization_Ratio' ,'Naive_Bayes_Classifier_Attrition_Flag_Card_Category_Contacts_Count_12_mon_Dependent_count_Education_Level_Months_Inactive_12_mon_2','Card_Category'])
176/714: newdf2
176/715: newdf2 = newdf2.dropna()
176/716: newdf2
176/717: newdf['Attrition_Flag_Churned'] = newdf['Attrition_Flag'].apply(lambda x: 1 if x == 'Attrited Customer' else 0)
176/718: newdf
176/719: churn_rates = newdf.groupby('Education_Level')['Attrition_Flag_Churned'].mean().reset_index(name='Churn_Rate')
176/720: churn_rates
176/721:
fig, ax = plt.subplots(figsize=(12, 8))
colors = ['blue', 'orange', 'brown', 'green', 'red', 'purple', 'lightgreen']

bars = ax.bar(churn_rates['Education_Level'], churn_rates['Churn_Rate'],color=colors)
ax.grid(axis='y', linestyle='-')

for bar in bars:
    height = bar.get_height()
    ax.annotate('{:.2f}%'.format(height*100), xy=(bar.get_x() + bar.get_width() / 2, height), xytext=(0, 3),textcoords="offset points", fontsize=10)
    
ax.set_title('Churn Rates by Education Level', fontsize=15)    
ax.set_xlabel('Education Level', fontsize=12)
ax.set_ylabel('Churn Rate', fontsize=12)
plt.xticks(rotation=45)
plt.show()
176/722:
customer_counts = newdf['Education_Level'].value_counts()
churn_rates['Churn_Rate_Ratio'] = churn_rates['Churn_Rate'] / customer_counts[churn_rates['Education_Level']].values
176/723:
fig, ax = plt.subplots(figsize=(12, 8))
colors = ['blue', 'orange', 'brown', 'green', 'red', 'purple', 'lightgreen']

bars = ax.bar(churn_rates['Education_Level'], churn_rates['Churn_Rate_Ratio'],color=colors)
ax.grid(axis='y', linestyle='-')

for bar in bars:
    height = bar.get_height()
    ax.annotate('{:.2f}%'.format(height*100), xy=(bar.get_x() + bar.get_width() / 2, height), xytext=(0, 3),textcoords="offset points", fontsize=10)
    
ax.set_title('Churn Rates by Education Level', fontsize=15)    
ax.set_xlabel('Education Level', fontsize=12)
ax.set_ylabel('Churn Rate', fontsize=12)
plt.xticks(rotation=45)
plt.show()
176/724: churn_rates2 = newdf.groupby('Marital_Status')['Attrition_Flag_Churned'].mean().reset_index(name='Churn_Rate')
176/725: churn_rates2
176/726:
plt.figure(figsize=(12,8))

colors = ['blue', 'orange', 'brown', 'green',]

bars = ax.bar(churn_rates2['Marital_Status'], churn_rates2['Churn_Rate'],color=colors)
ax.grid(axis='y', linestyle='-')

for bar in bars:
    height = bar.get_height()
    ax.annotate('{:.2f}%'.format(height*100), xy=(bar.get_x() + bar.get_width() / 2, height), xytext=(0, 3),textcoords="offset points", fontsize=10)
    
plt.xlabel('Marital Status')
plt.ylabel('Churn Rate')
plt.title('Churn Rates by Marital Status')
plt.show()
176/727: churn_rates2 = newdf.groupby('Marital_Status')['Attrition_Flag_Churned'].mean().reset_index(name='Churn_Rate')
176/728: churn_rates2
176/729:
plt.figure(figsize=(12,8))

colors = ['blue', 'orange', 'brown', 'green',]

bars = ax.bar(churn_rates2['Marital_Status'], churn_rates2['Churn_Rate'],color=colors)
ax.grid(axis='y', linestyle='-')

for bar in bars:
    height = bar.get_height()
    ax.annotate('{:.2f}%'.format(height*100), xy=(bar.get_x() + bar.get_width() / 2, height), xytext=(0, 3),textcoords="offset points", fontsize=10)
    
plt.xlabel('Marital Status')
plt.ylabel('Churn Rate')
plt.title('Churn Rates by Marital Status')
plt.show()
176/730:
plt.figure(figsize=(12,8))

colors = ['blue', 'orange', 'brown', 'green',]

ax = plt.bar(churn_rates['Marital_Status'], churn_rates['Churn_Rate'], color=['#00BFFF', '#F08080', '#008080', '#FFA500', '#FF69B4', '#800080'])

    
plt.xlabel('Marital Status')
plt.ylabel('Churn Rate')
plt.title('Churn Rates by Marital Status')
plt.show()
176/731:
plt.figure(figsize=(12,8))

colors = ['blue', 'orange', 'brown', 'green',]

ax = plt.bar(churn_rates['Marital_Status'], churn_rates['Churn_Rate'], color=colors)

    
plt.xlabel('Marital Status')
plt.ylabel('Churn Rate')
plt.title('Churn Rates by Marital Status')
plt.show()
176/732:
plt.figure(figsize=(12,8))

colors = ['blue', 'orange', 'brown', 'green',]

ax = plt.bar(churn_rates2['Marital_Status'], churn_rates2['Churn_Rate'], color=colors)

    
plt.xlabel('Marital Status')
plt.ylabel('Churn Rate')
plt.title('Churn Rates by Marital Status')
plt.show()
176/733:
plt.figure(figsize=(12,8))

colors = ['blue', 'orange', 'brown', 'green',]

ax = plt.bar(churn_rates2['Marital_Status'], churn_rates2['Churn_Rate'], color=colors)

for i, v in enumerate(churn_rates['Churn_Rate']):
    plt.text(i, v+0.01, str(round(v, 3)), ha='center')
    
plt.xlabel('Marital Status')
plt.ylabel('Churn Rate')
plt.title('Churn Rates by Marital Status')
plt.show()
176/734:
plt.figure(figsize=(12,8))

colors = ['blue', 'orange', 'brown', 'green',]

ax = plt.bar(churn_rates2['Marital_Status'], churn_rates2['Churn_Rate'], color=colors)

for bar in bars:
    height = bar.get_height()
    ax.annotate('{:.2f}%'.format(height*100), xy=(bar.get_x() + bar.get_width() / 2, height), xytext=(0, 3),textcoords="offset points", fontsize=10)
    
plt.xlabel('Marital Status')
plt.ylabel('Churn Rate')
plt.title('Churn Rates by Marital Status')
plt.show()
176/735:
plt.figure(figsize=(12,8))

colors = ['blue', 'orange', 'brown', 'green',]

ax = plt.bar(churn_rates2['Marital_Status'], churn_rates2['Churn_Rate'], color=colors)
ax.grid(axis='y', linestyle='-')

for bar in bars:
    height = bar.get_height()
    ax.annotate('{:.2f}%'.format(height*100), xy=(bar.get_x() + bar.get_width() / 2, height), xytext=(0, 3),textcoords="offset points", fontsize=10)
    
plt.xlabel('Marital Status')
plt.ylabel('Churn Rate')
plt.title('Churn Rates by Marital Status')
plt.show()
176/736:
plt.figure(figsize=(12,8))

colors = ['blue', 'orange', 'brown', 'green',]

bars = ax.bar(churn_rates2['Marital_Status'], churn_rates2['Churn_Rate'], color=colors)
ax.grid(axis='y', linestyle='-')

for bar in bars:
    height = bar.get_height()
    ax.annotate('{:.2f}%'.format(height*100), xy=(bar.get_x() + bar.get_width() / 2, height), xytext=(0, 3),textcoords="offset points", fontsize=10)
    
plt.xlabel('Marital Status')
plt.ylabel('Churn Rate')
plt.title('Churn Rates by Marital Status')
plt.show()
176/737:
fig, ax = plt.subplots(figsize=(12, 8))

colors = ['blue', 'orange', 'brown', 'green',]

bars = ax.bar(churn_rates2['Marital_Status'], churn_rates2['Churn_Rate'], color=colors)
ax.grid(axis='y', linestyle='-')

for bar in bars:
    height = bar.get_height()
    ax.annotate('{:.2f}%'.format(height*100), xy=(bar.get_x() + bar.get_width() / 2, height), xytext=(0, 3),textcoords="offset points", fontsize=10)
    
plt.xlabel('Marital Status')
plt.ylabel('Churn Rate')
plt.title('Churn Rates by Marital Status')
plt.show()
176/738:
fig, ax = plt.subplots(figsize=(12, 8))

colors = ['blue', 'orange', 'brown', 'green',]

bars = ax.bar(churn_rates2['Marital_Status'], churn_rates2['Churn_Rate'], color=colors)
ax.grid(axis='y', linestyle='-')

for bar in bars:
    height = bar.get_height()
    ax.annotate('{:.2f}%'.format(height*100), xy=(bar.get_x() + bar.get_width() / 2, height), xytext=(0, 3),textcoords="offset points", fontsize=10)
    
plt.xlabel('Marital Status', fontsize=15)
plt.ylabel('Churn Rate', fontsize=12)
plt.title('Churn Rates by Marital Status', fontsize=12)
plt.show()
176/739:
gender_ratio = df.groupby('Gender').size().reset_index(name='Ratio')
churn_rates = churn_rates.merge(gender_ratio, on='Gender')
176/740: marital_churn = pd.merge(total_customers, churned_customers, on='Marital_Status')
176/741:
df['Total_Customers'] = df.groupby('Marital_Status')['Marital_Status'].transform('count')

# calculate the ratio of customers for each marital status
df['Marital_Status_Ratio'] = df['Total_Customers'] / len(df)

# calculate churn rates by marital status
churn_rates = df.groupby('Marital_Status')['Attrition_Flag_Churned'].mean().reset_index(name='Churn_Rate')

# merge churn rates and marital status ratio on marital status
result = pd.merge(churn_rates, df[['Marital_Status', 'Marital_Status_Ratio']], on='Marital_Status')

# calculate the weighted churn rates based on marital status ratio
result['Weighted_Churn_Rate'] = result['Churn_Rate'] * result['Marital_Status_Ratio']
176/742:
newdf['Total_Customers'] = df.groupby('Marital_Status')['Marital_Status'].transform('count')

# calculate the ratio of customers for each marital status
newdf['Marital_Status_Ratio'] = df['Total_Customers'] / len(df)

# calculate churn rates by marital status
churn_rates = newdf.groupby('Marital_Status')['Attrition_Flag_Churned'].mean().reset_index(name='Churn_Rate')

# merge churn rates and marital status ratio on marital status
result = pd.merge(churn_rates, df[['Marital_Status', 'Marital_Status_Ratio']], on='Marital_Status')

# calculate the weighted churn rates based on marital status ratio
result['Weighted_Churn_Rate'] = result['Churn_Rate'] * result['Marital_Status_Ratio']
176/743:
plt.figure(figsize=(12, 8))
plt.bar(result['Marital_Status'], result['Weighted_Churn_Rate'])
plt.xlabel('Marital Status')
plt.ylabel('Churn Rate')
plt.title('Churn Rates vs Marital Status')
plt.show()
176/744:
plt.figure(figsize=(12, 8))
plt.bar(result['Marital_Status'], result['Weighted_Churn_Rate'])
plt.xlabel('Marital Status')
plt.ylabel('Churn Rate')
plt.title('Churn Rates vs Marital Status')
plt.show()
176/745:
plt.figure(figsize=(12, 8))
plt.bar(result['Marital_Status'], result['Weighted_Churn_Rate'])
plt.xlabel('Marital Status')
plt.ylabel('Churn Rate')
plt.title('Churn Rates vs Marital Status')
plt.show()
176/746:
newdf['Total_Customers'] = df.groupby('Marital_Status')['Marital_Status'].transform('count')

# calculate the ratio of customers for each marital status
newdf['Marital_Status_Ratio'] = df['Total_Customers'] / len(df)

# calculate churn rates by marital status
churn_rates = newdf.groupby('Marital_Status')['Attrition_Flag_Churned'].mean().reset_index(name='Churn_Rate')

# merge churn rates and marital status ratio on marital status
result = pd.merge(churn_rates, df[['Marital_Status', 'Marital_Status_Ratio']], on='Marital_Status')

# calculate the weighted churn rates based on marital status ratio
result['Weighted_Churn_Rate'] = result['Churn_Rate'] * result['Marital_Status_Ratio']
176/747:
import pandas as pd
import numpy as np
import matplotlib.pylab as plt
import seaborn as sns
import statsmodels.api as sm

df = pd.read_csv('BankChurners.csv')
df
176/748: df.shape
176/749: #The dataset has 10127 rows and 23 columns.
176/750: df.columns
176/751:
#We can see all the names of the columns in the dataset , there are a lot of columns some of which are not needed in my research.
#Therefore , I will be  remooving them in further steps.
176/752:
df.nunique(axis=0)
#To see the number of unique values in my dataset for each variable.
176/753:
print(df.dtypes)
#Checking the datat types of each column
176/754:
df.describe()
#A numerical summary of the variables in the dataset.
176/755: #The first step in cleaning my dataset is remvoing redundant variables.
176/756: newdf = df.drop(columns=['Avg_Open_To_Buy','Naive_Bayes_Classifier_Attrition_Flag_Card_Category_Contacts_Count_12_mon_Dependent_count_Education_Level_Months_Inactive_12_mon_1','Naive_Bayes_Classifier_Attrition_Flag_Card_Category_Contacts_Count_12_mon_Dependent_count_Education_Level_Months_Inactive_12_mon_2','CLIENTNUM' ,'Total_Relationship_Count','Contacts_Count_12_mon','Total_Trans_Ct','Total_Ct_Chng_Q4_Q1'])
176/757: newdf
176/758:
#The second step in cleaning my dataset is remvoing null values
newdf_cleaned = newdf.dropna(axis=0)
176/759: newdf.shape
176/760: newdf_cleaned.shape
176/761: #The dataset does not contain any null values .Therefore , the shape of the dataset has not been changed.
176/762:
newdf_cleaned = pd.get_dummies(newdf_cleaned, columns=['Gender', 'Education_Level', 'Marital_Status', 'Income_Category', 'Card_Category'], drop_first=True)
# Converting categorical variables into numerical values
176/763:
print(newdf_cleaned.dtypes)
# Checking the data types of each column
176/764: print(newdf_cleaned)
176/765:
sns.countplot(x='Attrition_Flag', data=newdf_cleaned)
plt.title('Churn Rates',fontdict={'size': 17})
plt.xlabel('Customer Type', fontdict={'size': 12})
plt.show()
176/766: # From the graph above , it can be observed that the attrition flag value is significantly  higher for existing customers than attrited customers.Thus , this clearly shows that the dataset is imbalanced as the dataset has a much larger value for existing customers than churned customers.
176/767:
sns.histplot(x='Customer_Age', data=newdf_cleaned, bins=20)
plt.title('Distribution of Age',fontdict={'size': 17})
plt.xlabel('Customer Age', fontdict={'size': 12})
plt.show()
176/768:
# From the graph above , it can be observed that the major percentage of customers are between the age range of appoximately 40 to 60 years old , with a few number of customers in the below 40 and above 60 years old age range. 
# The distribution of the histogram is roughly symmetric with a big peak between the 40 and 50 years old age range.
176/769:
sns.boxplot(x='Attrition_Flag', y='Customer_Age', data=newdf_cleaned)
plt.title('Relationship between Age and Churn Rate',fontdict={'size': 17})
plt.xlabel('Customer Type', fontdict={'size': 12})
plt.ylabel('Customer Age', fontdict={'size': 12})
plt.show()
176/770: # From the graph above , it can be observed that the median age of customers who have churned is a little higher than the median age of customers who have not churned. We can aslo see that the existing customers group have more outliers than the attrited customer group.
176/771:
sns.histplot(x='Credit_Limit', data=newdf_cleaned, bins=20)
plt.title('Distribution of Credit Limit',fontdict={'size': 17})
plt.xlabel('Customer Credit Limit', fontdict={'size': 12})
plt.show()
176/772:
# From the graph above , it can be observed that the majority of customers have a credit limit range of 0-20,000 with a big peak between the 0-5000 credit limit range.Along , with a few customers having a credit limit greater than 3000.
#The distribution of the graph is skewed to the right , which showcases that there are a less number of customers with a credit limit greater than 20,000 or with very high credit limits.
176/773:
sns.boxplot(x='Attrition_Flag', y='Credit_Limit', data=newdf_cleaned)
plt.title('Relationship between Credit Limit and Churn Rate',fontdict={'size': 17})
plt.xlabel('Customer Type', fontdict={'size': 12})
plt.ylabel('Customer Credit Limit', fontdict={'size': 12})
plt.show()
176/774:
# From the graph above , it can be observed that the median credit limit is a little higher for existing customers than customers who have churned.The distribution of the credit limit is wider for existing customers than attrited customers.The attried customers also havea higher number of outlier values than existing customers.
#The graph hints that higher credit limit may be related to lower churn rates but further analysis is required for a concrete conclusion.
176/775:
sns.countplot(x='Gender_M', data=newdf_cleaned)
plt.title('Distribution of Gender',fontdict={'size': 17})
plt.xlabel('Customer Gender (Male = 0 , Female = 1)', fontdict={'size': 12})
plt.show()
176/776: # From the graph above , it can be observed that the dataset contains slightly higher number of male customers than female customers.
176/777:
sns.countplot(x='Gender_M', hue='Attrition_Flag', data=newdf_cleaned)
plt.title('Relationship between Gender and Churn Rate',fontdict={'size': 17})
plt.xlabel('Customer Gender (Male = 0 , Female = 1)', fontdict={'size': 12})
plt.ylabel('Customer Type', fontdict={'size': 12})
plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left')
plt.show()
176/778: # From the graph above , it can be observed that the number of both attrited and exisiting customers is higher for male customers , however the datatset also contains higher number of male customers.Thus , further analysis is required for a concrete conclusion.
176/779:
sns.countplot(x='Education_Level', data=newdf)
plt.title('Distribution of Education Level',fontdict={'size': 17})
plt.xlabel('Education Level', fontdict={'size': 12})
plt.xticks(rotation=45)
plt.show()
176/780: # From the graph above , it can be observed that majority number of customers have a Graduate education level and with a high school education level being the second highest.Also , we can see that the doctorate education level has the least number of customers.
176/781:
sns.countplot(x='Education_Level', hue='Attrition_Flag', data=newdf, order=['Uneducated', 'High School', 'College', 'Graduate', 'Post-Graduate', 'Doctorate'])
plt.title('Relationship between Education Level and Churn Rate' , fontdict={'size': 15})
plt.xlabel('Education Level', fontdict={'size': 12})
plt.ylabel('Count', fontdict={'size': 12})
plt.xticks(rotation=45)
plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left')
plt.show()
176/782:
# From the graph above , it can be observed that the churn rates for graduate education level customers is the highest but it alsooo imporatant to remember that the number of graduate customers is also significantly higher.
# It can also be observed that the higher education levels have a lower churn rates but further analysis is required for a concrete conclusion.
176/783:
sns.countplot(x='Marital_Status', data=newdf)
plt.title('Distribution of Marital Status', fontdict={'size': 17})
plt.xlabel('Marital Status', fontdict={'size': 12})
plt.xticks(rotation=45)
plt.show()
176/784: # From the graph above , it can be observed that the majority of customers are married or single with number of married customers being slightly higher than single customers.
176/785:
sns.countplot(x='Marital_Status', hue='Attrition_Flag', data=newdf)
plt.title('Relationship between Marital Status and Churn Rate', fontdict={'size': 15})
plt.xlabel('Marital Status', fontdict={'size': 12})
plt.ylabel('Customer Type', fontdict={'size': 12})
plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left')
plt.show()
176/786:
# From the graph above , it can be observed that the churn rate for married and single customers is the highest but it also important to consider that the number of married and single customers is also significantly higher.
# Therefore , further analysis is required for a concrete conclusion.
176/787:
sns.countplot(x='Income_Category', data=newdf)
plt.title('Distribution of Income Category',fontdict={'size': 17})
plt.xlabel('Income Category', fontdict={'size': 12})
plt.xticks(rotation=45)
plt.show()
176/788: # From the graph above , it can be observed that the majority of customers are in the income category less than $40k , therefore making the graph skewed to the left.
176/789:
sns.countplot(x='Income_Category', hue='Attrition_Flag', data=newdf, order=['Unknown', 'Less than $40K', '$40K - $60K', '$60K - $80K', '$80K - $120K', '$120K +'])
plt.title('Relationship between Income Category and Churn Rate',fontdict={'size': 17})
plt.xlabel('Customer Income Category', fontdict={'size': 12})
plt.ylabel('Number of Customers', fontdict={'size': 12})
plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left')
plt.xticks(rotation=45)
plt.show()
176/790:
# From the graph above , it can be observed that the churn rates are the highest for customers in the less than $40k income category , but it also important to consider that the number of customers in the less than $40k income category is also significantly higher.
# Therefore , further analysis is required for a concrete conclusion.
176/791:
sns.countplot(x='Card_Category', data=newdf)
plt.title('Distribution of Card Category',fontdict={'size': 17})
plt.xlabel('Card Category', fontdict={'size': 12})
plt.show()
176/792: # From the graph above , it can be observed that the majority of customers are in the blue card category , therefore making the graph skewed to the left.
176/793:
sns.countplot(x='Card_Category', hue='Attrition_Flag', data=newdf)
plt.title('Relationship between Card Category and Churn Rate', fontdict={'size': 15})
plt.xlabel('Card Category', fontdict={'size': 12})
plt.ylabel('Customer Type', fontdict={'size': 12})
plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left')
plt.show()
176/794:
# From the graph above , it can be observed that the churn rates are the highest for customers in the blue card category , but it also important to consider that the number of customers in the blue card category is also significantly higher.
# Therefore , further analysis is required for a concrete conclusion.
176/795:
# I will firstly be analysisng the affect of customer age on churn rates.Below , i have firstly written code to calculate the churn rates for each customer age.
age_churn = newdf.groupby('Customer_Age')['Attrition_Flag'].mean()
176/796:
plt.figure(figsize=(12, 8))
plt.bar(result['Marital_Status'], result['Weighted_Churn_Rate'])
plt.xlabel('Marital Status')
plt.ylabel('Churn Rate')
plt.title('Churn Rates vs Marital Status')
plt.show()
176/797:
# Graph of churn rates for the calculated churn rates for each customer age.
plt.figure(figsize=(12, 8))
plt.xticks(range(10, 80 ,5))
plt.plot(age_churn.index, age_churn.values)
plt.plot(age_churn.index, age_churn.values, color='black', marker='o', markerfacecolor='orange')
plt.title('Churn Rates for each Customer Age', fontdict={'size': 15})
plt.xlabel('Customer Age', fontdict={'size': 12})
plt.ylabel('Churn Rate', fontdict={'size': 12})
plt.grid()
plt.show()
176/798: # From the graph above , it can be observed that the customers with age between 65 to 70 have the highest churn rates. It can be seen that younger age customers haver lower churn rates.
176/799:
#Adding churn column to my dataset
newdf['churn'] = newdf.apply(lambda x: 1 if x['Months_Inactive_12_mon'] >= 6 else 0, axis=1)
176/800:
# Performing regression analysis to model the relationship between demographic variables and churn rates
X = sm.add_constant(newdf['Customer_Age'])
y = newdf['churn']
model = sm.Logit(y, X).fit()
print(model.summary())
176/801:
#From the table above , it can be observed thatthere is a statistically significant relationship between customer age and churn rates as the p-value is less than 0.05. From the coefficient of age indicates that an one year increase in age , decreases the odds of churn rates by 0.0344.However , from the graph above
#we know this is not true between the age range 65-70.Overall , there is a significant realptionship between customer age and churn rates but there are other important factors too as the r-squared value is only of 0.0068.
176/802: newdf
176/803:
newdf2 = df.drop(columns=['CLIENTNUM', 'Naive_Bayes_Classifier_Attrition_Flag_Card_Category_Contacts_Count_12_mon_Dependent_count_Education_Level_Months_Inactive_12_mon_1', 'Customer_Age', 'Dependent_count', 'Months_on_book','Total_Relationship_Count', 'Months_Inactive_12_mon', 'Contacts_Count_12_mon', 'Credit_Limit','Total_Revolving_Bal', 'Avg_Open_To_Buy', 'Total_Amt_Chng_Q4_Q1', 'Total_Trans_Amt',
                          'Total_Trans_Ct', 'Total_Ct_Chng_Q4_Q1', 'Avg_Utilization_Ratio' ,'Naive_Bayes_Classifier_Attrition_Flag_Card_Category_Contacts_Count_12_mon_Dependent_count_Education_Level_Months_Inactive_12_mon_2','Card_Category'])
176/804: newdf2
176/805: newdf2 = newdf2.dropna()
176/806: newdf2
176/807: newdf['Attrition_Flag_Churned'] = newdf['Attrition_Flag'].apply(lambda x: 1 if x == 'Attrited Customer' else 0)
176/808: newdf
176/809: churn_rates = newdf.groupby('Education_Level')['Attrition_Flag_Churned'].mean().reset_index(name='Churn_Rate')
176/810: churn_rates
176/811:
fig, ax = plt.subplots(figsize=(12, 8))
colors = ['blue', 'orange', 'brown', 'green', 'red', 'purple', 'lightgreen']

bars = ax.bar(churn_rates['Education_Level'], churn_rates['Churn_Rate'],color=colors)
ax.grid(axis='y', linestyle='-')

for bar in bars:
    height = bar.get_height()
    ax.annotate('{:.2f}%'.format(height*100), xy=(bar.get_x() + bar.get_width() / 2, height), xytext=(0, 3),textcoords="offset points", fontsize=10)
    
ax.set_title('Churn Rates by Education Level', fontsize=15)    
ax.set_xlabel('Education Level', fontsize=12)
ax.set_ylabel('Churn Rate', fontsize=12)
plt.xticks(rotation=45)
plt.show()
176/812:
customer_counts = newdf['Education_Level'].value_counts()
churn_rates['Churn_Rate_Ratio'] = churn_rates['Churn_Rate'] / customer_counts[churn_rates['Education_Level']].values
176/813:
fig, ax = plt.subplots(figsize=(12, 8))
colors = ['blue', 'orange', 'brown', 'green', 'red', 'purple', 'lightgreen']

bars = ax.bar(churn_rates['Education_Level'], churn_rates['Churn_Rate_Ratio'],color=colors)
ax.grid(axis='y', linestyle='-')

for bar in bars:
    height = bar.get_height()
    ax.annotate('{:.2f}%'.format(height*100), xy=(bar.get_x() + bar.get_width() / 2, height), xytext=(0, 3),textcoords="offset points", fontsize=10)
    
ax.set_title('Churn Rates by Education Level', fontsize=15)    
ax.set_xlabel('Education Level', fontsize=12)
ax.set_ylabel('Churn Rate', fontsize=12)
plt.xticks(rotation=45)
plt.show()
176/814: churn_rates2 = newdf.groupby('Marital_Status')['Attrition_Flag_Churned'].mean().reset_index(name='Churn_Rate')
176/815: churn_rates2
176/816:
fig, ax = plt.subplots(figsize=(12, 8))

colors = ['blue', 'orange', 'brown', 'green',]

bars = ax.bar(churn_rates2['Marital_Status'], churn_rates2['Churn_Rate'], color=colors)
ax.grid(axis='y', linestyle='-')

for bar in bars:
    height = bar.get_height()
    ax.annotate('{:.2f}%'.format(height*100), xy=(bar.get_x() + bar.get_width() / 2, height), xytext=(0, 3),textcoords="offset points", fontsize=10)
    
plt.xlabel('Marital Status', fontsize=15)
plt.ylabel('Churn Rate', fontsize=12)
plt.title('Churn Rates by Marital Status', fontsize=12)
plt.show()
176/817:
newdf['Total_Customers'] = df.groupby('Marital_Status')['Marital_Status'].transform('count')

# calculate the ratio of customers for each marital status
newdf['Marital_Status_Ratio'] = df['Total_Customers'] / len(df)

# calculate churn rates by marital status
churn_rates = newdf.groupby('Marital_Status')['Attrition_Flag_Churned'].mean().reset_index(name='Churn_Rate')

# merge churn rates and marital status ratio on marital status
result = pd.merge(churn_rates, df[['Marital_Status', 'Marital_Status_Ratio']], on='Marital_Status')

# calculate the weighted churn rates based on marital status ratio
result['Weighted_Churn_Rate'] = result['Churn_Rate'] * result['Marital_Status_Ratio']
176/818:
newdf['Total_Customers'] = df.groupby('Marital_Status')['Marital_Status'].transform('count')

# calculate the ratio of customers for each marital status
newdf['Marital_Status_Ratio'] = newdf['Total_Customers'] / len(df)

# calculate churn rates by marital status
churn_rates = newdf.groupby('Marital_Status')['Attrition_Flag_Churned'].mean().reset_index(name='Churn_Rate')

# merge churn rates and marital status ratio on marital status
result = pd.merge(churn_rates, df[['Marital_Status', 'Marital_Status_Ratio']], on='Marital_Status')

# calculate the weighted churn rates based on marital status ratio
result['Weighted_Churn_Rate'] = result['Churn_Rate'] * result['Marital_Status_Ratio']
176/819:
newdf['Total_Customers'] = df.groupby('Marital_Status')['Marital_Status'].transform('count')

# calculate the ratio of customers for each marital status
newdf['Marital_Status_Ratio'] = newdf['Total_Customers'] / len(df)

# calculate churn rates by marital status
churn_rates = newdf.groupby('Marital_Status')['Attrition_Flag_Churned'].mean().reset_index(name='Churn_Rate')

# merge churn rates and marital status ratio on marital status
result = pd.merge(churn_rates, newdf[['Marital_Status', 'Marital_Status_Ratio']], on='Marital_Status')

# calculate the weighted churn rates based on marital status ratio
result['Weighted_Churn_Rate'] = result['Churn_Rate'] * result['Marital_Status_Ratio']
176/820:
plt.figure(figsize=(12, 8))
plt.bar(result['Marital_Status'], result['Weighted_Churn_Rate'])
plt.xlabel('Marital Status')
plt.ylabel('Churn Rate')
plt.title('Churn Rates vs Marital Status')
plt.show()
176/821: newdf['Attrition_Flag_Churned'] = newdf['Attrition_Flag'].apply(lambda x: 1 if x == 'Attrited Customer' else 0)
176/822: newdf
176/823: churn_rates0 = newdf.groupby('Gender')['Attrition_Flag_Churned'].mean().reset_index(name='Churn_Rate')
176/824: churn_rates0
176/825:
fig, ax = plt.subplots(figsize=(12, 8))
colors = ['blue', 'orange', 'brown', 'green', 'red', 'purple', 'lightgreen']

bars = ax.bar(churn_rates0['Gender'], churn_rates0['Churn_Rate'],color=colors)
ax.grid(axis='y', linestyle='-')

for bar in bars:
    height = bar.get_height()
    ax.annotate('{:.2f}%'.format(height*100), xy=(bar.get_x() + bar.get_width() / 2, height), xytext=(0, 3),textcoords="offset points", fontsize=10)
    
ax.set_title('Churn Rates by Education Level', fontsize=15)    
ax.set_xlabel('Education Level', fontsize=12)
ax.set_ylabel('Churn Rate', fontsize=12)
plt.xticks(rotation=45)
plt.show()
176/826:
gender_count = newdf['Gender'].value_counts()
churn_rates0['Churn_Rate_Ratio'] = churn_rates0['Churn_Rate'] / gender_count[churn_rates0['Gender']].values
176/827:
fig, ax = plt.subplots(figsize=(12, 8))
colors = ['blue', 'orange', 'brown', 'green', 'red', 'purple', 'lightgreen']

bars = ax.bar(churn_rates0['Gender'], churn_rates0['Churn_Rate_Ratio'],color=colors)
ax.grid(axis='y', linestyle='-')

for bar in bars:
    height = bar.get_height()
    ax.annotate('{:.2f}%'.format(height*100), xy=(bar.get_x() + bar.get_width() / 2, height), xytext=(0, 3),textcoords="offset points", fontsize=10)
    
ax.set_title('Churn Rates by Education Level', fontsize=15)    
ax.set_xlabel('Education Level', fontsize=12)
ax.set_ylabel('Churn Rate', fontsize=12)
plt.xticks(rotation=45)
plt.show()
176/828:
fig, ax = plt.subplots(figsize=(12, 8))
colors = ['blue', 'orange', 'brown', 'green', 'red', 'purple', 'lightgreen']

bars = ax.bar(churn_rates0['Gender'], churn_rates0['Churn_Rate_Ratio'],color=colors)
ax.grid(axis='y', linestyle='-')

for bar in bars:
    height = bar.get_height()
    ax.annotate('{:.5f}%'.format(height*100), xy=(bar.get_x() + bar.get_width() / 2, height), xytext=(0, 3),textcoords="offset points", fontsize=10)
    
ax.set_title('Churn Rates by Education Level', fontsize=15)    
ax.set_xlabel('Education Level', fontsize=12)
ax.set_ylabel('Churn Rate', fontsize=12)
plt.xticks(rotation=45)
plt.show()
176/829:
sns.countplot(x='Gender', hue='Attrition_Flag', data=newdf_cleaned)
plt.title('Relationship between Gender and Churn Rate',fontdict={'size': 17})
plt.xlabel('Customer Gender (Male = 0 , Female = 1)', fontdict={'size': 12})
plt.ylabel('Customer Type', fontdict={'size': 12})
plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left')
plt.show()
176/830:
sns.countplot(x='Gender', hue='Attrition_Flag', data=newdf)
plt.title('Relationship between Gender and Churn Rate',fontdict={'size': 17})
plt.xlabel('Customer Gender (Male = 0 , Female = 1)', fontdict={'size': 12})
plt.ylabel('Customer Type', fontdict={'size': 12})
plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left')
plt.show()
176/831:
sns.countplot(x='Gender', data=newdf_cleaned)
plt.title('Distribution of Gender',fontdict={'size': 17})
plt.xlabel('Customer Gender (Male = 0 , Female = 1)', fontdict={'size': 12})
plt.show()
176/832:
sns.countplot(x='Gender', data=newdf)
plt.title('Distribution of Gender',fontdict={'size': 17})
plt.xlabel('Customer Gender (Male = 0 , Female = 1)', fontdict={'size': 12})
plt.show()
176/833:
fig, ax = plt.subplots(figsize=(12, 8))
colors = ['blue', 'orange', 'brown', 'green', 'red', 'purple', 'lightgreen']

bars = ax.bar(churn_rates0['Gender'], churn_rates0['Churn_Rate'],color=colors)
ax.grid(axis='y', linestyle='-')

for bar in bars:
    height = bar.get_height()
    ax.annotate('{:.2f}%'.format(height*100), xy=(bar.get_x() + bar.get_width() / 2, height), xytext=(0, 3),textcoords="offset points", fontsize=10)
    
ax.set_title('Churn Rates by Education Level', fontsize=15)    
ax.set_xlabel('Education Level', fontsize=12)
ax.set_ylabel('Churn Rate', fontsize=12)
plt.show()
176/834:
fig, ax = plt.subplots(figsize=(12, 8))
colors = ['blue', 'orange', 'brown', 'green', 'red', 'purple', 'lightgreen']

bars = ax.bar(churn_rates0['Gender'], churn_rates0['Churn_Rate_Ratio'],color=colors)
ax.grid(axis='y', linestyle='-')

for bar in bars:
    height = bar.get_height()
    ax.annotate('{:.5f}%'.format(height*100), xy=(bar.get_x() + bar.get_width() / 2, height), xytext=(0, 3),textcoords="offset points", fontsize=10)
    
ax.set_title('Churn Rates by Education Level', fontsize=15)    
ax.set_xlabel('Education Level', fontsize=12)
ax.set_ylabel('Churn Rate', fontsize=12)
plt.show()
176/835:
#Code to count the each gender value and calculate the churn rate based on ratio of each gender.
gender_count = newdf['Gender'].value_counts()
churn_rates0['Churn_Rate_Ratio'] = churn_rates0['Churn_Rate'] / gender_count[churn_rates0['Gender']].values
176/836:
fig, ax = plt.subplots(figsize=(12, 8))
colors = ['blue', 'orange', 'brown', 'green', 'red', 'purple', 'lightgreen']

bars = ax.bar(churn_rates0['Gender'], churn_rates0['Churn_Rate_Ratio'],color=colors)
ax.grid(axis='y', linestyle='-')

for bar in bars:
    height = bar.get_height()
    ax.annotate('{:.5f}%'.format(height*100), xy=(bar.get_x() + bar.get_width() / 2, height), xytext=(0, 3),textcoords="offset points", fontsize=10)
    
ax.set_title('Churn Rates by Education Level', fontsize=15)    
ax.set_xlabel('Education Level', fontsize=12)
ax.set_ylabel('Churn Rate', fontsize=12)
plt.show()
176/837: # From the graph above , it can be observed that females still hvae higher churn rates than males based on ratio. Therefore , we can conlude that females do in fact have higher churn rates then men.
176/838: newdf['Attrition_Flag_Churned'] = newdf['Attrition_Flag'].apply(lambda x: 1 if x == 'Attrited Customer' else 0)
176/839:
fig, ax = plt.subplots(figsize=(12, 8))
colors = ['blue', 'orange', 'brown', 'green', 'red', 'purple', 'lightgreen']

bars = ax.bar(churn_rates0['Gender'], churn_rates0['Churn_Rate'],color=colors)
ax.grid(axis='y', linestyle='-')

for bar in bars:
    height = bar.get_height()
    ax.annotate('{:.2f}%'.format(height*100), xy=(bar.get_x() + bar.get_width() / 2, height), xytext=(0, 3),textcoords="offset points", fontsize=10)
    
ax.set_title('Churn Rates by Gender', fontsize=15)    
ax.set_xlabel('Customer Gender', fontsize=12)
ax.set_ylabel('Churn Rate', fontsize=12)
plt.show()
176/840:
fig, ax = plt.subplots(figsize=(12, 8))
colors = ['blue', 'orange', 'brown', 'green', 'red', 'purple', 'lightgreen']

bars = ax.bar(churn_rates0['Gender'], churn_rates0['Churn_Rate_Ratio'],color=colors)
ax.grid(axis='y', linestyle='-')

for bar in bars:
    height = bar.get_height()
    ax.annotate('{:.5f}%'.format(height*100), xy=(bar.get_x() + bar.get_width() / 2, height), xytext=(0, 3),textcoords="offset points", fontsize=10)
    
ax.set_title('Churn Rates by Gender', fontsize=15)    
ax.set_xlabel('Customer Gender', fontsize=12)
ax.set_ylabel('Churn Rate', fontsize=12)
plt.show()
176/841:
#Calculating the churn rate for each gender
churn_rates = newdf.groupby('Education_Level')['Attrition_Flag_Churned'].mean().reset_index(name='Churn_Rate')
176/842: churn_rates
176/843:
fig, ax = plt.subplots(figsize=(12, 8))
colors = ['blue', 'orange', 'brown', 'green', 'red', 'purple', 'lightgreen']

bars = ax.bar(churn_rates['Education_Level'], churn_rates['Churn_Rate_Ratio'],color=colors)
ax.grid(axis='y', linestyle='-')

for bar in bars:
    height = bar.get_height()
    ax.annotate('{:.4f}%'.format(height*100), xy=(bar.get_x() + bar.get_width() / 2, height), xytext=(0, 3),textcoords="offset points", fontsize=10)
    
ax.set_title('Churn Rates by Education Level', fontsize=15)    
ax.set_xlabel('Education Level', fontsize=12)
ax.set_ylabel('Churn Rate', fontsize=12)
plt.xticks(rotation=45)
plt.show()
176/844:
customer_counts = newdf['Education_Level'].value_counts()
churn_rates['Churn_Rate_Ratio'] = churn_rates['Churn_Rate'] / customer_counts[churn_rates['Education_Level']].values
176/845:
fig, ax = plt.subplots(figsize=(12, 8))
colors = ['blue', 'orange', 'brown', 'green', 'red', 'purple', 'lightgreen']

bars = ax.bar(churn_rates['Education_Level'], churn_rates['Churn_Rate_Ratio'],color=colors)
ax.grid(axis='y', linestyle='-')

for bar in bars:
    height = bar.get_height()
    ax.annotate('{:.4f}%'.format(height*100), xy=(bar.get_x() + bar.get_width() / 2, height), xytext=(0, 3),textcoords="offset points", fontsize=10)
    
ax.set_title('Churn Rates by Education Level', fontsize=15)    
ax.set_xlabel('Education Level', fontsize=12)
ax.set_ylabel('Churn Rate', fontsize=12)
plt.xticks(rotation=45)
plt.show()
176/846:
# From the graph above , it can be observed that the doctorate education level has a Significantly higher churn rate than then the rest of the education levels.However , from previous parts of this research we also know that the number of customers in the graduate education is higher than the rest.
#Therefore,in the next stpes we will calculate the churn rates based on the ratio of each education level
176/847:
#Calculating the churn rate for each education level
churn_rates = newdf.groupby('Education_Level')['Attrition_Flag_Churned'].mean().reset_index(name='Churn_Rate')
176/848: churn_rates
176/849:
fig, ax = plt.subplots(figsize=(12, 8))
colors = ['blue', 'orange', 'brown', 'green', 'red', 'purple', 'lightgreen']

bars = ax.bar(churn_rates['Education_Level'], churn_rates['Churn_Rate'],color=colors)
ax.grid(axis='y', linestyle='-')

for bar in bars:
    height = bar.get_height()
    ax.annotate('{:.2f}%'.format(height*100), xy=(bar.get_x() + bar.get_width() / 2, height), xytext=(0, 3),textcoords="offset points", fontsize=10)
    
ax.set_title('Churn Rates by Education Level', fontsize=15)    
ax.set_xlabel('Education Level', fontsize=12)
ax.set_ylabel('Churn Rate', fontsize=12)
plt.xticks(rotation=45)
plt.show()
176/850:
# From the graph above , it can be observed that the doctorate education level has a Significantly higher churn rate than then the rest of the education levels.However , from previous parts of this research we also know that the number of customers in the graduate education is higher than the rest.
#Therefore,in the next stpes we will calculate the churn rates based on the ratio of each education level
176/851:
customer_counts = newdf['Education_Level'].value_counts()
churn_rates['Churn_Rate_Ratio'] = churn_rates['Churn_Rate'] / customer_counts[churn_rates['Education_Level']].values
176/852:
fig, ax = plt.subplots(figsize=(12, 8))
colors = ['blue', 'orange', 'brown', 'green', 'red', 'purple', 'lightgreen']

bars = ax.bar(churn_rates['Education_Level'], churn_rates['Churn_Rate_Ratio'],color=colors)
ax.grid(axis='y', linestyle='-')

for bar in bars:
    height = bar.get_height()
    ax.annotate('{:.4f}%'.format(height*100), xy=(bar.get_x() + bar.get_width() / 2, height), xytext=(0, 3),textcoords="offset points", fontsize=10)
    
ax.set_title('Churn Rates by Education Level', fontsize=15)    
ax.set_xlabel('Education Level', fontsize=12)
ax.set_ylabel('Churn Rate', fontsize=12)
plt.xticks(rotation=45)
plt.show()
176/853:
#Code to count the each customer in the education levels and calculate the churn rate based on ratio of education level.
customer_counts = newdf['Education_Level'].value_counts()
churn_rates['Churn_Rate_Ratio'] = churn_rates['Churn_Rate'] / customer_counts[churn_rates['Education_Level']].values
176/854:
fig, ax = plt.subplots(figsize=(12, 8))
colors = ['blue', 'orange']

bars = ax.bar(churn_rates0['Gender'], churn_rates0['Churn_Rate'],color=colors)
ax.grid(axis='y', linestyle='-')

for bar in bars:
    height = bar.get_height()
    ax.annotate('{:.2f}%'.format(height*100), xy=(bar.get_x() + bar.get_width() / 2, height), xytext=(0, 3),textcoords="offset points", fontsize=10)
    
ax.set_title('Churn Rates by Gender', fontsize=15)    
ax.set_xlabel('Customer Gender', fontsize=12)
ax.set_ylabel('Churn Rate', fontsize=12)
plt.show()
176/855:
fig, ax = plt.subplots(figsize=(12, 8))
colors = ['blue', 'orange']

bars = ax.bar(churn_rates0['Gender'], churn_rates0['Churn_Rate_Ratio'],color=colors)
ax.grid(axis='y', linestyle='-')

for bar in bars:
    height = bar.get_height()
    ax.annotate('{:.5f}%'.format(height*100), xy=(bar.get_x() + bar.get_width() / 2, height), xytext=(0, 3),textcoords="offset points", fontsize=10)
    
ax.set_title('Churn Rates by Gender', fontsize=15)    
ax.set_xlabel('Customer Gender', fontsize=12)
ax.set_ylabel('Churn Rate', fontsize=12)
plt.show()
176/856:
fig, ax = plt.subplots(figsize=(12, 8))
colors = ['pink', 'blue']

bars = ax.bar(churn_rates0['Gender'], churn_rates0['Churn_Rate'],color=colors)
ax.grid(axis='y', linestyle='-')

for bar in bars:
    height = bar.get_height()
    ax.annotate('{:.2f}%'.format(height*100), xy=(bar.get_x() + bar.get_width() / 2, height), xytext=(0, 3),textcoords="offset points", fontsize=10)
    
ax.set_title('Churn Rates by Gender', fontsize=15)    
ax.set_xlabel('Customer Gender', fontsize=12)
ax.set_ylabel('Churn Rate', fontsize=12)
plt.show()
176/857:
fig, ax = plt.subplots(figsize=(12, 8))
colors = ['pink', 'blue']

bars = ax.bar(churn_rates0['Gender'], churn_rates0['Churn_Rate_Ratio'],color=colors)
ax.grid(axis='y', linestyle='-')

for bar in bars:
    height = bar.get_height()
    ax.annotate('{:.5f}%'.format(height*100), xy=(bar.get_x() + bar.get_width() / 2, height), xytext=(0, 3),textcoords="offset points", fontsize=10)
    
ax.set_title('Churn Rates by Gender', fontsize=15)    
ax.set_xlabel('Customer Gender', fontsize=12)
ax.set_ylabel('Churn Rate', fontsize=12)
plt.show()
176/858:
# From the graph above , it can be observed that the unknown and single marital status have a significantly higher churn rate than then the rest of the marital status.However , from previous parts of this research we also know that the number of customers in the divorced and married marital status is higher than the rest.
#Therefore,in the next stpes we will calculate the churn rates based on the ratio of each marital status.
176/859:
#Code to count the number of customers in each marital status and calculate the churn rate based on ratio of marital status.

newdf['Total_Customers'] = df.groupby('Marital_Status')['Marital_Status'].transform('count')
newdf['Marital_Status_Ratio'] = newdf['Total_Customers'] / len(df)
churn_rates = newdf.groupby('Marital_Status')['Attrition_Flag_Churned'].mean().reset_index(name='Churn_Rate')

# merge churn rates and marital status ratio on marital status
result = pd.merge(churn_rates, newdf[['Marital_Status', 'Marital_Status_Ratio']], on='Marital_Status')

# calculate the weighted churn rates based on marital status ratio
result['Weighted_Churn_Rate'] = result['Churn_Rate'] * result['Marital_Status_Ratio']
176/860:
#Code to count the number of customers in each marital status and calculate the churn rate based on ratio of marital status.

newdf['Total_Customers'] = df.groupby('Marital_Status')['Marital_Status'].transform('count')
newdf['Marital_Status_Ratio'] = newdf['Total_Customers'] / len(df)
churn_rates = newdf.groupby('Marital_Status')['Attrition_Flag_Churned'].mean().reset_index(name='Churn_Rate')

 # Merging churn rates and marital status ratio on marital status
result = pd.merge(churn_rates, newdf[['Marital_Status', 'Marital_Status_Ratio']], on='Marital_Status')
result['Weighted_Churn_Rate'] = result['Churn_Rate'] * result['Marital_Status_Ratio']
176/861:
plt.figure(figsize=(12, 8))
fig, ax = plt.subplots(figsize=(12, 8))

colors = ['blue', 'orange', 'brown', 'green',]

plt.bar(result['Marital_Status'], result['Weighted_Churn_Rate'])
plt.xlabel('Marital Status')
plt.ylabel('Churn Rate')
plt.title('Churn Rates vs Marital Status')
plt.show()
176/862:
plt.figure(figsize=(12, 8))
fig, ax = plt.subplots(figsize=(12, 8))

colors = ['blue', 'orange', 'brown', 'green',]

plt.bar(result['Marital_Status'], result['Weighted_Churn_Rate'])
ax.grid(axis='y', linestyle='-')

for bar in bars:
    height = bar.get_height()
    ax.annotate('{:.2f}%'.format(height*100), xy=(bar.get_x() + bar.get_width() / 2, height), xytext=(0, 3),textcoords="offset points", fontsize=10)
plt.xlabel('Marital Status')
plt.ylabel('Churn Rate')
plt.title('Churn Rates vs Marital Status')
plt.show()
176/863:
plt.figure(figsize=(12, 8))
fig, ax = plt.subplots(figsize=(12, 8))

colors = ['blue', 'orange', 'brown', 'green',]
bars = ax.bar(result['Marital_Status'], result['Weighted_Churn_Rate'], color=colors)
ax.grid(axis='y', linestyle='-')

for bar in bars:
    height = bar.get_height()
    ax.annotate('{:.2f}%'.format(height*100), xy=(bar.get_x() + bar.get_width() / 2, height), xytext=(0, 3),textcoords="offset points", fontsize=10)
plt.xlabel('Marital Status')
plt.ylabel('Churn Rate')
plt.title('Churn Rates vs Marital Status')
plt.show()
176/864:
plt.figure(figsize=(12, 8))
fig, ax = plt.subplots(figsize=(12, 8))

colors = ['blue', 'orange', 'brown', 'green',]

bars = ax.bar(result['Marital_Status'], result['Weighted_Churn_Rate'], color=colors)
ax.grid(axis='y', linestyle='-')

for bar in bars:
    height = bar.get_height()
    ax.annotate('{:.2f}%'.format(height*100), xy=(bar.get_x() + bar.get_width() / 2, height), xytext=(0, 3),textcoords="offset points", fontsize=10)
plt.xlabel('Marital Status')
plt.ylabel('Churn Rate')
plt.title('Churn Rates vs Marital Status')
plt.show()
176/865:
plt.figure(figsize=(12, 8))
fig, ax = plt.subplots(figsize=(12, 8))

colors = ['blue', 'orange', 'brown', 'green',]

bars = ax.bar(result['Marital_Status'], result['Weighted_Churn_Rate'], color=colors)
ax.grid(axis='y', linestyle='-')

for bar in bars:
    height = bar.get_height()
    ax.annotate('{:.2f}%'.format(height*100), xy=(bar.get_x() + bar.get_width() / 2, height), xytext=(0, 3),textcoords="offset points", fontsize=10)
    
plt.xlabel('Marital Status')
plt.ylabel('Churn Rate')
plt.title('Churn Rates vs Marital Status')
plt.show()
176/866:
plt.figure(figsize=(12, 8))
fig, ax = plt.subplots(figsize=(12, 8))

colors = ['blue', 'orange', 'brown', 'green',]

bars = ax.bar(result['Marital_Status'], result['Weighted_Churn_Rate'], color=colors)
ax.grid(axis='y', linestyle='-')

for bar in bars:
    height = bar.get_height()
    ax.annotate('{:.2f}%'.format(height*100), xy=(bar.get_x() + bar.get_width() / 2, height), xytext=(0, 3),textcoords="offset points", fontsize=10)
    
plt.xlabel('Marital Status')
plt.ylabel('Churn Rate')
plt.title('Churn Rates vs Marital Status')
plt.show()
176/867:
import pandas as pd
import numpy as np
import matplotlib.pylab as plt
import seaborn as sns
import statsmodels.api as sm

df = pd.read_csv('BankChurners.csv')
df
176/868:
#Calculating the churn rate for each marital status
churn_rates2 = newdf.groupby('Marital_Status')['Attrition_Flag_Churned'].mean().reset_index(name='Churn_Rate')
176/869: df.shape
176/870: churn_rates2
176/871: #The dataset has 10127 rows and 23 columns.
176/872:
fig, ax = plt.subplots(figsize=(12, 8))

colors = ['blue', 'orange', 'brown', 'green',]

bars = ax.bar(churn_rates2['Marital_Status'], churn_rates2['Churn_Rate'], color=colors)
ax.grid(axis='y', linestyle='-')

for bar in bars:
    height = bar.get_height()
    ax.annotate('{:.2f}%'.format(height*100), xy=(bar.get_x() + bar.get_width() / 2, height), xytext=(0, 3),textcoords="offset points", fontsize=10)
    
plt.xlabel('Marital Status', fontsize=15)
plt.ylabel('Churn Rate', fontsize=12)
plt.title('Churn Rates by Marital Status', fontsize=12)
plt.show()
176/873: df.columns
176/874:
# From the graph above , it can be observed that the unknown and single marital status have a significantly higher churn rate than then the rest of the marital status.However , from previous parts of this research we also know that the number of customers in the divorced and married marital status is higher than the rest.
#Therefore,in the next stpes we will calculate the churn rates based on the ratio of each marital status.
176/875:
#We can see all the names of the columns in the dataset , there are a lot of columns some of which are not needed in my research.
#Therefore , I will be  remooving them in further steps.
176/876:
#Code to count the number of customers in each marital status and calculate the churn rate based on ratio of marital status.

newdf['Total_Customers'] = df.groupby('Marital_Status')['Marital_Status'].transform('count')
newdf['Marital_Status_Ratio'] = newdf['Total_Customers'] / len(df)
churn_rates = newdf.groupby('Marital_Status')['Attrition_Flag_Churned'].mean().reset_index(name='Churn_Rate')

 # Merging churn rates and marital status ratio on marital status
result = pd.merge(churn_rates, newdf[['Marital_Status', 'Marital_Status_Ratio']], on='Marital_Status')
result['Weighted_Churn_Rate'] = result['Churn_Rate'] * result['Marital_Status_Ratio']
176/877:
df.nunique(axis=0)
#To see the number of unique values in my dataset for each variable.
176/878:
plt.figure(figsize=(12, 8))
fig, ax = plt.subplots(figsize=(12, 8))

colors = ['blue', 'orange', 'brown', 'green',]

bars = ax.bar(result['Marital_Status'], result['Weighted_Churn_Rate'], color=colors)
ax.grid(axis='y', linestyle='-')

for bar in bars:
    height = bar.get_height()
    ax.annotate('{:.2f}%'.format(height*100), xy=(bar.get_x() + bar.get_width() / 2, height), xytext=(0, 3),textcoords="offset points", fontsize=10)
    
plt.xlabel('Marital Status')
plt.ylabel('Churn Rate')
plt.title('Churn Rates vs Marital Status')
plt.show()
176/879:
print(df.dtypes)
#Checking the datat types of each column
176/880:
df.describe()
#A numerical summary of the variables in the dataset.
176/881: #The first step in cleaning my dataset is remvoing redundant variables.
176/882: newdf = df.drop(columns=['Avg_Open_To_Buy','Naive_Bayes_Classifier_Attrition_Flag_Card_Category_Contacts_Count_12_mon_Dependent_count_Education_Level_Months_Inactive_12_mon_1','Naive_Bayes_Classifier_Attrition_Flag_Card_Category_Contacts_Count_12_mon_Dependent_count_Education_Level_Months_Inactive_12_mon_2','CLIENTNUM' ,'Total_Relationship_Count','Contacts_Count_12_mon','Total_Trans_Ct','Total_Ct_Chng_Q4_Q1'])
176/883: newdf
176/884:
#The second step in cleaning my dataset is remvoing null values
newdf_cleaned = newdf.dropna(axis=0)
176/885: newdf.shape
176/886: newdf_cleaned.shape
176/887: #The dataset does not contain any null values .Therefore , the shape of the dataset has not been changed.
176/888:
newdf_cleaned = pd.get_dummies(newdf_cleaned, columns=['Gender', 'Education_Level', 'Marital_Status', 'Income_Category', 'Card_Category'], drop_first=True)
# Converting categorical variables into numerical values
176/889:
print(newdf_cleaned.dtypes)
# Checking the data types of each column
176/890: print(newdf_cleaned)
176/891:
sns.countplot(x='Attrition_Flag', data=newdf_cleaned)
plt.title('Churn Rates',fontdict={'size': 17})
plt.xlabel('Customer Type', fontdict={'size': 12})
plt.show()
176/892: # From the graph above , it can be observed that the attrition flag value is significantly  higher for existing customers than attrited customers.Thus , this clearly shows that the dataset is imbalanced as the dataset has a much larger value for existing customers than churned customers.
176/893:
sns.histplot(x='Customer_Age', data=newdf_cleaned, bins=20)
plt.title('Distribution of Age',fontdict={'size': 17})
plt.xlabel('Customer Age', fontdict={'size': 12})
plt.show()
176/894:
# From the graph above , it can be observed that the major percentage of customers are between the age range of appoximately 40 to 60 years old , with a few number of customers in the below 40 and above 60 years old age range. 
# The distribution of the histogram is roughly symmetric with a big peak between the 40 and 50 years old age range.
176/895:
sns.boxplot(x='Attrition_Flag', y='Customer_Age', data=newdf_cleaned)
plt.title('Relationship between Age and Churn Rate',fontdict={'size': 17})
plt.xlabel('Customer Type', fontdict={'size': 12})
plt.ylabel('Customer Age', fontdict={'size': 12})
plt.show()
176/896: # From the graph above , it can be observed that the median age of customers who have churned is a little higher than the median age of customers who have not churned. We can aslo see that the existing customers group have more outliers than the attrited customer group.
176/897:
sns.histplot(x='Credit_Limit', data=newdf_cleaned, bins=20)
plt.title('Distribution of Credit Limit',fontdict={'size': 17})
plt.xlabel('Customer Credit Limit', fontdict={'size': 12})
plt.show()
176/898:
# From the graph above , it can be observed that the majority of customers have a credit limit range of 0-20,000 with a big peak between the 0-5000 credit limit range.Along , with a few customers having a credit limit greater than 3000.
#The distribution of the graph is skewed to the right , which showcases that there are a less number of customers with a credit limit greater than 20,000 or with very high credit limits.
176/899:
sns.boxplot(x='Attrition_Flag', y='Credit_Limit', data=newdf_cleaned)
plt.title('Relationship between Credit Limit and Churn Rate',fontdict={'size': 17})
plt.xlabel('Customer Type', fontdict={'size': 12})
plt.ylabel('Customer Credit Limit', fontdict={'size': 12})
plt.show()
176/900:
# From the graph above , it can be observed that the median credit limit is a little higher for existing customers than customers who have churned.The distribution of the credit limit is wider for existing customers than attrited customers.The attried customers also havea higher number of outlier values than existing customers.
#The graph hints that higher credit limit may be related to lower churn rates but further analysis is required for a concrete conclusion.
176/901:
sns.countplot(x='Gender', data=newdf)
plt.title('Distribution of Gender',fontdict={'size': 17})
plt.xlabel('Customer Gender (Male = 0 , Female = 1)', fontdict={'size': 12})
plt.show()
176/902: # From the graph above , it can be observed that the dataset contains slightly higher number of female customers than male customers.
176/903:
sns.countplot(x='Gender', hue='Attrition_Flag', data=newdf)
plt.title('Relationship between Gender and Churn Rate',fontdict={'size': 17})
plt.xlabel('Customer Gender (Male = 0 , Female = 1)', fontdict={'size': 12})
plt.ylabel('Customer Type', fontdict={'size': 12})
plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left')
plt.show()
176/904: # From the graph above , it can be observed that the number of both attrited and exisiting customers is higher for female customers , however the datatset also contains higher number of female customers.Thus , further analysis is required for a concrete conclusion.
176/905:
sns.countplot(x='Education_Level', data=newdf)
plt.title('Distribution of Education Level',fontdict={'size': 17})
plt.xlabel('Education Level', fontdict={'size': 12})
plt.xticks(rotation=45)
plt.show()
176/906: # From the graph above , it can be observed that majority number of customers have a Graduate education level and with a high school education level being the second highest.Also , we can see that the doctorate education level has the least number of customers.
176/907:
sns.countplot(x='Education_Level', hue='Attrition_Flag', data=newdf, order=['Uneducated', 'High School', 'College', 'Graduate', 'Post-Graduate', 'Doctorate'])
plt.title('Relationship between Education Level and Churn Rate' , fontdict={'size': 15})
plt.xlabel('Education Level', fontdict={'size': 12})
plt.ylabel('Count', fontdict={'size': 12})
plt.xticks(rotation=45)
plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left')
plt.show()
176/908:
# From the graph above , it can be observed that the churn rates for graduate education level customers is the highest but it alsooo imporatant to remember that the number of graduate customers is also significantly higher.
# It can also be observed that the higher education levels have a lower churn rates but further analysis is required for a concrete conclusion.
176/909:
sns.countplot(x='Marital_Status', data=newdf)
plt.title('Distribution of Marital Status', fontdict={'size': 17})
plt.xlabel('Marital Status', fontdict={'size': 12})
plt.xticks(rotation=45)
plt.show()
176/910: # From the graph above , it can be observed that the majority of customers are married or single with number of married customers being slightly higher than single customers.
176/911:
sns.countplot(x='Marital_Status', hue='Attrition_Flag', data=newdf)
plt.title('Relationship between Marital Status and Churn Rate', fontdict={'size': 15})
plt.xlabel('Marital Status', fontdict={'size': 12})
plt.ylabel('Customer Type', fontdict={'size': 12})
plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left')
plt.show()
176/912:
# From the graph above , it can be observed that the churn rate for married and single customers is the highest but it also important to consider that the number of married and single customers is also significantly higher.
# Therefore , further analysis is required for a concrete conclusion.
176/913:
sns.countplot(x='Income_Category', data=newdf)
plt.title('Distribution of Income Category',fontdict={'size': 17})
plt.xlabel('Income Category', fontdict={'size': 12})
plt.xticks(rotation=45)
plt.show()
176/914: # From the graph above , it can be observed that the majority of customers are in the income category less than $40k , therefore making the graph skewed to the left.
176/915:
sns.countplot(x='Income_Category', hue='Attrition_Flag', data=newdf, order=['Unknown', 'Less than $40K', '$40K - $60K', '$60K - $80K', '$80K - $120K', '$120K +'])
plt.title('Relationship between Income Category and Churn Rate',fontdict={'size': 17})
plt.xlabel('Customer Income Category', fontdict={'size': 12})
plt.ylabel('Number of Customers', fontdict={'size': 12})
plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left')
plt.xticks(rotation=45)
plt.show()
176/916:
# From the graph above , it can be observed that the churn rates are the highest for customers in the less than $40k income category , but it also important to consider that the number of customers in the less than $40k income category is also significantly higher.
# Therefore , further analysis is required for a concrete conclusion.
176/917:
sns.countplot(x='Card_Category', data=newdf)
plt.title('Distribution of Card Category',fontdict={'size': 17})
plt.xlabel('Card Category', fontdict={'size': 12})
plt.show()
176/918: # From the graph above , it can be observed that the majority of customers are in the blue card category , therefore making the graph skewed to the left.
176/919:
sns.countplot(x='Card_Category', hue='Attrition_Flag', data=newdf)
plt.title('Relationship between Card Category and Churn Rate', fontdict={'size': 15})
plt.xlabel('Card Category', fontdict={'size': 12})
plt.ylabel('Customer Type', fontdict={'size': 12})
plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left')
plt.show()
176/920:
# From the graph above , it can be observed that the churn rates are the highest for customers in the blue card category , but it also important to consider that the number of customers in the blue card category is also significantly higher.
# Therefore , further analysis is required for a concrete conclusion.
176/921:
# I will firstly be analysisng the affect of customer age on churn rates.Below , i have firstly written code to calculate the churn rates for each customer age.
age_churn = newdf.groupby('Customer_Age')['Attrition_Flag'].mean()
176/922:
import pandas as pd
import numpy as np
import matplotlib.pylab as plt
import seaborn as sns
import statsmodels.api as sm

df = pd.read_csv('BankChurners.csv')
df
176/923: df.shape
176/924: #The dataset has 10127 rows and 23 columns.
176/925: df.columns
176/926:
#We can see all the names of the columns in the dataset , there are a lot of columns some of which are not needed in my research.
#Therefore , I will be  remooving them in further steps.
176/927:
df.nunique(axis=0)
#To see the number of unique values in my dataset for each variable.
176/928:
print(df.dtypes)
#Checking the datat types of each column
176/929:
df.describe()
#A numerical summary of the variables in the dataset.
176/930: #The first step in cleaning my dataset is remvoing redundant variables.
176/931: newdf = df.drop(columns=['Avg_Open_To_Buy','Naive_Bayes_Classifier_Attrition_Flag_Card_Category_Contacts_Count_12_mon_Dependent_count_Education_Level_Months_Inactive_12_mon_1','Naive_Bayes_Classifier_Attrition_Flag_Card_Category_Contacts_Count_12_mon_Dependent_count_Education_Level_Months_Inactive_12_mon_2','CLIENTNUM' ,'Total_Relationship_Count','Contacts_Count_12_mon','Total_Trans_Ct','Total_Ct_Chng_Q4_Q1'])
176/932: newdf
176/933:
#The second step in cleaning my dataset is remvoing null values
newdf_cleaned = newdf.dropna(axis=0)
176/934: newdf.shape
176/935: newdf_cleaned.shape
176/936: #The dataset does not contain any null values .Therefore , the shape of the dataset has not been changed.
176/937:
newdf_cleaned = pd.get_dummies(newdf_cleaned, columns=['Gender', 'Education_Level', 'Marital_Status', 'Income_Category', 'Card_Category'], drop_first=True)
# Converting categorical variables into numerical values
176/938:
print(newdf_cleaned.dtypes)
# Checking the data types of each column
176/939: print(newdf_cleaned)
176/940:
sns.countplot(x='Attrition_Flag', data=newdf_cleaned)
plt.title('Churn Rates',fontdict={'size': 17})
plt.xlabel('Customer Type', fontdict={'size': 12})
plt.show()
176/941: # From the graph above , it can be observed that the attrition flag value is significantly  higher for existing customers than attrited customers.Thus , this clearly shows that the dataset is imbalanced as the dataset has a much larger value for existing customers than churned customers.
176/942:
sns.histplot(x='Customer_Age', data=newdf_cleaned, bins=20)
plt.title('Distribution of Age',fontdict={'size': 17})
plt.xlabel('Customer Age', fontdict={'size': 12})
plt.show()
176/943:
# From the graph above , it can be observed that the major percentage of customers are between the age range of appoximately 40 to 60 years old , with a few number of customers in the below 40 and above 60 years old age range. 
# The distribution of the histogram is roughly symmetric with a big peak between the 40 and 50 years old age range.
176/944:
sns.boxplot(x='Attrition_Flag', y='Customer_Age', data=newdf_cleaned)
plt.title('Relationship between Age and Churn Rate',fontdict={'size': 17})
plt.xlabel('Customer Type', fontdict={'size': 12})
plt.ylabel('Customer Age', fontdict={'size': 12})
plt.show()
176/945: # From the graph above , it can be observed that the median age of customers who have churned is a little higher than the median age of customers who have not churned. We can aslo see that the existing customers group have more outliers than the attrited customer group.
176/946:
sns.histplot(x='Credit_Limit', data=newdf_cleaned, bins=20)
plt.title('Distribution of Credit Limit',fontdict={'size': 17})
plt.xlabel('Customer Credit Limit', fontdict={'size': 12})
plt.show()
176/947:
# From the graph above , it can be observed that the majority of customers have a credit limit range of 0-20,000 with a big peak between the 0-5000 credit limit range.Along , with a few customers having a credit limit greater than 3000.
#The distribution of the graph is skewed to the right , which showcases that there are a less number of customers with a credit limit greater than 20,000 or with very high credit limits.
176/948:
sns.boxplot(x='Attrition_Flag', y='Credit_Limit', data=newdf_cleaned)
plt.title('Relationship between Credit Limit and Churn Rate',fontdict={'size': 17})
plt.xlabel('Customer Type', fontdict={'size': 12})
plt.ylabel('Customer Credit Limit', fontdict={'size': 12})
plt.show()
176/949:
# From the graph above , it can be observed that the median credit limit is a little higher for existing customers than customers who have churned.The distribution of the credit limit is wider for existing customers than attrited customers.The attried customers also havea higher number of outlier values than existing customers.
#The graph hints that higher credit limit may be related to lower churn rates but further analysis is required for a concrete conclusion.
176/950:
sns.countplot(x='Gender', data=newdf)
plt.title('Distribution of Gender',fontdict={'size': 17})
plt.xlabel('Customer Gender (Male = 0 , Female = 1)', fontdict={'size': 12})
plt.show()
176/951: # From the graph above , it can be observed that the dataset contains slightly higher number of female customers than male customers.
176/952:
sns.countplot(x='Gender', hue='Attrition_Flag', data=newdf)
plt.title('Relationship between Gender and Churn Rate',fontdict={'size': 17})
plt.xlabel('Customer Gender (Male = 0 , Female = 1)', fontdict={'size': 12})
plt.ylabel('Customer Type', fontdict={'size': 12})
plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left')
plt.show()
176/953: # From the graph above , it can be observed that the number of both attrited and exisiting customers is higher for female customers , however the datatset also contains higher number of female customers.Thus , further analysis is required for a concrete conclusion.
176/954:
sns.countplot(x='Education_Level', data=newdf)
plt.title('Distribution of Education Level',fontdict={'size': 17})
plt.xlabel('Education Level', fontdict={'size': 12})
plt.xticks(rotation=45)
plt.show()
176/955: # From the graph above , it can be observed that majority number of customers have a Graduate education level and with a high school education level being the second highest.Also , we can see that the doctorate education level has the least number of customers.
176/956:
sns.countplot(x='Education_Level', hue='Attrition_Flag', data=newdf, order=['Uneducated', 'High School', 'College', 'Graduate', 'Post-Graduate', 'Doctorate'])
plt.title('Relationship between Education Level and Churn Rate' , fontdict={'size': 15})
plt.xlabel('Education Level', fontdict={'size': 12})
plt.ylabel('Count', fontdict={'size': 12})
plt.xticks(rotation=45)
plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left')
plt.show()
176/957:
# From the graph above , it can be observed that the churn rates for graduate education level customers is the highest but it alsooo imporatant to remember that the number of graduate customers is also significantly higher.
# It can also be observed that the higher education levels have a lower churn rates but further analysis is required for a concrete conclusion.
176/958:
sns.countplot(x='Marital_Status', data=newdf)
plt.title('Distribution of Marital Status', fontdict={'size': 17})
plt.xlabel('Marital Status', fontdict={'size': 12})
plt.xticks(rotation=45)
plt.show()
176/959: # From the graph above , it can be observed that the majority of customers are married or single with number of married customers being slightly higher than single customers.
176/960:
sns.countplot(x='Marital_Status', hue='Attrition_Flag', data=newdf)
plt.title('Relationship between Marital Status and Churn Rate', fontdict={'size': 15})
plt.xlabel('Marital Status', fontdict={'size': 12})
plt.ylabel('Customer Type', fontdict={'size': 12})
plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left')
plt.show()
176/961:
# From the graph above , it can be observed that the churn rate for married and single customers is the highest but it also important to consider that the number of married and single customers is also significantly higher.
# Therefore , further analysis is required for a concrete conclusion.
176/962:
sns.countplot(x='Income_Category', data=newdf)
plt.title('Distribution of Income Category',fontdict={'size': 17})
plt.xlabel('Income Category', fontdict={'size': 12})
plt.xticks(rotation=45)
plt.show()
176/963: # From the graph above , it can be observed that the majority of customers are in the income category less than $40k , therefore making the graph skewed to the left.
176/964:
sns.countplot(x='Income_Category', hue='Attrition_Flag', data=newdf, order=['Unknown', 'Less than $40K', '$40K - $60K', '$60K - $80K', '$80K - $120K', '$120K +'])
plt.title('Relationship between Income Category and Churn Rate',fontdict={'size': 17})
plt.xlabel('Customer Income Category', fontdict={'size': 12})
plt.ylabel('Number of Customers', fontdict={'size': 12})
plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left')
plt.xticks(rotation=45)
plt.show()
176/965:
# From the graph above , it can be observed that the churn rates are the highest for customers in the less than $40k income category , but it also important to consider that the number of customers in the less than $40k income category is also significantly higher.
# Therefore , further analysis is required for a concrete conclusion.
176/966:
sns.countplot(x='Card_Category', data=newdf)
plt.title('Distribution of Card Category',fontdict={'size': 17})
plt.xlabel('Card Category', fontdict={'size': 12})
plt.show()
176/967: # From the graph above , it can be observed that the majority of customers are in the blue card category , therefore making the graph skewed to the left.
176/968:
sns.countplot(x='Card_Category', hue='Attrition_Flag', data=newdf)
plt.title('Relationship between Card Category and Churn Rate', fontdict={'size': 15})
plt.xlabel('Card Category', fontdict={'size': 12})
plt.ylabel('Customer Type', fontdict={'size': 12})
plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left')
plt.show()
176/969:
# From the graph above , it can be observed that the churn rates are the highest for customers in the blue card category , but it also important to consider that the number of customers in the blue card category is also significantly higher.
# Therefore , further analysis is required for a concrete conclusion.
176/970:
# I will firstly be analysisng the affect of customer age on churn rates.Below , i have firstly written code to calculate the churn rates for each customer age.
age_churn = newdf.groupby('Customer_Age')['Attrition_Flag'].mean()
176/971:
#Adding churn column to my dataset
newdf['churn'] = newdf.apply(lambda x: 1 if x['Months_Inactive_12_mon'] >= 6 else 0, axis=1)
176/972:
# Performing regression analysis to model the relationship between demographic variables and churn rates
X = sm.add_constant(newdf['Customer_Age'])
y = newdf['churn']
model = sm.Logit(y, X).fit()
print(model.summary())
176/973:
#From the table above , it can be observed thatthere is a statistically significant relationship between customer age and churn rates as the p-value is less than 0.05. From the coefficient of age indicates that an one year increase in age , decreases the odds of churn rates by 0.0344.However , from the graph above
#we know this is not true between the age range 65-70.Overall , there is a significant realptionship between customer age and churn rates but there are other important factors too as the r-squared value is only of 0.0068.
176/974: newdf['Attrition_Flag_Churned'] = newdf['Attrition_Flag'].apply(lambda x: 1 if x == 'Attrited Customer' else 0)
176/975: newdf
176/976:
#Calculating the churn rate for each gender
churn_rates0 = newdf.groupby('Gender')['Attrition_Flag_Churned'].mean().reset_index(name='Churn_Rate')
176/977: churn_rates0
176/978:
fig, ax = plt.subplots(figsize=(12, 8))
colors = ['pink', 'blue']

bars = ax.bar(churn_rates0['Gender'], churn_rates0['Churn_Rate'],color=colors)
ax.grid(axis='y', linestyle='-')

for bar in bars:
    height = bar.get_height()
    ax.annotate('{:.2f}%'.format(height*100), xy=(bar.get_x() + bar.get_width() / 2, height), xytext=(0, 3),textcoords="offset points", fontsize=10)
    
ax.set_title('Churn Rates by Gender', fontsize=15)    
ax.set_xlabel('Customer Gender', fontsize=12)
ax.set_ylabel('Churn Rate', fontsize=12)
plt.show()
176/979: # From the graph above , it can be observed that Females have higher churn rates than males , but since we know that the dataset includes more female values.Thus , in the next steps we will calculte the churn rate based on the ratio of each gender.
176/980:
#Code to count the each gender value and calculate the churn rate based on ratio of each gender.
gender_count = newdf['Gender'].value_counts()
churn_rates0['Churn_Rate_Ratio'] = churn_rates0['Churn_Rate'] / gender_count[churn_rates0['Gender']].values
176/981:
fig, ax = plt.subplots(figsize=(12, 8))
colors = ['pink', 'blue']

bars = ax.bar(churn_rates0['Gender'], churn_rates0['Churn_Rate_Ratio'],color=colors)
ax.grid(axis='y', linestyle='-')

for bar in bars:
    height = bar.get_height()
    ax.annotate('{:.5f}%'.format(height*100), xy=(bar.get_x() + bar.get_width() / 2, height), xytext=(0, 3),textcoords="offset points", fontsize=10)
    
ax.set_title('Churn Rates by Gender', fontsize=15)    
ax.set_xlabel('Customer Gender', fontsize=12)
ax.set_ylabel('Churn Rate', fontsize=12)
plt.show()
176/982: # From the graph above , it can be observed that females still hvae higher churn rates than males based on ratio. Therefore , we can conlude that females do in fact have higher churn rates then men.
176/983: newdf['Attrition_Flag_Churned'] = newdf['Attrition_Flag'].apply(lambda x: 1 if x == 'Attrited Customer' else 0)
176/984: newdf
176/985:
#Calculating the churn rate for each education level
churn_rates = newdf.groupby('Education_Level')['Attrition_Flag_Churned'].mean().reset_index(name='Churn_Rate')
176/986: churn_rates
176/987:
fig, ax = plt.subplots(figsize=(12, 8))
colors = ['blue', 'orange', 'brown', 'green', 'red', 'purple', 'lightgreen']

bars = ax.bar(churn_rates['Education_Level'], churn_rates['Churn_Rate'],color=colors)
ax.grid(axis='y', linestyle='-')

for bar in bars:
    height = bar.get_height()
    ax.annotate('{:.2f}%'.format(height*100), xy=(bar.get_x() + bar.get_width() / 2, height), xytext=(0, 3),textcoords="offset points", fontsize=10)
    
ax.set_title('Churn Rates by Education Level', fontsize=15)    
ax.set_xlabel('Education Level', fontsize=12)
ax.set_ylabel('Churn Rate', fontsize=12)
plt.xticks(rotation=45)
plt.show()
176/988:
# From the graph above , it can be observed that the doctorate education level has a Significantly higher churn rate than then the rest of the education levels.However , from previous parts of this research we also know that the number of customers in the graduate education is higher than the rest.
#Therefore,in the next stpes we will calculate the churn rates based on the ratio of each education level
176/989:
#Code to count the each customer in the education levels and calculate the churn rate based on ratio of education level.
customer_counts = newdf['Education_Level'].value_counts()
churn_rates['Churn_Rate_Ratio'] = churn_rates['Churn_Rate'] / customer_counts[churn_rates['Education_Level']].values
176/990:
fig, ax = plt.subplots(figsize=(12, 8))
colors = ['blue', 'orange', 'brown', 'green', 'red', 'purple', 'lightgreen']

bars = ax.bar(churn_rates['Education_Level'], churn_rates['Churn_Rate_Ratio'],color=colors)
ax.grid(axis='y', linestyle='-')

for bar in bars:
    height = bar.get_height()
    ax.annotate('{:.4f}%'.format(height*100), xy=(bar.get_x() + bar.get_width() / 2, height), xytext=(0, 3),textcoords="offset points", fontsize=10)
    
ax.set_title('Churn Rates by Education Level', fontsize=15)    
ax.set_xlabel('Education Level', fontsize=12)
ax.set_ylabel('Churn Rate', fontsize=12)
plt.xticks(rotation=45)
plt.show()
176/991:
# From the graph above , it can be observed that the doctorate education level still has a Significantly higher ratio churn rate than then the rest of the education levels.Therefore , I can conclude that the doctorate education level has the highest churn rates. 
# I can also notice that post-graduate education level has the second-highest churn rate.Thus , as the education level increases the chances of churring also increase.
176/992:
#Calculating the churn rate for each marital status
churn_rates2 = newdf.groupby('Marital_Status')['Attrition_Flag_Churned'].mean().reset_index(name='Churn_Rate')
176/993: churn_rates2
176/994:
fig, ax = plt.subplots(figsize=(12, 8))

colors = ['blue', 'orange', 'brown', 'green',]

bars = ax.bar(churn_rates2['Marital_Status'], churn_rates2['Churn_Rate'], color=colors)
ax.grid(axis='y', linestyle='-')

for bar in bars:
    height = bar.get_height()
    ax.annotate('{:.2f}%'.format(height*100), xy=(bar.get_x() + bar.get_width() / 2, height), xytext=(0, 3),textcoords="offset points", fontsize=10)
    
plt.xlabel('Marital Status', fontsize=15)
plt.ylabel('Churn Rate', fontsize=12)
plt.title('Churn Rates by Marital Status', fontsize=12)
plt.show()
176/995:
# From the graph above , it can be observed that the unknown and single marital status have a significantly higher churn rate than then the rest of the marital status.However , from previous parts of this research we also know that the number of customers in the divorced and married marital status is higher than the rest.
#Therefore,in the next stpes we will calculate the churn rates based on the ratio of each marital status.
176/996:
#Code to count the number of customers in each marital status and calculate the churn rate based on ratio of marital status.

newdf['Total_Customers'] = df.groupby('Marital_Status')['Marital_Status'].transform('count')
newdf['Marital_Status_Ratio'] = newdf['Total_Customers'] / len(df)
churn_rates = newdf.groupby('Marital_Status')['Attrition_Flag_Churned'].mean().reset_index(name='Churn_Rate')

 # Merging churn rates and marital status ratio on marital status
result = pd.merge(churn_rates, newdf[['Marital_Status', 'Marital_Status_Ratio']], on='Marital_Status')
result['Weighted_Churn_Rate'] = result['Churn_Rate'] * result['Marital_Status_Ratio']
176/997:
plt.figure(figsize=(12, 8))
fig, ax = plt.subplots(figsize=(12, 8))

colors = ['blue', 'orange', 'brown', 'green',]

bars = ax.bar(result['Marital_Status'], result['Weighted_Churn_Rate'], color=colors)
ax.grid(axis='y', linestyle='-')

for bar in bars:
    height = bar.get_height()
    ax.annotate('{:.2f}%'.format(height*100), xy=(bar.get_x() + bar.get_width() / 2, height), xytext=(0, 3),textcoords="offset points", fontsize=10)
    
plt.xlabel('Marital Status')
plt.ylabel('Churn Rate')
plt.title('Churn Rates vs Marital Status')
plt.show()
176/998:
fig, ax = plt.subplots(figsize=(12, 8))

colors = ['blue', 'orange', 'brown', 'green',]

bars = ax.bar(result['Marital_Status'], result['Weighted_Churn_Rate'], color=colors)
ax.grid(axis='y', linestyle='-')

for bar in bars:
    height = bar.get_height()
    ax.annotate('{:.2f}%'.format(height*100), xy=(bar.get_x() + bar.get_width() / 2, height), xytext=(0, 3),textcoords="offset points", fontsize=10)
    
plt.xlabel('Marital Status')
plt.ylabel('Churn Rate')
plt.title('Churn Rates vs Marital Status')
plt.show()
176/999:
fig, ax = plt.subplots(figsize=(12, 8))

colors = ['blue', 'orange', 'brown', 'green',]

bars = ax.bar(result['Marital_Status'], result['Weighted_Churn_Rate'], color=colors)
ax.grid(axis='y', linestyle='-')

for bar in bars:
    height = bar.get_height()
    ax.annotate('{:.2f}%'.format(height*100), xy=(bar.get_x() + bar.get_width() / 2, height), xytext=(0, 3),textcoords="offset points", fontsize=10)
    
plt.xlabel('Marital Status')
plt.ylabel('Churn Rate')
plt.title('Churn Rates by Ratio of Marital Status')
plt.show()
176/1000:
fig, ax = plt.subplots(figsize=(12, 8))
colors = ['pink', 'blue']

bars = ax.bar(churn_rates0['Gender'], churn_rates0['Churn_Rate_Ratio'],color=colors)
ax.grid(axis='y', linestyle='-')

for bar in bars:
    height = bar.get_height()
    ax.annotate('{:.5f}%'.format(height*100), xy=(bar.get_x() + bar.get_width() / 2, height), xytext=(0, 3),textcoords="offset points", fontsize=10)
    
ax.set_title('Churn Rates by Ratio of Gender', fontsize=15)    
ax.set_xlabel('Customer Gender', fontsize=12)
ax.set_ylabel('Churn Rate', fontsize=12)
plt.show()
176/1001: # From the graph above , it can be observed that females still hvae higher churn rates than males based on ratio. Therefore , we can conlude that females do in fact have higher churn rates then men.
176/1002: newdf['Attrition_Flag_Churned'] = newdf['Attrition_Flag'].apply(lambda x: 1 if x == 'Attrited Customer' else 0)
176/1003: newdf
176/1004:
#Calculating the churn rate for each education level
churn_rates = newdf.groupby('Education_Level')['Attrition_Flag_Churned'].mean().reset_index(name='Churn_Rate')
176/1005: churn_rates
176/1006:
fig, ax = plt.subplots(figsize=(12, 8))
colors = ['blue', 'orange', 'brown', 'green', 'red', 'purple', 'lightgreen']

bars = ax.bar(churn_rates['Education_Level'], churn_rates['Churn_Rate'],color=colors)
ax.grid(axis='y', linestyle='-')

for bar in bars:
    height = bar.get_height()
    ax.annotate('{:.2f}%'.format(height*100), xy=(bar.get_x() + bar.get_width() / 2, height), xytext=(0, 3),textcoords="offset points", fontsize=10)
    
ax.set_title('Churn Rates by Education Level', fontsize=15)    
ax.set_xlabel('Education Level', fontsize=12)
ax.set_ylabel('Churn Rate', fontsize=12)
plt.xticks(rotation=45)
plt.show()
176/1007:
# From the graph above , it can be observed that the doctorate education level has a Significantly higher churn rate than then the rest of the education levels.However , from previous parts of this research we also know that the number of customers in the graduate education is higher than the rest.
#Therefore,in the next stpes we will calculate the churn rates based on the ratio of each education level
176/1008:
#Code to count the each customer in the education levels and calculate the churn rate based on ratio of education level.
customer_counts = newdf['Education_Level'].value_counts()
churn_rates['Churn_Rate_Ratio'] = churn_rates['Churn_Rate'] / customer_counts[churn_rates['Education_Level']].values
176/1009:
fig, ax = plt.subplots(figsize=(12, 8))
colors = ['blue', 'orange', 'brown', 'green', 'red', 'purple', 'lightgreen']

bars = ax.bar(churn_rates['Education_Level'], churn_rates['Churn_Rate_Ratio'],color=colors)
ax.grid(axis='y', linestyle='-')

for bar in bars:
    height = bar.get_height()
    ax.annotate('{:.4f}%'.format(height*100), xy=(bar.get_x() + bar.get_width() / 2, height), xytext=(0, 3),textcoords="offset points", fontsize=10)
    
ax.set_title('Churn Rates by Ratio of Education Level', fontsize=15)    
ax.set_xlabel('Education Level', fontsize=12)
ax.set_ylabel('Churn Rate', fontsize=12)
plt.xticks(rotation=45)
plt.show()
176/1010:
# From the graph above , it can be observed that the doctorate education level still has a Significantly higher ratio churn rate than then the rest of the education levels.Therefore , I can conclude that the doctorate education level has the highest churn rates. 
# I can also notice that post-graduate education level has the second-highest churn rate.Thus , as the education level increases the chances of churring also increase.
176/1011:
#Calculating the churn rate for each marital status
churn_rates2 = newdf.groupby('Marital_Status')['Attrition_Flag_Churned'].mean().reset_index(name='Churn_Rate')
176/1012: churn_rates2
176/1013:
fig, ax = plt.subplots(figsize=(12, 8))

colors = ['blue', 'orange', 'brown', 'green',]

bars = ax.bar(churn_rates2['Marital_Status'], churn_rates2['Churn_Rate'], color=colors)
ax.grid(axis='y', linestyle='-')

for bar in bars:
    height = bar.get_height()
    ax.annotate('{:.2f}%'.format(height*100), xy=(bar.get_x() + bar.get_width() / 2, height), xytext=(0, 3),textcoords="offset points", fontsize=10)
    
plt.xlabel('Marital Status', fontsize=15)
plt.ylabel('Churn Rate', fontsize=12)
plt.title('Churn Rates by Marital Status', fontsize=12)
plt.show()
176/1014:
# From the graph above , it can be observed that the unknown and single marital status have a significantly higher churn rate than then the rest of the marital status.However , from previous parts of this research we also know that the number of customers in the divorced and married marital status is higher than the rest.
#Therefore,in the next stpes we will calculate the churn rates based on the ratio of each marital status.
176/1015:
#Code to count the number of customers in each marital status and calculate the churn rate based on ratio of marital status.

newdf['Total_Customers'] = df.groupby('Marital_Status')['Marital_Status'].transform('count')
newdf['Marital_Status_Ratio'] = newdf['Total_Customers'] / len(df)
churn_rates = newdf.groupby('Marital_Status')['Attrition_Flag_Churned'].mean().reset_index(name='Churn_Rate')

 # Merging churn rates and marital status ratio on marital status
result = pd.merge(churn_rates, newdf[['Marital_Status', 'Marital_Status_Ratio']], on='Marital_Status')
result['Weighted_Churn_Rate'] = result['Churn_Rate'] * result['Marital_Status_Ratio']
176/1016:
fig, ax = plt.subplots(figsize=(12, 8))

colors = ['blue', 'orange', 'brown', 'green',]

bars = ax.bar(result['Marital_Status'], result['Weighted_Churn_Rate'], color=colors)
ax.grid(axis='y', linestyle='-')

for bar in bars:
    height = bar.get_height()
    ax.annotate('{:.2f}%'.format(height*100), xy=(bar.get_x() + bar.get_width() / 2, height), xytext=(0, 3),textcoords="offset points", fontsize=10)
    
plt.xlabel('Marital Status')
plt.ylabel('Churn Rate')
plt.title('Churn Rates by Ratio of Marital Status')
plt.show()
176/1017:
#Calculating the churn rate for each income category
churn_rates3 = df.groupby('Income_Category')['Attrition_Flag_Churned'].mean().reset_index(name='Churn_Rate')
176/1018: newdf['Attrition_Flag_Churned'] = newdf['Attrition_Flag'].apply(lambda x: 1 if x == 'Attrited Customer' else 0)
176/1019: newdf
176/1020:
#Calculating the churn rate for each education level
churn_rates = newdf.groupby('Education_Level')['Attrition_Flag_Churned'].mean().reset_index(name='Churn_Rate')
176/1021: churn_rates
176/1022:
fig, ax = plt.subplots(figsize=(12, 8))
colors = ['blue', 'orange', 'brown', 'green', 'red', 'purple', 'lightgreen']

bars = ax.bar(churn_rates['Education_Level'], churn_rates['Churn_Rate'],color=colors)
ax.grid(axis='y', linestyle='-')

for bar in bars:
    height = bar.get_height()
    ax.annotate('{:.2f}%'.format(height*100), xy=(bar.get_x() + bar.get_width() / 2, height), xytext=(0, 3),textcoords="offset points", fontsize=10)
    
ax.set_title('Churn Rates by Education Level', fontsize=15)    
ax.set_xlabel('Education Level', fontsize=12)
ax.set_ylabel('Churn Rate', fontsize=12)
plt.xticks(rotation=45)
plt.show()
176/1023:
# From the graph above , it can be observed that the doctorate education level has a Significantly higher churn rate than then the rest of the education levels.However , from previous parts of this research we also know that the number of customers in the graduate education is higher than the rest.
#Therefore,in the next stpes we will calculate the churn rates based on the ratio of each education level
176/1024:
#Code to count the each customer in the education levels and calculate the churn rate based on ratio of education level.
customer_counts = newdf['Education_Level'].value_counts()
churn_rates['Churn_Rate_Ratio'] = churn_rates['Churn_Rate'] / customer_counts[churn_rates['Education_Level']].values
176/1025:
fig, ax = plt.subplots(figsize=(12, 8))
colors = ['blue', 'orange', 'brown', 'green', 'red', 'purple', 'lightgreen']

bars = ax.bar(churn_rates['Education_Level'], churn_rates['Churn_Rate_Ratio'],color=colors)
ax.grid(axis='y', linestyle='-')

for bar in bars:
    height = bar.get_height()
    ax.annotate('{:.4f}%'.format(height*100), xy=(bar.get_x() + bar.get_width() / 2, height), xytext=(0, 3),textcoords="offset points", fontsize=10)
    
ax.set_title('Churn Rates by Ratio of Education Level', fontsize=15)    
ax.set_xlabel('Education Level', fontsize=12)
ax.set_ylabel('Churn Rate', fontsize=12)
plt.xticks(rotation=45)
plt.show()
176/1026:
# From the graph above , it can be observed that the doctorate education level still has a Significantly higher ratio churn rate than then the rest of the education levels.Therefore , I can conclude that the doctorate education level has the highest churn rates. 
# I can also notice that post-graduate education level has the second-highest churn rate.Thus , as the education level increases the chances of churring also increase.
176/1027:
#Calculating the churn rate for each marital status
churn_rates2 = newdf.groupby('Marital_Status')['Attrition_Flag_Churned'].mean().reset_index(name='Churn_Rate')
176/1028: churn_rates2
176/1029:
fig, ax = plt.subplots(figsize=(12, 8))

colors = ['blue', 'orange', 'brown', 'green',]

bars = ax.bar(churn_rates2['Marital_Status'], churn_rates2['Churn_Rate'], color=colors)
ax.grid(axis='y', linestyle='-')

for bar in bars:
    height = bar.get_height()
    ax.annotate('{:.2f}%'.format(height*100), xy=(bar.get_x() + bar.get_width() / 2, height), xytext=(0, 3),textcoords="offset points", fontsize=10)
    
plt.xlabel('Marital Status', fontsize=15)
plt.ylabel('Churn Rate', fontsize=12)
plt.title('Churn Rates by Marital Status', fontsize=12)
plt.show()
176/1030:
# From the graph above , it can be observed that the unknown and single marital status have a significantly higher churn rate than then the rest of the marital status.However , from previous parts of this research we also know that the number of customers in the divorced and married marital status is higher than the rest.
#Therefore,in the next stpes we will calculate the churn rates based on the ratio of each marital status.
176/1031:
#Code to count the number of customers in each marital status and calculate the churn rate based on ratio of marital status.

newdf['Total_Customers'] = df.groupby('Marital_Status')['Marital_Status'].transform('count')
newdf['Marital_Status_Ratio'] = newdf['Total_Customers'] / len(df)
churn_rates = newdf.groupby('Marital_Status')['Attrition_Flag_Churned'].mean().reset_index(name='Churn_Rate')

 # Merging churn rates and marital status ratio on marital status
result = pd.merge(churn_rates, newdf[['Marital_Status', 'Marital_Status_Ratio']], on='Marital_Status')
result['Weighted_Churn_Rate'] = result['Churn_Rate'] * result['Marital_Status_Ratio']
176/1032:
fig, ax = plt.subplots(figsize=(12, 8))

colors = ['blue', 'orange', 'brown', 'green',]

bars = ax.bar(result['Marital_Status'], result['Weighted_Churn_Rate'], color=colors)
ax.grid(axis='y', linestyle='-')

for bar in bars:
    height = bar.get_height()
    ax.annotate('{:.2f}%'.format(height*100), xy=(bar.get_x() + bar.get_width() / 2, height), xytext=(0, 3),textcoords="offset points", fontsize=10)
    
plt.xlabel('Marital Status')
plt.ylabel('Churn Rate')
plt.title('Churn Rates by Ratio of Marital Status')
plt.show()
176/1033:
#Calculating the churn rate for each income category
churn_rates3 = df.groupby('Income_Category')['Attrition_Flag_Churned'].mean().reset_index(name='Churn_Rate')
176/1034:
#Calculating the churn rate for each income category
newdf['Attrition_Flag_Churned'] = newdf['Attrition_Flag'].apply(lambda x: 1 if x == 'Attrited Customer' else 0)
churn_rates3 = df.groupby('Income_Category')['Attrition_Flag_Churned'].mean().reset_index(name='Churn_Rate')
176/1035: churn_rates3
176/1036:
#Calculating the churn rate for each income category
churn_rates3 = newf.groupby('Income_Category')['Attrition_Flag_Churned'].mean().reset_index(name='Churn_Rate')
176/1037:
#Calculating the churn rate for each income category
churn_rates3 = newdf.groupby('Income_Category')['Attrition_Flag_Churned'].mean().reset_index(name='Churn_Rate')
176/1038: churn_rates3
176/1039:
fig, ax = plt.subplots(figsize=(12, 8))

colors = ['blue', 'orange', 'brown', 'green','purple' ,'pink']

bars = ax.bar(churn_rates3['Income_Category'], churn_rates3['Churn_Rate'], color=colors)
ax.grid(axis='y', linestyle='-')

for bar in bars:
    height = bar.get_height()
    ax.annotate('{:.2f}%'.format(height*100), xy=(bar.get_x() + bar.get_width() / 2, height), xytext=(0, 3),textcoords="offset points", fontsize=10)
    
plt.xlabel('Income Category', fontsize=12)
plt.ylabel('Churn Rate', fontsize=12)
plt.title('Churn Rates by Marital Status', fontsize=15)
plt.show()
176/1040:
fig, ax = plt.subplots(figsize=(12, 8))

colors = ['blue', 'orange', 'brown', 'green','purple' ,'pink']

bars = ax.bar(churn_rates3['Income_Category'], churn_rates3['Churn_Rate'], color=colors)
ax.grid(axis='y', linestyle='-')

for bar in bars:
    height = bar.get_height()
    ax.annotate('{:.2f}%'.format(height*100), xy=(bar.get_x() + bar.get_width() / 2, height), xytext=(0, 3),textcoords="offset points", fontsize=10)
    
plt.xlabel('Income Category', fontsize=12)
plt.ylabel('Churn Rate', fontsize=12)
plt.title('Churn Rates by Marital Status', fontsize=15)
plt.show()
176/1041:
fig, ax = plt.subplots(figsize=(12, 8))

colors = ['blue', 'orange', 'brown', 'green',]

bars = ax.bar(result['Marital_Status'], result['Weighted_Churn_Rate'], color=colors)
ax.grid(axis='y', linestyle='-')

for bar in bars:
    height = bar.get_height()
    ax.annotate('{:.2f}%'.format(height*100), xy=(bar.get_x() + bar.get_width() / 2, height), xytext=(0, 3),textcoords="offset points", fontsize=10)
    
plt.xlabel('Marital Status', fontsize=12)
plt.ylabel('Churn Rate', fontsize=12)
plt.title('Churn Rates by Ratio of Marital Status', fontsize=15)
plt.show()
176/1042:
fig, ax = plt.subplots(figsize=(12, 8))

colors = ['blue', 'orange', 'brown', 'green',]

bars = ax.bar(churn_rates2['Marital_Status'], churn_rates2['Churn_Rate'], color=colors)
ax.grid(axis='y', linestyle='-')

for bar in bars:
    height = bar.get_height()
    ax.annotate('{:.2f}%'.format(height*100), xy=(bar.get_x() + bar.get_width() / 2, height), xytext=(0, 3),textcoords="offset points", fontsize=10)
    
plt.xlabel('Marital Status', fontsize=12)
plt.ylabel('Churn Rate', fontsize=12)
plt.title('Churn Rates by Marital Status', fontsize=15)
plt.show()
176/1043:
fig, ax = plt.subplots(figsize=(12, 8))

colors = ['blue', 'orange', 'brown', 'green','purple' ,'pink']

bars = ax.bar(churn_rates3['Income_Category'], churn_rates3['Churn_Rate'], color=colors)
ax.grid(axis='y', linestyle='-')

for bar in bars:
    height = bar.get_height()
    ax.annotate('{:.2f}%'.format(height*100), xy=(bar.get_x() + bar.get_width() / 2, height), xytext=(0, 3),textcoords="offset points", fontsize=10)
    
plt.xlabel('Income Category', fontsize=12)
plt.ylabel('Churn Rate', fontsize=12)
plt.title('Churn Rates byIncome Category', fontsize=15)
plt.show()
176/1044:
fig, ax = plt.subplots(figsize=(12, 8))

colors = ['blue', 'orange', 'brown', 'green','purple' ,'pink']

bars = ax.bar(churn_rates3['Income_Category'], churn_rates3['Churn_Rate'], color=colors)
ax.grid(axis='y', linestyle='-')

for bar in bars:
    height = bar.get_height()
    ax.annotate('{:.2f}%'.format(height*100), xy=(bar.get_x() + bar.get_width() / 2, height), xytext=(0, 3),textcoords="offset points", fontsize=10)
    
plt.xlabel('Income Category', fontsize=12)
plt.ylabel('Churn Rate', fontsize=12)
plt.title('Churn Rates by Income Category', fontsize=15)
plt.show()
176/1045: #Code to count the number of customers in each income category and calculate the churn rate based on ratio of each income category
176/1046:
#Code to count the number of customers in each income category and calculate the churn rate based on ratio of each income category
income_ratios = df['Income_Category'].value_counts(normalize=True).reset_index(name='Ratio')
income_ratios.columns = ['Income_Category', 'Ratio']
176/1047:
#Code to count the number of customers in each income category and calculate the churn rate based on ratio of each income category
income_ratios = df['Income_Category'].value_counts(normalize=True).reset_index(name='Ratio')
income_ratios.columns = ['Income_Category', 'Ratio']
churn_rates = churn_rates.merge(income_ratios, on='Income_Category')

# Calculate churn counts for each income category
churn_counts = df.groupby('Income_Category')['Attrition_Flag_Churned'].sum().reset_index(name='Churn_Count')

# Merge churn rates and churn counts on income category
churn_rates = churn_rates.merge(churn_counts, on='Income_Category')
176/1048:
#Code to count the number of customers in each income category and calculate the churn rate based on ratio of each income category
income_ratios = newdf['Income_Category'].value_counts(normalize=True).reset_index(name='Ratio')
income_ratios.columns = ['Income_Category', 'Ratio']
churn_rates = churn_rates.merge(income_ratios, on='Income_Category')

churn_counts = newdf.groupby('Income_Category')['Attrition_Flag_Churned'].sum().reset_index(name='Churn_Count')

# Merge churn rates and churn counts on income category
churn_rates = churn_rates.merge(churn_counts, on='Income_Category')
176/1049:
# From the graph above , it can be observed that the $120k+ and less than 4$0k income category have a  higher churn rate than then the rest of the income category.However , from previous parts of this research we also know that the number of customers in the less than 4$0k income category is higher than the rest.
#Therefore,in the next stpes we will calculate the churn rates based on the ratio of each income category.
176/1050:
#Code to count the number of customers in each income category and calculate the churn rate based on ratio of each income category
income_ratios = newdf['Income_Category'].value_counts(normalize=True).reset_index(name='Ratio')
income_ratios.columns = ['Income_Category', 'Ratio']
churn_rates = churn_rates.merge(income_ratios, on='Income_Category')

churn_counts = newdf.groupby('Income_Category')['Attrition_Flag_Churned'].sum().reset_index(name='Churn_Count')

# Merge churn rates and churn counts on income category
churn_rates = churn_rates.merge(churn_counts, on='Income_Category')
176/1051:
#Code to count the number of customers in each income category and calculate the churn rate based on ratio of each income category
income_ratio = df['Income_Category'].value_counts(normalize=True).reset_index()
income_ratio.columns = ['Income_Category', 'Income_Ratio']

# merge the churn rates and income ratio dataframes
churn_rates = pd.merge(churn_rates, income_ratio, on='Income_Category')
176/1052:
#Code to count the number of customers in each income category and calculate the churn rate based on ratio of each income category
income_ratio = newdf['Income_Category'].value_counts(normalize=True).reset_index()
income_ratio.columns = ['Income_Category', 'Income_Ratio']

# merge the churn rates and income ratio dataframes
churn_rates = pd.merge(churn_rates, income_ratio, on='Income_Category')
176/1053:
#Code to count the number of customers in each income category and calculate the churn rate based on ratio of each income category
income_ratio = newdf['Income_Category'].value_counts(normalize=True).reset_index()
income_ratio.columns = ['Income_Category', 'Income_Ratio']

# merge the churn rates and income ratio dataframes
churn_rates = pd.merge(churn_rates, income_ratio, on = 'Income_Category')
176/1054:
#Code to count the number of customers in each income category and calculate the churn rate based on ratio of each income category
income_ratio = newdf['Income_Category'].value_counts(normalize=True).reset_index()
income_ratio.columns = ['Income_Category', 'Income_Ratio']
churn_rates = pd.merge(churn_rates, income_ratio, on = 'Income_Category')
176/1055:
fig, ax = plt.subplots(figsize=(12, 8))

colors = ['blue', 'orange', 'brown', 'green',]

bars = ax.bar(result['Marital_Status'], result['Weighted_Churn_Rate'], color=colors)
ax.grid(axis='y', linestyle='-')

for bar in bars:
    height = bar.get_height()
    ax.annotate('{:.2f}%'.format(height*100), xy=(bar.get_x() + bar.get_width() / 2, height), xytext=(0, 3),textcoords="offset points", fontsize=10)
    
plt.xlabel('Marital Status', fontsize=12)
plt.ylabel('Churn Rate', fontsize=12)
plt.title('Churn Rates by Ratio of Marital Status', fontsize=15)
plt.show()
176/1056: churn_rates4 = df.groupby('Card_Category')['Attrition_Flag_Churned'].mean().reset_index(name='Churn_Rate')
176/1057: churn_rates4
176/1058: churn_rates4 = df.groupby('Card_Category')['Attrition_Flag_Churned'].mean().reset_index(name='Churn_Rate')
176/1059:
#Calculating the churn rate for each income category
churn_rates3 = newdf.groupby('Income_Category')['Attrition_Flag_Churned'].mean().reset_index(name='Churn_Rate')
176/1060: churn_rates3
176/1061:
fig, ax = plt.subplots(figsize=(12, 8))

colors = ['blue', 'orange', 'brown', 'green','purple' ,'pink']

bars = ax.bar(churn_rates3['Income_Category'], churn_rates3['Churn_Rate'], color=colors)
ax.grid(axis='y', linestyle='-')

for bar in bars:
    height = bar.get_height()
    ax.annotate('{:.2f}%'.format(height*100), xy=(bar.get_x() + bar.get_width() / 2, height), xytext=(0, 3),textcoords="offset points", fontsize=10)
    
plt.xlabel('Income Category', fontsize=12)
plt.ylabel('Churn Rate', fontsize=12)
plt.title('Churn Rates by Income Category', fontsize=15)
plt.show()
176/1062:
# From the graph above , it can be observed that the $120k+ and less than 4$0k income category have a  higher churn rate than then the rest of the income category.However , from previous parts of this research we also know that the number of customers in the less than 4$0k income category is higher than the rest.
#Therefore,in the next stpes we will calculate the churn rates based on the ratio of each income category.
176/1063:
#Code to count the number of customers in each income category and calculate the churn rate based on ratio of each income category
income_ratio = newdf['Income_Category'].value_counts(normalize=True).reset_index()
income_ratio.columns = ['Income_Category', 'Income_Ratio']
churn_rates = pd.merge(churn_rates, income_ratio, on = 'Income_Category')
176/1064: churn_rates4 = df.groupby('Card_Category')['Attrition_Flag_Churned'].mean().reset_index(name='Churn_Rate')
176/1065: churn_rates4
176/1066:
fig, ax = plt.subplots(figsize=(12, 8))

colors = ['blue', 'orange', 'brown', 'green','purple' ,'pink']

bars = ax.bar(churn_rates3['Income_Category'], churn_rates3['Churn_Rate'], color=colors)
ax.grid(axis='y', linestyle='-')

for bar in bars:
    height = bar.get_height()
    ax.annotate('{:.2f}%'.format(height*100), xy=(bar.get_x() + bar.get_width() / 2, height), xytext=(0, 3),textcoords="offset points", fontsize=10)
    
plt.xlabel('Income Category', fontsize=12)
plt.ylabel('Churn Rate', fontsize=12)
plt.title('Churn Rates by Income Category', fontsize=15)
plt.show()
176/1067: churn_rates4 = newdf.groupby('Card_Category')['Attrition_Flag_Churned'].mean().reset_index(name='Churn_Rate')
176/1068: churn_rates4
176/1069:
fig, ax = plt.subplots(figsize=(12, 8))

colors = ['blue', 'orange', 'brown', 'green','purple' ,'pink']

bars = ax.bar(churn_rates3['Income_Category'], churn_rates3['Churn_Rate'], color=colors)
ax.grid(axis='y', linestyle='-')

for bar in bars:
    height = bar.get_height()
    ax.annotate('{:.2f}%'.format(height*100), xy=(bar.get_x() + bar.get_width() / 2, height), xytext=(0, 3),textcoords="offset points", fontsize=10)
    
plt.xlabel('Income Category', fontsize=12)
plt.ylabel('Churn Rate', fontsize=12)
plt.title('Churn Rates by Income Category', fontsize=15)
plt.show()
176/1070:
fig, ax = plt.subplots(figsize=(12, 8))

colors = ['blue', 'orange', 'brown', 'green','purple' ,'pink']

bars = ax.bar(churn_rates4['Card_Category'], churn_rates4['Churn_Rate'], color=colors)
ax.grid(axis='y', linestyle='-')

for bar in bars:
    height = bar.get_height()
    ax.annotate('{:.2f}%'.format(height*100), xy=(bar.get_x() + bar.get_width() / 2, height), xytext=(0, 3),textcoords="offset points", fontsize=10)
    
plt.xlabel('Income Category', fontsize=12)
plt.ylabel('Churn Rate', fontsize=12)
plt.title('Churn Rates by Income Category', fontsize=15)
plt.show()
176/1071:
fig, ax = plt.subplots(figsize=(12, 8))

colors = ['blue', 'orange', 'silver', 'green','purple' ,'pink']

bars = ax.bar(churn_rates4['Card_Category'], churn_rates4['Churn_Rate'], color=colors)
ax.grid(axis='y', linestyle='-')

for bar in bars:
    height = bar.get_height()
    ax.annotate('{:.2f}%'.format(height*100), xy=(bar.get_x() + bar.get_width() / 2, height), xytext=(0, 3),textcoords="offset points", fontsize=10)
    
plt.xlabel('Income Category', fontsize=12)
plt.ylabel('Churn Rate', fontsize=12)
plt.title('Churn Rates by Income Category', fontsize=15)
plt.show()
176/1072:
fig, ax = plt.subplots(figsize=(12, 8))

colors = ['blue', 'orange', 'silver', 'dark silver','purple' ,'pink']

bars = ax.bar(churn_rates4['Card_Category'], churn_rates4['Churn_Rate'], color=colors)
ax.grid(axis='y', linestyle='-')

for bar in bars:
    height = bar.get_height()
    ax.annotate('{:.2f}%'.format(height*100), xy=(bar.get_x() + bar.get_width() / 2, height), xytext=(0, 3),textcoords="offset points", fontsize=10)
    
plt.xlabel('Income Category', fontsize=12)
plt.ylabel('Churn Rate', fontsize=12)
plt.title('Churn Rates by Income Category', fontsize=15)
plt.show()
176/1073:
fig, ax = plt.subplots(figsize=(12, 8))

colors = ['blue', 'orange', 'silver', 'grey','purple' ,'pink']

bars = ax.bar(churn_rates4['Card_Category'], churn_rates4['Churn_Rate'], color=colors)
ax.grid(axis='y', linestyle='-')

for bar in bars:
    height = bar.get_height()
    ax.annotate('{:.2f}%'.format(height*100), xy=(bar.get_x() + bar.get_width() / 2, height), xytext=(0, 3),textcoords="offset points", fontsize=10)
    
plt.xlabel('Income Category', fontsize=12)
plt.ylabel('Churn Rate', fontsize=12)
plt.title('Churn Rates by Income Category', fontsize=15)
plt.show()
176/1074:
fig, ax = plt.subplots(figsize=(12, 8))

colors = ['blue', 'orange', 'silver', 'grey','purple' ,'pink']

bars = ax.bar(churn_rates4['Card_Category'], churn_rates4['Churn_Rate'], color=colors)
ax.grid(axis='y', linestyle='-')

for bar in bars:
    height = bar.get_height()
    ax.annotate('{:.2f}%'.format(height*100), xy=(bar.get_x() + bar.get_width() / 2, height), xytext=(0, 3),textcoords="offset points", fontsize=10)
    
plt.xlabel('Card Category', fontsize=12)
plt.ylabel('Churn Rate', fontsize=12)
plt.title('Churn Rates by Card Category', fontsize=15)
plt.show()
176/1075:
#Code to count the number of customers in each income category and calculate the churn rate based on ratio of each income category
income_ratio = df['Income_Category'].value_counts(normalize=True).reset_index()
income_ratio.columns = ['Income_Category', 'Ratio']

# calculate churn rates by income category
churn_rates = df.groupby('Income_Category')['Attrition_Flag_Churned'].mean().reset_index(name='Churn_Rate')

# merge churn rates and income ratio by income category
churn_rates = pd.merge(churn_rates, income_ratio, on='Income_Category')

# calculate weighted churn rate based on ratio
churn_rates['Weighted_Churn_Rate'] = churn_rates['Churn_Rate'] * churn_rates['Ratio']
176/1076:
#Code to count the number of customers in each income category and calculate the churn rate based on ratio of each income category
newdf['Attrition_Flag_Churned'] = newdf['Attrition_Flag'].apply(lambda x: 1 if x == 'Attrited Customer' else 0)
income_ratio = newdf['Income_Category'].value_counts(normalize=True).reset_index()
income_ratio.columns = ['Income_Category', 'Income_Ratio']
churn_rates = pd.merge(churn_rates, income_ratio, on = 'Income_Category')
176/1077:
#Code to count the number of customers in each income category and calculate the churn rate based on ratio of each income category
newdf['Attrition_Flag_Churned'] = newdf['Attrition_Flag'].apply(lambda x: 1 if x == 'Attrited Customer' else 0)
income_ratio = df['Income_Category'].value_counts(normalize=True).reset_index()
income_ratio.columns = ['Income_Category', 'Ratio']

# calculate churn rates by income category
churn_rates = df.groupby('Income_Category')['Attrition_Flag_Churned'].mean().reset_index(name='Churn_Rate')

# merge churn rates and income ratio by income category
churn_rates = pd.merge(churn_rates, income_ratio, on='Income_Category')

# calculate weighted churn rate based on ratio
churn_rates['Weighted_Churn_Rate'] = churn_rates['Churn_Rate'] * churn_rates['Ratio']
176/1078: #Code to count the number of customers in each income category and calculate the churn rate based on ratio of each income category
176/1079: #Code to count the number of customers in each income category and calculate the churn rate based on ratio of each income category
176/1080:
# Graph of churn rates for the calculated churn rates for each customer age.
plt.figure(figsize=(12, 8))
plt.xticks(range(10, 80 ,5))
plt.plot(age_churn.index, age_churn.values)
plt.plot(age_churn.index, age_churn.values, color='black', marker='o', markerfacecolor='orange')
plt.title('Churn Rates for each Customer Age', fontdict={'size': 15})
plt.xlabel('Customer Age', fontdict={'size': 12})
plt.ylabel('Churn Rate', fontdict={'size': 12})
plt.grid()
plt.show()
176/1081: newdf['Churned'] = newdf['Churned'].apply(lambda x: 1 if x == 'Attrited Customer' else 0)
176/1082: newdf
176/1083: newdf['Churned'] = newdf['Attrition_Flag'].apply(lambda x: 1 if x == 'Attrited Customer' else 0)
176/1084:
#Calculating the churn rate for each gender
churn_rates0 = newdf.groupby('Gender')['Churned'].mean().reset_index(name='Churn_Rate')
176/1085: churn_rates0
176/1086:
fig, ax = plt.subplots(figsize=(12, 8))
colors = ['pink', 'blue']

bars = ax.bar(churn_rates0['Gender'], churn_rates0['Churn_Rate'],color=colors)
ax.grid(axis='y', linestyle='-')

for bar in bars:
    height = bar.get_height()
    ax.annotate('{:.2f}%'.format(height*100), xy=(bar.get_x() + bar.get_width() / 2, height), xytext=(0, 3),textcoords="offset points", fontsize=10)
    
ax.set_title('Churn Rates by Gender', fontsize=15)    
ax.set_xlabel('Customer Gender', fontsize=12)
ax.set_ylabel('Churn Rate', fontsize=12)
plt.show()
176/1087: # From the graph above , it can be observed that Females have higher churn rates than males , but since we know that the dataset includes more female values.Thus , in the next steps we will calculte the churn rate based on the ratio of each gender.
176/1088:
#Code to count the each gender value and calculate the churn rate based on ratio of each gender.
gender_count = newdf['Gender'].value_counts()
churn_rates0['Churn_Rate_Ratio'] = churn_rates0['Churn_Rate'] / gender_count[churn_rates0['Gender']].values
176/1089:
fig, ax = plt.subplots(figsize=(12, 8))
colors = ['pink', 'blue']

bars = ax.bar(churn_rates0['Gender'], churn_rates0['Churn_Rate_Ratio'],color=colors)
ax.grid(axis='y', linestyle='-')

for bar in bars:
    height = bar.get_height()
    ax.annotate('{:.5f}%'.format(height*100), xy=(bar.get_x() + bar.get_width() / 2, height), xytext=(0, 3),textcoords="offset points", fontsize=10)
    
ax.set_title('Churn Rates by Ratio of Gender', fontsize=15)    
ax.set_xlabel('Customer Gender', fontsize=12)
ax.set_ylabel('Churn Rate', fontsize=12)
plt.show()
176/1090: # From the graph above , it can be observed that females still hvae higher churn rates than males based on ratio. Therefore , we can conlude that females do in fact have higher churn rates then men.
176/1091: newdf['Churned'] = newdf['Attrition_Flag'].apply(lambda x: 1 if x == 'Attrited Customer' else 0)
176/1092: newdf
176/1093:
#Calculating the churn rate for each education level
churn_rates = newdf.groupby('Education_Level')['Attrition_Flag_Churned'].mean().reset_index(name='Churn_Rate')
176/1094: churn_rates
176/1095:
fig, ax = plt.subplots(figsize=(12, 8))
colors = ['blue', 'orange', 'brown', 'green', 'red', 'purple', 'lightgreen']

bars = ax.bar(churn_rates['Education_Level'], churn_rates['Churn_Rate'],color=colors)
ax.grid(axis='y', linestyle='-')

for bar in bars:
    height = bar.get_height()
    ax.annotate('{:.2f}%'.format(height*100), xy=(bar.get_x() + bar.get_width() / 2, height), xytext=(0, 3),textcoords="offset points", fontsize=10)
    
ax.set_title('Churn Rates by Education Level', fontsize=15)    
ax.set_xlabel('Education Level', fontsize=12)
ax.set_ylabel('Churn Rate', fontsize=12)
plt.xticks(rotation=45)
plt.show()
176/1096:
# From the graph above , it can be observed that the doctorate education level has a Significantly higher churn rate than then the rest of the education levels.However , from previous parts of this research we also know that the number of customers in the graduate education is higher than the rest.
#Therefore,in the next stpes we will calculate the churn rates based on the ratio of each education level
176/1097:
#Code to count the each customer in the education levels and calculate the churn rate based on ratio of education level.
customer_counts = newdf['Education_Level'].value_counts()
churn_rates['Churn_Rate_Ratio'] = churn_rates['Churn_Rate'] / customer_counts[churn_rates['Education_Level']].values
176/1098:
fig, ax = plt.subplots(figsize=(12, 8))
colors = ['blue', 'orange', 'brown', 'green', 'red', 'purple', 'lightgreen']

bars = ax.bar(churn_rates['Education_Level'], churn_rates['Churn_Rate_Ratio'],color=colors)
ax.grid(axis='y', linestyle='-')

for bar in bars:
    height = bar.get_height()
    ax.annotate('{:.4f}%'.format(height*100), xy=(bar.get_x() + bar.get_width() / 2, height), xytext=(0, 3),textcoords="offset points", fontsize=10)
    
ax.set_title('Churn Rates by Ratio of Education Level', fontsize=15)    
ax.set_xlabel('Education Level', fontsize=12)
ax.set_ylabel('Churn Rate', fontsize=12)
plt.xticks(rotation=45)
plt.show()
176/1099:
# From the graph above , it can be observed that the doctorate education level still has a Significantly higher ratio churn rate than then the rest of the education levels.Therefore , I can conclude that the doctorate education level has the highest churn rates. 
# I can also notice that post-graduate education level has the second-highest ratio churn rate.Thus , as the education level increases the chances of churring also increase.
176/1100:
#Calculating the churn rate for each marital status
churn_rates2 = newdf.groupby('Marital_Status')['Attrition_Flag_Churned'].mean().reset_index(name='Churn_Rate')
176/1101:
#Calculating the churn rate for each marital status
churn_rates2 = newdf.groupby('Marital_Status')['Churned'].mean().reset_index(name='Churn_Rate')
176/1102: churn_rates2
176/1103:
fig, ax = plt.subplots(figsize=(12, 8))

colors = ['blue', 'orange', 'brown', 'green',]

bars = ax.bar(churn_rates2['Marital_Status'], churn_rates2['Churn_Rate'], color=colors)
ax.grid(axis='y', linestyle='-')

for bar in bars:
    height = bar.get_height()
    ax.annotate('{:.2f}%'.format(height*100), xy=(bar.get_x() + bar.get_width() / 2, height), xytext=(0, 3),textcoords="offset points", fontsize=10)
    
plt.xlabel('Marital Status', fontsize=12)
plt.ylabel('Churn Rate', fontsize=12)
plt.title('Churn Rates by Marital Status', fontsize=15)
plt.show()
176/1104:
# From the graph above , it can be observed that the unknown and single marital status have a significantly higher churn rate than then the rest of the marital status.However , from previous parts of this research we also know that the number of customers in the divorced and married marital status is higher than the rest.
#Therefore,in the next stpes we will calculate the churn rates based on the ratio of each marital status.
176/1105:
#Code to count the number of customers in each marital status and calculate the churn rate based on ratio of marital status.

newdf['Total_Customers'] = df.groupby('Marital_Status')['Marital_Status'].transform('count')
newdf['Marital_Status_Ratio'] = newdf['Total_Customers'] / len(df)
churn_rates = newdf.groupby('Marital_Status')['Attrition_Flag_Churned'].mean().reset_index(name='Churn_Rate')

 # Merging churn rates and marital status ratio on marital status
result = pd.merge(churn_rates, newdf[['Marital_Status', 'Marital_Status_Ratio']], on='Marital_Status')
result['Weighted_Churn_Rate'] = result['Churn_Rate'] * result['Marital_Status_Ratio']
176/1106:
fig, ax = plt.subplots(figsize=(12, 8))

colors = ['blue', 'orange', 'brown', 'green',]

bars = ax.bar(result['Marital_Status'], result['Weighted_Churn_Rate'], color=colors)
ax.grid(axis='y', linestyle='-')

for bar in bars:
    height = bar.get_height()
    ax.annotate('{:.2f}%'.format(height*100), xy=(bar.get_x() + bar.get_width() / 2, height), xytext=(0, 3),textcoords="offset points", fontsize=10)
    
plt.xlabel('Marital Status', fontsize=12)
plt.ylabel('Churn Rate', fontsize=12)
plt.title('Churn Rates by Ratio of Marital Status', fontsize=15)
plt.show()
179/1: %history -g
   1: %history -g -f analysis3(Ajneya)
   2: %history -g -f analysis3(Ajneya)
   3: %history -g -f analysis3(Ajneya)
   4: %history -g -f history
